{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from script.generate_multivariate_samples import generate_multivariate_samples\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from script.curate_training_test_data import curate_training_test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('eua_price_data.csv', thousands=',') \n",
    "df_all['Date'] = pd.to_datetime(df_all['Date'], format='%Y-%m-%d')  \n",
    "df_all = df_all.sort_values(by = 'Date', ascending=True).reset_index(drop = True)\n",
    "df_all = df_all[(df_all['Date'] > pd.to_datetime('2020-11-24')) & (df_all['Date'] < pd.to_datetime('2024-10-07'))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Date=%{x}<br>EUA=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "showlegend": false,
         "type": "scattergl",
         "x": [
          "2020-11-25T00:00:00",
          "2020-11-26T00:00:00",
          "2020-11-27T00:00:00",
          "2020-11-28T00:00:00",
          "2020-11-29T00:00:00",
          "2020-11-30T00:00:00",
          "2020-12-01T00:00:00",
          "2020-12-02T00:00:00",
          "2020-12-03T00:00:00",
          "2020-12-04T00:00:00",
          "2020-12-05T00:00:00",
          "2020-12-06T00:00:00",
          "2020-12-07T00:00:00",
          "2020-12-08T00:00:00",
          "2020-12-09T00:00:00",
          "2020-12-10T00:00:00",
          "2020-12-11T00:00:00",
          "2020-12-12T00:00:00",
          "2020-12-13T00:00:00",
          "2020-12-14T00:00:00",
          "2020-12-15T00:00:00",
          "2020-12-16T00:00:00",
          "2020-12-17T00:00:00",
          "2020-12-18T00:00:00",
          "2020-12-19T00:00:00",
          "2020-12-20T00:00:00",
          "2020-12-21T00:00:00",
          "2020-12-22T00:00:00",
          "2020-12-23T00:00:00",
          "2020-12-24T00:00:00",
          "2020-12-25T00:00:00",
          "2020-12-26T00:00:00",
          "2020-12-27T00:00:00",
          "2020-12-28T00:00:00",
          "2020-12-29T00:00:00",
          "2020-12-30T00:00:00",
          "2020-12-31T00:00:00",
          "2021-01-01T00:00:00",
          "2021-01-02T00:00:00",
          "2021-01-03T00:00:00",
          "2021-01-04T00:00:00",
          "2021-01-05T00:00:00",
          "2021-01-06T00:00:00",
          "2021-01-07T00:00:00",
          "2021-01-08T00:00:00",
          "2021-01-09T00:00:00",
          "2021-01-10T00:00:00",
          "2021-01-11T00:00:00",
          "2021-01-12T00:00:00",
          "2021-01-13T00:00:00",
          "2021-01-14T00:00:00",
          "2021-01-15T00:00:00",
          "2021-01-16T00:00:00",
          "2021-01-17T00:00:00",
          "2021-01-18T00:00:00",
          "2021-01-19T00:00:00",
          "2021-01-20T00:00:00",
          "2021-01-21T00:00:00",
          "2021-01-22T00:00:00",
          "2021-01-23T00:00:00",
          "2021-01-24T00:00:00",
          "2021-01-25T00:00:00",
          "2021-01-26T00:00:00",
          "2021-01-27T00:00:00",
          "2021-01-28T00:00:00",
          "2021-01-29T00:00:00",
          "2021-01-30T00:00:00",
          "2021-01-31T00:00:00",
          "2021-02-01T00:00:00",
          "2021-02-02T00:00:00",
          "2021-02-03T00:00:00",
          "2021-02-04T00:00:00",
          "2021-02-05T00:00:00",
          "2021-02-06T00:00:00",
          "2021-02-07T00:00:00",
          "2021-02-08T00:00:00",
          "2021-02-09T00:00:00",
          "2021-02-10T00:00:00",
          "2021-02-11T00:00:00",
          "2021-02-12T00:00:00",
          "2021-02-13T00:00:00",
          "2021-02-14T00:00:00",
          "2021-02-15T00:00:00",
          "2021-02-16T00:00:00",
          "2021-02-17T00:00:00",
          "2021-02-18T00:00:00",
          "2021-02-19T00:00:00",
          "2021-02-20T00:00:00",
          "2021-02-21T00:00:00",
          "2021-02-22T00:00:00",
          "2021-02-23T00:00:00",
          "2021-02-24T00:00:00",
          "2021-02-25T00:00:00",
          "2021-02-26T00:00:00",
          "2021-02-27T00:00:00",
          "2021-02-28T00:00:00",
          "2021-03-01T00:00:00",
          "2021-03-02T00:00:00",
          "2021-03-03T00:00:00",
          "2021-03-04T00:00:00",
          "2021-03-05T00:00:00",
          "2021-03-06T00:00:00",
          "2021-03-07T00:00:00",
          "2021-03-08T00:00:00",
          "2021-03-09T00:00:00",
          "2021-03-10T00:00:00",
          "2021-03-11T00:00:00",
          "2021-03-12T00:00:00",
          "2021-03-13T00:00:00",
          "2021-03-14T00:00:00",
          "2021-03-15T00:00:00",
          "2021-03-16T00:00:00",
          "2021-03-17T00:00:00",
          "2021-03-18T00:00:00",
          "2021-03-19T00:00:00",
          "2021-03-20T00:00:00",
          "2021-03-21T00:00:00",
          "2021-03-22T00:00:00",
          "2021-03-23T00:00:00",
          "2021-03-24T00:00:00",
          "2021-03-25T00:00:00",
          "2021-03-26T00:00:00",
          "2021-03-27T00:00:00",
          "2021-03-28T00:00:00",
          "2021-03-29T00:00:00",
          "2021-03-30T00:00:00",
          "2021-03-31T00:00:00",
          "2021-04-01T00:00:00",
          "2021-04-02T00:00:00",
          "2021-04-03T00:00:00",
          "2021-04-04T00:00:00",
          "2021-04-05T00:00:00",
          "2021-04-06T00:00:00",
          "2021-04-07T00:00:00",
          "2021-04-08T00:00:00",
          "2021-04-09T00:00:00",
          "2021-04-10T00:00:00",
          "2021-04-11T00:00:00",
          "2021-04-12T00:00:00",
          "2021-04-13T00:00:00",
          "2021-04-14T00:00:00",
          "2021-04-15T00:00:00",
          "2021-04-16T00:00:00",
          "2021-04-17T00:00:00",
          "2021-04-18T00:00:00",
          "2021-04-19T00:00:00",
          "2021-04-20T00:00:00",
          "2021-04-21T00:00:00",
          "2021-04-22T00:00:00",
          "2021-04-23T00:00:00",
          "2021-04-24T00:00:00",
          "2021-04-25T00:00:00",
          "2021-04-26T00:00:00",
          "2021-04-27T00:00:00",
          "2021-04-28T00:00:00",
          "2021-04-29T00:00:00",
          "2021-04-30T00:00:00",
          "2021-05-01T00:00:00",
          "2021-05-02T00:00:00",
          "2021-05-03T00:00:00",
          "2021-05-04T00:00:00",
          "2021-05-05T00:00:00",
          "2021-05-06T00:00:00",
          "2021-05-07T00:00:00",
          "2021-05-08T00:00:00",
          "2021-05-09T00:00:00",
          "2021-05-10T00:00:00",
          "2021-05-11T00:00:00",
          "2021-05-12T00:00:00",
          "2021-05-13T00:00:00",
          "2021-05-14T00:00:00",
          "2021-05-15T00:00:00",
          "2021-05-16T00:00:00",
          "2021-05-17T00:00:00",
          "2021-05-18T00:00:00",
          "2021-05-19T00:00:00",
          "2021-05-20T00:00:00",
          "2021-05-21T00:00:00",
          "2021-05-22T00:00:00",
          "2021-05-23T00:00:00",
          "2021-05-24T00:00:00",
          "2021-05-25T00:00:00",
          "2021-05-26T00:00:00",
          "2021-05-27T00:00:00",
          "2021-05-28T00:00:00",
          "2021-05-29T00:00:00",
          "2021-05-30T00:00:00",
          "2021-05-31T00:00:00",
          "2021-06-01T00:00:00",
          "2021-06-02T00:00:00",
          "2021-06-03T00:00:00",
          "2021-06-04T00:00:00",
          "2021-06-05T00:00:00",
          "2021-06-06T00:00:00",
          "2021-06-07T00:00:00",
          "2021-06-08T00:00:00",
          "2021-06-09T00:00:00",
          "2021-06-10T00:00:00",
          "2021-06-11T00:00:00",
          "2021-06-12T00:00:00",
          "2021-06-13T00:00:00",
          "2021-06-14T00:00:00",
          "2021-06-15T00:00:00",
          "2021-06-16T00:00:00",
          "2021-06-17T00:00:00",
          "2021-06-18T00:00:00",
          "2021-06-19T00:00:00",
          "2021-06-20T00:00:00",
          "2021-06-21T00:00:00",
          "2021-06-22T00:00:00",
          "2021-06-23T00:00:00",
          "2021-06-24T00:00:00",
          "2021-06-25T00:00:00",
          "2021-06-26T00:00:00",
          "2021-06-27T00:00:00",
          "2021-06-28T00:00:00",
          "2021-06-29T00:00:00",
          "2021-06-30T00:00:00",
          "2021-07-01T00:00:00",
          "2021-07-02T00:00:00",
          "2021-07-03T00:00:00",
          "2021-07-04T00:00:00",
          "2021-07-05T00:00:00",
          "2021-07-06T00:00:00",
          "2021-07-07T00:00:00",
          "2021-07-08T00:00:00",
          "2021-07-09T00:00:00",
          "2021-07-10T00:00:00",
          "2021-07-11T00:00:00",
          "2021-07-12T00:00:00",
          "2021-07-13T00:00:00",
          "2021-07-14T00:00:00",
          "2021-07-15T00:00:00",
          "2021-07-16T00:00:00",
          "2021-07-17T00:00:00",
          "2021-07-18T00:00:00",
          "2021-07-19T00:00:00",
          "2021-07-20T00:00:00",
          "2021-07-21T00:00:00",
          "2021-07-22T00:00:00",
          "2021-07-23T00:00:00",
          "2021-07-24T00:00:00",
          "2021-07-25T00:00:00",
          "2021-07-26T00:00:00",
          "2021-07-27T00:00:00",
          "2021-07-28T00:00:00",
          "2021-07-29T00:00:00",
          "2021-07-30T00:00:00",
          "2021-07-31T00:00:00",
          "2021-08-01T00:00:00",
          "2021-08-02T00:00:00",
          "2021-08-03T00:00:00",
          "2021-08-04T00:00:00",
          "2021-08-05T00:00:00",
          "2021-08-06T00:00:00",
          "2021-08-07T00:00:00",
          "2021-08-08T00:00:00",
          "2021-08-09T00:00:00",
          "2021-08-10T00:00:00",
          "2021-08-11T00:00:00",
          "2021-08-12T00:00:00",
          "2021-08-13T00:00:00",
          "2021-08-14T00:00:00",
          "2021-08-15T00:00:00",
          "2021-08-16T00:00:00",
          "2021-08-17T00:00:00",
          "2021-08-18T00:00:00",
          "2021-08-19T00:00:00",
          "2021-08-20T00:00:00",
          "2021-08-21T00:00:00",
          "2021-08-22T00:00:00",
          "2021-08-23T00:00:00",
          "2021-08-24T00:00:00",
          "2021-08-25T00:00:00",
          "2021-08-26T00:00:00",
          "2021-08-27T00:00:00",
          "2021-08-28T00:00:00",
          "2021-08-29T00:00:00",
          "2021-08-30T00:00:00",
          "2021-08-31T00:00:00",
          "2021-09-01T00:00:00",
          "2021-09-02T00:00:00",
          "2021-09-03T00:00:00",
          "2021-09-04T00:00:00",
          "2021-09-05T00:00:00",
          "2021-09-06T00:00:00",
          "2021-09-07T00:00:00",
          "2021-09-08T00:00:00",
          "2021-09-09T00:00:00",
          "2021-09-10T00:00:00",
          "2021-09-11T00:00:00",
          "2021-09-12T00:00:00",
          "2021-09-13T00:00:00",
          "2021-09-14T00:00:00",
          "2021-09-15T00:00:00",
          "2021-09-16T00:00:00",
          "2021-09-17T00:00:00",
          "2021-09-18T00:00:00",
          "2021-09-19T00:00:00",
          "2021-09-20T00:00:00",
          "2021-09-21T00:00:00",
          "2021-09-22T00:00:00",
          "2021-09-23T00:00:00",
          "2021-09-24T00:00:00",
          "2021-09-25T00:00:00",
          "2021-09-26T00:00:00",
          "2021-09-27T00:00:00",
          "2021-09-28T00:00:00",
          "2021-09-29T00:00:00",
          "2021-09-30T00:00:00",
          "2021-10-01T00:00:00",
          "2021-10-02T00:00:00",
          "2021-10-03T00:00:00",
          "2021-10-04T00:00:00",
          "2021-10-05T00:00:00",
          "2021-10-06T00:00:00",
          "2021-10-07T00:00:00",
          "2021-10-08T00:00:00",
          "2021-10-09T00:00:00",
          "2021-10-10T00:00:00",
          "2021-10-11T00:00:00",
          "2021-10-12T00:00:00",
          "2021-10-13T00:00:00",
          "2021-10-14T00:00:00",
          "2021-10-15T00:00:00",
          "2021-10-16T00:00:00",
          "2021-10-17T00:00:00",
          "2021-10-18T00:00:00",
          "2021-10-19T00:00:00",
          "2021-10-20T00:00:00",
          "2021-10-21T00:00:00",
          "2021-10-22T00:00:00",
          "2021-10-23T00:00:00",
          "2021-10-24T00:00:00",
          "2021-10-25T00:00:00",
          "2021-10-26T00:00:00",
          "2021-10-27T00:00:00",
          "2021-10-28T00:00:00",
          "2021-10-29T00:00:00",
          "2021-10-30T00:00:00",
          "2021-10-31T00:00:00",
          "2021-11-01T00:00:00",
          "2021-11-02T00:00:00",
          "2021-11-03T00:00:00",
          "2021-11-04T00:00:00",
          "2021-11-05T00:00:00",
          "2021-11-06T00:00:00",
          "2021-11-07T00:00:00",
          "2021-11-08T00:00:00",
          "2021-11-09T00:00:00",
          "2021-11-10T00:00:00",
          "2021-11-11T00:00:00",
          "2021-11-12T00:00:00",
          "2021-11-13T00:00:00",
          "2021-11-14T00:00:00",
          "2021-11-15T00:00:00",
          "2021-11-16T00:00:00",
          "2021-11-17T00:00:00",
          "2021-11-18T00:00:00",
          "2021-11-19T00:00:00",
          "2021-11-20T00:00:00",
          "2021-11-21T00:00:00",
          "2021-11-22T00:00:00",
          "2021-11-23T00:00:00",
          "2021-11-24T00:00:00",
          "2021-11-25T00:00:00",
          "2021-11-26T00:00:00",
          "2021-11-27T00:00:00",
          "2021-11-28T00:00:00",
          "2021-11-29T00:00:00",
          "2021-11-30T00:00:00",
          "2021-12-01T00:00:00",
          "2021-12-02T00:00:00",
          "2021-12-03T00:00:00",
          "2021-12-04T00:00:00",
          "2021-12-05T00:00:00",
          "2021-12-06T00:00:00",
          "2021-12-07T00:00:00",
          "2021-12-08T00:00:00",
          "2021-12-09T00:00:00",
          "2021-12-10T00:00:00",
          "2021-12-11T00:00:00",
          "2021-12-12T00:00:00",
          "2021-12-13T00:00:00",
          "2021-12-14T00:00:00",
          "2021-12-15T00:00:00",
          "2021-12-16T00:00:00",
          "2021-12-17T00:00:00",
          "2021-12-18T00:00:00",
          "2021-12-19T00:00:00",
          "2021-12-20T00:00:00",
          "2021-12-21T00:00:00",
          "2021-12-22T00:00:00",
          "2021-12-23T00:00:00",
          "2021-12-24T00:00:00",
          "2021-12-25T00:00:00",
          "2021-12-26T00:00:00",
          "2021-12-27T00:00:00",
          "2021-12-28T00:00:00",
          "2021-12-29T00:00:00",
          "2021-12-30T00:00:00",
          "2021-12-31T00:00:00",
          "2022-01-01T00:00:00",
          "2022-01-02T00:00:00",
          "2022-01-03T00:00:00",
          "2022-01-04T00:00:00",
          "2022-01-05T00:00:00",
          "2022-01-06T00:00:00",
          "2022-01-07T00:00:00",
          "2022-01-08T00:00:00",
          "2022-01-09T00:00:00",
          "2022-01-10T00:00:00",
          "2022-01-11T00:00:00",
          "2022-01-12T00:00:00",
          "2022-01-13T00:00:00",
          "2022-01-14T00:00:00",
          "2022-01-15T00:00:00",
          "2022-01-16T00:00:00",
          "2022-01-17T00:00:00",
          "2022-01-18T00:00:00",
          "2022-01-19T00:00:00",
          "2022-01-20T00:00:00",
          "2022-01-21T00:00:00",
          "2022-01-22T00:00:00",
          "2022-01-23T00:00:00",
          "2022-01-24T00:00:00",
          "2022-01-25T00:00:00",
          "2022-01-26T00:00:00",
          "2022-01-27T00:00:00",
          "2022-01-28T00:00:00",
          "2022-01-29T00:00:00",
          "2022-01-30T00:00:00",
          "2022-01-31T00:00:00",
          "2022-02-01T00:00:00",
          "2022-02-02T00:00:00",
          "2022-02-03T00:00:00",
          "2022-02-04T00:00:00",
          "2022-02-05T00:00:00",
          "2022-02-06T00:00:00",
          "2022-02-07T00:00:00",
          "2022-02-08T00:00:00",
          "2022-02-09T00:00:00",
          "2022-02-10T00:00:00",
          "2022-02-11T00:00:00",
          "2022-02-12T00:00:00",
          "2022-02-13T00:00:00",
          "2022-02-14T00:00:00",
          "2022-02-15T00:00:00",
          "2022-02-16T00:00:00",
          "2022-02-17T00:00:00",
          "2022-02-18T00:00:00",
          "2022-02-19T00:00:00",
          "2022-02-20T00:00:00",
          "2022-02-21T00:00:00",
          "2022-02-22T00:00:00",
          "2022-02-23T00:00:00",
          "2022-02-24T00:00:00",
          "2022-02-25T00:00:00",
          "2022-02-26T00:00:00",
          "2022-02-27T00:00:00",
          "2022-02-28T00:00:00",
          "2022-03-01T00:00:00",
          "2022-03-02T00:00:00",
          "2022-03-03T00:00:00",
          "2022-03-04T00:00:00",
          "2022-03-05T00:00:00",
          "2022-03-06T00:00:00",
          "2022-03-07T00:00:00",
          "2022-03-08T00:00:00",
          "2022-03-09T00:00:00",
          "2022-03-10T00:00:00",
          "2022-03-11T00:00:00",
          "2022-03-12T00:00:00",
          "2022-03-13T00:00:00",
          "2022-03-14T00:00:00",
          "2022-03-15T00:00:00",
          "2022-03-16T00:00:00",
          "2022-03-17T00:00:00",
          "2022-03-18T00:00:00",
          "2022-03-19T00:00:00",
          "2022-03-20T00:00:00",
          "2022-03-21T00:00:00",
          "2022-03-22T00:00:00",
          "2022-03-23T00:00:00",
          "2022-03-24T00:00:00",
          "2022-03-25T00:00:00",
          "2022-03-26T00:00:00",
          "2022-03-27T00:00:00",
          "2022-03-28T00:00:00",
          "2022-03-29T00:00:00",
          "2022-03-30T00:00:00",
          "2022-03-31T00:00:00",
          "2022-04-01T00:00:00",
          "2022-04-02T00:00:00",
          "2022-04-03T00:00:00",
          "2022-04-04T00:00:00",
          "2022-04-05T00:00:00",
          "2022-04-06T00:00:00",
          "2022-04-07T00:00:00",
          "2022-04-08T00:00:00",
          "2022-04-09T00:00:00",
          "2022-04-10T00:00:00",
          "2022-04-11T00:00:00",
          "2022-04-12T00:00:00",
          "2022-04-13T00:00:00",
          "2022-04-14T00:00:00",
          "2022-04-15T00:00:00",
          "2022-04-16T00:00:00",
          "2022-04-17T00:00:00",
          "2022-04-18T00:00:00",
          "2022-04-19T00:00:00",
          "2022-04-20T00:00:00",
          "2022-04-21T00:00:00",
          "2022-04-22T00:00:00",
          "2022-04-23T00:00:00",
          "2022-04-24T00:00:00",
          "2022-04-25T00:00:00",
          "2022-04-26T00:00:00",
          "2022-04-27T00:00:00",
          "2022-04-28T00:00:00",
          "2022-04-29T00:00:00",
          "2022-04-30T00:00:00",
          "2022-05-01T00:00:00",
          "2022-05-02T00:00:00",
          "2022-05-03T00:00:00",
          "2022-05-04T00:00:00",
          "2022-05-05T00:00:00",
          "2022-05-06T00:00:00",
          "2022-05-07T00:00:00",
          "2022-05-08T00:00:00",
          "2022-05-09T00:00:00",
          "2022-05-10T00:00:00",
          "2022-05-11T00:00:00",
          "2022-05-12T00:00:00",
          "2022-05-13T00:00:00",
          "2022-05-14T00:00:00",
          "2022-05-15T00:00:00",
          "2022-05-16T00:00:00",
          "2022-05-17T00:00:00",
          "2022-05-18T00:00:00",
          "2022-05-19T00:00:00",
          "2022-05-20T00:00:00",
          "2022-05-21T00:00:00",
          "2022-05-22T00:00:00",
          "2022-05-23T00:00:00",
          "2022-05-24T00:00:00",
          "2022-05-25T00:00:00",
          "2022-05-26T00:00:00",
          "2022-05-27T00:00:00",
          "2022-05-28T00:00:00",
          "2022-05-29T00:00:00",
          "2022-05-30T00:00:00",
          "2022-05-31T00:00:00",
          "2022-06-01T00:00:00",
          "2022-06-02T00:00:00",
          "2022-06-03T00:00:00",
          "2022-06-04T00:00:00",
          "2022-06-05T00:00:00",
          "2022-06-06T00:00:00",
          "2022-06-07T00:00:00",
          "2022-06-08T00:00:00",
          "2022-06-09T00:00:00",
          "2022-06-10T00:00:00",
          "2022-06-11T00:00:00",
          "2022-06-12T00:00:00",
          "2022-06-13T00:00:00",
          "2022-06-14T00:00:00",
          "2022-06-15T00:00:00",
          "2022-06-16T00:00:00",
          "2022-06-17T00:00:00",
          "2022-06-18T00:00:00",
          "2022-06-19T00:00:00",
          "2022-06-20T00:00:00",
          "2022-06-21T00:00:00",
          "2022-06-22T00:00:00",
          "2022-06-23T00:00:00",
          "2022-06-24T00:00:00",
          "2022-06-25T00:00:00",
          "2022-06-26T00:00:00",
          "2022-06-27T00:00:00",
          "2022-06-28T00:00:00",
          "2022-06-29T00:00:00",
          "2022-06-30T00:00:00",
          "2022-07-01T00:00:00",
          "2022-07-02T00:00:00",
          "2022-07-03T00:00:00",
          "2022-07-04T00:00:00",
          "2022-07-05T00:00:00",
          "2022-07-06T00:00:00",
          "2022-07-07T00:00:00",
          "2022-07-08T00:00:00",
          "2022-07-09T00:00:00",
          "2022-07-10T00:00:00",
          "2022-07-11T00:00:00",
          "2022-07-12T00:00:00",
          "2022-07-13T00:00:00",
          "2022-07-14T00:00:00",
          "2022-07-15T00:00:00",
          "2022-07-16T00:00:00",
          "2022-07-17T00:00:00",
          "2022-07-18T00:00:00",
          "2022-07-19T00:00:00",
          "2022-07-20T00:00:00",
          "2022-07-21T00:00:00",
          "2022-07-22T00:00:00",
          "2022-07-23T00:00:00",
          "2022-07-24T00:00:00",
          "2022-07-25T00:00:00",
          "2022-07-26T00:00:00",
          "2022-07-27T00:00:00",
          "2022-07-28T00:00:00",
          "2022-07-29T00:00:00",
          "2022-07-30T00:00:00",
          "2022-07-31T00:00:00",
          "2022-08-01T00:00:00",
          "2022-08-02T00:00:00",
          "2022-08-03T00:00:00",
          "2022-08-04T00:00:00",
          "2022-08-05T00:00:00",
          "2022-08-06T00:00:00",
          "2022-08-07T00:00:00",
          "2022-08-08T00:00:00",
          "2022-08-09T00:00:00",
          "2022-08-10T00:00:00",
          "2022-08-11T00:00:00",
          "2022-08-12T00:00:00",
          "2022-08-13T00:00:00",
          "2022-08-14T00:00:00",
          "2022-08-15T00:00:00",
          "2022-08-16T00:00:00",
          "2022-08-17T00:00:00",
          "2022-08-18T00:00:00",
          "2022-08-19T00:00:00",
          "2022-08-20T00:00:00",
          "2022-08-21T00:00:00",
          "2022-08-22T00:00:00",
          "2022-08-23T00:00:00",
          "2022-08-24T00:00:00",
          "2022-08-25T00:00:00",
          "2022-08-26T00:00:00",
          "2022-08-27T00:00:00",
          "2022-08-28T00:00:00",
          "2022-08-29T00:00:00",
          "2022-08-30T00:00:00",
          "2022-08-31T00:00:00",
          "2022-09-01T00:00:00",
          "2022-09-02T00:00:00",
          "2022-09-03T00:00:00",
          "2022-09-04T00:00:00",
          "2022-09-05T00:00:00",
          "2022-09-06T00:00:00",
          "2022-09-07T00:00:00",
          "2022-09-08T00:00:00",
          "2022-09-09T00:00:00",
          "2022-09-10T00:00:00",
          "2022-09-11T00:00:00",
          "2022-09-12T00:00:00",
          "2022-09-13T00:00:00",
          "2022-09-14T00:00:00",
          "2022-09-15T00:00:00",
          "2022-09-16T00:00:00",
          "2022-09-17T00:00:00",
          "2022-09-18T00:00:00",
          "2022-09-19T00:00:00",
          "2022-09-20T00:00:00",
          "2022-09-21T00:00:00",
          "2022-09-22T00:00:00",
          "2022-09-23T00:00:00",
          "2022-09-24T00:00:00",
          "2022-09-25T00:00:00",
          "2022-09-26T00:00:00",
          "2022-09-27T00:00:00",
          "2022-09-28T00:00:00",
          "2022-09-29T00:00:00",
          "2022-09-30T00:00:00",
          "2022-10-01T00:00:00",
          "2022-10-02T00:00:00",
          "2022-10-03T00:00:00",
          "2022-10-04T00:00:00",
          "2022-10-05T00:00:00",
          "2022-10-06T00:00:00",
          "2022-10-07T00:00:00",
          "2022-10-08T00:00:00",
          "2022-10-09T00:00:00",
          "2022-10-10T00:00:00",
          "2022-10-11T00:00:00",
          "2022-10-12T00:00:00",
          "2022-10-13T00:00:00",
          "2022-10-14T00:00:00",
          "2022-10-15T00:00:00",
          "2022-10-16T00:00:00",
          "2022-10-17T00:00:00",
          "2022-10-18T00:00:00",
          "2022-10-19T00:00:00",
          "2022-10-20T00:00:00",
          "2022-10-21T00:00:00",
          "2022-10-22T00:00:00",
          "2022-10-23T00:00:00",
          "2022-10-24T00:00:00",
          "2022-10-25T00:00:00",
          "2022-10-26T00:00:00",
          "2022-10-27T00:00:00",
          "2022-10-28T00:00:00",
          "2022-10-29T00:00:00",
          "2022-10-30T00:00:00",
          "2022-10-31T00:00:00",
          "2022-11-01T00:00:00",
          "2022-11-02T00:00:00",
          "2022-11-03T00:00:00",
          "2022-11-04T00:00:00",
          "2022-11-05T00:00:00",
          "2022-11-06T00:00:00",
          "2022-11-07T00:00:00",
          "2022-11-08T00:00:00",
          "2022-11-09T00:00:00",
          "2022-11-10T00:00:00",
          "2022-11-11T00:00:00",
          "2022-11-12T00:00:00",
          "2022-11-13T00:00:00",
          "2022-11-14T00:00:00",
          "2022-11-15T00:00:00",
          "2022-11-16T00:00:00",
          "2022-11-17T00:00:00",
          "2022-11-18T00:00:00",
          "2022-11-19T00:00:00",
          "2022-11-20T00:00:00",
          "2022-11-21T00:00:00",
          "2022-11-22T00:00:00",
          "2022-11-23T00:00:00",
          "2022-11-24T00:00:00",
          "2022-11-25T00:00:00",
          "2022-11-26T00:00:00",
          "2022-11-27T00:00:00",
          "2022-11-28T00:00:00",
          "2022-11-29T00:00:00",
          "2022-11-30T00:00:00",
          "2022-12-01T00:00:00",
          "2022-12-02T00:00:00",
          "2022-12-03T00:00:00",
          "2022-12-04T00:00:00",
          "2022-12-05T00:00:00",
          "2022-12-06T00:00:00",
          "2022-12-07T00:00:00",
          "2022-12-08T00:00:00",
          "2022-12-09T00:00:00",
          "2022-12-10T00:00:00",
          "2022-12-11T00:00:00",
          "2022-12-12T00:00:00",
          "2022-12-13T00:00:00",
          "2022-12-14T00:00:00",
          "2022-12-15T00:00:00",
          "2022-12-16T00:00:00",
          "2022-12-17T00:00:00",
          "2022-12-18T00:00:00",
          "2022-12-19T00:00:00",
          "2022-12-20T00:00:00",
          "2022-12-21T00:00:00",
          "2022-12-22T00:00:00",
          "2022-12-23T00:00:00",
          "2022-12-24T00:00:00",
          "2022-12-25T00:00:00",
          "2022-12-26T00:00:00",
          "2022-12-27T00:00:00",
          "2022-12-28T00:00:00",
          "2022-12-29T00:00:00",
          "2022-12-30T00:00:00",
          "2022-12-31T00:00:00",
          "2023-01-01T00:00:00",
          "2023-01-02T00:00:00",
          "2023-01-03T00:00:00",
          "2023-01-04T00:00:00",
          "2023-01-05T00:00:00",
          "2023-01-06T00:00:00",
          "2023-01-07T00:00:00",
          "2023-01-08T00:00:00",
          "2023-01-09T00:00:00",
          "2023-01-10T00:00:00",
          "2023-01-11T00:00:00",
          "2023-01-12T00:00:00",
          "2023-01-13T00:00:00",
          "2023-01-14T00:00:00",
          "2023-01-15T00:00:00",
          "2023-01-16T00:00:00",
          "2023-01-17T00:00:00",
          "2023-01-18T00:00:00",
          "2023-01-19T00:00:00",
          "2023-01-20T00:00:00",
          "2023-01-21T00:00:00",
          "2023-01-22T00:00:00",
          "2023-01-23T00:00:00",
          "2023-01-24T00:00:00",
          "2023-01-25T00:00:00",
          "2023-01-26T00:00:00",
          "2023-01-27T00:00:00",
          "2023-01-28T00:00:00",
          "2023-01-29T00:00:00",
          "2023-01-30T00:00:00",
          "2023-01-31T00:00:00",
          "2023-02-01T00:00:00",
          "2023-02-02T00:00:00",
          "2023-02-03T00:00:00",
          "2023-02-04T00:00:00",
          "2023-02-05T00:00:00",
          "2023-02-06T00:00:00",
          "2023-02-07T00:00:00",
          "2023-02-08T00:00:00",
          "2023-02-09T00:00:00",
          "2023-02-10T00:00:00",
          "2023-02-11T00:00:00",
          "2023-02-12T00:00:00",
          "2023-02-13T00:00:00",
          "2023-02-14T00:00:00",
          "2023-02-15T00:00:00",
          "2023-02-16T00:00:00",
          "2023-02-17T00:00:00",
          "2023-02-18T00:00:00",
          "2023-02-19T00:00:00",
          "2023-02-20T00:00:00",
          "2023-02-21T00:00:00",
          "2023-02-22T00:00:00",
          "2023-02-23T00:00:00",
          "2023-02-24T00:00:00",
          "2023-02-25T00:00:00",
          "2023-02-26T00:00:00",
          "2023-02-27T00:00:00",
          "2023-02-28T00:00:00",
          "2023-03-01T00:00:00",
          "2023-03-02T00:00:00",
          "2023-03-03T00:00:00",
          "2023-03-04T00:00:00",
          "2023-03-05T00:00:00",
          "2023-03-06T00:00:00",
          "2023-03-07T00:00:00",
          "2023-03-08T00:00:00",
          "2023-03-09T00:00:00",
          "2023-03-10T00:00:00",
          "2023-03-11T00:00:00",
          "2023-03-12T00:00:00",
          "2023-03-13T00:00:00",
          "2023-03-14T00:00:00",
          "2023-03-15T00:00:00",
          "2023-03-16T00:00:00",
          "2023-03-17T00:00:00",
          "2023-03-18T00:00:00",
          "2023-03-19T00:00:00",
          "2023-03-20T00:00:00",
          "2023-03-21T00:00:00",
          "2023-03-22T00:00:00",
          "2023-03-23T00:00:00",
          "2023-03-24T00:00:00",
          "2023-03-25T00:00:00",
          "2023-03-26T00:00:00",
          "2023-03-27T00:00:00",
          "2023-03-28T00:00:00",
          "2023-03-29T00:00:00",
          "2023-03-30T00:00:00",
          "2023-03-31T00:00:00",
          "2023-04-01T00:00:00",
          "2023-04-02T00:00:00",
          "2023-04-03T00:00:00",
          "2023-04-04T00:00:00",
          "2023-04-05T00:00:00",
          "2023-04-06T00:00:00",
          "2023-04-07T00:00:00",
          "2023-04-08T00:00:00",
          "2023-04-09T00:00:00",
          "2023-04-10T00:00:00",
          "2023-04-11T00:00:00",
          "2023-04-12T00:00:00",
          "2023-04-13T00:00:00",
          "2023-04-14T00:00:00",
          "2023-04-15T00:00:00",
          "2023-04-16T00:00:00",
          "2023-04-17T00:00:00",
          "2023-04-18T00:00:00",
          "2023-04-19T00:00:00",
          "2023-04-20T00:00:00",
          "2023-04-21T00:00:00",
          "2023-04-22T00:00:00",
          "2023-04-23T00:00:00",
          "2023-04-24T00:00:00",
          "2023-04-25T00:00:00",
          "2023-04-26T00:00:00",
          "2023-04-27T00:00:00",
          "2023-04-28T00:00:00",
          "2023-04-29T00:00:00",
          "2023-04-30T00:00:00",
          "2023-05-01T00:00:00",
          "2023-05-02T00:00:00",
          "2023-05-03T00:00:00",
          "2023-05-04T00:00:00",
          "2023-05-05T00:00:00",
          "2023-05-06T00:00:00",
          "2023-05-07T00:00:00",
          "2023-05-08T00:00:00",
          "2023-05-09T00:00:00",
          "2023-05-10T00:00:00",
          "2023-05-11T00:00:00",
          "2023-05-12T00:00:00",
          "2023-05-13T00:00:00",
          "2023-05-14T00:00:00",
          "2023-05-15T00:00:00",
          "2023-05-16T00:00:00",
          "2023-05-17T00:00:00",
          "2023-05-18T00:00:00",
          "2023-05-19T00:00:00",
          "2023-05-20T00:00:00",
          "2023-05-21T00:00:00",
          "2023-05-22T00:00:00",
          "2023-05-23T00:00:00",
          "2023-05-24T00:00:00",
          "2023-05-25T00:00:00",
          "2023-05-26T00:00:00",
          "2023-05-27T00:00:00",
          "2023-05-28T00:00:00",
          "2023-05-29T00:00:00",
          "2023-05-30T00:00:00",
          "2023-05-31T00:00:00",
          "2023-06-01T00:00:00",
          "2023-06-02T00:00:00",
          "2023-06-03T00:00:00",
          "2023-06-04T00:00:00",
          "2023-06-05T00:00:00",
          "2023-06-06T00:00:00",
          "2023-06-07T00:00:00",
          "2023-06-08T00:00:00",
          "2023-06-09T00:00:00",
          "2023-06-10T00:00:00",
          "2023-06-11T00:00:00",
          "2023-06-12T00:00:00",
          "2023-06-13T00:00:00",
          "2023-06-14T00:00:00",
          "2023-06-15T00:00:00",
          "2023-06-16T00:00:00",
          "2023-06-17T00:00:00",
          "2023-06-18T00:00:00",
          "2023-06-19T00:00:00",
          "2023-06-20T00:00:00",
          "2023-06-21T00:00:00",
          "2023-06-22T00:00:00",
          "2023-06-23T00:00:00",
          "2023-06-24T00:00:00",
          "2023-06-25T00:00:00",
          "2023-06-26T00:00:00",
          "2023-06-27T00:00:00",
          "2023-06-28T00:00:00",
          "2023-06-29T00:00:00",
          "2023-06-30T00:00:00",
          "2023-07-01T00:00:00",
          "2023-07-02T00:00:00",
          "2023-07-03T00:00:00",
          "2023-07-04T00:00:00",
          "2023-07-05T00:00:00",
          "2023-07-06T00:00:00",
          "2023-07-07T00:00:00",
          "2023-07-08T00:00:00",
          "2023-07-09T00:00:00",
          "2023-07-10T00:00:00",
          "2023-07-11T00:00:00",
          "2023-07-12T00:00:00",
          "2023-07-13T00:00:00",
          "2023-07-14T00:00:00",
          "2023-07-15T00:00:00",
          "2023-07-16T00:00:00",
          "2023-07-17T00:00:00",
          "2023-07-18T00:00:00",
          "2023-07-19T00:00:00",
          "2023-07-20T00:00:00",
          "2023-07-21T00:00:00",
          "2023-07-22T00:00:00",
          "2023-07-23T00:00:00",
          "2023-07-24T00:00:00",
          "2023-07-25T00:00:00",
          "2023-07-26T00:00:00",
          "2023-07-27T00:00:00",
          "2023-07-28T00:00:00",
          "2023-07-29T00:00:00",
          "2023-07-30T00:00:00",
          "2023-07-31T00:00:00",
          "2023-08-01T00:00:00",
          "2023-08-02T00:00:00",
          "2023-08-03T00:00:00",
          "2023-08-04T00:00:00",
          "2023-08-05T00:00:00",
          "2023-08-06T00:00:00",
          "2023-08-07T00:00:00",
          "2023-08-08T00:00:00",
          "2023-08-09T00:00:00",
          "2023-08-10T00:00:00",
          "2023-08-11T00:00:00",
          "2023-08-12T00:00:00",
          "2023-08-13T00:00:00",
          "2023-08-14T00:00:00",
          "2023-08-15T00:00:00",
          "2023-08-16T00:00:00",
          "2023-08-17T00:00:00",
          "2023-08-18T00:00:00",
          "2023-08-19T00:00:00",
          "2023-08-20T00:00:00",
          "2023-08-21T00:00:00",
          "2023-08-22T00:00:00",
          "2023-08-23T00:00:00",
          "2023-08-24T00:00:00",
          "2023-08-25T00:00:00",
          "2023-08-26T00:00:00",
          "2023-08-27T00:00:00",
          "2023-08-28T00:00:00",
          "2023-08-29T00:00:00",
          "2023-08-30T00:00:00",
          "2023-08-31T00:00:00",
          "2023-09-01T00:00:00",
          "2023-09-02T00:00:00",
          "2023-09-03T00:00:00",
          "2023-09-04T00:00:00",
          "2023-09-05T00:00:00",
          "2023-09-06T00:00:00",
          "2023-09-07T00:00:00",
          "2023-09-08T00:00:00",
          "2023-09-09T00:00:00",
          "2023-09-10T00:00:00",
          "2023-09-11T00:00:00",
          "2023-09-12T00:00:00",
          "2023-09-13T00:00:00",
          "2023-09-14T00:00:00",
          "2023-09-15T00:00:00",
          "2023-09-16T00:00:00",
          "2023-09-17T00:00:00",
          "2023-09-18T00:00:00",
          "2023-09-19T00:00:00",
          "2023-09-20T00:00:00",
          "2023-09-21T00:00:00",
          "2023-09-22T00:00:00",
          "2023-09-23T00:00:00",
          "2023-09-24T00:00:00",
          "2023-09-25T00:00:00",
          "2023-09-26T00:00:00",
          "2023-09-27T00:00:00",
          "2023-09-28T00:00:00",
          "2023-09-29T00:00:00",
          "2023-09-30T00:00:00",
          "2023-10-01T00:00:00",
          "2023-10-02T00:00:00",
          "2023-10-03T00:00:00",
          "2023-10-04T00:00:00",
          "2023-10-05T00:00:00",
          "2023-10-06T00:00:00",
          "2023-10-07T00:00:00",
          "2023-10-08T00:00:00",
          "2023-10-09T00:00:00",
          "2023-10-10T00:00:00",
          "2023-10-11T00:00:00",
          "2023-10-12T00:00:00",
          "2023-10-13T00:00:00",
          "2023-10-14T00:00:00",
          "2023-10-15T00:00:00",
          "2023-10-16T00:00:00",
          "2023-10-17T00:00:00",
          "2023-10-18T00:00:00",
          "2023-10-19T00:00:00",
          "2023-10-20T00:00:00",
          "2023-10-21T00:00:00",
          "2023-10-22T00:00:00",
          "2023-10-23T00:00:00",
          "2023-10-24T00:00:00",
          "2023-10-25T00:00:00",
          "2023-10-26T00:00:00",
          "2023-10-27T00:00:00",
          "2023-10-28T00:00:00",
          "2023-10-29T00:00:00",
          "2023-10-30T00:00:00",
          "2023-10-31T00:00:00",
          "2023-11-01T00:00:00",
          "2023-11-02T00:00:00",
          "2023-11-03T00:00:00",
          "2023-11-04T00:00:00",
          "2023-11-05T00:00:00",
          "2023-11-06T00:00:00",
          "2023-11-07T00:00:00",
          "2023-11-08T00:00:00",
          "2023-11-09T00:00:00",
          "2023-11-10T00:00:00",
          "2023-11-11T00:00:00",
          "2023-11-12T00:00:00",
          "2023-11-13T00:00:00",
          "2023-11-14T00:00:00",
          "2023-11-15T00:00:00",
          "2023-11-16T00:00:00",
          "2023-11-17T00:00:00",
          "2023-11-18T00:00:00",
          "2023-11-19T00:00:00",
          "2023-11-20T00:00:00",
          "2023-11-21T00:00:00",
          "2023-11-22T00:00:00",
          "2023-11-23T00:00:00",
          "2023-11-24T00:00:00",
          "2023-11-25T00:00:00",
          "2023-11-26T00:00:00",
          "2023-11-27T00:00:00",
          "2023-11-28T00:00:00",
          "2023-11-29T00:00:00",
          "2023-11-30T00:00:00",
          "2023-12-01T00:00:00",
          "2023-12-02T00:00:00",
          "2023-12-03T00:00:00",
          "2023-12-04T00:00:00",
          "2023-12-05T00:00:00",
          "2023-12-06T00:00:00",
          "2023-12-07T00:00:00",
          "2023-12-08T00:00:00",
          "2023-12-09T00:00:00",
          "2023-12-10T00:00:00",
          "2023-12-11T00:00:00",
          "2023-12-12T00:00:00",
          "2023-12-13T00:00:00",
          "2023-12-14T00:00:00",
          "2023-12-15T00:00:00",
          "2023-12-16T00:00:00",
          "2023-12-17T00:00:00",
          "2023-12-18T00:00:00",
          "2023-12-19T00:00:00",
          "2023-12-20T00:00:00",
          "2023-12-21T00:00:00",
          "2023-12-22T00:00:00",
          "2023-12-23T00:00:00",
          "2023-12-24T00:00:00",
          "2023-12-25T00:00:00",
          "2023-12-26T00:00:00",
          "2023-12-27T00:00:00",
          "2023-12-28T00:00:00",
          "2023-12-29T00:00:00",
          "2023-12-30T00:00:00",
          "2023-12-31T00:00:00",
          "2024-01-01T00:00:00",
          "2024-01-02T00:00:00",
          "2024-01-03T00:00:00",
          "2024-01-04T00:00:00",
          "2024-01-05T00:00:00",
          "2024-01-06T00:00:00",
          "2024-01-07T00:00:00",
          "2024-01-08T00:00:00",
          "2024-01-09T00:00:00",
          "2024-01-10T00:00:00",
          "2024-01-11T00:00:00",
          "2024-01-12T00:00:00",
          "2024-01-13T00:00:00",
          "2024-01-14T00:00:00",
          "2024-01-15T00:00:00",
          "2024-01-16T00:00:00",
          "2024-01-17T00:00:00",
          "2024-01-18T00:00:00",
          "2024-01-19T00:00:00",
          "2024-01-20T00:00:00",
          "2024-01-21T00:00:00",
          "2024-01-22T00:00:00",
          "2024-01-23T00:00:00",
          "2024-01-24T00:00:00",
          "2024-01-25T00:00:00",
          "2024-01-26T00:00:00",
          "2024-01-27T00:00:00",
          "2024-01-28T00:00:00",
          "2024-01-29T00:00:00",
          "2024-01-30T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-01T00:00:00",
          "2024-02-02T00:00:00",
          "2024-02-03T00:00:00",
          "2024-02-04T00:00:00",
          "2024-02-05T00:00:00",
          "2024-02-06T00:00:00",
          "2024-02-07T00:00:00",
          "2024-02-08T00:00:00",
          "2024-02-09T00:00:00",
          "2024-02-10T00:00:00",
          "2024-02-11T00:00:00",
          "2024-02-12T00:00:00",
          "2024-02-13T00:00:00",
          "2024-02-14T00:00:00",
          "2024-02-15T00:00:00",
          "2024-02-16T00:00:00",
          "2024-02-17T00:00:00",
          "2024-02-18T00:00:00",
          "2024-02-19T00:00:00",
          "2024-02-20T00:00:00",
          "2024-02-21T00:00:00",
          "2024-02-22T00:00:00",
          "2024-02-23T00:00:00",
          "2024-02-24T00:00:00",
          "2024-02-25T00:00:00",
          "2024-02-26T00:00:00",
          "2024-02-27T00:00:00",
          "2024-02-28T00:00:00",
          "2024-02-29T00:00:00",
          "2024-03-01T00:00:00",
          "2024-03-02T00:00:00",
          "2024-03-03T00:00:00",
          "2024-03-04T00:00:00",
          "2024-03-05T00:00:00",
          "2024-03-06T00:00:00",
          "2024-03-07T00:00:00",
          "2024-03-08T00:00:00",
          "2024-03-09T00:00:00",
          "2024-03-10T00:00:00",
          "2024-03-11T00:00:00",
          "2024-03-12T00:00:00",
          "2024-03-13T00:00:00",
          "2024-03-14T00:00:00",
          "2024-03-15T00:00:00",
          "2024-03-16T00:00:00",
          "2024-03-17T00:00:00",
          "2024-03-18T00:00:00",
          "2024-03-19T00:00:00",
          "2024-03-20T00:00:00",
          "2024-03-21T00:00:00",
          "2024-03-22T00:00:00",
          "2024-03-23T00:00:00",
          "2024-03-24T00:00:00",
          "2024-03-25T00:00:00",
          "2024-03-26T00:00:00",
          "2024-03-27T00:00:00",
          "2024-03-28T00:00:00",
          "2024-03-29T00:00:00",
          "2024-03-30T00:00:00",
          "2024-03-31T00:00:00",
          "2024-04-01T00:00:00",
          "2024-04-02T00:00:00",
          "2024-04-03T00:00:00",
          "2024-04-04T00:00:00",
          "2024-04-05T00:00:00",
          "2024-04-06T00:00:00",
          "2024-04-07T00:00:00",
          "2024-04-08T00:00:00",
          "2024-04-09T00:00:00",
          "2024-04-10T00:00:00",
          "2024-04-11T00:00:00",
          "2024-04-12T00:00:00",
          "2024-04-13T00:00:00",
          "2024-04-14T00:00:00",
          "2024-04-15T00:00:00",
          "2024-04-16T00:00:00",
          "2024-04-17T00:00:00",
          "2024-04-18T00:00:00",
          "2024-04-19T00:00:00",
          "2024-04-20T00:00:00",
          "2024-04-21T00:00:00",
          "2024-04-22T00:00:00",
          "2024-04-23T00:00:00",
          "2024-04-24T00:00:00",
          "2024-04-25T00:00:00",
          "2024-04-26T00:00:00",
          "2024-04-27T00:00:00",
          "2024-04-28T00:00:00",
          "2024-04-29T00:00:00",
          "2024-04-30T00:00:00",
          "2024-05-01T00:00:00",
          "2024-05-02T00:00:00",
          "2024-05-03T00:00:00",
          "2024-05-04T00:00:00",
          "2024-05-05T00:00:00",
          "2024-05-06T00:00:00",
          "2024-05-07T00:00:00",
          "2024-05-08T00:00:00",
          "2024-05-09T00:00:00",
          "2024-05-10T00:00:00",
          "2024-05-11T00:00:00",
          "2024-05-12T00:00:00",
          "2024-05-13T00:00:00",
          "2024-05-14T00:00:00",
          "2024-05-15T00:00:00",
          "2024-05-16T00:00:00",
          "2024-05-17T00:00:00",
          "2024-05-18T00:00:00",
          "2024-05-19T00:00:00",
          "2024-05-20T00:00:00",
          "2024-05-21T00:00:00",
          "2024-05-22T00:00:00",
          "2024-05-23T00:00:00",
          "2024-05-24T00:00:00",
          "2024-05-25T00:00:00",
          "2024-05-26T00:00:00",
          "2024-05-27T00:00:00",
          "2024-05-28T00:00:00",
          "2024-05-29T00:00:00",
          "2024-05-30T00:00:00",
          "2024-05-31T00:00:00",
          "2024-06-01T00:00:00",
          "2024-06-02T00:00:00",
          "2024-06-03T00:00:00",
          "2024-06-04T00:00:00",
          "2024-06-05T00:00:00",
          "2024-06-06T00:00:00",
          "2024-06-07T00:00:00",
          "2024-06-08T00:00:00",
          "2024-06-09T00:00:00",
          "2024-06-10T00:00:00",
          "2024-06-11T00:00:00",
          "2024-06-12T00:00:00",
          "2024-06-13T00:00:00",
          "2024-06-14T00:00:00",
          "2024-06-15T00:00:00",
          "2024-06-16T00:00:00",
          "2024-06-17T00:00:00",
          "2024-06-18T00:00:00",
          "2024-06-19T00:00:00",
          "2024-06-20T00:00:00",
          "2024-06-21T00:00:00",
          "2024-06-22T00:00:00",
          "2024-06-23T00:00:00",
          "2024-06-24T00:00:00",
          "2024-06-25T00:00:00",
          "2024-06-26T00:00:00",
          "2024-06-27T00:00:00",
          "2024-06-28T00:00:00",
          "2024-06-29T00:00:00",
          "2024-06-30T00:00:00",
          "2024-07-01T00:00:00",
          "2024-07-02T00:00:00",
          "2024-07-03T00:00:00",
          "2024-07-04T00:00:00",
          "2024-07-05T00:00:00",
          "2024-07-06T00:00:00",
          "2024-07-07T00:00:00",
          "2024-07-08T00:00:00",
          "2024-07-09T00:00:00",
          "2024-07-10T00:00:00",
          "2024-07-11T00:00:00",
          "2024-07-12T00:00:00",
          "2024-07-13T00:00:00",
          "2024-07-14T00:00:00",
          "2024-07-15T00:00:00",
          "2024-07-16T00:00:00",
          "2024-07-17T00:00:00",
          "2024-07-18T00:00:00",
          "2024-07-19T00:00:00",
          "2024-07-20T00:00:00",
          "2024-07-21T00:00:00",
          "2024-07-22T00:00:00",
          "2024-07-23T00:00:00",
          "2024-07-24T00:00:00",
          "2024-07-25T00:00:00",
          "2024-07-26T00:00:00",
          "2024-07-27T00:00:00",
          "2024-07-28T00:00:00",
          "2024-07-29T00:00:00",
          "2024-07-30T00:00:00",
          "2024-07-31T00:00:00",
          "2024-08-01T00:00:00",
          "2024-08-02T00:00:00",
          "2024-08-03T00:00:00",
          "2024-08-04T00:00:00",
          "2024-08-05T00:00:00",
          "2024-08-06T00:00:00",
          "2024-08-07T00:00:00",
          "2024-08-08T00:00:00",
          "2024-08-09T00:00:00",
          "2024-08-10T00:00:00",
          "2024-08-11T00:00:00",
          "2024-08-12T00:00:00",
          "2024-08-13T00:00:00",
          "2024-08-14T00:00:00",
          "2024-08-15T00:00:00",
          "2024-08-16T00:00:00",
          "2024-08-17T00:00:00",
          "2024-08-18T00:00:00",
          "2024-08-19T00:00:00",
          "2024-08-20T00:00:00",
          "2024-08-21T00:00:00",
          "2024-08-22T00:00:00",
          "2024-08-23T00:00:00",
          "2024-08-24T00:00:00",
          "2024-08-25T00:00:00",
          "2024-08-26T00:00:00",
          "2024-08-27T00:00:00",
          "2024-08-28T00:00:00",
          "2024-08-29T00:00:00",
          "2024-08-30T00:00:00",
          "2024-08-31T00:00:00",
          "2024-09-01T00:00:00",
          "2024-09-02T00:00:00",
          "2024-09-03T00:00:00",
          "2024-09-04T00:00:00",
          "2024-09-05T00:00:00",
          "2024-09-06T00:00:00",
          "2024-09-07T00:00:00",
          "2024-09-08T00:00:00",
          "2024-09-09T00:00:00",
          "2024-09-10T00:00:00",
          "2024-09-11T00:00:00",
          "2024-09-12T00:00:00",
          "2024-09-13T00:00:00",
          "2024-09-14T00:00:00",
          "2024-09-15T00:00:00",
          "2024-09-16T00:00:00",
          "2024-09-17T00:00:00",
          "2024-09-18T00:00:00",
          "2024-09-19T00:00:00",
          "2024-09-20T00:00:00",
          "2024-09-21T00:00:00",
          "2024-09-22T00:00:00",
          "2024-09-23T00:00:00",
          "2024-09-24T00:00:00",
          "2024-09-25T00:00:00",
          "2024-09-26T00:00:00",
          "2024-09-27T00:00:00",
          "2024-09-28T00:00:00",
          "2024-09-29T00:00:00",
          "2024-09-30T00:00:00",
          "2024-10-01T00:00:00",
          "2024-10-02T00:00:00",
          "2024-10-03T00:00:00",
          "2024-10-04T00:00:00",
          "2024-10-05T00:00:00",
          "2024-10-06T00:00:00"
         ],
         "xaxis": "x",
         "y": [
          28.04,
          28.54,
          28.59,
          28.59,
          28.59,
          29.6,
          29.33,
          30.01,
          29.46,
          30.57,
          30.57,
          30.57,
          30.07,
          30.02,
          30.16,
          31.36,
          30.98,
          30.98,
          30.98,
          31.27,
          32.43,
          32.03,
          32.21,
          31.36,
          31.36,
          31.36,
          31.14,
          31.39,
          32.15,
          32.41,
          32.41,
          32.41,
          32.41,
          33.66,
          33.25,
          32.42,
          32.94,
          32.94,
          32.94,
          32.94,
          33.89,
          33.15,
          33.83,
          34.97,
          35.14,
          35.14,
          35.14,
          34.76,
          34.88,
          33.88,
          33.76,
          31.96,
          31.96,
          31.96,
          31.84,
          33.3,
          33.12,
          34.32,
          34.45,
          34.45,
          34.45,
          33.39,
          33.56,
          33.51,
          34.17,
          33.18,
          33.18,
          33.18,
          33.08,
          35.19,
          37.65,
          37.49,
          38.43,
          38.43,
          38.43,
          38.84,
          38.49,
          39.56,
          39,
          40.28,
          40.28,
          40.28,
          39.81,
          39.13,
          38.4,
          38.61,
          37.7,
          37.7,
          37.7,
          38.26,
          38.97,
          39.45,
          38.57,
          37.6,
          37.6,
          37.6,
          37.45,
          38.69,
          37.82,
          38.51,
          39.36,
          39.36,
          39.36,
          39.47,
          40.98,
          41.87,
          42.27,
          43.19,
          43.19,
          43.19,
          42.73,
          41.96,
          43.34,
          42.74,
          42.31,
          42.31,
          42.31,
          43.18,
          41.78,
          41.96,
          40.71,
          42.09,
          42.09,
          42.09,
          42.2,
          42.4,
          42.89,
          42.81,
          42.81,
          42.81,
          42.81,
          42.81,
          44.6,
          44.23,
          43.85,
          44.03,
          44.03,
          44.03,
          44.86,
          44.24,
          44.2,
          44.55,
          44.8,
          44.8,
          44.8,
          44.74,
          45.29,
          46.32,
          47.51,
          47.38,
          47.38,
          47.38,
          47.67,
          47.78,
          48.28,
          48.51,
          49.31,
          49.31,
          49.31,
          49.9,
          49.06,
          49.91,
          50.41,
          50.93,
          50.93,
          50.93,
          52.72,
          53.55,
          55.85,
          55.04,
          57.23,
          57.23,
          57.23,
          56.97,
          53.74,
          50.35,
          53.41,
          52.43,
          52.43,
          52.43,
          53.41,
          53.83,
          54.22,
          52.39,
          51.58,
          51.58,
          51.58,
          52.24,
          52.97,
          51.94,
          50.73,
          50.47,
          50.47,
          50.47,
          51.97,
          52.58,
          53.9,
          54.15,
          53.07,
          53.07,
          53.07,
          53.29,
          51.76,
          51.72,
          51.28,
          52.26,
          52.26,
          52.26,
          52.78,
          53.76,
          55.03,
          55.49,
          55.48,
          55.48,
          55.48,
          55.9,
          56.04,
          56.78,
          58.06,
          57.76,
          57.76,
          57.76,
          58.28,
          54.44,
          53.03,
          52.77,
          54.67,
          54.67,
          54.67,
          52.12,
          53.26,
          53.78,
          53.37,
          53.28,
          53.28,
          53.28,
          52.81,
          51.59,
          52.51,
          51.16,
          51.26,
          51.26,
          51.26,
          53.57,
          53.28,
          54.2,
          54.41,
          53.69,
          53.69,
          53.69,
          54.79,
          54.55,
          55.82,
          56.34,
          57.02,
          57.02,
          57.02,
          56.98,
          57.77,
          58.14,
          56.63,
          55.74,
          55.74,
          55.74,
          58.52,
          57.56,
          57.45,
          53.84,
          54.72,
          54.72,
          54.72,
          55.67,
          56.97,
          56.87,
          57.19,
          59.32,
          59.32,
          59.32,
          61.08,
          61.07,
          60.42,
          61.83,
          61.63,
          61.63,
          61.63,
          62.61,
          62.28,
          62.74,
          63.04,
          61.22,
          61.22,
          61.22,
          61.37,
          60.16,
          60.18,
          59.63,
          59.82,
          59.82,
          59.82,
          61.02,
          60.5,
          60.94,
          60.89,
          63.29,
          63.29,
          63.29,
          64.72,
          62.29,
          63.28,
          62.16,
          62.45,
          62.45,
          62.45,
          63.82,
          65.16,
          59.58,
          60.81,
          58.76,
          58.76,
          58.76,
          59.58,
          59.34,
          59.45,
          61.79,
          59.79,
          59.79,
          59.79,
          58.92,
          54.92,
          58.14,
          58.37,
          58.64,
          58.64,
          58.64,
          59.35,
          60.16,
          60.27,
          58.94,
          59.08,
          59.08,
          59.08,
          57.29,
          59.79,
          60.15,
          60.18,
          59.73,
          59.73,
          59.73,
          60.96,
          60.75,
          63.48,
          64.02,
          63.58,
          63.58,
          63.58,
          66.22,
          67.83,
          67.45,
          69.38,
          69.65,
          69.65,
          69.65,
          70.22,
          69.49,
          73.23,
          74.79,
          73.12,
          73.12,
          73.12,
          74.54,
          75.73,
          77.2,
          80.25,
          78.64,
          78.64,
          78.64,
          81.65,
          85.34,
          89.41,
          80.88,
          84.37,
          84.37,
          84.37,
          82.72,
          80.12,
          81.19,
          85.71,
          74.02,
          74.02,
          74.02,
          80.09,
          80.94,
          76.83,
          74.46,
          76.31,
          76.31,
          76.31,
          76.92,
          79.29,
          80.36,
          80.16,
          80.65,
          80.65,
          80.65,
          84.01,
          84.91,
          87.58,
          86.74,
          85.42,
          85.42,
          85.42,
          80.09,
          81.3,
          80.01,
          80.56,
          82.08,
          82.08,
          82.08,
          80.58,
          82.67,
          82.09,
          85.59,
          84.47,
          84.47,
          84.47,
          84.02,
          87.45,
          88.66,
          89.76,
          89.22,
          89.22,
          89.22,
          89.24,
          89.52,
          94.21,
          94.81,
          96.45,
          96.45,
          96.45,
          96.7,
          96.93,
          90.79,
          90.78,
          92.87,
          92.87,
          92.87,
          91.76,
          91.14,
          89.86,
          86.44,
          89.47,
          89.47,
          89.47,
          89.68,
          89.77,
          95.07,
          87.03,
          88.14,
          88.14,
          88.14,
          82.21,
          68.85,
          68.49,
          67.35,
          65.1,
          65.1,
          65.1,
          58.3,
          68.51,
          73.18,
          76.41,
          76.76,
          76.76,
          76.76,
          78.28,
          77.43,
          78.16,
          79.89,
          78.89,
          78.89,
          78.89,
          78.39,
          80.67,
          76.6,
          78.24,
          78.6,
          78.6,
          78.6,
          80.81,
          81.7,
          78.31,
          76.48,
          78.49,
          78.49,
          78.49,
          78.5,
          78.05,
          77.18,
          79.94,
          80.09,
          80.09,
          80.09,
          77.95,
          79.01,
          77.44,
          79.97,
          79.97,
          79.97,
          79.97,
          79.97,
          80.2,
          87.82,
          86.44,
          88.99,
          88.99,
          88.99,
          83.46,
          82.71,
          81.01,
          82.68,
          84.45,
          84.45,
          84.45,
          83.04,
          88.19,
          88.31,
          88.91,
          91.54,
          91.54,
          91.54,
          87.02,
          87.34,
          88.83,
          88.26,
          88.48,
          88.48,
          88.48,
          89.56,
          91.72,
          84.64,
          83.18,
          80.39,
          80.39,
          80.39,
          78.15,
          81.32,
          81.4,
          84.76,
          84.2,
          84.2,
          84.2,
          83.97,
          84.02,
          86.08,
          86.34,
          86.87,
          86.87,
          86.87,
          81.43,
          81.31,
          79.81,
          81.01,
          81.86,
          81.86,
          81.86,
          81.54,
          84.15,
          86.2,
          83,
          82.37,
          82.37,
          82.37,
          84,
          84.73,
          81.88,
          84.13,
          83.43,
          83.43,
          83.43,
          85.05,
          87.4,
          88.35,
          90.16,
          85.58,
          85.58,
          85.58,
          84.55,
          83.19,
          83.22,
          84.92,
          82.79,
          82.79,
          82.79,
          84.36,
          85.65,
          83.86,
          83.97,
          85.38,
          85.38,
          85.38,
          84.94,
          83.65,
          78.84,
          78.11,
          76.3,
          76.3,
          76.3,
          76.37,
          76.68,
          76.14,
          78.96,
          78.55,
          78.55,
          78.55,
          80.58,
          81.95,
          83.99,
          84.19,
          84.76,
          84.76,
          84.76,
          83.81,
          85.93,
          85.92,
          87.55,
          88.87,
          88.87,
          88.87,
          90.78,
          92.08,
          95.8,
          96.04,
          98.01,
          98.01,
          98.01,
          92.17,
          89.29,
          89.24,
          89.31,
          90.31,
          90.31,
          90.31,
          86.66,
          80.81,
          80.03,
          80.79,
          77.89,
          77.89,
          77.89,
          74.45,
          69.88,
          69.03,
          67.24,
          66.08,
          66.08,
          66.08,
          71.82,
          69.75,
          72.54,
          71.85,
          73.27,
          73.27,
          73.27,
          71.1,
          71.14,
          69.79,
          70.44,
          65.77,
          65.77,
          65.77,
          70.33,
          67.96,
          65.15,
          65.73,
          66.73,
          66.73,
          66.73,
          65.94,
          66.92,
          67.07,
          68.96,
          69.85,
          69.85,
          69.85,
          66.77,
          66.34,
          66.71,
          68.84,
          68.02,
          68.02,
          68.02,
          67.51,
          67.77,
          67.29,
          66.87,
          68.72,
          68.72,
          68.72,
          72.32,
          77.11,
          75.79,
          80.21,
          81.21,
          81.21,
          81.21,
          79.97,
          76.72,
          76.7,
          76.28,
          76.36,
          76.36,
          76.36,
          77.49,
          76.06,
          72.76,
          73.05,
          75.84,
          75.84,
          75.84,
          75.23,
          76.65,
          73.41,
          72.4,
          72.47,
          72.47,
          72.47,
          74.28,
          73.87,
          75.87,
          78.69,
          78.97,
          78.97,
          78.97,
          78.59,
          81.39,
          84.9,
          84.88,
          87.98,
          87.98,
          87.98,
          87.17,
          88.61,
          88.19,
          88.93,
          87.73,
          87.73,
          87.73,
          89.81,
          88.99,
          86.19,
          85.2,
          83.68,
          83.68,
          83.68,
          84.69,
          86.87,
          85.6,
          86.85,
          86.85,
          86.85,
          86.85,
          86.85,
          86.08,
          84.13,
          82.36,
          79.4,
          79.4,
          79.4,
          83.67,
          80.42,
          75.4,
          76.24,
          75.55,
          75.55,
          75.55,
          79.1,
          78.38,
          76.64,
          77.76,
          77.2,
          77.2,
          77.2,
          75.07,
          77.21,
          81.42,
          81.86,
          82.6,
          82.6,
          82.6,
          81.8,
          79.62,
          82.28,
          86.81,
          86.94,
          86.94,
          86.94,
          87.21,
          90.13,
          92.65,
          90.65,
          90.9,
          90.9,
          90.9,
          87.96,
          87.9,
          87.59,
          88.49,
          90.44,
          90.44,
          90.44,
          89.35,
          88.62,
          91.51,
          95.13,
          93.33,
          93.33,
          93.33,
          95.11,
          97.12,
          93.45,
          93.84,
          94.79,
          94.79,
          94.79,
          96.9,
          95.88,
          93.8,
          90.1,
          89.27,
          89.27,
          89.27,
          89.96,
          92.87,
          94.76,
          95.4,
          96.83,
          96.83,
          96.83,
          92.99,
          89.73,
          86.65,
          85.27,
          85.57,
          85.57,
          85.57,
          85.18,
          87.38,
          86.63,
          90.18,
          85.4,
          85.4,
          85.4,
          88.13,
          89.4,
          90.02,
          90.8,
          91.75,
          91.75,
          91.75,
          96,
          94.98,
          97.01,
          97.01,
          97.01,
          97.01,
          97.01,
          97.01,
          97.47,
          96.27,
          94.39,
          94.11,
          94.11,
          94.11,
          92.91,
          95.15,
          94.39,
          91.74,
          89.86,
          89.86,
          89.86,
          88.56,
          86.81,
          86.24,
          86.68,
          87.65,
          87.65,
          87.65,
          85.63,
          88.52,
          85.15,
          84.5,
          84.96,
          84.96,
          84.96,
          85.59,
          87.51,
          89.06,
          88.57,
          88.93,
          88.93,
          88.93,
          87.14,
          88.93,
          88.04,
          89.65,
          89.43,
          89.43,
          89.43,
          87.25,
          85.8,
          84.79,
          82.63,
          83.13,
          83.13,
          83.13,
          83,
          80.38,
          80.77,
          78.95,
          78.52,
          78.52,
          78.52,
          82.86,
          81.64,
          83.86,
          83.35,
          86.14,
          86.14,
          86.14,
          88.22,
          90.72,
          93.62,
          92.93,
          91.92,
          91.92,
          91.92,
          93.23,
          94.51,
          90.85,
          90.95,
          87.55,
          87.55,
          87.55,
          86.49,
          89.09,
          88.21,
          88.13,
          89.57,
          89.57,
          89.57,
          87.58,
          87.69,
          85.81,
          86.29,
          86.15,
          86.15,
          86.15,
          86.26,
          87.05,
          85.83,
          85.88,
          86.35,
          86.35,
          86.35,
          86.78,
          88.18,
          88.98,
          90.84,
          91.82,
          91.82,
          91.82,
          91.29,
          92.34,
          90.77,
          90.92,
          88.7,
          88.7,
          88.7,
          86.81,
          84.62,
          83.2,
          84.41,
          83.41,
          83.41,
          83.41,
          82.64,
          83.97,
          83.9,
          84.55,
          86.8,
          86.8,
          86.8,
          87.95,
          86.87,
          88.58,
          88.85,
          88.05,
          88.05,
          88.05,
          87.85,
          90.01,
          88,
          85.21,
          85.25,
          85.25,
          85.25,
          85.6,
          85,
          86,
          86.03,
          85.64,
          85.64,
          85.64,
          84.08,
          83.91,
          83.7,
          83.29,
          81.62,
          81.62,
          81.62,
          81.73,
          81.12,
          83.76,
          82.93,
          82.1,
          82.1,
          82.1,
          80.88,
          81.3,
          82.76,
          84.43,
          85.3,
          85.3,
          85.3,
          84.89,
          82.51,
          81.86,
          83.11,
          81.45,
          81.45,
          81.45,
          80.7,
          79.8,
          81.82,
          80.86,
          80.62,
          80.62,
          80.62,
          81.63,
          84.74,
          83.78,
          85.45,
          85.66,
          85.66,
          85.66,
          83.41,
          82.65,
          81.79,
          82,
          81.67,
          81.67,
          81.67,
          80.3,
          80.66,
          79.93,
          79.58,
          79.36,
          79.36,
          79.36,
          78.78,
          79.41,
          78.66,
          79.06,
          77.2,
          77.2,
          77.2,
          75.88,
          75.36,
          75.4,
          77.3,
          78.5,
          78.5,
          78.5,
          77.04,
          78.57,
          79.8,
          77.2,
          76.23,
          76.23,
          76.23,
          76.66,
          75.21,
          75.1,
          76.57,
          76.46,
          76.46,
          76.46,
          73.07,
          72.5,
          70.78,
          70.56,
          72.45,
          72.45,
          72.45,
          70.43,
          68.91,
          68.96,
          69.97,
          68.62,
          68.62,
          68.62,
          67.34,
          68.24,
          68.88,
          66.73,
          67.57,
          67.57,
          67.57,
          69.61,
          69.76,
          73.2,
          75.88,
          76.94,
          76.94,
          76.94,
          76.94,
          76.94,
          77.74,
          77.94,
          77.94,
          77.94,
          77.94,
          77.94,
          74.09,
          75.42,
          73.78,
          73.97,
          73.97,
          73.97,
          69.96,
          69.9,
          67.72,
          65.96,
          63.8,
          63.8,
          63.8,
          66.9,
          65.49,
          63.31,
          63.28,
          63.42,
          63.42,
          63.42,
          62.41,
          63.27,
          65.8,
          63.41,
          63.1,
          63.1,
          63.1,
          61.77,
          64.02,
          64.4,
          62.32,
          63.5,
          63.5,
          63.5,
          62.59,
          63.49,
          62.32,
          60.71,
          58.8,
          58.8,
          58.8,
          57.2,
          56.65,
          56.44,
          57.95,
          57.11,
          57.11,
          57.11,
          53.14,
          54.21,
          54.51,
          52.59,
          52.51,
          52.51,
          52.51,
          53.83,
          55.96,
          57.21,
          56.44,
          56.31,
          56.31,
          56.31,
          57.28,
          60,
          58.79,
          59.44,
          58.5,
          58.5,
          58.5,
          56.13,
          57,
          55.87,
          58.8,
          59.38,
          59.38,
          59.38,
          61.42,
          61.31,
          60.01,
          59.37,
          61.5,
          61.5,
          61.5,
          64.84,
          63,
          62.61,
          62.61,
          62.61,
          62.61,
          62.61,
          62.61,
          58.9,
          57.55,
          58.39,
          61.01,
          61.01,
          61.01,
          63.39,
          63.96,
          62.85,
          68.83,
          71.64,
          71.64,
          71.64,
          70.16,
          74.25,
          70.33,
          71.55,
          68.52,
          68.52,
          68.52,
          66.4,
          66.38,
          66.85,
          68.41,
          67.51,
          67.51,
          67.51,
          65.8,
          69.2,
          67.91,
          72.69,
          71.84,
          71.84,
          71.84,
          73.67,
          70.85,
          71.92,
          73.62,
          71.59,
          71.59,
          71.59,
          70.07,
          70.1,
          69.19,
          70.79,
          70.52,
          70.52,
          70.52,
          74.24,
          76.2,
          76.67,
          76.1,
          75.78,
          75.78,
          75.78,
          76.51,
          74.6,
          73.95,
          75.2,
          74.07,
          74.07,
          74.07,
          74.63,
          72.58,
          72,
          71.53,
          71.42,
          71.42,
          71.42,
          70.91,
          70.41,
          70.3,
          70.87,
          68.53,
          68.53,
          68.53,
          68.16,
          68.38,
          70.74,
          69.19,
          68.05,
          68.05,
          68.05,
          67.56,
          67.8,
          67.23,
          66.49,
          67.36,
          67.36,
          67.36,
          68.33,
          70.93,
          70.91,
          70.18,
          70.35,
          70.35,
          70.35,
          69.04,
          68.52,
          67.96,
          68.52,
          69.35,
          69.35,
          69.35,
          67.58,
          67.94,
          66.42,
          66.11,
          66,
          66,
          66,
          64.79,
          65.79,
          68.9,
          67.08,
          67.71,
          67.71,
          67.71,
          68.78,
          68.58,
          69.24,
          71.17,
          70.44,
          70.44,
          70.44,
          68.86,
          69.92,
          70.57,
          71.06,
          70.14,
          70.14,
          70.14,
          72.65,
          71.29,
          71.87,
          72.11,
          72.52,
          72.52,
          72.52,
          73.14,
          73.07,
          72.14,
          71.57,
          71.13,
          71.13,
          71.13,
          70.49,
          71.49,
          70.77,
          71.06,
          70.3,
          70.3,
          70.3,
          70.43,
          68.16,
          67,
          66.2,
          66.5,
          66.5,
          66.5,
          66.52,
          64.92,
          66.4,
          65.45,
          64.99,
          64.99,
          64.99,
          64.99,
          64.34,
          63.7,
          62.82,
          63.39,
          63.39,
          63.39,
          64.1,
          63.87,
          65.24,
          66.52,
          66.33,
          66.33,
          66.33,
          65.56,
          63.61,
          62.6,
          62.76,
          62.05,
          62.05,
          62.05
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "EUA Over Time"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Date"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "EUA"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming df_all is your DataFrame\n",
    "fig = px.line(df_all, x='Date', y='EUA', title='EUA Over Time')\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.resample('W', on = 'Date').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EUA</th>\n",
       "      <th>Market_size</th>\n",
       "      <th>Oil</th>\n",
       "      <th>Coal</th>\n",
       "      <th>NG</th>\n",
       "      <th>Power</th>\n",
       "      <th>IR</th>\n",
       "      <th>GDP</th>\n",
       "      <th>USEU</th>\n",
       "      <th>S&amp;P_clean</th>\n",
       "      <th>DAX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-11-29</th>\n",
       "      <td>28.470000</td>\n",
       "      <td>148231.760000</td>\n",
       "      <td>48.190000</td>\n",
       "      <td>53.720000</td>\n",
       "      <td>14.260200</td>\n",
       "      <td>38.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3610544.5</td>\n",
       "      <td>0.837160</td>\n",
       "      <td>1487.202000</td>\n",
       "      <td>13316.682000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-06</th>\n",
       "      <td>30.015714</td>\n",
       "      <td>67020.242857</td>\n",
       "      <td>48.531429</td>\n",
       "      <td>62.207143</td>\n",
       "      <td>14.718143</td>\n",
       "      <td>38.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3610544.5</td>\n",
       "      <td>0.827086</td>\n",
       "      <td>1472.747143</td>\n",
       "      <td>13305.205714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-13</th>\n",
       "      <td>30.650000</td>\n",
       "      <td>159197.042857</td>\n",
       "      <td>49.521429</td>\n",
       "      <td>64.071429</td>\n",
       "      <td>15.279000</td>\n",
       "      <td>38.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3610544.5</td>\n",
       "      <td>0.825614</td>\n",
       "      <td>1494.747143</td>\n",
       "      <td>13218.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-20</th>\n",
       "      <td>31.717143</td>\n",
       "      <td>68718.328571</td>\n",
       "      <td>51.487143</td>\n",
       "      <td>65.864286</td>\n",
       "      <td>16.258857</td>\n",
       "      <td>38.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3610544.5</td>\n",
       "      <td>0.818243</td>\n",
       "      <td>1610.590000</td>\n",
       "      <td>13530.112857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-27</th>\n",
       "      <td>32.045714</td>\n",
       "      <td>16584.285714</td>\n",
       "      <td>51.050000</td>\n",
       "      <td>66.178571</td>\n",
       "      <td>17.504857</td>\n",
       "      <td>38.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3610544.5</td>\n",
       "      <td>0.819557</td>\n",
       "      <td>1744.878571</td>\n",
       "      <td>13514.365714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  EUA    Market_size        Oil       Coal         NG  Power  \\\n",
       "Date                                                                           \n",
       "2020-11-29  28.470000  148231.760000  48.190000  53.720000  14.260200  38.77   \n",
       "2020-12-06  30.015714   67020.242857  48.531429  62.207143  14.718143  38.77   \n",
       "2020-12-13  30.650000  159197.042857  49.521429  64.071429  15.279000  38.77   \n",
       "2020-12-20  31.717143   68718.328571  51.487143  65.864286  16.258857  38.77   \n",
       "2020-12-27  32.045714   16584.285714  51.050000  66.178571  17.504857  38.77   \n",
       "\n",
       "             IR        GDP      USEU    S&P_clean           DAX  \n",
       "Date                                                             \n",
       "2020-11-29  0.0  3610544.5  0.837160  1487.202000  13316.682000  \n",
       "2020-12-06  0.0  3610544.5  0.827086  1472.747143  13305.205714  \n",
       "2020-12-13  0.0  3610544.5  0.825614  1494.747143  13218.340000  \n",
       "2020-12-20  0.0  3610544.5  0.818243  1610.590000  13530.112857  \n",
       "2020-12-27  0.0  3610544.5  0.819557  1744.878571  13514.365714  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(model, checkpoint_path, X_train, y_train):\n",
    "    try:\n",
    "        model.load_weights(checkpoint_path) \n",
    "        with open(os.path.join(checkpoint_path.split('/')[1],checkpoint_path.split('/')[-1].split('.')[0]), 'rb') as f:\n",
    "            history = pickle.load(f)\n",
    "    except:\n",
    "        def lr_scheduler(epoch, lr):\n",
    "        # if epoch < 10:\n",
    "            return lr\n",
    "        # Learning rate scheduler callback\n",
    "        lr_scheduler_callback = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "        checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                    monitor='val_loss', \n",
    "                                    save_best_only=True,\n",
    "                                    mode='min',  \n",
    "                                    verbose=1)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True, verbose=1)\n",
    "\n",
    "        history = model.fit(X_train, y_train, epochs=1000, batch_size=128, \n",
    "                            validation_split=0.05,\n",
    "                            verbose=1, callbacks=[checkpoint, lr_scheduler_callback, early_stopping])# ,early_stopping]) \n",
    "        \n",
    "        with open(os.path.join(checkpoint_path.split('/')[1],checkpoint_path.split('/')[-1].split('.')[0]), 'wb') as f:\n",
    "            pickle.dump(history, f)\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729585256.340778    7081 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729585256.341025    7081 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:d5:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729585256.379467    7081 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729585256.379531    7081 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:d5:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729585256.379561    7081 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729585256.379594    7081 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:d5:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729585256.904744    7081 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729585256.904915    7081 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:d5:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729585256.905016    7081 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729585256.905099    7081 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:d5:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729585256.905178    7081 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729585256.905255    7081 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:d5:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729585256.935420    7081 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729585256.935999    7081 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:d5:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729585256.936132    7081 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-22 17:20:56.936161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1729585256.936280    7081 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:d5:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-22 17:20:56.936299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 1, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1729585256.936413    7081 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-22 17:20:56.936475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21770 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:73:00.0, compute capability: 8.6\n",
      "I0000 00:00:1729585256.944716    7081 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:d5:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-22 17:20:56.944802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21770 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:d5:00.0, compute capability: 8.6\n",
      "/home/honggeunjo/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 2.1412\n",
      "Epoch 1: val_loss improved from inf to 0.56330, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 185ms/step - loss: 2.0758 - val_loss: 0.5633 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.5699\n",
      "Epoch 2: val_loss improved from 0.56330 to 0.38005, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.5686 - val_loss: 0.3800 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.4578\n",
      "Epoch 3: val_loss improved from 0.38005 to 0.36614, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.4570 - val_loss: 0.3661 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.4179\n",
      "Epoch 4: val_loss improved from 0.36614 to 0.34940, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.4173 - val_loss: 0.3494 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.3981\n",
      "Epoch 5: val_loss improved from 0.34940 to 0.34580, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.3974 - val_loss: 0.3458 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.3790\n",
      "Epoch 6: val_loss improved from 0.34580 to 0.33483, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.3786 - val_loss: 0.3348 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3632\n",
      "Epoch 7: val_loss improved from 0.33483 to 0.33149, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.3632 - val_loss: 0.3315 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.3542\n",
      "Epoch 8: val_loss improved from 0.33149 to 0.32135, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.3542 - val_loss: 0.3213 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.3454\n",
      "Epoch 9: val_loss improved from 0.32135 to 0.31448, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.3454 - val_loss: 0.3145 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.3394\n",
      "Epoch 10: val_loss improved from 0.31448 to 0.30800, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.3391 - val_loss: 0.3080 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.3307\n",
      "Epoch 11: val_loss improved from 0.30800 to 0.30145, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.3306 - val_loss: 0.3014 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.3235\n",
      "Epoch 12: val_loss improved from 0.30145 to 0.29671, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.3234 - val_loss: 0.2967 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.3136\n",
      "Epoch 13: val_loss improved from 0.29671 to 0.28867, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.3135 - val_loss: 0.2887 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.3057\n",
      "Epoch 14: val_loss improved from 0.28867 to 0.27988, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.3056 - val_loss: 0.2799 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.2990\n",
      "Epoch 15: val_loss improved from 0.27988 to 0.27288, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.2989 - val_loss: 0.2729 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.2919\n",
      "Epoch 16: val_loss improved from 0.27288 to 0.26971, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.2918 - val_loss: 0.2697 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.2861\n",
      "Epoch 17: val_loss improved from 0.26971 to 0.26074, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.2859 - val_loss: 0.2607 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.2788\n",
      "Epoch 18: val_loss improved from 0.26074 to 0.25674, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.2786 - val_loss: 0.2567 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.2719\n",
      "Epoch 19: val_loss improved from 0.25674 to 0.25217, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.2718 - val_loss: 0.2522 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.2665\n",
      "Epoch 20: val_loss improved from 0.25217 to 0.24391, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.2663 - val_loss: 0.2439 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.2593\n",
      "Epoch 21: val_loss improved from 0.24391 to 0.23873, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.2593 - val_loss: 0.2387 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.2544\n",
      "Epoch 22: val_loss improved from 0.23873 to 0.23620, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.2544 - val_loss: 0.2362 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.2488\n",
      "Epoch 23: val_loss improved from 0.23620 to 0.22776, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.2487 - val_loss: 0.2278 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.2441\n",
      "Epoch 24: val_loss improved from 0.22776 to 0.22350, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.2440 - val_loss: 0.2235 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.2380\n",
      "Epoch 25: val_loss improved from 0.22350 to 0.21974, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.2380 - val_loss: 0.2197 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.2327\n",
      "Epoch 26: val_loss improved from 0.21974 to 0.21468, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.2326 - val_loss: 0.2147 - learning_rate: 0.0010\n",
      "Epoch 27/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.2277\n",
      "Epoch 27: val_loss improved from 0.21468 to 0.20993, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.2276 - val_loss: 0.2099 - learning_rate: 0.0010\n",
      "Epoch 28/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.2211\n",
      "Epoch 28: val_loss improved from 0.20993 to 0.20524, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.2210 - val_loss: 0.2052 - learning_rate: 0.0010\n",
      "Epoch 29/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.2160\n",
      "Epoch 29: val_loss improved from 0.20524 to 0.20219, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.2161 - val_loss: 0.2022 - learning_rate: 0.0010\n",
      "Epoch 30/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.2155\n",
      "Epoch 30: val_loss improved from 0.20219 to 0.19608, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.2153 - val_loss: 0.1961 - learning_rate: 0.0010\n",
      "Epoch 31/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.2103\n",
      "Epoch 31: val_loss improved from 0.19608 to 0.19248, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.2102 - val_loss: 0.1925 - learning_rate: 0.0010\n",
      "Epoch 32/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.2051\n",
      "Epoch 32: val_loss improved from 0.19248 to 0.18844, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.2050 - val_loss: 0.1884 - learning_rate: 0.0010\n",
      "Epoch 33/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.2028\n",
      "Epoch 33: val_loss improved from 0.18844 to 0.18739, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.2029 - val_loss: 0.1874 - learning_rate: 0.0010\n",
      "Epoch 34/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1992\n",
      "Epoch 34: val_loss improved from 0.18739 to 0.18192, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1991 - val_loss: 0.1819 - learning_rate: 0.0010\n",
      "Epoch 35/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1928\n",
      "Epoch 35: val_loss improved from 0.18192 to 0.17632, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1929 - val_loss: 0.1763 - learning_rate: 0.0010\n",
      "Epoch 36/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.1926\n",
      "Epoch 36: val_loss did not improve from 0.17632\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.1925 - val_loss: 0.1776 - learning_rate: 0.0010\n",
      "Epoch 37/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1895\n",
      "Epoch 37: val_loss improved from 0.17632 to 0.17559, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1894 - val_loss: 0.1756 - learning_rate: 0.0010\n",
      "Epoch 38/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1845\n",
      "Epoch 38: val_loss improved from 0.17559 to 0.16672, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.1845 - val_loss: 0.1667 - learning_rate: 0.0010\n",
      "Epoch 39/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1825\n",
      "Epoch 39: val_loss did not improve from 0.16672\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.1824 - val_loss: 0.1704 - learning_rate: 0.0010\n",
      "Epoch 40/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1778\n",
      "Epoch 40: val_loss did not improve from 0.16672\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.1777 - val_loss: 0.1701 - learning_rate: 0.0010\n",
      "Epoch 41/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.1743\n",
      "Epoch 41: val_loss improved from 0.16672 to 0.15705, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1743 - val_loss: 0.1570 - learning_rate: 0.0010\n",
      "Epoch 42/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.1721\n",
      "Epoch 42: val_loss improved from 0.15705 to 0.15682, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.1721 - val_loss: 0.1568 - learning_rate: 0.0010\n",
      "Epoch 43/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.1692\n",
      "Epoch 43: val_loss improved from 0.15682 to 0.15354, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1692 - val_loss: 0.1535 - learning_rate: 0.0010\n",
      "Epoch 44/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1660\n",
      "Epoch 44: val_loss did not improve from 0.15354\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.1659 - val_loss: 0.1549 - learning_rate: 0.0010\n",
      "Epoch 45/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1607\n",
      "Epoch 45: val_loss improved from 0.15354 to 0.14733, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1607 - val_loss: 0.1473 - learning_rate: 0.0010\n",
      "Epoch 46/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.1588\n",
      "Epoch 46: val_loss did not improve from 0.14733\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.1589 - val_loss: 0.1475 - learning_rate: 0.0010\n",
      "Epoch 47/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1600\n",
      "Epoch 47: val_loss improved from 0.14733 to 0.14511, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1598 - val_loss: 0.1451 - learning_rate: 0.0010\n",
      "Epoch 48/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.1543\n",
      "Epoch 48: val_loss improved from 0.14511 to 0.14413, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1543 - val_loss: 0.1441 - learning_rate: 0.0010\n",
      "Epoch 49/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1546\n",
      "Epoch 49: val_loss improved from 0.14413 to 0.13770, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1545 - val_loss: 0.1377 - learning_rate: 0.0010\n",
      "Epoch 50/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.1495\n",
      "Epoch 50: val_loss improved from 0.13770 to 0.13333, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1495 - val_loss: 0.1333 - learning_rate: 0.0010\n",
      "Epoch 51/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1483\n",
      "Epoch 51: val_loss did not improve from 0.13333\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.1483 - val_loss: 0.1386 - learning_rate: 0.0010\n",
      "Epoch 52/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.1457\n",
      "Epoch 52: val_loss did not improve from 0.13333\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.1456 - val_loss: 0.1335 - learning_rate: 0.0010\n",
      "Epoch 53/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.1434\n",
      "Epoch 53: val_loss improved from 0.13333 to 0.12799, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1433 - val_loss: 0.1280 - learning_rate: 0.0010\n",
      "Epoch 54/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1414\n",
      "Epoch 54: val_loss did not improve from 0.12799\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.1413 - val_loss: 0.1300 - learning_rate: 0.0010\n",
      "Epoch 55/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1413\n",
      "Epoch 55: val_loss improved from 0.12799 to 0.12797, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.1412 - val_loss: 0.1280 - learning_rate: 0.0010\n",
      "Epoch 56/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1369\n",
      "Epoch 56: val_loss did not improve from 0.12797\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.1369 - val_loss: 0.1288 - learning_rate: 0.0010\n",
      "Epoch 57/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.1344\n",
      "Epoch 57: val_loss improved from 0.12797 to 0.12305, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1344 - val_loss: 0.1231 - learning_rate: 0.0010\n",
      "Epoch 58/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.1331\n",
      "Epoch 58: val_loss did not improve from 0.12305\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1330 - val_loss: 0.1251 - learning_rate: 0.0010\n",
      "Epoch 59/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1308\n",
      "Epoch 59: val_loss improved from 0.12305 to 0.11559, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1309 - val_loss: 0.1156 - learning_rate: 0.0010\n",
      "Epoch 60/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1294\n",
      "Epoch 60: val_loss did not improve from 0.11559\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.1295 - val_loss: 0.1158 - learning_rate: 0.0010\n",
      "Epoch 61/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1278\n",
      "Epoch 61: val_loss improved from 0.11559 to 0.11462, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1279 - val_loss: 0.1146 - learning_rate: 0.0010\n",
      "Epoch 62/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1281\n",
      "Epoch 62: val_loss improved from 0.11462 to 0.11436, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1282 - val_loss: 0.1144 - learning_rate: 0.0010\n",
      "Epoch 63/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.1277\n",
      "Epoch 63: val_loss improved from 0.11436 to 0.11242, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1276 - val_loss: 0.1124 - learning_rate: 0.0010\n",
      "Epoch 64/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.1279\n",
      "Epoch 64: val_loss improved from 0.11242 to 0.11131, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1277 - val_loss: 0.1113 - learning_rate: 0.0010\n",
      "Epoch 65/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.1236\n",
      "Epoch 65: val_loss did not improve from 0.11131\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.1236 - val_loss: 0.1162 - learning_rate: 0.0010\n",
      "Epoch 66/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.1234\n",
      "Epoch 66: val_loss did not improve from 0.11131\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.1233 - val_loss: 0.1142 - learning_rate: 0.0010\n",
      "Epoch 67/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1194\n",
      "Epoch 67: val_loss improved from 0.11131 to 0.11058, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1194 - val_loss: 0.1106 - learning_rate: 0.0010\n",
      "Epoch 68/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.1190\n",
      "Epoch 68: val_loss improved from 0.11058 to 0.10485, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1190 - val_loss: 0.1049 - learning_rate: 0.0010\n",
      "Epoch 69/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.1180\n",
      "Epoch 69: val_loss improved from 0.10485 to 0.10153, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1180 - val_loss: 0.1015 - learning_rate: 0.0010\n",
      "Epoch 70/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.1161\n",
      "Epoch 70: val_loss did not improve from 0.10153\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1161 - val_loss: 0.1051 - learning_rate: 0.0010\n",
      "Epoch 71/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.1124\n",
      "Epoch 71: val_loss improved from 0.10153 to 0.09945, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1125 - val_loss: 0.0995 - learning_rate: 0.0010\n",
      "Epoch 72/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.1119\n",
      "Epoch 72: val_loss improved from 0.09945 to 0.09782, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1119 - val_loss: 0.0978 - learning_rate: 0.0010\n",
      "Epoch 73/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1101\n",
      "Epoch 73: val_loss improved from 0.09782 to 0.09611, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1101 - val_loss: 0.0961 - learning_rate: 0.0010\n",
      "Epoch 74/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1070\n",
      "Epoch 74: val_loss did not improve from 0.09611\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.1070 - val_loss: 0.0976 - learning_rate: 0.0010\n",
      "Epoch 75/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1065\n",
      "Epoch 75: val_loss did not improve from 0.09611\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.1065 - val_loss: 0.0979 - learning_rate: 0.0010\n",
      "Epoch 76/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.1047\n",
      "Epoch 76: val_loss improved from 0.09611 to 0.09358, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1047 - val_loss: 0.0936 - learning_rate: 0.0010\n",
      "Epoch 77/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1033\n",
      "Epoch 77: val_loss did not improve from 0.09358\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.1034 - val_loss: 0.0939 - learning_rate: 0.0010\n",
      "Epoch 78/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1032\n",
      "Epoch 78: val_loss did not improve from 0.09358\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.1032 - val_loss: 0.1008 - learning_rate: 0.0010\n",
      "Epoch 79/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1058\n",
      "Epoch 79: val_loss did not improve from 0.09358\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.1057 - val_loss: 0.0962 - learning_rate: 0.0010\n",
      "Epoch 80/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.1023\n",
      "Epoch 80: val_loss improved from 0.09358 to 0.08955, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1023 - val_loss: 0.0896 - learning_rate: 0.0010\n",
      "Epoch 81/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.1003\n",
      "Epoch 81: val_loss did not improve from 0.08955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.1003 - val_loss: 0.0918 - learning_rate: 0.0010\n",
      "Epoch 82/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0998\n",
      "Epoch 82: val_loss improved from 0.08955 to 0.08731, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0997 - val_loss: 0.0873 - learning_rate: 0.0010\n",
      "Epoch 83/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0990\n",
      "Epoch 83: val_loss improved from 0.08731 to 0.08533, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0989 - val_loss: 0.0853 - learning_rate: 0.0010\n",
      "Epoch 84/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0983\n",
      "Epoch 84: val_loss did not improve from 0.08533\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0984 - val_loss: 0.0972 - learning_rate: 0.0010\n",
      "Epoch 85/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0981\n",
      "Epoch 85: val_loss did not improve from 0.08533\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0980 - val_loss: 0.0942 - learning_rate: 0.0010\n",
      "Epoch 86/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0948\n",
      "Epoch 86: val_loss did not improve from 0.08533\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0948 - val_loss: 0.1008 - learning_rate: 0.0010\n",
      "Epoch 87/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0956\n",
      "Epoch 87: val_loss improved from 0.08533 to 0.08432, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0956 - val_loss: 0.0843 - learning_rate: 0.0010\n",
      "Epoch 88/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0950\n",
      "Epoch 88: val_loss did not improve from 0.08432\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0950 - val_loss: 0.0852 - learning_rate: 0.0010\n",
      "Epoch 89/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0933\n",
      "Epoch 89: val_loss did not improve from 0.08432\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0931 - val_loss: 0.0893 - learning_rate: 0.0010\n",
      "Epoch 90/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0917\n",
      "Epoch 90: val_loss improved from 0.08432 to 0.08248, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0917 - val_loss: 0.0825 - learning_rate: 0.0010\n",
      "Epoch 91/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0911\n",
      "Epoch 91: val_loss improved from 0.08248 to 0.07977, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0910 - val_loss: 0.0798 - learning_rate: 0.0010\n",
      "Epoch 92/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0894\n",
      "Epoch 92: val_loss did not improve from 0.07977\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0895 - val_loss: 0.0803 - learning_rate: 0.0010\n",
      "Epoch 93/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0914\n",
      "Epoch 93: val_loss improved from 0.07977 to 0.07725, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0914 - val_loss: 0.0772 - learning_rate: 0.0010\n",
      "Epoch 94/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0894\n",
      "Epoch 94: val_loss did not improve from 0.07725\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0894 - val_loss: 0.0793 - learning_rate: 0.0010\n",
      "Epoch 95/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0870\n",
      "Epoch 95: val_loss did not improve from 0.07725\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0870 - val_loss: 0.0779 - learning_rate: 0.0010\n",
      "Epoch 96/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0855\n",
      "Epoch 96: val_loss improved from 0.07725 to 0.07405, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0855 - val_loss: 0.0741 - learning_rate: 0.0010\n",
      "Epoch 97/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0849\n",
      "Epoch 97: val_loss did not improve from 0.07405\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0848 - val_loss: 0.0756 - learning_rate: 0.0010\n",
      "Epoch 98/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0841\n",
      "Epoch 98: val_loss did not improve from 0.07405\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0841 - val_loss: 0.0779 - learning_rate: 0.0010\n",
      "Epoch 99/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0830\n",
      "Epoch 99: val_loss improved from 0.07405 to 0.07189, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0829 - val_loss: 0.0719 - learning_rate: 0.0010\n",
      "Epoch 100/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0820\n",
      "Epoch 100: val_loss did not improve from 0.07189\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0820 - val_loss: 0.0781 - learning_rate: 0.0010\n",
      "Epoch 101/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0816\n",
      "Epoch 101: val_loss did not improve from 0.07189\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0816 - val_loss: 0.0759 - learning_rate: 0.0010\n",
      "Epoch 102/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0811\n",
      "Epoch 102: val_loss did not improve from 0.07189\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0811 - val_loss: 0.0734 - learning_rate: 0.0010\n",
      "Epoch 103/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0814\n",
      "Epoch 103: val_loss improved from 0.07189 to 0.07003, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0813 - val_loss: 0.0700 - learning_rate: 0.0010\n",
      "Epoch 104/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0796\n",
      "Epoch 104: val_loss did not improve from 0.07003\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0797 - val_loss: 0.0721 - learning_rate: 0.0010\n",
      "Epoch 105/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0796 \n",
      "Epoch 105: val_loss did not improve from 0.07003\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0796 - val_loss: 0.0716 - learning_rate: 0.0010\n",
      "Epoch 106/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0793\n",
      "Epoch 106: val_loss improved from 0.07003 to 0.06713, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0793 - val_loss: 0.0671 - learning_rate: 0.0010\n",
      "Epoch 107/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0789\n",
      "Epoch 107: val_loss improved from 0.06713 to 0.06589, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0789 - val_loss: 0.0659 - learning_rate: 0.0010\n",
      "Epoch 108/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0768\n",
      "Epoch 108: val_loss did not improve from 0.06589\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0768 - val_loss: 0.0669 - learning_rate: 0.0010\n",
      "Epoch 109/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0762\n",
      "Epoch 109: val_loss did not improve from 0.06589\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0762 - val_loss: 0.0674 - learning_rate: 0.0010\n",
      "Epoch 110/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0746\n",
      "Epoch 110: val_loss did not improve from 0.06589\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0747 - val_loss: 0.0678 - learning_rate: 0.0010\n",
      "Epoch 111/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0752\n",
      "Epoch 111: val_loss improved from 0.06589 to 0.06429, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0752 - val_loss: 0.0643 - learning_rate: 0.0010\n",
      "Epoch 112/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0738\n",
      "Epoch 112: val_loss did not improve from 0.06429\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0738 - val_loss: 0.0696 - learning_rate: 0.0010\n",
      "Epoch 113/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0741\n",
      "Epoch 113: val_loss improved from 0.06429 to 0.06375, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0741 - val_loss: 0.0638 - learning_rate: 0.0010\n",
      "Epoch 114/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0716\n",
      "Epoch 114: val_loss improved from 0.06375 to 0.06279, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0717 - val_loss: 0.0628 - learning_rate: 0.0010\n",
      "Epoch 115/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0720\n",
      "Epoch 115: val_loss improved from 0.06279 to 0.06248, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0720 - val_loss: 0.0625 - learning_rate: 0.0010\n",
      "Epoch 116/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0705\n",
      "Epoch 116: val_loss did not improve from 0.06248\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0705 - val_loss: 0.0627 - learning_rate: 0.0010\n",
      "Epoch 117/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0720\n",
      "Epoch 117: val_loss did not improve from 0.06248\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0719 - val_loss: 0.0632 - learning_rate: 0.0010\n",
      "Epoch 118/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0695\n",
      "Epoch 118: val_loss improved from 0.06248 to 0.06071, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0695 - val_loss: 0.0607 - learning_rate: 0.0010\n",
      "Epoch 119/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0695\n",
      "Epoch 119: val_loss improved from 0.06071 to 0.05937, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0695 - val_loss: 0.0594 - learning_rate: 0.0010\n",
      "Epoch 120/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0684\n",
      "Epoch 120: val_loss improved from 0.05937 to 0.05843, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0685 - val_loss: 0.0584 - learning_rate: 0.0010\n",
      "Epoch 121/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0696\n",
      "Epoch 121: val_loss did not improve from 0.05843\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0696 - val_loss: 0.0626 - learning_rate: 0.0010\n",
      "Epoch 122/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0697\n",
      "Epoch 122: val_loss did not improve from 0.05843\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0697 - val_loss: 0.0661 - learning_rate: 0.0010\n",
      "Epoch 123/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0684\n",
      "Epoch 123: val_loss did not improve from 0.05843\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0684 - val_loss: 0.0608 - learning_rate: 0.0010\n",
      "Epoch 124/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0668\n",
      "Epoch 124: val_loss did not improve from 0.05843\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0669 - val_loss: 0.0628 - learning_rate: 0.0010\n",
      "Epoch 125/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0677\n",
      "Epoch 125: val_loss did not improve from 0.05843\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0677 - val_loss: 0.0681 - learning_rate: 0.0010\n",
      "Epoch 126/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0673\n",
      "Epoch 126: val_loss did not improve from 0.05843\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0673 - val_loss: 0.0643 - learning_rate: 0.0010\n",
      "Epoch 127/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0664\n",
      "Epoch 127: val_loss did not improve from 0.05843\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0664 - val_loss: 0.0609 - learning_rate: 0.0010\n",
      "Epoch 128/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0658\n",
      "Epoch 128: val_loss did not improve from 0.05843\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0660 - val_loss: 0.0604 - learning_rate: 0.0010\n",
      "Epoch 129/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0697\n",
      "Epoch 129: val_loss improved from 0.05843 to 0.05613, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0696 - val_loss: 0.0561 - learning_rate: 0.0010\n",
      "Epoch 130/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0660\n",
      "Epoch 130: val_loss improved from 0.05613 to 0.05612, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0659 - val_loss: 0.0561 - learning_rate: 0.0010\n",
      "Epoch 131/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0641\n",
      "Epoch 131: val_loss improved from 0.05612 to 0.05505, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0641 - val_loss: 0.0550 - learning_rate: 0.0010\n",
      "Epoch 132/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0631\n",
      "Epoch 132: val_loss improved from 0.05505 to 0.05419, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0632 - val_loss: 0.0542 - learning_rate: 0.0010\n",
      "Epoch 133/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0656\n",
      "Epoch 133: val_loss did not improve from 0.05419\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0656 - val_loss: 0.0548 - learning_rate: 0.0010\n",
      "Epoch 134/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0621\n",
      "Epoch 134: val_loss improved from 0.05419 to 0.05192, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0621 - val_loss: 0.0519 - learning_rate: 0.0010\n",
      "Epoch 135/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0608\n",
      "Epoch 135: val_loss did not improve from 0.05192\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0609 - val_loss: 0.0526 - learning_rate: 0.0010\n",
      "Epoch 136/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0622\n",
      "Epoch 136: val_loss did not improve from 0.05192\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0622 - val_loss: 0.0571 - learning_rate: 0.0010\n",
      "Epoch 137/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0607\n",
      "Epoch 137: val_loss improved from 0.05192 to 0.05163, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0607 - val_loss: 0.0516 - learning_rate: 0.0010\n",
      "Epoch 138/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0627\n",
      "Epoch 138: val_loss did not improve from 0.05163\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0627 - val_loss: 0.0605 - learning_rate: 0.0010\n",
      "Epoch 139/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0606\n",
      "Epoch 139: val_loss improved from 0.05163 to 0.05000, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0607 - val_loss: 0.0500 - learning_rate: 0.0010\n",
      "Epoch 140/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0599\n",
      "Epoch 140: val_loss did not improve from 0.05000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0599 - val_loss: 0.0533 - learning_rate: 0.0010\n",
      "Epoch 141/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0602\n",
      "Epoch 141: val_loss improved from 0.05000 to 0.04969, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0601 - val_loss: 0.0497 - learning_rate: 0.0010\n",
      "Epoch 142/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0580\n",
      "Epoch 142: val_loss did not improve from 0.04969\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0581 - val_loss: 0.0537 - learning_rate: 0.0010\n",
      "Epoch 143/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0583\n",
      "Epoch 143: val_loss improved from 0.04969 to 0.04813, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0583 - val_loss: 0.0481 - learning_rate: 0.0010\n",
      "Epoch 144/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0583\n",
      "Epoch 144: val_loss did not improve from 0.04813\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0582 - val_loss: 0.0510 - learning_rate: 0.0010\n",
      "Epoch 145/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0584\n",
      "Epoch 145: val_loss did not improve from 0.04813\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0584 - val_loss: 0.0491 - learning_rate: 0.0010\n",
      "Epoch 146/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0578\n",
      "Epoch 146: val_loss did not improve from 0.04813\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0579 - val_loss: 0.0524 - learning_rate: 0.0010\n",
      "Epoch 147/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0571\n",
      "Epoch 147: val_loss did not improve from 0.04813\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0571 - val_loss: 0.0547 - learning_rate: 0.0010\n",
      "Epoch 148/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0567\n",
      "Epoch 148: val_loss did not improve from 0.04813\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0567 - val_loss: 0.0486 - learning_rate: 0.0010\n",
      "Epoch 149/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0571\n",
      "Epoch 149: val_loss did not improve from 0.04813\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0571 - val_loss: 0.0492 - learning_rate: 0.0010\n",
      "Epoch 150/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0560\n",
      "Epoch 150: val_loss did not improve from 0.04813\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0560 - val_loss: 0.0491 - learning_rate: 0.0010\n",
      "Epoch 151/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0563\n",
      "Epoch 151: val_loss did not improve from 0.04813\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0563 - val_loss: 0.0495 - learning_rate: 0.0010\n",
      "Epoch 152/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0551\n",
      "Epoch 152: val_loss improved from 0.04813 to 0.04609, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0551 - val_loss: 0.0461 - learning_rate: 0.0010\n",
      "Epoch 153/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0533\n",
      "Epoch 153: val_loss did not improve from 0.04609\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0533 - val_loss: 0.0462 - learning_rate: 0.0010\n",
      "Epoch 154/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0538\n",
      "Epoch 154: val_loss improved from 0.04609 to 0.04521, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0538 - val_loss: 0.0452 - learning_rate: 0.0010\n",
      "Epoch 155/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0517\n",
      "Epoch 155: val_loss improved from 0.04521 to 0.04433, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0517 - val_loss: 0.0443 - learning_rate: 0.0010\n",
      "Epoch 156/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0520\n",
      "Epoch 156: val_loss did not improve from 0.04433\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0521 - val_loss: 0.0449 - learning_rate: 0.0010\n",
      "Epoch 157/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0517\n",
      "Epoch 157: val_loss did not improve from 0.04433\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0517 - val_loss: 0.0464 - learning_rate: 0.0010\n",
      "Epoch 158/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0532\n",
      "Epoch 158: val_loss did not improve from 0.04433\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0533 - val_loss: 0.0461 - learning_rate: 0.0010\n",
      "Epoch 159/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0531\n",
      "Epoch 159: val_loss did not improve from 0.04433\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0531 - val_loss: 0.0461 - learning_rate: 0.0010\n",
      "Epoch 160/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0529\n",
      "Epoch 160: val_loss did not improve from 0.04433\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0528 - val_loss: 0.0475 - learning_rate: 0.0010\n",
      "Epoch 161/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0502\n",
      "Epoch 161: val_loss did not improve from 0.04433\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0503 - val_loss: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 162/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0511\n",
      "Epoch 162: val_loss improved from 0.04433 to 0.04307, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0511 - val_loss: 0.0431 - learning_rate: 0.0010\n",
      "Epoch 163/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0504\n",
      "Epoch 163: val_loss did not improve from 0.04307\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0505 - val_loss: 0.0493 - learning_rate: 0.0010\n",
      "Epoch 164/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0500\n",
      "Epoch 164: val_loss improved from 0.04307 to 0.04076, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0500 - val_loss: 0.0408 - learning_rate: 0.0010\n",
      "Epoch 165/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0496\n",
      "Epoch 165: val_loss did not improve from 0.04076\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0497 - val_loss: 0.0421 - learning_rate: 0.0010\n",
      "Epoch 166/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0495\n",
      "Epoch 166: val_loss did not improve from 0.04076\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0495 - val_loss: 0.0427 - learning_rate: 0.0010\n",
      "Epoch 167/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0484\n",
      "Epoch 167: val_loss did not improve from 0.04076\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0484 - val_loss: 0.0409 - learning_rate: 0.0010\n",
      "Epoch 168/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0473\n",
      "Epoch 168: val_loss did not improve from 0.04076\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0474 - val_loss: 0.0424 - learning_rate: 0.0010\n",
      "Epoch 169/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0484\n",
      "Epoch 169: val_loss improved from 0.04076 to 0.04061, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0484 - val_loss: 0.0406 - learning_rate: 0.0010\n",
      "Epoch 170/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0485\n",
      "Epoch 170: val_loss did not improve from 0.04061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0485 - val_loss: 0.0435 - learning_rate: 0.0010\n",
      "Epoch 171/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0468\n",
      "Epoch 171: val_loss did not improve from 0.04061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0469 - val_loss: 0.0452 - learning_rate: 0.0010\n",
      "Epoch 172/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0473\n",
      "Epoch 172: val_loss did not improve from 0.04061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0474 - val_loss: 0.0458 - learning_rate: 0.0010\n",
      "Epoch 173/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0480\n",
      "Epoch 173: val_loss did not improve from 0.04061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0480 - val_loss: 0.0407 - learning_rate: 0.0010\n",
      "Epoch 174/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0472\n",
      "Epoch 174: val_loss improved from 0.04061 to 0.03902, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0472 - val_loss: 0.0390 - learning_rate: 0.0010\n",
      "Epoch 175/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0490\n",
      "Epoch 175: val_loss did not improve from 0.03902\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0490 - val_loss: 0.0394 - learning_rate: 0.0010\n",
      "Epoch 176/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0483\n",
      "Epoch 176: val_loss improved from 0.03902 to 0.03777, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0482 - val_loss: 0.0378 - learning_rate: 0.0010\n",
      "Epoch 177/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0470\n",
      "Epoch 177: val_loss improved from 0.03777 to 0.03610, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0470 - val_loss: 0.0361 - learning_rate: 0.0010\n",
      "Epoch 178/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0460\n",
      "Epoch 178: val_loss did not improve from 0.03610\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0460 - val_loss: 0.0386 - learning_rate: 0.0010\n",
      "Epoch 179/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0444\n",
      "Epoch 179: val_loss did not improve from 0.03610\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0444 - val_loss: 0.0381 - learning_rate: 0.0010\n",
      "Epoch 180/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0461\n",
      "Epoch 180: val_loss did not improve from 0.03610\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0460 - val_loss: 0.0379 - learning_rate: 0.0010\n",
      "Epoch 181/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0451\n",
      "Epoch 181: val_loss did not improve from 0.03610\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0452 - val_loss: 0.0368 - learning_rate: 0.0010\n",
      "Epoch 182/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0444\n",
      "Epoch 182: val_loss did not improve from 0.03610\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0445 - val_loss: 0.0370 - learning_rate: 0.0010\n",
      "Epoch 183/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0458\n",
      "Epoch 183: val_loss did not improve from 0.03610\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0458 - val_loss: 0.0381 - learning_rate: 0.0010\n",
      "Epoch 184/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0464\n",
      "Epoch 184: val_loss improved from 0.03610 to 0.03391, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0465 - val_loss: 0.0339 - learning_rate: 0.0010\n",
      "Epoch 185/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0449\n",
      "Epoch 185: val_loss did not improve from 0.03391\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0449 - val_loss: 0.0346 - learning_rate: 0.0010\n",
      "Epoch 186/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0440\n",
      "Epoch 186: val_loss did not improve from 0.03391\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0440 - val_loss: 0.0364 - learning_rate: 0.0010\n",
      "Epoch 187/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0456\n",
      "Epoch 187: val_loss did not improve from 0.03391\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0455 - val_loss: 0.0363 - learning_rate: 0.0010\n",
      "Epoch 188/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0432\n",
      "Epoch 188: val_loss did not improve from 0.03391\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0432 - val_loss: 0.0359 - learning_rate: 0.0010\n",
      "Epoch 189/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0437\n",
      "Epoch 189: val_loss did not improve from 0.03391\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0437 - val_loss: 0.0343 - learning_rate: 0.0010\n",
      "Epoch 190/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0446\n",
      "Epoch 190: val_loss improved from 0.03391 to 0.03184, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0445 - val_loss: 0.0318 - learning_rate: 0.0010\n",
      "Epoch 191/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0437\n",
      "Epoch 191: val_loss did not improve from 0.03184\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0437 - val_loss: 0.0323 - learning_rate: 0.0010\n",
      "Epoch 192/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0422\n",
      "Epoch 192: val_loss improved from 0.03184 to 0.03182, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0422 - val_loss: 0.0318 - learning_rate: 0.0010\n",
      "Epoch 193/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0411\n",
      "Epoch 193: val_loss did not improve from 0.03182\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0411 - val_loss: 0.0322 - learning_rate: 0.0010\n",
      "Epoch 194/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0422\n",
      "Epoch 194: val_loss did not improve from 0.03182\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0422 - val_loss: 0.0328 - learning_rate: 0.0010\n",
      "Epoch 195/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0412\n",
      "Epoch 195: val_loss did not improve from 0.03182\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0413 - val_loss: 0.0342 - learning_rate: 0.0010\n",
      "Epoch 196/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0415\n",
      "Epoch 196: val_loss did not improve from 0.03182\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0415 - val_loss: 0.0415 - learning_rate: 0.0010\n",
      "Epoch 197/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0411\n",
      "Epoch 197: val_loss improved from 0.03182 to 0.03157, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0411 - val_loss: 0.0316 - learning_rate: 0.0010\n",
      "Epoch 198/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0398\n",
      "Epoch 198: val_loss did not improve from 0.03157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0398 - val_loss: 0.0361 - learning_rate: 0.0010\n",
      "Epoch 199/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0404\n",
      "Epoch 199: val_loss did not improve from 0.03157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0404 - val_loss: 0.0360 - learning_rate: 0.0010\n",
      "Epoch 200/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0388\n",
      "Epoch 200: val_loss did not improve from 0.03157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0389 - val_loss: 0.0329 - learning_rate: 0.0010\n",
      "Epoch 201/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0386\n",
      "Epoch 201: val_loss did not improve from 0.03157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0387 - val_loss: 0.0343 - learning_rate: 0.0010\n",
      "Epoch 202/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0407\n",
      "Epoch 202: val_loss did not improve from 0.03157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0407 - val_loss: 0.0326 - learning_rate: 0.0010\n",
      "Epoch 203/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0390\n",
      "Epoch 203: val_loss did not improve from 0.03157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0390 - val_loss: 0.0317 - learning_rate: 0.0010\n",
      "Epoch 204/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0403\n",
      "Epoch 204: val_loss improved from 0.03157 to 0.02962, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0403 - val_loss: 0.0296 - learning_rate: 0.0010\n",
      "Epoch 205/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0393\n",
      "Epoch 205: val_loss did not improve from 0.02962\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0393 - val_loss: 0.0318 - learning_rate: 0.0010\n",
      "Epoch 206/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0380\n",
      "Epoch 206: val_loss did not improve from 0.02962\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0380 - val_loss: 0.0345 - learning_rate: 0.0010\n",
      "Epoch 207/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0388\n",
      "Epoch 207: val_loss did not improve from 0.02962\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0389 - val_loss: 0.0376 - learning_rate: 0.0010\n",
      "Epoch 208/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0396\n",
      "Epoch 208: val_loss did not improve from 0.02962\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0396 - val_loss: 0.0325 - learning_rate: 0.0010\n",
      "Epoch 209/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0381\n",
      "Epoch 209: val_loss improved from 0.02962 to 0.02955, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0381 - val_loss: 0.0295 - learning_rate: 0.0010\n",
      "Epoch 210/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0387\n",
      "Epoch 210: val_loss did not improve from 0.02955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0386 - val_loss: 0.0299 - learning_rate: 0.0010\n",
      "Epoch 211/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0378\n",
      "Epoch 211: val_loss improved from 0.02955 to 0.02794, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0379 - val_loss: 0.0279 - learning_rate: 0.0010\n",
      "Epoch 212/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0373\n",
      "Epoch 212: val_loss did not improve from 0.02794\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0374 - val_loss: 0.0290 - learning_rate: 0.0010\n",
      "Epoch 213/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0375\n",
      "Epoch 213: val_loss did not improve from 0.02794\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0375 - val_loss: 0.0316 - learning_rate: 0.0010\n",
      "Epoch 214/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0376\n",
      "Epoch 214: val_loss did not improve from 0.02794\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0376 - val_loss: 0.0308 - learning_rate: 0.0010\n",
      "Epoch 215/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0373\n",
      "Epoch 215: val_loss did not improve from 0.02794\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0373 - val_loss: 0.0361 - learning_rate: 0.0010\n",
      "Epoch 216/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0355\n",
      "Epoch 216: val_loss did not improve from 0.02794\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0355 - val_loss: 0.0284 - learning_rate: 0.0010\n",
      "Epoch 217/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0359\n",
      "Epoch 217: val_loss improved from 0.02794 to 0.02695, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0359 - val_loss: 0.0270 - learning_rate: 0.0010\n",
      "Epoch 218/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0354\n",
      "Epoch 218: val_loss did not improve from 0.02695\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0355 - val_loss: 0.0327 - learning_rate: 0.0010\n",
      "Epoch 219/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0362\n",
      "Epoch 219: val_loss did not improve from 0.02695\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0362 - val_loss: 0.0275 - learning_rate: 0.0010\n",
      "Epoch 220/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0370\n",
      "Epoch 220: val_loss did not improve from 0.02695\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0370 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 221/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0362\n",
      "Epoch 221: val_loss improved from 0.02695 to 0.02694, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0362 - val_loss: 0.0269 - learning_rate: 0.0010\n",
      "Epoch 222/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0381\n",
      "Epoch 222: val_loss did not improve from 0.02694\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0380 - val_loss: 0.0302 - learning_rate: 0.0010\n",
      "Epoch 223/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0348\n",
      "Epoch 223: val_loss did not improve from 0.02694\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0348 - val_loss: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 224/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0344\n",
      "Epoch 224: val_loss improved from 0.02694 to 0.02657, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0344 - val_loss: 0.0266 - learning_rate: 0.0010\n",
      "Epoch 225/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0359\n",
      "Epoch 225: val_loss did not improve from 0.02657\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0359 - val_loss: 0.0279 - learning_rate: 0.0010\n",
      "Epoch 226/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0352\n",
      "Epoch 226: val_loss improved from 0.02657 to 0.02655, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0352 - val_loss: 0.0266 - learning_rate: 0.0010\n",
      "Epoch 227/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0348\n",
      "Epoch 227: val_loss did not improve from 0.02655\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0349 - val_loss: 0.0274 - learning_rate: 0.0010\n",
      "Epoch 228/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0336\n",
      "Epoch 228: val_loss improved from 0.02655 to 0.02573, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0337 - val_loss: 0.0257 - learning_rate: 0.0010\n",
      "Epoch 229/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0333\n",
      "Epoch 229: val_loss did not improve from 0.02573\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0334 - val_loss: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 230/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0337\n",
      "Epoch 230: val_loss improved from 0.02573 to 0.02432, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0336 - val_loss: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 231/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0333\n",
      "Epoch 231: val_loss did not improve from 0.02432\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0333 - val_loss: 0.0268 - learning_rate: 0.0010\n",
      "Epoch 232/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0340\n",
      "Epoch 232: val_loss did not improve from 0.02432\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0341 - val_loss: 0.0314 - learning_rate: 0.0010\n",
      "Epoch 233/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0336\n",
      "Epoch 233: val_loss did not improve from 0.02432\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0336 - val_loss: 0.0277 - learning_rate: 0.0010\n",
      "Epoch 234/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0343\n",
      "Epoch 234: val_loss did not improve from 0.02432\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0342 - val_loss: 0.0275 - learning_rate: 0.0010\n",
      "Epoch 235/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0344\n",
      "Epoch 235: val_loss did not improve from 0.02432\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0344 - val_loss: 0.0270 - learning_rate: 0.0010\n",
      "Epoch 236/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0340\n",
      "Epoch 236: val_loss did not improve from 0.02432\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0341 - val_loss: 0.0286 - learning_rate: 0.0010\n",
      "Epoch 237/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0349\n",
      "Epoch 237: val_loss did not improve from 0.02432\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0348 - val_loss: 0.0265 - learning_rate: 0.0010\n",
      "Epoch 238/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0342\n",
      "Epoch 238: val_loss improved from 0.02432 to 0.02345, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0342 - val_loss: 0.0234 - learning_rate: 0.0010\n",
      "Epoch 239/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0339\n",
      "Epoch 239: val_loss did not improve from 0.02345\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0339 - val_loss: 0.0237 - learning_rate: 0.0010\n",
      "Epoch 240/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0328\n",
      "Epoch 240: val_loss did not improve from 0.02345\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0328 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 241/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0320\n",
      "Epoch 241: val_loss did not improve from 0.02345\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0321 - val_loss: 0.0272 - learning_rate: 0.0010\n",
      "Epoch 242/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0312\n",
      "Epoch 242: val_loss improved from 0.02345 to 0.02243, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0313 - val_loss: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 243/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0305\n",
      "Epoch 243: val_loss did not improve from 0.02243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0306 - val_loss: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 244/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0324\n",
      "Epoch 244: val_loss did not improve from 0.02243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0323 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 245/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0320\n",
      "Epoch 245: val_loss did not improve from 0.02243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0321 - val_loss: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 246/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0322\n",
      "Epoch 246: val_loss did not improve from 0.02243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0322 - val_loss: 0.0264 - learning_rate: 0.0010\n",
      "Epoch 247/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0306\n",
      "Epoch 247: val_loss did not improve from 0.02243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0307 - val_loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 248/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0327\n",
      "Epoch 248: val_loss did not improve from 0.02243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0327 - val_loss: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 249/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0328\n",
      "Epoch 249: val_loss did not improve from 0.02243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0328 - val_loss: 0.0251 - learning_rate: 0.0010\n",
      "Epoch 250/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0331\n",
      "Epoch 250: val_loss did not improve from 0.02243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0331 - val_loss: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 251/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0309\n",
      "Epoch 251: val_loss did not improve from 0.02243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0310 - val_loss: 0.0232 - learning_rate: 0.0010\n",
      "Epoch 252/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0307\n",
      "Epoch 252: val_loss improved from 0.02243 to 0.02241, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0307 - val_loss: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 253/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0291\n",
      "Epoch 253: val_loss did not improve from 0.02241\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0292 - val_loss: 0.0246 - learning_rate: 0.0010\n",
      "Epoch 254/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0314\n",
      "Epoch 254: val_loss did not improve from 0.02241\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0314 - val_loss: 0.0229 - learning_rate: 0.0010\n",
      "Epoch 255/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0311\n",
      "Epoch 255: val_loss did not improve from 0.02241\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0310 - val_loss: 0.0267 - learning_rate: 0.0010\n",
      "Epoch 256/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0311\n",
      "Epoch 256: val_loss improved from 0.02241 to 0.02206, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0311 - val_loss: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 257/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0307\n",
      "Epoch 257: val_loss did not improve from 0.02206\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0307 - val_loss: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 258/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0306\n",
      "Epoch 258: val_loss improved from 0.02206 to 0.02139, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0307 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 259/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0294\n",
      "Epoch 259: val_loss did not improve from 0.02139\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0294 - val_loss: 0.0257 - learning_rate: 0.0010\n",
      "Epoch 260/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0284\n",
      "Epoch 260: val_loss improved from 0.02139 to 0.02131, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0285 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 261/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0291\n",
      "Epoch 261: val_loss improved from 0.02131 to 0.02118, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0291 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 262/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0283\n",
      "Epoch 262: val_loss did not improve from 0.02118\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0284 - val_loss: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 263/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0285\n",
      "Epoch 263: val_loss did not improve from 0.02118\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0285 - val_loss: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 264/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0282\n",
      "Epoch 264: val_loss did not improve from 0.02118\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0282 - val_loss: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 265/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0294\n",
      "Epoch 265: val_loss did not improve from 0.02118\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0293 - val_loss: 0.0235 - learning_rate: 0.0010\n",
      "Epoch 266/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0280\n",
      "Epoch 266: val_loss did not improve from 0.02118\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0281 - val_loss: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 267/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0285\n",
      "Epoch 267: val_loss improved from 0.02118 to 0.02069, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0285 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 268/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0284\n",
      "Epoch 268: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0284 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 269/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0279\n",
      "Epoch 269: val_loss improved from 0.02069 to 0.02036, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0279 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 270/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0271 \n",
      "Epoch 270: val_loss did not improve from 0.02036\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0271 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 271/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0280\n",
      "Epoch 271: val_loss improved from 0.02036 to 0.01959, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0280 - val_loss: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 272/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0281\n",
      "Epoch 272: val_loss did not improve from 0.01959\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0282 - val_loss: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 273/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0281\n",
      "Epoch 273: val_loss improved from 0.01959 to 0.01861, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0281 - val_loss: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 274/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0266\n",
      "Epoch 274: val_loss did not improve from 0.01861\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0267 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 275/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0268 \n",
      "Epoch 275: val_loss did not improve from 0.01861\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0268 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 276/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0262\n",
      "Epoch 276: val_loss did not improve from 0.01861\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0262 - val_loss: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 277/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0256\n",
      "Epoch 277: val_loss did not improve from 0.01861\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0257 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 278/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0261\n",
      "Epoch 278: val_loss did not improve from 0.01861\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0262 - val_loss: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 279/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0265\n",
      "Epoch 279: val_loss did not improve from 0.01861\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0266 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 280/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0271\n",
      "Epoch 280: val_loss improved from 0.01861 to 0.01768, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0271 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 281/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0277\n",
      "Epoch 281: val_loss did not improve from 0.01768\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0276 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 282/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0261\n",
      "Epoch 282: val_loss did not improve from 0.01768\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0262 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 283/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0256\n",
      "Epoch 283: val_loss did not improve from 0.01768\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0257 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 284/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0260\n",
      "Epoch 284: val_loss did not improve from 0.01768\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0260 - val_loss: 0.0210 - learning_rate: 0.0010\n",
      "Epoch 285/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0265\n",
      "Epoch 285: val_loss improved from 0.01768 to 0.01738, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0265 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 286/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0258\n",
      "Epoch 286: val_loss did not improve from 0.01738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0258 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 287/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0249\n",
      "Epoch 287: val_loss did not improve from 0.01738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0250 - val_loss: 0.0219 - learning_rate: 0.0010\n",
      "Epoch 288/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0250\n",
      "Epoch 288: val_loss did not improve from 0.01738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0251 - val_loss: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 289/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0265\n",
      "Epoch 289: val_loss did not improve from 0.01738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0265 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 290/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0263\n",
      "Epoch 290: val_loss did not improve from 0.01738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0263 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 291/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0267\n",
      "Epoch 291: val_loss did not improve from 0.01738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0267 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 292/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0257\n",
      "Epoch 292: val_loss did not improve from 0.01738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0257 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 293/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0257\n",
      "Epoch 293: val_loss improved from 0.01738 to 0.01637, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0258 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 294/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0271\n",
      "Epoch 294: val_loss did not improve from 0.01637\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0272 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 295/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0268\n",
      "Epoch 295: val_loss did not improve from 0.01637\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0268 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 296/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0256\n",
      "Epoch 296: val_loss did not improve from 0.01637\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0256 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 297/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0250\n",
      "Epoch 297: val_loss did not improve from 0.01637\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0250 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 298/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0245\n",
      "Epoch 298: val_loss did not improve from 0.01637\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0245 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 299/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0242\n",
      "Epoch 299: val_loss did not improve from 0.01637\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0243 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 300/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0246\n",
      "Epoch 300: val_loss did not improve from 0.01637\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0246 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 301/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0253\n",
      "Epoch 301: val_loss did not improve from 0.01637\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0253 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 302/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0264\n",
      "Epoch 302: val_loss did not improve from 0.01637\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0264 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 303/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0247\n",
      "Epoch 303: val_loss did not improve from 0.01637\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0248 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 304/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0248\n",
      "Epoch 304: val_loss did not improve from 0.01637\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0248 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 305/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0238\n",
      "Epoch 305: val_loss did not improve from 0.01637\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0239 - val_loss: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 306/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0268\n",
      "Epoch 306: val_loss did not improve from 0.01637\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0268 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 307/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0256\n",
      "Epoch 307: val_loss did not improve from 0.01637\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0256 - val_loss: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 308/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0264\n",
      "Epoch 308: val_loss did not improve from 0.01637\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0262 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 309/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0246\n",
      "Epoch 309: val_loss did not improve from 0.01637\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0246 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 310/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0237\n",
      "Epoch 310: val_loss improved from 0.01637 to 0.01616, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0237 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 311/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0243\n",
      "Epoch 311: val_loss did not improve from 0.01616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0243 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 312/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0233\n",
      "Epoch 312: val_loss improved from 0.01616 to 0.01576, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0234 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 313/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0239\n",
      "Epoch 313: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0239 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 314/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0226\n",
      "Epoch 314: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0226 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 315/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0235\n",
      "Epoch 315: val_loss improved from 0.01576 to 0.01532, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0234 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 316/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0230\n",
      "Epoch 316: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0231 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 317/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0240\n",
      "Epoch 317: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0241 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 318/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0232\n",
      "Epoch 318: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0232 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 319/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0231\n",
      "Epoch 319: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0231 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 320/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0227\n",
      "Epoch 320: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0227 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 321/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0233\n",
      "Epoch 321: val_loss improved from 0.01532 to 0.01467, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0233 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 322/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0230\n",
      "Epoch 322: val_loss improved from 0.01467 to 0.01455, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0230 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 323/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0225\n",
      "Epoch 323: val_loss did not improve from 0.01455\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0225 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 324/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0235\n",
      "Epoch 324: val_loss did not improve from 0.01455\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0235 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 325/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0224\n",
      "Epoch 325: val_loss did not improve from 0.01455\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0224 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 326/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0222\n",
      "Epoch 326: val_loss did not improve from 0.01455\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0223 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 327/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0228\n",
      "Epoch 327: val_loss did not improve from 0.01455\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0228 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 328/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0217\n",
      "Epoch 328: val_loss improved from 0.01455 to 0.01405, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0218 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 329/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0227\n",
      "Epoch 329: val_loss did not improve from 0.01405\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0227 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 330/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0239\n",
      "Epoch 330: val_loss did not improve from 0.01405\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0239 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 331/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0241\n",
      "Epoch 331: val_loss did not improve from 0.01405\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0240 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 332/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0214\n",
      "Epoch 332: val_loss did not improve from 0.01405\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0215 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 333/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0218\n",
      "Epoch 333: val_loss did not improve from 0.01405\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0217 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 334/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0208\n",
      "Epoch 334: val_loss did not improve from 0.01405\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0208 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 335/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0216\n",
      "Epoch 335: val_loss did not improve from 0.01405\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0216 - val_loss: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 336/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0220\n",
      "Epoch 336: val_loss did not improve from 0.01405\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0221 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 337/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0209\n",
      "Epoch 337: val_loss improved from 0.01405 to 0.01362, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0210 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 338/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0210\n",
      "Epoch 338: val_loss did not improve from 0.01362\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0210 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 339/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0219\n",
      "Epoch 339: val_loss did not improve from 0.01362\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0219 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 340/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0213\n",
      "Epoch 340: val_loss did not improve from 0.01362\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0214 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 341/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0218\n",
      "Epoch 341: val_loss improved from 0.01362 to 0.01346, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0218 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 342/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0223\n",
      "Epoch 342: val_loss did not improve from 0.01346\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0223 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 343/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0216\n",
      "Epoch 343: val_loss did not improve from 0.01346\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0216 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 344/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0221\n",
      "Epoch 344: val_loss did not improve from 0.01346\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0221 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 345/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0220\n",
      "Epoch 345: val_loss did not improve from 0.01346\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0220 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 346/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0218\n",
      "Epoch 346: val_loss did not improve from 0.01346\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0218 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 347/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0227\n",
      "Epoch 347: val_loss did not improve from 0.01346\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0227 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 348/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0208\n",
      "Epoch 348: val_loss improved from 0.01346 to 0.01248, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0208 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 349/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0211\n",
      "Epoch 349: val_loss did not improve from 0.01248\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0211 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 350/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0215\n",
      "Epoch 350: val_loss did not improve from 0.01248\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0216 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 351/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0226\n",
      "Epoch 351: val_loss did not improve from 0.01248\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0226 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 352/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0225\n",
      "Epoch 352: val_loss did not improve from 0.01248\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0224 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 353/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0207\n",
      "Epoch 353: val_loss did not improve from 0.01248\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0207 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 354/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0224\n",
      "Epoch 354: val_loss did not improve from 0.01248\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0224 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 355/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0219\n",
      "Epoch 355: val_loss did not improve from 0.01248\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0218 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 356/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0205\n",
      "Epoch 356: val_loss did not improve from 0.01248\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0205 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 357/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0206\n",
      "Epoch 357: val_loss improved from 0.01248 to 0.01244, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0207 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 358/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0194\n",
      "Epoch 358: val_loss did not improve from 0.01244\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0195 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 359/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0197\n",
      "Epoch 359: val_loss did not improve from 0.01244\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0196 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 360/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0193\n",
      "Epoch 360: val_loss did not improve from 0.01244\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0193 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 361/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0216\n",
      "Epoch 361: val_loss did not improve from 0.01244\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0215 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 362/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0206\n",
      "Epoch 362: val_loss did not improve from 0.01244\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0206 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 363/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0198\n",
      "Epoch 363: val_loss did not improve from 0.01244\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0198 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 364/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0197\n",
      "Epoch 364: val_loss did not improve from 0.01244\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0198 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 365/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0202\n",
      "Epoch 365: val_loss improved from 0.01244 to 0.01234, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0202 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 366/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0193\n",
      "Epoch 366: val_loss did not improve from 0.01234\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0194 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 367/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0204\n",
      "Epoch 367: val_loss did not improve from 0.01234\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0206 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 368/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0213\n",
      "Epoch 368: val_loss did not improve from 0.01234\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0213 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 369/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0239\n",
      "Epoch 369: val_loss did not improve from 0.01234\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0238 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 370/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0217\n",
      "Epoch 370: val_loss did not improve from 0.01234\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0217 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 371/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0207\n",
      "Epoch 371: val_loss did not improve from 0.01234\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0208 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 372/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0204\n",
      "Epoch 372: val_loss did not improve from 0.01234\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0204 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 373/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0207\n",
      "Epoch 373: val_loss did not improve from 0.01234\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0207 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 374/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0206\n",
      "Epoch 374: val_loss did not improve from 0.01234\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0206 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 375/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0208\n",
      "Epoch 375: val_loss improved from 0.01234 to 0.01226, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0209 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 376/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0200\n",
      "Epoch 376: val_loss did not improve from 0.01226\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0199 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 377/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0204\n",
      "Epoch 377: val_loss did not improve from 0.01226\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0204 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 378/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0186\n",
      "Epoch 378: val_loss did not improve from 0.01226\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0187 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 379/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0189\n",
      "Epoch 379: val_loss improved from 0.01226 to 0.01134, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0190 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 380/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0192\n",
      "Epoch 380: val_loss did not improve from 0.01134\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0192 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 381/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0188\n",
      "Epoch 381: val_loss did not improve from 0.01134\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0189 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 382/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0187\n",
      "Epoch 382: val_loss did not improve from 0.01134\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0187 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 383/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0195\n",
      "Epoch 383: val_loss improved from 0.01134 to 0.01065, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0195 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 384/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0188\n",
      "Epoch 384: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0189 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 385/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0175\n",
      "Epoch 385: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0175 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 386/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0183\n",
      "Epoch 386: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0183 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 387/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0183\n",
      "Epoch 387: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0183 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 388/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0182\n",
      "Epoch 388: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0182 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 389/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0174\n",
      "Epoch 389: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0175 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 390/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0178\n",
      "Epoch 390: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0178 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 391/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0182\n",
      "Epoch 391: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0182 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 392/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0196\n",
      "Epoch 392: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0196 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 393/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0179\n",
      "Epoch 393: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0179 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 394/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0182\n",
      "Epoch 394: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0182 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 395/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0184\n",
      "Epoch 395: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0184 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 396/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0183\n",
      "Epoch 396: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0183 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 397/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0173\n",
      "Epoch 397: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0174 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 398/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0185\n",
      "Epoch 398: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0185 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 399/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0189\n",
      "Epoch 399: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0189 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 400/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0189\n",
      "Epoch 400: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0190 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 401/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0195\n",
      "Epoch 401: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0195 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 402/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0191\n",
      "Epoch 402: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0191 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 403/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0177\n",
      "Epoch 403: val_loss did not improve from 0.01065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0177 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 404/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0186\n",
      "Epoch 404: val_loss improved from 0.01065 to 0.01038, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0186 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 405/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0188\n",
      "Epoch 405: val_loss did not improve from 0.01038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0188 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 406/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0178\n",
      "Epoch 406: val_loss did not improve from 0.01038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0178 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 407/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0181\n",
      "Epoch 407: val_loss did not improve from 0.01038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0181 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 408/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0187\n",
      "Epoch 408: val_loss did not improve from 0.01038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0186 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 409/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0167\n",
      "Epoch 409: val_loss did not improve from 0.01038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0167 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 410/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0179\n",
      "Epoch 410: val_loss did not improve from 0.01038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0179 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 411/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0178\n",
      "Epoch 411: val_loss did not improve from 0.01038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0178 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 412/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0179\n",
      "Epoch 412: val_loss did not improve from 0.01038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0179 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 413/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0187\n",
      "Epoch 413: val_loss did not improve from 0.01038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0187 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 414/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0180\n",
      "Epoch 414: val_loss did not improve from 0.01038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0180 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 415/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0176\n",
      "Epoch 415: val_loss did not improve from 0.01038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0176 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 416/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0168\n",
      "Epoch 416: val_loss did not improve from 0.01038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0168 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 417/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0177\n",
      "Epoch 417: val_loss did not improve from 0.01038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0177 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 418/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0175\n",
      "Epoch 418: val_loss improved from 0.01038 to 0.00976, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0175 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 419/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0183\n",
      "Epoch 419: val_loss did not improve from 0.00976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0182 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 420/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0176\n",
      "Epoch 420: val_loss did not improve from 0.00976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0176 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 421/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0171\n",
      "Epoch 421: val_loss did not improve from 0.00976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0171 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 422/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0164\n",
      "Epoch 422: val_loss did not improve from 0.00976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0164 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 423/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0182\n",
      "Epoch 423: val_loss did not improve from 0.00976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0181 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 424/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0174\n",
      "Epoch 424: val_loss did not improve from 0.00976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0174 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 425/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0173\n",
      "Epoch 425: val_loss did not improve from 0.00976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0173 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 426/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0179\n",
      "Epoch 426: val_loss did not improve from 0.00976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0179 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 427/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0182\n",
      "Epoch 427: val_loss did not improve from 0.00976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0182 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 428/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0180\n",
      "Epoch 428: val_loss did not improve from 0.00976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0180 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 429/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0173\n",
      "Epoch 429: val_loss did not improve from 0.00976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0173 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 430/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0169\n",
      "Epoch 430: val_loss did not improve from 0.00976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0169 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 431/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0177\n",
      "Epoch 431: val_loss did not improve from 0.00976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0177 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 432/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0180\n",
      "Epoch 432: val_loss did not improve from 0.00976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0180 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 433/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0172\n",
      "Epoch 433: val_loss did not improve from 0.00976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0172 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 434/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0193\n",
      "Epoch 434: val_loss improved from 0.00976 to 0.00969, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0192 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 435/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0181\n",
      "Epoch 435: val_loss did not improve from 0.00969\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0180 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 436/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0161\n",
      "Epoch 436: val_loss did not improve from 0.00969\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0161 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 437/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0156\n",
      "Epoch 437: val_loss did not improve from 0.00969\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0157 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 438/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0165\n",
      "Epoch 438: val_loss did not improve from 0.00969\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0165 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 439/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0165\n",
      "Epoch 439: val_loss did not improve from 0.00969\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0165 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 440/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0165\n",
      "Epoch 440: val_loss did not improve from 0.00969\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0165 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 441/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0172\n",
      "Epoch 441: val_loss did not improve from 0.00969\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0172 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 442/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0168\n",
      "Epoch 442: val_loss did not improve from 0.00969\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0168 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 443/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0168\n",
      "Epoch 443: val_loss did not improve from 0.00969\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0168 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 444/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0170\n",
      "Epoch 444: val_loss did not improve from 0.00969\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0169 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 445/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0165\n",
      "Epoch 445: val_loss did not improve from 0.00969\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0165 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 446/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0165\n",
      "Epoch 446: val_loss did not improve from 0.00969\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0165 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 447/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0181\n",
      "Epoch 447: val_loss did not improve from 0.00969\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0181 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 448/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0186\n",
      "Epoch 448: val_loss did not improve from 0.00969\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0186 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 449/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0180\n",
      "Epoch 449: val_loss improved from 0.00969 to 0.00950, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0180 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 450/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0177\n",
      "Epoch 450: val_loss did not improve from 0.00950\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0177 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 451/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0162\n",
      "Epoch 451: val_loss did not improve from 0.00950\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0163 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 452/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0169\n",
      "Epoch 452: val_loss did not improve from 0.00950\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0169 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 453/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0179\n",
      "Epoch 453: val_loss did not improve from 0.00950\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0178 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 454/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0176\n",
      "Epoch 454: val_loss improved from 0.00950 to 0.00939, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0175 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 455/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0179\n",
      "Epoch 455: val_loss did not improve from 0.00939\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0178 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 456/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0170\n",
      "Epoch 456: val_loss did not improve from 0.00939\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0170 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 457/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0162\n",
      "Epoch 457: val_loss improved from 0.00939 to 0.00925, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0162 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 458/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0163\n",
      "Epoch 458: val_loss did not improve from 0.00925\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0163 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 459/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0160\n",
      "Epoch 459: val_loss did not improve from 0.00925\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0160 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 460/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0163\n",
      "Epoch 460: val_loss did not improve from 0.00925\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0163 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 461/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0156\n",
      "Epoch 461: val_loss did not improve from 0.00925\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0156 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 462/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0163\n",
      "Epoch 462: val_loss did not improve from 0.00925\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0163 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 463/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0168\n",
      "Epoch 463: val_loss did not improve from 0.00925\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0168 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 464/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0163\n",
      "Epoch 464: val_loss did not improve from 0.00925\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0163 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 465/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0154\n",
      "Epoch 465: val_loss did not improve from 0.00925\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0155 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 466/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0159\n",
      "Epoch 466: val_loss did not improve from 0.00925\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0159 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 467/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0157\n",
      "Epoch 467: val_loss improved from 0.00925 to 0.00898, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0158 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 468/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0160\n",
      "Epoch 468: val_loss improved from 0.00898 to 0.00877, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0160 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 469/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0158\n",
      "Epoch 469: val_loss did not improve from 0.00877\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0158 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 470/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0149\n",
      "Epoch 470: val_loss did not improve from 0.00877\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0149 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 471/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0149\n",
      "Epoch 471: val_loss did not improve from 0.00877\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0149 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 472/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0166\n",
      "Epoch 472: val_loss did not improve from 0.00877\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0166 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 473/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0170\n",
      "Epoch 473: val_loss did not improve from 0.00877\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0170 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 474/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0168\n",
      "Epoch 474: val_loss did not improve from 0.00877\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0168 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 475/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0165\n",
      "Epoch 475: val_loss did not improve from 0.00877\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0164 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 476/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0157\n",
      "Epoch 476: val_loss did not improve from 0.00877\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0157 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 477/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0168\n",
      "Epoch 477: val_loss did not improve from 0.00877\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0167 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 478/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0145\n",
      "Epoch 478: val_loss did not improve from 0.00877\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0146 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 479/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0164\n",
      "Epoch 479: val_loss did not improve from 0.00877\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0163 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 480/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0162\n",
      "Epoch 480: val_loss did not improve from 0.00877\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0163 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 481/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0162\n",
      "Epoch 481: val_loss did not improve from 0.00877\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0163 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 482/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0163\n",
      "Epoch 482: val_loss did not improve from 0.00877\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0163 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 483/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0159\n",
      "Epoch 483: val_loss improved from 0.00877 to 0.00860, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0159 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 484/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0159\n",
      "Epoch 484: val_loss did not improve from 0.00860\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0159 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 485/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0150\n",
      "Epoch 485: val_loss did not improve from 0.00860\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0150 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 486/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0147\n",
      "Epoch 486: val_loss did not improve from 0.00860\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0147 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 487/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0159\n",
      "Epoch 487: val_loss did not improve from 0.00860\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0159 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 488/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0154\n",
      "Epoch 488: val_loss did not improve from 0.00860\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0153 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 489/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0163\n",
      "Epoch 489: val_loss did not improve from 0.00860\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0163 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 490/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0141\n",
      "Epoch 490: val_loss did not improve from 0.00860\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0142 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 491/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0156\n",
      "Epoch 491: val_loss improved from 0.00860 to 0.00824, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0156 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 492/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0167\n",
      "Epoch 492: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0167 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 493/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0164\n",
      "Epoch 493: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0164 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 494/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0151\n",
      "Epoch 494: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0151 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 495/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0156\n",
      "Epoch 495: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0156 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 496/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0162\n",
      "Epoch 496: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0162 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 497/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0166\n",
      "Epoch 497: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0165 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 498/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0162\n",
      "Epoch 498: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0163 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 499/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0151\n",
      "Epoch 499: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0152 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 500/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0165\n",
      "Epoch 500: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0164 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 501/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0145\n",
      "Epoch 501: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0146 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 502/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0151\n",
      "Epoch 502: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0151 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 503/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0150\n",
      "Epoch 503: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0150 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 504/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0153\n",
      "Epoch 504: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0153 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 505/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0157\n",
      "Epoch 505: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0157 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 506/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0152\n",
      "Epoch 506: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0152 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 507/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0140\n",
      "Epoch 507: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0141 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 508/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0145\n",
      "Epoch 508: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0146 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 509/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0148\n",
      "Epoch 509: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0148 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 510/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0153\n",
      "Epoch 510: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0154 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 511/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0150\n",
      "Epoch 511: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0150 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 512/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0151\n",
      "Epoch 512: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0151 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 513/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0162\n",
      "Epoch 513: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0162 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 514/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0157\n",
      "Epoch 514: val_loss did not improve from 0.00824\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0157 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 515/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0147 \n",
      "Epoch 515: val_loss improved from 0.00824 to 0.00794, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0147 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 516/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0151\n",
      "Epoch 516: val_loss did not improve from 0.00794\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0151 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 517/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0159\n",
      "Epoch 517: val_loss did not improve from 0.00794\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0159 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 518/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0155\n",
      "Epoch 518: val_loss did not improve from 0.00794\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0155 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 519/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0157\n",
      "Epoch 519: val_loss did not improve from 0.00794\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0157 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 520/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0159\n",
      "Epoch 520: val_loss did not improve from 0.00794\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0159 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 521/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0153\n",
      "Epoch 521: val_loss did not improve from 0.00794\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0154 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 522/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0158\n",
      "Epoch 522: val_loss did not improve from 0.00794\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0158 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 523/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0157\n",
      "Epoch 523: val_loss did not improve from 0.00794\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0157 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 524/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0150\n",
      "Epoch 524: val_loss did not improve from 0.00794\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0151 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 525/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0151\n",
      "Epoch 525: val_loss did not improve from 0.00794\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0151 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 526/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0153\n",
      "Epoch 526: val_loss did not improve from 0.00794\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0153 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 527/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0150\n",
      "Epoch 527: val_loss improved from 0.00794 to 0.00789, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0149 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 528/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0153\n",
      "Epoch 528: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0152 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 529/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0142\n",
      "Epoch 529: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0143 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 530/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0151\n",
      "Epoch 530: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0151 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 531/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0160\n",
      "Epoch 531: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0160 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 532/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0150\n",
      "Epoch 532: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0150 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 533/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0143\n",
      "Epoch 533: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0143 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 534/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0141\n",
      "Epoch 534: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0142 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 535/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0146\n",
      "Epoch 535: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0145 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 536/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0146\n",
      "Epoch 536: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0145 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 537/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0142\n",
      "Epoch 537: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0142 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 538/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0138\n",
      "Epoch 538: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0139 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 539/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0145\n",
      "Epoch 539: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0145 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 540/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0142\n",
      "Epoch 540: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0143 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 541/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0139\n",
      "Epoch 541: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0139 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 542/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0139\n",
      "Epoch 542: val_loss improved from 0.00789 to 0.00759, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0140 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 543/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0146\n",
      "Epoch 543: val_loss did not improve from 0.00759\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0146 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 544/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0146\n",
      "Epoch 544: val_loss did not improve from 0.00759\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0146 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 545/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0148\n",
      "Epoch 545: val_loss did not improve from 0.00759\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0149 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 546/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0146\n",
      "Epoch 546: val_loss did not improve from 0.00759\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0146 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 547/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0137\n",
      "Epoch 547: val_loss did not improve from 0.00759\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0138 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 548/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0144\n",
      "Epoch 548: val_loss did not improve from 0.00759\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0145 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 549/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0140\n",
      "Epoch 549: val_loss improved from 0.00759 to 0.00738, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0140 - val_loss: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 550/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0133\n",
      "Epoch 550: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0134 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 551/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0138\n",
      "Epoch 551: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0138 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 552/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0137\n",
      "Epoch 552: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0138 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 553/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0138\n",
      "Epoch 553: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0139 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 554/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0137\n",
      "Epoch 554: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0137 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 555/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0143\n",
      "Epoch 555: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0143 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 556/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0148\n",
      "Epoch 556: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0148 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 557/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0138\n",
      "Epoch 557: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0138 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 558/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0156\n",
      "Epoch 558: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0156 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 559/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0143\n",
      "Epoch 559: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0144 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 560/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0146\n",
      "Epoch 560: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0145 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 561/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0132\n",
      "Epoch 561: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0133 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 562/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0135\n",
      "Epoch 562: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0136 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 563/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0140\n",
      "Epoch 563: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0140 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 564/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0134\n",
      "Epoch 564: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0134 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 565/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0138\n",
      "Epoch 565: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0138 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 566/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0135\n",
      "Epoch 566: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0135 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 567/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0134\n",
      "Epoch 567: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0134 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 568/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0134\n",
      "Epoch 568: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0134 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 569/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0133\n",
      "Epoch 569: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0133 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 570/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0128\n",
      "Epoch 570: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0129 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 571/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0137\n",
      "Epoch 571: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0137 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 572/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0150\n",
      "Epoch 572: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0149 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 573/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0141\n",
      "Epoch 573: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0141 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 574/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0137\n",
      "Epoch 574: val_loss did not improve from 0.00738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0138 - val_loss: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 575/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0147\n",
      "Epoch 575: val_loss improved from 0.00738 to 0.00730, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0147 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 576/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0146\n",
      "Epoch 576: val_loss did not improve from 0.00730\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0146 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 577/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0148\n",
      "Epoch 577: val_loss did not improve from 0.00730\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0148 - val_loss: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 578/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0157\n",
      "Epoch 578: val_loss did not improve from 0.00730\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0156 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 579/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0145\n",
      "Epoch 579: val_loss did not improve from 0.00730\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0145 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 580/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0136\n",
      "Epoch 580: val_loss did not improve from 0.00730\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0136 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 581/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0143\n",
      "Epoch 581: val_loss did not improve from 0.00730\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0143 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 582/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0144\n",
      "Epoch 582: val_loss did not improve from 0.00730\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0144 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 583/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0134\n",
      "Epoch 583: val_loss did not improve from 0.00730\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0134 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 584/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0132\n",
      "Epoch 584: val_loss improved from 0.00730 to 0.00718, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0133 - val_loss: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 585/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0133\n",
      "Epoch 585: val_loss did not improve from 0.00718\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0133 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 586/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0142\n",
      "Epoch 586: val_loss did not improve from 0.00718\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0143 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 587/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0135\n",
      "Epoch 587: val_loss improved from 0.00718 to 0.00705, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0135 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 588/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0128\n",
      "Epoch 588: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0128 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 589/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0132\n",
      "Epoch 589: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0133 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 590/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0135\n",
      "Epoch 590: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0135 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 591/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0149\n",
      "Epoch 591: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0148 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 592/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0147\n",
      "Epoch 592: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0147 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 593/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0142\n",
      "Epoch 593: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0142 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 594/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0144\n",
      "Epoch 594: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0144 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 595/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0132\n",
      "Epoch 595: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0133 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 596/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0133\n",
      "Epoch 596: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0133 - val_loss: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 597/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0136\n",
      "Epoch 597: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0136 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 598/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0140\n",
      "Epoch 598: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0140 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 599/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0132\n",
      "Epoch 599: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0133 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 600/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0132\n",
      "Epoch 600: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0132 - val_loss: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 601/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0144\n",
      "Epoch 601: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0144 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 602/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0133\n",
      "Epoch 602: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0133 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 603/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0133\n",
      "Epoch 603: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0134 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 604/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0140\n",
      "Epoch 604: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0140 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 605/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0135\n",
      "Epoch 605: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0135 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 606/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0133\n",
      "Epoch 606: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0133 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 607/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0138\n",
      "Epoch 607: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0138 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 608/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0133\n",
      "Epoch 608: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0134 - val_loss: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 609/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0138\n",
      "Epoch 609: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0138 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 610/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0125\n",
      "Epoch 610: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0125 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 611/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0133\n",
      "Epoch 611: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0132 - val_loss: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 612/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0130\n",
      "Epoch 612: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0130 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 613/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0136\n",
      "Epoch 613: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0136 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 614/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0147\n",
      "Epoch 614: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0147 - val_loss: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 615/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0143\n",
      "Epoch 615: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0142 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 616/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0135\n",
      "Epoch 616: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0135 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 617/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0136\n",
      "Epoch 617: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0136 - val_loss: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 618/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0127\n",
      "Epoch 618: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0127 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 619/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0130\n",
      "Epoch 619: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0131 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 620/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0131\n",
      "Epoch 620: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0131 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 621/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0138\n",
      "Epoch 621: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0138 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 622/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0135\n",
      "Epoch 622: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0135 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 623/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0129\n",
      "Epoch 623: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0129 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 624/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0134\n",
      "Epoch 624: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0134 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 625/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0135\n",
      "Epoch 625: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0135 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 626/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0140\n",
      "Epoch 626: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0140 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 627/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0132\n",
      "Epoch 627: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0132 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 628/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0129\n",
      "Epoch 628: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0129 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 629/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0125\n",
      "Epoch 629: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0126 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 630/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0128\n",
      "Epoch 630: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0128 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 631/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0128\n",
      "Epoch 631: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0128 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 632/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0128\n",
      "Epoch 632: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0129 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 633/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0127\n",
      "Epoch 633: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0128 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 634/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0132\n",
      "Epoch 634: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0132 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 635/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0125\n",
      "Epoch 635: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0125 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 636/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0130\n",
      "Epoch 636: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0130 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 637/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0135\n",
      "Epoch 637: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0135 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 638/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0132\n",
      "Epoch 638: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0133 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 639/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0130\n",
      "Epoch 639: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0130 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 640/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0130\n",
      "Epoch 640: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0131 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 641/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0125\n",
      "Epoch 641: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0126 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 642/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0129\n",
      "Epoch 642: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0130 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 643/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0132\n",
      "Epoch 643: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0132 - val_loss: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 644/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0127\n",
      "Epoch 644: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0127 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 645/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0135\n",
      "Epoch 645: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0135 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 646/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0130\n",
      "Epoch 646: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0129 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 647/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0122\n",
      "Epoch 647: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0122 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 648/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0127\n",
      "Epoch 648: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0127 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 649/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0118\n",
      "Epoch 649: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0119 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 650/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0121\n",
      "Epoch 650: val_loss did not improve from 0.00705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0122 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 651/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0144\n",
      "Epoch 651: val_loss improved from 0.00705 to 0.00682, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0144 - val_loss: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 652/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0130\n",
      "Epoch 652: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0130 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 653/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0126\n",
      "Epoch 653: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0125 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 654/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0134\n",
      "Epoch 654: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0134 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 655/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0136\n",
      "Epoch 655: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0136 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 656/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0141\n",
      "Epoch 656: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0140 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 657/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0132\n",
      "Epoch 657: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0132 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 658/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0126\n",
      "Epoch 658: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0126 - val_loss: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 659/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0128\n",
      "Epoch 659: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0129 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 660/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0131\n",
      "Epoch 660: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0131 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 661/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0135\n",
      "Epoch 661: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0134 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 662/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0124\n",
      "Epoch 662: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0124 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 663/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0132\n",
      "Epoch 663: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0132 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 664/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0131\n",
      "Epoch 664: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0132 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 665/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0124\n",
      "Epoch 665: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0124 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 666/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0119\n",
      "Epoch 666: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0119 - val_loss: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 667/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0126\n",
      "Epoch 667: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0126 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 668/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0132\n",
      "Epoch 668: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0131 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 669/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0137\n",
      "Epoch 669: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0137 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 670/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0131\n",
      "Epoch 670: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0131 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 671/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0127\n",
      "Epoch 671: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0127 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 672/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0129\n",
      "Epoch 672: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0129 - val_loss: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 673/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0128\n",
      "Epoch 673: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0127 - val_loss: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 674/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0129\n",
      "Epoch 674: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0129 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 675/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0126\n",
      "Epoch 675: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0126 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 676/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0123\n",
      "Epoch 676: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0123 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 677/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0120\n",
      "Epoch 677: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0121 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 678/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0132\n",
      "Epoch 678: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0131 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 679/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0125\n",
      "Epoch 679: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0124 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 680/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0125\n",
      "Epoch 680: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0126 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 681/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0121\n",
      "Epoch 681: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0121 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 682/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0125\n",
      "Epoch 682: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0126 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 683/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0131\n",
      "Epoch 683: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0131 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 684/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0122\n",
      "Epoch 684: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0123 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 685/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0123\n",
      "Epoch 685: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0124 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 686/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0120\n",
      "Epoch 686: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0120 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 687/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0115\n",
      "Epoch 687: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0115 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 688/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0115\n",
      "Epoch 688: val_loss did not improve from 0.00682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0115 - val_loss: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 689/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0121\n",
      "Epoch 689: val_loss improved from 0.00682 to 0.00665, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0121 - val_loss: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 690/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0119\n",
      "Epoch 690: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0119 - val_loss: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 691/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0117\n",
      "Epoch 691: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0117 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 692/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0113\n",
      "Epoch 692: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0113 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 693/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0127\n",
      "Epoch 693: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0127 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 694/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0137\n",
      "Epoch 694: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0138 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 695/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0143\n",
      "Epoch 695: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0142 - val_loss: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 696/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0136\n",
      "Epoch 696: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0136 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 697/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0141\n",
      "Epoch 697: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0141 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 698/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0131\n",
      "Epoch 698: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0131 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 699/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0134\n",
      "Epoch 699: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0134 - val_loss: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 700/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0130\n",
      "Epoch 700: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0130 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 701/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0120\n",
      "Epoch 701: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0120 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 702/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0123\n",
      "Epoch 702: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0123 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 703/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0119\n",
      "Epoch 703: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0119 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 704/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0121\n",
      "Epoch 704: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0122 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 705/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0124\n",
      "Epoch 705: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0124 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 706/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0116\n",
      "Epoch 706: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0116 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 707/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0122\n",
      "Epoch 707: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0122 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 708/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0127\n",
      "Epoch 708: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0127 - val_loss: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 709/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0120\n",
      "Epoch 709: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0120 - val_loss: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 710/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0129\n",
      "Epoch 710: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0129 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 711/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0128\n",
      "Epoch 711: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0128 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 712/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0126\n",
      "Epoch 712: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0126 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 713/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0124\n",
      "Epoch 713: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0124 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 714/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0118\n",
      "Epoch 714: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0118 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 715/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0120\n",
      "Epoch 715: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0121 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 716/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0143\n",
      "Epoch 716: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0144 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 717/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0143\n",
      "Epoch 717: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0143 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 718/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0126\n",
      "Epoch 718: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0127 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 719/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0128\n",
      "Epoch 719: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0128 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 720/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0120\n",
      "Epoch 720: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0120 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 721/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0120\n",
      "Epoch 721: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0120 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 722/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0131\n",
      "Epoch 722: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0130 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 723/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0121\n",
      "Epoch 723: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0122 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 724/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0135\n",
      "Epoch 724: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0135 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 725/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0130\n",
      "Epoch 725: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0130 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 726/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0131\n",
      "Epoch 726: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0131 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 727/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0115\n",
      "Epoch 727: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0116 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 728/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0127\n",
      "Epoch 728: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0126 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 729/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0123\n",
      "Epoch 729: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0123 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 730/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0114\n",
      "Epoch 730: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0114 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 731/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0120\n",
      "Epoch 731: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0120 - val_loss: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 732/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0115\n",
      "Epoch 732: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0116 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 733/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0118\n",
      "Epoch 733: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0118 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 734/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0117\n",
      "Epoch 734: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0117 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 735/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0123\n",
      "Epoch 735: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0122 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 736/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0123\n",
      "Epoch 736: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0123 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 737/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0118\n",
      "Epoch 737: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0119 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 738/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0128\n",
      "Epoch 738: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0128 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 739/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0138\n",
      "Epoch 739: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0137 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 740/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0127\n",
      "Epoch 740: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0126 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 741/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0128\n",
      "Epoch 741: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0128 - val_loss: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 742/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0119\n",
      "Epoch 742: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0119 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 743/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0117\n",
      "Epoch 743: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0117 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 744/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0116\n",
      "Epoch 744: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0117 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 745/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0122\n",
      "Epoch 745: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0122 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 746/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0118\n",
      "Epoch 746: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0118 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 747/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0117\n",
      "Epoch 747: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0117 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 748/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0116\n",
      "Epoch 748: val_loss did not improve from 0.00665\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0116 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 749/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0118\n",
      "Epoch 749: val_loss improved from 0.00665 to 0.00658, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0118 - val_loss: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 750/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0112\n",
      "Epoch 750: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0112 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 751/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0112\n",
      "Epoch 751: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0112 - val_loss: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 752/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0116\n",
      "Epoch 752: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0116 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 753/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0112\n",
      "Epoch 753: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0112 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 754/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0115\n",
      "Epoch 754: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0115 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 755/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0126\n",
      "Epoch 755: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0126 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 756/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0124\n",
      "Epoch 756: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0124 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 757/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0137\n",
      "Epoch 757: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0136 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 758/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0117\n",
      "Epoch 758: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0117 - val_loss: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 759/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0114\n",
      "Epoch 759: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0114 - val_loss: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 760/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0119\n",
      "Epoch 760: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0119 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 761/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0117\n",
      "Epoch 761: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0118 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 762/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0117\n",
      "Epoch 762: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0118 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 763/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0114\n",
      "Epoch 763: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0114 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 764/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0114\n",
      "Epoch 764: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0114 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 765/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0140\n",
      "Epoch 765: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0140 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 766/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0123\n",
      "Epoch 766: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0123 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 767/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0120\n",
      "Epoch 767: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0119 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 768/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0114\n",
      "Epoch 768: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0114 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 769/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0116\n",
      "Epoch 769: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0116 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 770/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0111\n",
      "Epoch 770: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0112 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 771/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0120\n",
      "Epoch 771: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0120 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 772/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0111\n",
      "Epoch 772: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0111 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 773/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0117\n",
      "Epoch 773: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0117 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 774/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0116\n",
      "Epoch 774: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0116 - val_loss: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 775/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0114\n",
      "Epoch 775: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0114 - val_loss: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 776/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0122\n",
      "Epoch 776: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0123 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 777/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0129\n",
      "Epoch 777: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0129 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 778/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0120\n",
      "Epoch 778: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0120 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 779/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0113\n",
      "Epoch 779: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0113 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 780/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0109\n",
      "Epoch 780: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0110 - val_loss: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 781/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0121\n",
      "Epoch 781: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0120 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 782/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0112\n",
      "Epoch 782: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0112 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 783/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0110\n",
      "Epoch 783: val_loss did not improve from 0.00658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0110 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 784/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0111\n",
      "Epoch 784: val_loss improved from 0.00658 to 0.00636, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0112 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 785/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0111\n",
      "Epoch 785: val_loss did not improve from 0.00636\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0111 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 786/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0111\n",
      "Epoch 786: val_loss improved from 0.00636 to 0.00627, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0111 - val_loss: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 787/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0109\n",
      "Epoch 787: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0109 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 788/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0116\n",
      "Epoch 788: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0116 - val_loss: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 789/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0112\n",
      "Epoch 789: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0113 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 790/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0121\n",
      "Epoch 790: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0121 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 791/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0122\n",
      "Epoch 791: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0122 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 792/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0114\n",
      "Epoch 792: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0113 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 793/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0107\n",
      "Epoch 793: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0107 - val_loss: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 794/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0106\n",
      "Epoch 794: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0106 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 795/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0112\n",
      "Epoch 795: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0112 - val_loss: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 796/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0110\n",
      "Epoch 796: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0110 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 797/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0114\n",
      "Epoch 797: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0114 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 798/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0106\n",
      "Epoch 798: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0106 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 799/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0115\n",
      "Epoch 799: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0115 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 800/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0111\n",
      "Epoch 800: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0111 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 801/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0116\n",
      "Epoch 801: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0116 - val_loss: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 802/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0107\n",
      "Epoch 802: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0107 - val_loss: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 803/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0106\n",
      "Epoch 803: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0107 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 804/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0117\n",
      "Epoch 804: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0117 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 805/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0107\n",
      "Epoch 805: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0107 - val_loss: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 806/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0111\n",
      "Epoch 806: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0111 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 807/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0108\n",
      "Epoch 807: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0108 - val_loss: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 808/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0111\n",
      "Epoch 808: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0111 - val_loss: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 809/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0103\n",
      "Epoch 809: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0104 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 810/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0121\n",
      "Epoch 810: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0120 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 811/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0115\n",
      "Epoch 811: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0115 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 812/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0121\n",
      "Epoch 812: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0120 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 813/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0102\n",
      "Epoch 813: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0103 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 814/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0106\n",
      "Epoch 814: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0106 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 815/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0115\n",
      "Epoch 815: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0115 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 816/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0106\n",
      "Epoch 816: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0107 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 817/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0107\n",
      "Epoch 817: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0107 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 818/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0107\n",
      "Epoch 818: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0107 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 819/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0109\n",
      "Epoch 819: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0109 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 820/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0106\n",
      "Epoch 820: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0106 - val_loss: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 821/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0107\n",
      "Epoch 821: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0107 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 822/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0113\n",
      "Epoch 822: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0113 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 823/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0107\n",
      "Epoch 823: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0107 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 824/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0109\n",
      "Epoch 824: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0109 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 825/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0106\n",
      "Epoch 825: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0107 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 826/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0109\n",
      "Epoch 826: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0109 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 827/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0109\n",
      "Epoch 827: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0109 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 828/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0105\n",
      "Epoch 828: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0105 - val_loss: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 829/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0112\n",
      "Epoch 829: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0112 - val_loss: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 830/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0110\n",
      "Epoch 830: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0111 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 831/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0115\n",
      "Epoch 831: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0115 - val_loss: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 832/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0114\n",
      "Epoch 832: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0114 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 833/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0120\n",
      "Epoch 833: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0120 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 834/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0116\n",
      "Epoch 834: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0116 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 835/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0115\n",
      "Epoch 835: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0115 - val_loss: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 836/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0122\n",
      "Epoch 836: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0122 - val_loss: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 837/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0114\n",
      "Epoch 837: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0114 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 838/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0107\n",
      "Epoch 838: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0107 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 839/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0109\n",
      "Epoch 839: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0109 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 840/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0112\n",
      "Epoch 840: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0111 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 841/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0107\n",
      "Epoch 841: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0107 - val_loss: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 842/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0103\n",
      "Epoch 842: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0103 - val_loss: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 843/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0104\n",
      "Epoch 843: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0104 - val_loss: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 844/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0113\n",
      "Epoch 844: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0112 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 845/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0117\n",
      "Epoch 845: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0117 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 846/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0116\n",
      "Epoch 846: val_loss did not improve from 0.00627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0115 - val_loss: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 847/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0113\n",
      "Epoch 847: val_loss improved from 0.00627 to 0.00619, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0113 - val_loss: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 848/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0104\n",
      "Epoch 848: val_loss did not improve from 0.00619\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0104 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 849/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0105\n",
      "Epoch 849: val_loss did not improve from 0.00619\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0105 - val_loss: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 850/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0107\n",
      "Epoch 850: val_loss did not improve from 0.00619\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0106 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 851/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0106\n",
      "Epoch 851: val_loss did not improve from 0.00619\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0106 - val_loss: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 852/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0107\n",
      "Epoch 852: val_loss did not improve from 0.00619\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0108 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 853/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0119\n",
      "Epoch 853: val_loss did not improve from 0.00619\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0119 - val_loss: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 854/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0107\n",
      "Epoch 854: val_loss did not improve from 0.00619\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0107 - val_loss: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 855/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0113\n",
      "Epoch 855: val_loss did not improve from 0.00619\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0112 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 856/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0105\n",
      "Epoch 856: val_loss did not improve from 0.00619\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0105 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 857/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0111\n",
      "Epoch 857: val_loss did not improve from 0.00619\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0110 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 858/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0106\n",
      "Epoch 858: val_loss did not improve from 0.00619\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0106 - val_loss: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 859/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0113\n",
      "Epoch 859: val_loss did not improve from 0.00619\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0113 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 860/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0108\n",
      "Epoch 860: val_loss did not improve from 0.00619\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0108 - val_loss: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 861/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0106\n",
      "Epoch 861: val_loss did not improve from 0.00619\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0107 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 862/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0109\n",
      "Epoch 862: val_loss improved from 0.00619 to 0.00616, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0109 - val_loss: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 863/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0113\n",
      "Epoch 863: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0113 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 864/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0110\n",
      "Epoch 864: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0110 - val_loss: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 865/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0107\n",
      "Epoch 865: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0107 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 866/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0108\n",
      "Epoch 866: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0108 - val_loss: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 867/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0112\n",
      "Epoch 867: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0113 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 868/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0110\n",
      "Epoch 868: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0110 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 869/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0107\n",
      "Epoch 869: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0108 - val_loss: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 870/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0111\n",
      "Epoch 870: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0111 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 871/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0114\n",
      "Epoch 871: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0113 - val_loss: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 872/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0113\n",
      "Epoch 872: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0113 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 873/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0108\n",
      "Epoch 873: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0108 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 874/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0105\n",
      "Epoch 874: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0105 - val_loss: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 875/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0101\n",
      "Epoch 875: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0101 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 876/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0116\n",
      "Epoch 876: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0115 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 877/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0111\n",
      "Epoch 877: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0112 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 878/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0116\n",
      "Epoch 878: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0116 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 879/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0108\n",
      "Epoch 879: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0108 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 880/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0109\n",
      "Epoch 880: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0109 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 881/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0106\n",
      "Epoch 881: val_loss did not improve from 0.00616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0107 - val_loss: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 882/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0107\n",
      "Epoch 882: val_loss improved from 0.00616 to 0.00614, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0107 - val_loss: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 883/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0116\n",
      "Epoch 883: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0115 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 884/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0112\n",
      "Epoch 884: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0112 - val_loss: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 885/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0102\n",
      "Epoch 885: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0102 - val_loss: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 886/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0108\n",
      "Epoch 886: val_loss improved from 0.00614 to 0.00614, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0108 - val_loss: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 887/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0103\n",
      "Epoch 887: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0103 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 888/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0106\n",
      "Epoch 888: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0107 - val_loss: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 889/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0105\n",
      "Epoch 889: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0105 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 890/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0114\n",
      "Epoch 890: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0114 - val_loss: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 891/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0131\n",
      "Epoch 891: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0130 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 892/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0117\n",
      "Epoch 892: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0116 - val_loss: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 893/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0108\n",
      "Epoch 893: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0108 - val_loss: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 894/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0106\n",
      "Epoch 894: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0106 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 895/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0102\n",
      "Epoch 895: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0102 - val_loss: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 896/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0106\n",
      "Epoch 896: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0106 - val_loss: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 897/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0105 \n",
      "Epoch 897: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0105 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 898/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0099\n",
      "Epoch 898: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0099 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 899/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0104\n",
      "Epoch 899: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0104 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 900/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0102\n",
      "Epoch 900: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0102 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 901/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0106\n",
      "Epoch 901: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0106 - val_loss: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 902/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0110\n",
      "Epoch 902: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0110 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 903/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0106\n",
      "Epoch 903: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0106 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 904/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0101\n",
      "Epoch 904: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0101 - val_loss: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 905/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0097\n",
      "Epoch 905: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0098 - val_loss: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 906/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0103\n",
      "Epoch 906: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0104 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 907/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0099\n",
      "Epoch 907: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0100 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 908/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0104\n",
      "Epoch 908: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0104 - val_loss: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 909/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0107\n",
      "Epoch 909: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0107 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 910/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0108\n",
      "Epoch 910: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0108 - val_loss: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 911/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0115\n",
      "Epoch 911: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0116 - val_loss: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 912/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0110\n",
      "Epoch 912: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0110 - val_loss: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 913/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0110\n",
      "Epoch 913: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0110 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 914/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0103\n",
      "Epoch 914: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0103 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 915/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0104\n",
      "Epoch 915: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0104 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 916/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0098\n",
      "Epoch 916: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0098 - val_loss: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 917/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0101\n",
      "Epoch 917: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0101 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 918/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0102\n",
      "Epoch 918: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0101 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 919/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0098\n",
      "Epoch 919: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0098 - val_loss: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 920/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0107\n",
      "Epoch 920: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0107 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 921/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0099\n",
      "Epoch 921: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0099 - val_loss: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 922/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0105\n",
      "Epoch 922: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0105 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 923/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0107\n",
      "Epoch 923: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0107 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 924/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0114\n",
      "Epoch 924: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0114 - val_loss: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 925/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0111\n",
      "Epoch 925: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0111 - val_loss: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 926/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0110\n",
      "Epoch 926: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0110 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 927/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0109\n",
      "Epoch 927: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0109 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 928/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0113\n",
      "Epoch 928: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0113 - val_loss: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 929/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0105\n",
      "Epoch 929: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0105 - val_loss: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 930/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0106\n",
      "Epoch 930: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0106 - val_loss: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 931/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0106\n",
      "Epoch 931: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0106 - val_loss: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 932/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0105\n",
      "Epoch 932: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0106 - val_loss: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 933/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0099 \n",
      "Epoch 933: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0100 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 934/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0107\n",
      "Epoch 934: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0107 - val_loss: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 935/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0101\n",
      "Epoch 935: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0101 - val_loss: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 936/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0104\n",
      "Epoch 936: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0104 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 937/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0100\n",
      "Epoch 937: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0100 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 938/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0098\n",
      "Epoch 938: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0098 - val_loss: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 939/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0106\n",
      "Epoch 939: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0105 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 940/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0102\n",
      "Epoch 940: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0103 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 941/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0106\n",
      "Epoch 941: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0106 - val_loss: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 942/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0100\n",
      "Epoch 942: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0100 - val_loss: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 943/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0101\n",
      "Epoch 943: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0101 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 944/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0104\n",
      "Epoch 944: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0104 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 945/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0103\n",
      "Epoch 945: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0103 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 946/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0100\n",
      "Epoch 946: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0101 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 947/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0103\n",
      "Epoch 947: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0103 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 948/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0106\n",
      "Epoch 948: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0106 - val_loss: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 949/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0104\n",
      "Epoch 949: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0104 - val_loss: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 950/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0100\n",
      "Epoch 950: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0100 - val_loss: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 951/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0099\n",
      "Epoch 951: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0099 - val_loss: 0.0067 - learning_rate: 0.0010\n",
      "Epoch 952/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0099\n",
      "Epoch 952: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0099 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 953/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0104\n",
      "Epoch 953: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0104 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 954/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0106\n",
      "Epoch 954: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0106 - val_loss: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 955/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0109\n",
      "Epoch 955: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0109 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 956/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0101\n",
      "Epoch 956: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0102 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 957/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0100\n",
      "Epoch 957: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0100 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 958/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0102\n",
      "Epoch 958: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0103 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 959/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0102\n",
      "Epoch 959: val_loss did not improve from 0.00614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0102 - val_loss: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 960/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0099\n",
      "Epoch 960: val_loss improved from 0.00614 to 0.00589, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0099 - val_loss: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 961/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0100\n",
      "Epoch 961: val_loss did not improve from 0.00589\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0100 - val_loss: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 962/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0103\n",
      "Epoch 962: val_loss did not improve from 0.00589\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0103 - val_loss: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 963/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0101\n",
      "Epoch 963: val_loss did not improve from 0.00589\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0101 - val_loss: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 964/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0103\n",
      "Epoch 964: val_loss improved from 0.00589 to 0.00588, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0102 - val_loss: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 965/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0100\n",
      "Epoch 965: val_loss did not improve from 0.00588\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0100 - val_loss: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 966/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0096\n",
      "Epoch 966: val_loss did not improve from 0.00588\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0097 - val_loss: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 967/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0101\n",
      "Epoch 967: val_loss did not improve from 0.00588\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0101 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 968/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0097\n",
      "Epoch 968: val_loss did not improve from 0.00588\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0097 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 969/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0095\n",
      "Epoch 969: val_loss did not improve from 0.00588\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0095 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 970/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0098\n",
      "Epoch 970: val_loss did not improve from 0.00588\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0098 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 971/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0107\n",
      "Epoch 971: val_loss did not improve from 0.00588\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0107 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 972/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0102\n",
      "Epoch 972: val_loss did not improve from 0.00588\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0102 - val_loss: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 973/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0101\n",
      "Epoch 973: val_loss did not improve from 0.00588\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0101 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 974/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0106\n",
      "Epoch 974: val_loss did not improve from 0.00588\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0106 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 975/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0102\n",
      "Epoch 975: val_loss did not improve from 0.00588\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0103 - val_loss: 0.0061 - learning_rate: 0.0010\n",
      "Epoch 976/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0104\n",
      "Epoch 976: val_loss improved from 0.00588 to 0.00577, saving model to ./result_folder_no_misc/lstm_ts_3.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0104 - val_loss: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 977/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0101\n",
      "Epoch 977: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0101 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 978/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0106\n",
      "Epoch 978: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0105 - val_loss: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 979/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0102\n",
      "Epoch 979: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0103 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 980/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0104\n",
      "Epoch 980: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0104 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 981/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0096\n",
      "Epoch 981: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0097 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 982/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0101\n",
      "Epoch 982: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0101 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 983/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0094\n",
      "Epoch 983: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0094 - val_loss: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 984/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0096\n",
      "Epoch 984: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0096 - val_loss: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 985/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0089\n",
      "Epoch 985: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0090 - val_loss: 0.0062 - learning_rate: 0.0010\n",
      "Epoch 986/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0100\n",
      "Epoch 986: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0100 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 987/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0101\n",
      "Epoch 987: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0102 - val_loss: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 988/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0105\n",
      "Epoch 988: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0105 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 989/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0104\n",
      "Epoch 989: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0104 - val_loss: 0.0066 - learning_rate: 0.0010\n",
      "Epoch 990/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0113\n",
      "Epoch 990: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0113 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 991/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0099\n",
      "Epoch 991: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0100 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 992/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0100\n",
      "Epoch 992: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0100 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 993/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0098\n",
      "Epoch 993: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0098 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 994/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0093\n",
      "Epoch 994: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0093 - val_loss: 0.0064 - learning_rate: 0.0010\n",
      "Epoch 995/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0103\n",
      "Epoch 995: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0103 - val_loss: 0.0076 - learning_rate: 0.0010\n",
      "Epoch 996/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0099\n",
      "Epoch 996: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0099 - val_loss: 0.0070 - learning_rate: 0.0010\n",
      "Epoch 997/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0093\n",
      "Epoch 997: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0093 - val_loss: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 998/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0095\n",
      "Epoch 998: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0095 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 999/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0092\n",
      "Epoch 999: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0093 - val_loss: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 1000/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0102\n",
      "Epoch 1000: val_loss did not improve from 0.00577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0101 - val_loss: 0.0065 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 976.\n",
      "EUA\n",
      "0.07205873252810431\n",
      "Oil\n",
      "0.12170323073304223\n",
      "Coal\n",
      "0.024388380373017566\n",
      "NG\n",
      "0.061390007567675015\n",
      "USEU\n",
      "0.07174250011005781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 180/180 [01:33<00:00,  1.93it/s]\n",
      "100%|| 180/180 [05:28<00:00,  1.82s/it]\n",
      "/home/honggeunjo/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.9362\n",
      "Epoch 1: val_loss improved from inf to 0.80294, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 187ms/step - loss: 1.8836 - val_loss: 0.8029 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.5847\n",
      "Epoch 2: val_loss improved from 0.80294 to 0.40438, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.5832 - val_loss: 0.4044 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.4604\n",
      "Epoch 3: val_loss improved from 0.40438 to 0.38280, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.4601 - val_loss: 0.3828 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.4291\n",
      "Epoch 4: val_loss improved from 0.38280 to 0.36674, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.4281 - val_loss: 0.3667 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.3935\n",
      "Epoch 5: val_loss improved from 0.36674 to 0.35355, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.3934 - val_loss: 0.3536 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.3805\n",
      "Epoch 6: val_loss improved from 0.35355 to 0.34480, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.3803 - val_loss: 0.3448 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.3711\n",
      "Epoch 7: val_loss improved from 0.34480 to 0.33401, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.3709 - val_loss: 0.3340 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.3606\n",
      "Epoch 8: val_loss improved from 0.33401 to 0.33008, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.3606 - val_loss: 0.3301 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.3532\n",
      "Epoch 9: val_loss improved from 0.33008 to 0.32133, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.3529 - val_loss: 0.3213 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.3458\n",
      "Epoch 10: val_loss improved from 0.32133 to 0.31716, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.3455 - val_loss: 0.3172 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.3356\n",
      "Epoch 11: val_loss improved from 0.31716 to 0.30861, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.3355 - val_loss: 0.3086 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.3278\n",
      "Epoch 12: val_loss improved from 0.30861 to 0.30177, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.3277 - val_loss: 0.3018 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.3224\n",
      "Epoch 13: val_loss improved from 0.30177 to 0.29411, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.3222 - val_loss: 0.2941 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.3135\n",
      "Epoch 14: val_loss improved from 0.29411 to 0.28986, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.3134 - val_loss: 0.2899 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.3072\n",
      "Epoch 15: val_loss improved from 0.28986 to 0.28311, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.3071 - val_loss: 0.2831 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.2990\n",
      "Epoch 16: val_loss improved from 0.28311 to 0.27798, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.2989 - val_loss: 0.2780 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.2904 \n",
      "Epoch 17: val_loss improved from 0.27798 to 0.26967, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.2904 - val_loss: 0.2697 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.2841\n",
      "Epoch 18: val_loss improved from 0.26967 to 0.26709, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.2840 - val_loss: 0.2671 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.2784\n",
      "Epoch 19: val_loss improved from 0.26709 to 0.25621, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.2783 - val_loss: 0.2562 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.2717\n",
      "Epoch 20: val_loss improved from 0.25621 to 0.25149, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.2717 - val_loss: 0.2515 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.2651\n",
      "Epoch 21: val_loss improved from 0.25149 to 0.24835, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.2651 - val_loss: 0.2484 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.2608\n",
      "Epoch 22: val_loss improved from 0.24835 to 0.24074, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.2607 - val_loss: 0.2407 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.2542\n",
      "Epoch 23: val_loss improved from 0.24074 to 0.23947, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.2541 - val_loss: 0.2395 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.2494\n",
      "Epoch 24: val_loss improved from 0.23947 to 0.23356, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.2493 - val_loss: 0.2336 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.2426\n",
      "Epoch 25: val_loss improved from 0.23356 to 0.22552, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.2427 - val_loss: 0.2255 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.2383\n",
      "Epoch 26: val_loss improved from 0.22552 to 0.22154, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.2383 - val_loss: 0.2215 - learning_rate: 0.0010\n",
      "Epoch 27/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.2343\n",
      "Epoch 27: val_loss improved from 0.22154 to 0.21718, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.2343 - val_loss: 0.2172 - learning_rate: 0.0010\n",
      "Epoch 28/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.2293\n",
      "Epoch 28: val_loss improved from 0.21718 to 0.20888, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.2292 - val_loss: 0.2089 - learning_rate: 0.0010\n",
      "Epoch 29/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.2223\n",
      "Epoch 29: val_loss improved from 0.20888 to 0.20575, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.2224 - val_loss: 0.2057 - learning_rate: 0.0010\n",
      "Epoch 30/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.2175\n",
      "Epoch 30: val_loss did not improve from 0.20575\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.2175 - val_loss: 0.2198 - learning_rate: 0.0010\n",
      "Epoch 31/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.2148\n",
      "Epoch 31: val_loss improved from 0.20575 to 0.19908, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.2148 - val_loss: 0.1991 - learning_rate: 0.0010\n",
      "Epoch 32/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.2102\n",
      "Epoch 32: val_loss improved from 0.19908 to 0.19468, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.2101 - val_loss: 0.1947 - learning_rate: 0.0010\n",
      "Epoch 33/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.2066\n",
      "Epoch 33: val_loss improved from 0.19468 to 0.18917, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.2065 - val_loss: 0.1892 - learning_rate: 0.0010\n",
      "Epoch 34/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.2012\n",
      "Epoch 34: val_loss improved from 0.18917 to 0.18636, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.2011 - val_loss: 0.1864 - learning_rate: 0.0010\n",
      "Epoch 35/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.1962\n",
      "Epoch 35: val_loss did not improve from 0.18636\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1962 - val_loss: 0.1868 - learning_rate: 0.0010\n",
      "Epoch 36/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.1933\n",
      "Epoch 36: val_loss improved from 0.18636 to 0.18231, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1933 - val_loss: 0.1823 - learning_rate: 0.0010\n",
      "Epoch 37/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.1895\n",
      "Epoch 37: val_loss improved from 0.18231 to 0.17389, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1895 - val_loss: 0.1739 - learning_rate: 0.0010\n",
      "Epoch 38/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.1869\n",
      "Epoch 38: val_loss improved from 0.17389 to 0.17137, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.1867 - val_loss: 0.1714 - learning_rate: 0.0010\n",
      "Epoch 39/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.1843\n",
      "Epoch 39: val_loss did not improve from 0.17137\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1842 - val_loss: 0.1717 - learning_rate: 0.0010\n",
      "Epoch 40/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.1815\n",
      "Epoch 40: val_loss improved from 0.17137 to 0.17077, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.1813 - val_loss: 0.1708 - learning_rate: 0.0010\n",
      "Epoch 41/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1764\n",
      "Epoch 41: val_loss improved from 0.17077 to 0.16102, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.1764 - val_loss: 0.1610 - learning_rate: 0.0010\n",
      "Epoch 42/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.1743\n",
      "Epoch 42: val_loss did not improve from 0.16102\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1743 - val_loss: 0.1669 - learning_rate: 0.0010\n",
      "Epoch 43/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.1699\n",
      "Epoch 43: val_loss improved from 0.16102 to 0.15416, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.1698 - val_loss: 0.1542 - learning_rate: 0.0010\n",
      "Epoch 44/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.1645\n",
      "Epoch 44: val_loss did not improve from 0.15416\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1645 - val_loss: 0.1574 - learning_rate: 0.0010\n",
      "Epoch 45/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.1617\n",
      "Epoch 45: val_loss improved from 0.15416 to 0.14991, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.1617 - val_loss: 0.1499 - learning_rate: 0.0010\n",
      "Epoch 46/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.1594\n",
      "Epoch 46: val_loss improved from 0.14991 to 0.14891, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.1594 - val_loss: 0.1489 - learning_rate: 0.0010\n",
      "Epoch 47/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1581\n",
      "Epoch 47: val_loss improved from 0.14891 to 0.14561, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.1581 - val_loss: 0.1456 - learning_rate: 0.0010\n",
      "Epoch 48/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.1554\n",
      "Epoch 48: val_loss improved from 0.14561 to 0.14149, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.1553 - val_loss: 0.1415 - learning_rate: 0.0010\n",
      "Epoch 49/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1512\n",
      "Epoch 49: val_loss improved from 0.14149 to 0.14051, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.1513 - val_loss: 0.1405 - learning_rate: 0.0010\n",
      "Epoch 50/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.1499\n",
      "Epoch 50: val_loss improved from 0.14051 to 0.13733, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.1498 - val_loss: 0.1373 - learning_rate: 0.0010\n",
      "Epoch 51/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.1466\n",
      "Epoch 51: val_loss did not improve from 0.13733\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1466 - val_loss: 0.1393 - learning_rate: 0.0010\n",
      "Epoch 52/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1447\n",
      "Epoch 52: val_loss improved from 0.13733 to 0.13292, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.1448 - val_loss: 0.1329 - learning_rate: 0.0010\n",
      "Epoch 53/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.1441\n",
      "Epoch 53: val_loss did not improve from 0.13292\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1440 - val_loss: 0.1368 - learning_rate: 0.0010\n",
      "Epoch 54/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.1410\n",
      "Epoch 54: val_loss improved from 0.13292 to 0.12882, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.1410 - val_loss: 0.1288 - learning_rate: 0.0010\n",
      "Epoch 55/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1388\n",
      "Epoch 55: val_loss improved from 0.12882 to 0.12576, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.1389 - val_loss: 0.1258 - learning_rate: 0.0010\n",
      "Epoch 56/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.1390\n",
      "Epoch 56: val_loss did not improve from 0.12576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1390 - val_loss: 0.1293 - learning_rate: 0.0010\n",
      "Epoch 57/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1359\n",
      "Epoch 57: val_loss improved from 0.12576 to 0.12252, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.1359 - val_loss: 0.1225 - learning_rate: 0.0010\n",
      "Epoch 58/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.1334\n",
      "Epoch 58: val_loss improved from 0.12252 to 0.12148, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.1334 - val_loss: 0.1215 - learning_rate: 0.0010\n",
      "Epoch 59/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.1321\n",
      "Epoch 59: val_loss did not improve from 0.12148\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1321 - val_loss: 0.1215 - learning_rate: 0.0010\n",
      "Epoch 60/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.1304\n",
      "Epoch 60: val_loss did not improve from 0.12148\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1303 - val_loss: 0.1258 - learning_rate: 0.0010\n",
      "Epoch 61/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.1283\n",
      "Epoch 61: val_loss improved from 0.12148 to 0.12140, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.1281 - val_loss: 0.1214 - learning_rate: 0.0010\n",
      "Epoch 62/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.1249\n",
      "Epoch 62: val_loss improved from 0.12140 to 0.11448, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.1248 - val_loss: 0.1145 - learning_rate: 0.0010\n",
      "Epoch 63/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.1231\n",
      "Epoch 63: val_loss improved from 0.11448 to 0.11263, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1232 - val_loss: 0.1126 - learning_rate: 0.0010\n",
      "Epoch 64/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.1232\n",
      "Epoch 64: val_loss improved from 0.11263 to 0.11020, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.1231 - val_loss: 0.1102 - learning_rate: 0.0010\n",
      "Epoch 65/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.1198\n",
      "Epoch 65: val_loss improved from 0.11020 to 0.10938, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.1198 - val_loss: 0.1094 - learning_rate: 0.0010\n",
      "Epoch 66/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.1199\n",
      "Epoch 66: val_loss did not improve from 0.10938\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1199 - val_loss: 0.1110 - learning_rate: 0.0010\n",
      "Epoch 67/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.1155\n",
      "Epoch 67: val_loss did not improve from 0.10938\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1156 - val_loss: 0.1106 - learning_rate: 0.0010\n",
      "Epoch 68/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.1144\n",
      "Epoch 68: val_loss did not improve from 0.10938\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.1145 - val_loss: 0.1126 - learning_rate: 0.0010\n",
      "Epoch 69/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.1143\n",
      "Epoch 69: val_loss improved from 0.10938 to 0.10769, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.1143 - val_loss: 0.1077 - learning_rate: 0.0010\n",
      "Epoch 70/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.1147\n",
      "Epoch 70: val_loss improved from 0.10769 to 0.10164, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1146 - val_loss: 0.1016 - learning_rate: 0.0010\n",
      "Epoch 71/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.1135\n",
      "Epoch 71: val_loss did not improve from 0.10164\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.1135 - val_loss: 0.1083 - learning_rate: 0.0010\n",
      "Epoch 72/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.1118\n",
      "Epoch 72: val_loss improved from 0.10164 to 0.09911, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.1118 - val_loss: 0.0991 - learning_rate: 0.0010\n",
      "Epoch 73/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.1086\n",
      "Epoch 73: val_loss did not improve from 0.09911\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1086 - val_loss: 0.0994 - learning_rate: 0.0010\n",
      "Epoch 74/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.1062\n",
      "Epoch 74: val_loss did not improve from 0.09911\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1062 - val_loss: 0.0996 - learning_rate: 0.0010\n",
      "Epoch 75/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.1052\n",
      "Epoch 75: val_loss improved from 0.09911 to 0.09842, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.1051 - val_loss: 0.0984 - learning_rate: 0.0010\n",
      "Epoch 76/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.1024\n",
      "Epoch 76: val_loss did not improve from 0.09842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1025 - val_loss: 0.1058 - learning_rate: 0.0010\n",
      "Epoch 77/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.1038\n",
      "Epoch 77: val_loss did not improve from 0.09842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.1037 - val_loss: 0.1001 - learning_rate: 0.0010\n",
      "Epoch 78/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.1030\n",
      "Epoch 78: val_loss improved from 0.09842 to 0.09837, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.1029 - val_loss: 0.0984 - learning_rate: 0.0010\n",
      "Epoch 79/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.1012\n",
      "Epoch 79: val_loss improved from 0.09837 to 0.09622, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1011 - val_loss: 0.0962 - learning_rate: 0.0010\n",
      "Epoch 80/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0992\n",
      "Epoch 80: val_loss improved from 0.09622 to 0.09243, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0992 - val_loss: 0.0924 - learning_rate: 0.0010\n",
      "Epoch 81/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0971\n",
      "Epoch 81: val_loss improved from 0.09243 to 0.09019, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0972 - val_loss: 0.0902 - learning_rate: 0.0010\n",
      "Epoch 82/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0978\n",
      "Epoch 82: val_loss did not improve from 0.09019\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0979 - val_loss: 0.0920 - learning_rate: 0.0010\n",
      "Epoch 83/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0989\n",
      "Epoch 83: val_loss did not improve from 0.09019\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0989 - val_loss: 0.0924 - learning_rate: 0.0010\n",
      "Epoch 84/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0973\n",
      "Epoch 84: val_loss improved from 0.09019 to 0.08751, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0972 - val_loss: 0.0875 - learning_rate: 0.0010\n",
      "Epoch 85/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0940\n",
      "Epoch 85: val_loss did not improve from 0.08751\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0940 - val_loss: 0.0894 - learning_rate: 0.0010\n",
      "Epoch 86/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0930\n",
      "Epoch 86: val_loss did not improve from 0.08751\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0931 - val_loss: 0.0888 - learning_rate: 0.0010\n",
      "Epoch 87/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0943\n",
      "Epoch 87: val_loss improved from 0.08751 to 0.08326, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0942 - val_loss: 0.0833 - learning_rate: 0.0010\n",
      "Epoch 88/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0919\n",
      "Epoch 88: val_loss did not improve from 0.08326\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0919 - val_loss: 0.0861 - learning_rate: 0.0010\n",
      "Epoch 89/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0919\n",
      "Epoch 89: val_loss improved from 0.08326 to 0.07996, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0918 - val_loss: 0.0800 - learning_rate: 0.0010\n",
      "Epoch 90/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0899\n",
      "Epoch 90: val_loss did not improve from 0.07996\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0899 - val_loss: 0.0836 - learning_rate: 0.0010\n",
      "Epoch 91/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0894\n",
      "Epoch 91: val_loss did not improve from 0.07996\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0893 - val_loss: 0.0806 - learning_rate: 0.0010\n",
      "Epoch 92/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0881\n",
      "Epoch 92: val_loss did not improve from 0.07996\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0881 - val_loss: 0.0828 - learning_rate: 0.0010\n",
      "Epoch 93/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0879\n",
      "Epoch 93: val_loss did not improve from 0.07996\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0879 - val_loss: 0.0801 - learning_rate: 0.0010\n",
      "Epoch 94/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0850\n",
      "Epoch 94: val_loss improved from 0.07996 to 0.07664, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0850 - val_loss: 0.0766 - learning_rate: 0.0010\n",
      "Epoch 95/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0853\n",
      "Epoch 95: val_loss improved from 0.07664 to 0.07630, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0853 - val_loss: 0.0763 - learning_rate: 0.0010\n",
      "Epoch 96/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0847\n",
      "Epoch 96: val_loss did not improve from 0.07630\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0847 - val_loss: 0.0872 - learning_rate: 0.0010\n",
      "Epoch 97/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0831 \n",
      "Epoch 97: val_loss did not improve from 0.07630\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0831 - val_loss: 0.0793 - learning_rate: 0.0010\n",
      "Epoch 98/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0802\n",
      "Epoch 98: val_loss improved from 0.07630 to 0.07288, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0803 - val_loss: 0.0729 - learning_rate: 0.0010\n",
      "Epoch 99/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0816\n",
      "Epoch 99: val_loss did not improve from 0.07288\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0817 - val_loss: 0.0823 - learning_rate: 0.0010\n",
      "Epoch 100/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0824\n",
      "Epoch 100: val_loss did not improve from 0.07288\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0824 - val_loss: 0.0812 - learning_rate: 0.0010\n",
      "Epoch 101/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0819\n",
      "Epoch 101: val_loss did not improve from 0.07288\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0818 - val_loss: 0.0779 - learning_rate: 0.0010\n",
      "Epoch 102/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0809\n",
      "Epoch 102: val_loss improved from 0.07288 to 0.07134, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0808 - val_loss: 0.0713 - learning_rate: 0.0010\n",
      "Epoch 103/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0761\n",
      "Epoch 103: val_loss improved from 0.07134 to 0.07117, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0762 - val_loss: 0.0712 - learning_rate: 0.0010\n",
      "Epoch 104/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0761\n",
      "Epoch 104: val_loss improved from 0.07117 to 0.06915, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0761 - val_loss: 0.0692 - learning_rate: 0.0010\n",
      "Epoch 105/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0770\n",
      "Epoch 105: val_loss did not improve from 0.06915\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0770 - val_loss: 0.0704 - learning_rate: 0.0010\n",
      "Epoch 106/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0783\n",
      "Epoch 106: val_loss did not improve from 0.06915\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0782 - val_loss: 0.0809 - learning_rate: 0.0010\n",
      "Epoch 107/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0762\n",
      "Epoch 107: val_loss improved from 0.06915 to 0.06654, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0763 - val_loss: 0.0665 - learning_rate: 0.0010\n",
      "Epoch 108/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0766 \n",
      "Epoch 108: val_loss did not improve from 0.06654\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0765 - val_loss: 0.0760 - learning_rate: 0.0010\n",
      "Epoch 109/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0766\n",
      "Epoch 109: val_loss did not improve from 0.06654\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0767 - val_loss: 0.0693 - learning_rate: 0.0010\n",
      "Epoch 110/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0741\n",
      "Epoch 110: val_loss did not improve from 0.06654\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0742 - val_loss: 0.0710 - learning_rate: 0.0010\n",
      "Epoch 111/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0745\n",
      "Epoch 111: val_loss improved from 0.06654 to 0.06484, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0745 - val_loss: 0.0648 - learning_rate: 0.0010\n",
      "Epoch 112/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0731\n",
      "Epoch 112: val_loss did not improve from 0.06484\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0731 - val_loss: 0.0725 - learning_rate: 0.0010\n",
      "Epoch 113/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0714\n",
      "Epoch 113: val_loss did not improve from 0.06484\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0714 - val_loss: 0.0655 - learning_rate: 0.0010\n",
      "Epoch 114/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0716\n",
      "Epoch 114: val_loss did not improve from 0.06484\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0716 - val_loss: 0.0719 - learning_rate: 0.0010\n",
      "Epoch 115/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0702\n",
      "Epoch 115: val_loss improved from 0.06484 to 0.06417, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0703 - val_loss: 0.0642 - learning_rate: 0.0010\n",
      "Epoch 116/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0726\n",
      "Epoch 116: val_loss did not improve from 0.06417\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0724 - val_loss: 0.0676 - learning_rate: 0.0010\n",
      "Epoch 117/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0701\n",
      "Epoch 117: val_loss improved from 0.06417 to 0.06226, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0701 - val_loss: 0.0623 - learning_rate: 0.0010\n",
      "Epoch 118/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0683\n",
      "Epoch 118: val_loss did not improve from 0.06226\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0683 - val_loss: 0.0627 - learning_rate: 0.0010\n",
      "Epoch 119/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0673\n",
      "Epoch 119: val_loss improved from 0.06226 to 0.05977, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0673 - val_loss: 0.0598 - learning_rate: 0.0010\n",
      "Epoch 120/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0671\n",
      "Epoch 120: val_loss did not improve from 0.05977\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0671 - val_loss: 0.0612 - learning_rate: 0.0010\n",
      "Epoch 121/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0669\n",
      "Epoch 121: val_loss did not improve from 0.05977\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0670 - val_loss: 0.0614 - learning_rate: 0.0010\n",
      "Epoch 122/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0687\n",
      "Epoch 122: val_loss did not improve from 0.05977\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0687 - val_loss: 0.0602 - learning_rate: 0.0010\n",
      "Epoch 123/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0656\n",
      "Epoch 123: val_loss improved from 0.05977 to 0.05936, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0656 - val_loss: 0.0594 - learning_rate: 0.0010\n",
      "Epoch 124/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0644\n",
      "Epoch 124: val_loss did not improve from 0.05936\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0644 - val_loss: 0.0610 - learning_rate: 0.0010\n",
      "Epoch 125/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0645\n",
      "Epoch 125: val_loss improved from 0.05936 to 0.05847, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0645 - val_loss: 0.0585 - learning_rate: 0.0010\n",
      "Epoch 126/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0638\n",
      "Epoch 126: val_loss did not improve from 0.05847\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0638 - val_loss: 0.0603 - learning_rate: 0.0010\n",
      "Epoch 127/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0637\n",
      "Epoch 127: val_loss did not improve from 0.05847\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0637 - val_loss: 0.0629 - learning_rate: 0.0010\n",
      "Epoch 128/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0635\n",
      "Epoch 128: val_loss improved from 0.05847 to 0.05786, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0635 - val_loss: 0.0579 - learning_rate: 0.0010\n",
      "Epoch 129/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0635\n",
      "Epoch 129: val_loss did not improve from 0.05786\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0635 - val_loss: 0.0579 - learning_rate: 0.0010\n",
      "Epoch 130/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0625\n",
      "Epoch 130: val_loss improved from 0.05786 to 0.05370, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0625 - val_loss: 0.0537 - learning_rate: 0.0010\n",
      "Epoch 131/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0614\n",
      "Epoch 131: val_loss did not improve from 0.05370\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0614 - val_loss: 0.0595 - learning_rate: 0.0010\n",
      "Epoch 132/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0606\n",
      "Epoch 132: val_loss did not improve from 0.05370\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0606 - val_loss: 0.0569 - learning_rate: 0.0010\n",
      "Epoch 133/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0599\n",
      "Epoch 133: val_loss did not improve from 0.05370\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0600 - val_loss: 0.0555 - learning_rate: 0.0010\n",
      "Epoch 134/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0608\n",
      "Epoch 134: val_loss improved from 0.05370 to 0.05101, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0608 - val_loss: 0.0510 - learning_rate: 0.0010\n",
      "Epoch 135/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0587\n",
      "Epoch 135: val_loss did not improve from 0.05101\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0588 - val_loss: 0.0517 - learning_rate: 0.0010\n",
      "Epoch 136/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0594\n",
      "Epoch 136: val_loss did not improve from 0.05101\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0594 - val_loss: 0.0546 - learning_rate: 0.0010\n",
      "Epoch 137/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0597\n",
      "Epoch 137: val_loss did not improve from 0.05101\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0597 - val_loss: 0.0548 - learning_rate: 0.0010\n",
      "Epoch 138/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0580\n",
      "Epoch 138: val_loss did not improve from 0.05101\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0581 - val_loss: 0.0513 - learning_rate: 0.0010\n",
      "Epoch 139/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0584\n",
      "Epoch 139: val_loss did not improve from 0.05101\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0584 - val_loss: 0.0524 - learning_rate: 0.0010\n",
      "Epoch 140/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0574\n",
      "Epoch 140: val_loss improved from 0.05101 to 0.04971, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0574 - val_loss: 0.0497 - learning_rate: 0.0010\n",
      "Epoch 141/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0567\n",
      "Epoch 141: val_loss did not improve from 0.04971\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0568 - val_loss: 0.0533 - learning_rate: 0.0010\n",
      "Epoch 142/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0573\n",
      "Epoch 142: val_loss did not improve from 0.04971\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0574 - val_loss: 0.0549 - learning_rate: 0.0010\n",
      "Epoch 143/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0564\n",
      "Epoch 143: val_loss did not improve from 0.04971\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0564 - val_loss: 0.0504 - learning_rate: 0.0010\n",
      "Epoch 144/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0553\n",
      "Epoch 144: val_loss improved from 0.04971 to 0.04836, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0553 - val_loss: 0.0484 - learning_rate: 0.0010\n",
      "Epoch 145/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0566\n",
      "Epoch 145: val_loss did not improve from 0.04836\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0566 - val_loss: 0.0520 - learning_rate: 0.0010\n",
      "Epoch 146/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0560\n",
      "Epoch 146: val_loss improved from 0.04836 to 0.04719, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0560 - val_loss: 0.0472 - learning_rate: 0.0010\n",
      "Epoch 147/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0560\n",
      "Epoch 147: val_loss did not improve from 0.04719\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0559 - val_loss: 0.0500 - learning_rate: 0.0010\n",
      "Epoch 148/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0537\n",
      "Epoch 148: val_loss did not improve from 0.04719\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0537 - val_loss: 0.0549 - learning_rate: 0.0010\n",
      "Epoch 149/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0535\n",
      "Epoch 149: val_loss improved from 0.04719 to 0.04517, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0535 - val_loss: 0.0452 - learning_rate: 0.0010\n",
      "Epoch 150/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0523\n",
      "Epoch 150: val_loss did not improve from 0.04517\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0523 - val_loss: 0.0462 - learning_rate: 0.0010\n",
      "Epoch 151/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0518\n",
      "Epoch 151: val_loss did not improve from 0.04517\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0518 - val_loss: 0.0466 - learning_rate: 0.0010\n",
      "Epoch 152/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0514\n",
      "Epoch 152: val_loss did not improve from 0.04517\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0514 - val_loss: 0.0465 - learning_rate: 0.0010\n",
      "Epoch 153/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0516\n",
      "Epoch 153: val_loss did not improve from 0.04517\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0517 - val_loss: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 154/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0526\n",
      "Epoch 154: val_loss improved from 0.04517 to 0.04453, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0526 - val_loss: 0.0445 - learning_rate: 0.0010\n",
      "Epoch 155/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0527\n",
      "Epoch 155: val_loss did not improve from 0.04453\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0526 - val_loss: 0.0451 - learning_rate: 0.0010\n",
      "Epoch 156/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0512\n",
      "Epoch 156: val_loss did not improve from 0.04453\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0512 - val_loss: 0.0499 - learning_rate: 0.0010\n",
      "Epoch 157/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0513\n",
      "Epoch 157: val_loss did not improve from 0.04453\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0513 - val_loss: 0.0510 - learning_rate: 0.0010\n",
      "Epoch 158/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0517\n",
      "Epoch 158: val_loss did not improve from 0.04453\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0517 - val_loss: 0.0463 - learning_rate: 0.0010\n",
      "Epoch 159/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0509\n",
      "Epoch 159: val_loss improved from 0.04453 to 0.04266, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0510 - val_loss: 0.0427 - learning_rate: 0.0010\n",
      "Epoch 160/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0500\n",
      "Epoch 160: val_loss did not improve from 0.04266\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0501 - val_loss: 0.0447 - learning_rate: 0.0010\n",
      "Epoch 161/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0504\n",
      "Epoch 161: val_loss did not improve from 0.04266\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0504 - val_loss: 0.0432 - learning_rate: 0.0010\n",
      "Epoch 162/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0499\n",
      "Epoch 162: val_loss did not improve from 0.04266\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0499 - val_loss: 0.0451 - learning_rate: 0.0010\n",
      "Epoch 163/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0479\n",
      "Epoch 163: val_loss did not improve from 0.04266\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0479 - val_loss: 0.0450 - learning_rate: 0.0010\n",
      "Epoch 164/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0492\n",
      "Epoch 164: val_loss did not improve from 0.04266\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0492 - val_loss: 0.0471 - learning_rate: 0.0010\n",
      "Epoch 165/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0482\n",
      "Epoch 165: val_loss did not improve from 0.04266\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0483 - val_loss: 0.0458 - learning_rate: 0.0010\n",
      "Epoch 166/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0499\n",
      "Epoch 166: val_loss did not improve from 0.04266\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0499 - val_loss: 0.0454 - learning_rate: 0.0010\n",
      "Epoch 167/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0494\n",
      "Epoch 167: val_loss did not improve from 0.04266\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0493 - val_loss: 0.0450 - learning_rate: 0.0010\n",
      "Epoch 168/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0477\n",
      "Epoch 168: val_loss did not improve from 0.04266\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0477 - val_loss: 0.0435 - learning_rate: 0.0010\n",
      "Epoch 169/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0478\n",
      "Epoch 169: val_loss did not improve from 0.04266\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0478 - val_loss: 0.0446 - learning_rate: 0.0010\n",
      "Epoch 170/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0482\n",
      "Epoch 170: val_loss did not improve from 0.04266\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0481 - val_loss: 0.0441 - learning_rate: 0.0010\n",
      "Epoch 171/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0476 \n",
      "Epoch 171: val_loss did not improve from 0.04266\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0475 - val_loss: 0.0469 - learning_rate: 0.0010\n",
      "Epoch 172/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0461\n",
      "Epoch 172: val_loss did not improve from 0.04266\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0461 - val_loss: 0.0451 - learning_rate: 0.0010\n",
      "Epoch 173/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0465\n",
      "Epoch 173: val_loss did not improve from 0.04266\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0465 - val_loss: 0.0439 - learning_rate: 0.0010\n",
      "Epoch 174/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0467\n",
      "Epoch 174: val_loss did not improve from 0.04266\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0466 - val_loss: 0.0490 - learning_rate: 0.0010\n",
      "Epoch 175/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0464\n",
      "Epoch 175: val_loss improved from 0.04266 to 0.03876, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0464 - val_loss: 0.0388 - learning_rate: 0.0010\n",
      "Epoch 176/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0445\n",
      "Epoch 176: val_loss did not improve from 0.03876\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0445 - val_loss: 0.0442 - learning_rate: 0.0010\n",
      "Epoch 177/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0433\n",
      "Epoch 177: val_loss did not improve from 0.03876\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0434 - val_loss: 0.0437 - learning_rate: 0.0010\n",
      "Epoch 178/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0438\n",
      "Epoch 178: val_loss did not improve from 0.03876\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0438 - val_loss: 0.0476 - learning_rate: 0.0010\n",
      "Epoch 179/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0459\n",
      "Epoch 179: val_loss improved from 0.03876 to 0.03867, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0459 - val_loss: 0.0387 - learning_rate: 0.0010\n",
      "Epoch 180/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0452\n",
      "Epoch 180: val_loss did not improve from 0.03867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0452 - val_loss: 0.0402 - learning_rate: 0.0010\n",
      "Epoch 181/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0445\n",
      "Epoch 181: val_loss did not improve from 0.03867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0446 - val_loss: 0.0434 - learning_rate: 0.0010\n",
      "Epoch 182/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0449\n",
      "Epoch 182: val_loss did not improve from 0.03867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0450 - val_loss: 0.0405 - learning_rate: 0.0010\n",
      "Epoch 183/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0455\n",
      "Epoch 183: val_loss improved from 0.03867 to 0.03748, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0455 - val_loss: 0.0375 - learning_rate: 0.0010\n",
      "Epoch 184/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0434\n",
      "Epoch 184: val_loss did not improve from 0.03748\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0434 - val_loss: 0.0386 - learning_rate: 0.0010\n",
      "Epoch 185/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0453\n",
      "Epoch 185: val_loss did not improve from 0.03748\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0452 - val_loss: 0.0404 - learning_rate: 0.0010\n",
      "Epoch 186/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0419\n",
      "Epoch 186: val_loss improved from 0.03748 to 0.03422, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0419 - val_loss: 0.0342 - learning_rate: 0.0010\n",
      "Epoch 187/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0424\n",
      "Epoch 187: val_loss did not improve from 0.03422\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0423 - val_loss: 0.0372 - learning_rate: 0.0010\n",
      "Epoch 188/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0417 \n",
      "Epoch 188: val_loss did not improve from 0.03422\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0417 - val_loss: 0.0396 - learning_rate: 0.0010\n",
      "Epoch 189/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0402\n",
      "Epoch 189: val_loss did not improve from 0.03422\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0403 - val_loss: 0.0384 - learning_rate: 0.0010\n",
      "Epoch 190/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0414\n",
      "Epoch 190: val_loss did not improve from 0.03422\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0414 - val_loss: 0.0379 - learning_rate: 0.0010\n",
      "Epoch 191/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0405\n",
      "Epoch 191: val_loss did not improve from 0.03422\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0406 - val_loss: 0.0360 - learning_rate: 0.0010\n",
      "Epoch 192/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0397\n",
      "Epoch 192: val_loss did not improve from 0.03422\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0397 - val_loss: 0.0355 - learning_rate: 0.0010\n",
      "Epoch 193/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0406\n",
      "Epoch 193: val_loss did not improve from 0.03422\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0405 - val_loss: 0.0370 - learning_rate: 0.0010\n",
      "Epoch 194/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0391\n",
      "Epoch 194: val_loss did not improve from 0.03422\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0392 - val_loss: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 195/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0401\n",
      "Epoch 195: val_loss did not improve from 0.03422\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0400 - val_loss: 0.0350 - learning_rate: 0.0010\n",
      "Epoch 196/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0388\n",
      "Epoch 196: val_loss improved from 0.03422 to 0.03255, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0389 - val_loss: 0.0325 - learning_rate: 0.0010\n",
      "Epoch 197/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0389\n",
      "Epoch 197: val_loss did not improve from 0.03255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0389 - val_loss: 0.0402 - learning_rate: 0.0010\n",
      "Epoch 198/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0392\n",
      "Epoch 198: val_loss did not improve from 0.03255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0392 - val_loss: 0.0353 - learning_rate: 0.0010\n",
      "Epoch 199/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0385\n",
      "Epoch 199: val_loss did not improve from 0.03255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0385 - val_loss: 0.0361 - learning_rate: 0.0010\n",
      "Epoch 200/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0382\n",
      "Epoch 200: val_loss did not improve from 0.03255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0382 - val_loss: 0.0354 - learning_rate: 0.0010\n",
      "Epoch 201/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0380\n",
      "Epoch 201: val_loss did not improve from 0.03255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0381 - val_loss: 0.0361 - learning_rate: 0.0010\n",
      "Epoch 202/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0395\n",
      "Epoch 202: val_loss did not improve from 0.03255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0395 - val_loss: 0.0329 - learning_rate: 0.0010\n",
      "Epoch 203/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0400\n",
      "Epoch 203: val_loss did not improve from 0.03255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0400 - val_loss: 0.0340 - learning_rate: 0.0010\n",
      "Epoch 204/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0396\n",
      "Epoch 204: val_loss did not improve from 0.03255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0396 - val_loss: 0.0332 - learning_rate: 0.0010\n",
      "Epoch 205/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0374\n",
      "Epoch 205: val_loss did not improve from 0.03255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0374 - val_loss: 0.0333 - learning_rate: 0.0010\n",
      "Epoch 206/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0371\n",
      "Epoch 206: val_loss improved from 0.03255 to 0.03098, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0372 - val_loss: 0.0310 - learning_rate: 0.0010\n",
      "Epoch 207/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0372\n",
      "Epoch 207: val_loss did not improve from 0.03098\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0372 - val_loss: 0.0356 - learning_rate: 0.0010\n",
      "Epoch 208/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0364\n",
      "Epoch 208: val_loss did not improve from 0.03098\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0365 - val_loss: 0.0324 - learning_rate: 0.0010\n",
      "Epoch 209/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0364\n",
      "Epoch 209: val_loss did not improve from 0.03098\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0364 - val_loss: 0.0315 - learning_rate: 0.0010\n",
      "Epoch 210/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0352\n",
      "Epoch 210: val_loss improved from 0.03098 to 0.03025, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0352 - val_loss: 0.0302 - learning_rate: 0.0010\n",
      "Epoch 211/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0366\n",
      "Epoch 211: val_loss did not improve from 0.03025\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0365 - val_loss: 0.0304 - learning_rate: 0.0010\n",
      "Epoch 212/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0361\n",
      "Epoch 212: val_loss did not improve from 0.03025\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0362 - val_loss: 0.0348 - learning_rate: 0.0010\n",
      "Epoch 213/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0398\n",
      "Epoch 213: val_loss did not improve from 0.03025\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0396 - val_loss: 0.0348 - learning_rate: 0.0010\n",
      "Epoch 214/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0352\n",
      "Epoch 214: val_loss did not improve from 0.03025\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0353 - val_loss: 0.0336 - learning_rate: 0.0010\n",
      "Epoch 215/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0352\n",
      "Epoch 215: val_loss did not improve from 0.03025\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0352 - val_loss: 0.0308 - learning_rate: 0.0010\n",
      "Epoch 216/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0364\n",
      "Epoch 216: val_loss did not improve from 0.03025\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0363 - val_loss: 0.0322 - learning_rate: 0.0010\n",
      "Epoch 217/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0353\n",
      "Epoch 217: val_loss did not improve from 0.03025\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0352 - val_loss: 0.0323 - learning_rate: 0.0010\n",
      "Epoch 218/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0335\n",
      "Epoch 218: val_loss did not improve from 0.03025\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0335 - val_loss: 0.0304 - learning_rate: 0.0010\n",
      "Epoch 219/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0338\n",
      "Epoch 219: val_loss improved from 0.03025 to 0.02979, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0338 - val_loss: 0.0298 - learning_rate: 0.0010\n",
      "Epoch 220/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0339\n",
      "Epoch 220: val_loss did not improve from 0.02979\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0339 - val_loss: 0.0330 - learning_rate: 0.0010\n",
      "Epoch 221/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0342\n",
      "Epoch 221: val_loss did not improve from 0.02979\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0342 - val_loss: 0.0300 - learning_rate: 0.0010\n",
      "Epoch 222/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0353\n",
      "Epoch 222: val_loss did not improve from 0.02979\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0353 - val_loss: 0.0357 - learning_rate: 0.0010\n",
      "Epoch 223/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0361\n",
      "Epoch 223: val_loss improved from 0.02979 to 0.02791, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0361 - val_loss: 0.0279 - learning_rate: 0.0010\n",
      "Epoch 224/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0354\n",
      "Epoch 224: val_loss did not improve from 0.02791\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0354 - val_loss: 0.0318 - learning_rate: 0.0010\n",
      "Epoch 225/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0345\n",
      "Epoch 225: val_loss did not improve from 0.02791\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0346 - val_loss: 0.0299 - learning_rate: 0.0010\n",
      "Epoch 226/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0351\n",
      "Epoch 226: val_loss did not improve from 0.02791\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0352 - val_loss: 0.0314 - learning_rate: 0.0010\n",
      "Epoch 227/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0345\n",
      "Epoch 227: val_loss did not improve from 0.02791\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0346 - val_loss: 0.0354 - learning_rate: 0.0010\n",
      "Epoch 228/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0336\n",
      "Epoch 228: val_loss did not improve from 0.02791\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0336 - val_loss: 0.0294 - learning_rate: 0.0010\n",
      "Epoch 229/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0333\n",
      "Epoch 229: val_loss did not improve from 0.02791\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0334 - val_loss: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 230/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0330\n",
      "Epoch 230: val_loss improved from 0.02791 to 0.02654, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0331 - val_loss: 0.0265 - learning_rate: 0.0010\n",
      "Epoch 231/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0372\n",
      "Epoch 231: val_loss did not improve from 0.02654\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0372 - val_loss: 0.0320 - learning_rate: 0.0010\n",
      "Epoch 232/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0343\n",
      "Epoch 232: val_loss improved from 0.02654 to 0.02577, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0343 - val_loss: 0.0258 - learning_rate: 0.0010\n",
      "Epoch 233/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0332\n",
      "Epoch 233: val_loss did not improve from 0.02577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0332 - val_loss: 0.0262 - learning_rate: 0.0010\n",
      "Epoch 234/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0334\n",
      "Epoch 234: val_loss did not improve from 0.02577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0334 - val_loss: 0.0298 - learning_rate: 0.0010\n",
      "Epoch 235/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0317\n",
      "Epoch 235: val_loss did not improve from 0.02577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0316 - val_loss: 0.0314 - learning_rate: 0.0010\n",
      "Epoch 236/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0322\n",
      "Epoch 236: val_loss did not improve from 0.02577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0322 - val_loss: 0.0273 - learning_rate: 0.0010\n",
      "Epoch 237/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0322\n",
      "Epoch 237: val_loss did not improve from 0.02577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0322 - val_loss: 0.0377 - learning_rate: 0.0010\n",
      "Epoch 238/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0320\n",
      "Epoch 238: val_loss did not improve from 0.02577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0320 - val_loss: 0.0261 - learning_rate: 0.0010\n",
      "Epoch 239/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0333\n",
      "Epoch 239: val_loss did not improve from 0.02577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0333 - val_loss: 0.0260 - learning_rate: 0.0010\n",
      "Epoch 240/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0315\n",
      "Epoch 240: val_loss did not improve from 0.02577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0314 - val_loss: 0.0267 - learning_rate: 0.0010\n",
      "Epoch 241/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0307\n",
      "Epoch 241: val_loss did not improve from 0.02577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0307 - val_loss: 0.0271 - learning_rate: 0.0010\n",
      "Epoch 242/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0303\n",
      "Epoch 242: val_loss did not improve from 0.02577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0303 - val_loss: 0.0268 - learning_rate: 0.0010\n",
      "Epoch 243/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0293\n",
      "Epoch 243: val_loss did not improve from 0.02577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0294 - val_loss: 0.0301 - learning_rate: 0.0010\n",
      "Epoch 244/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0306\n",
      "Epoch 244: val_loss improved from 0.02577 to 0.02339, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0307 - val_loss: 0.0234 - learning_rate: 0.0010\n",
      "Epoch 245/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0297 \n",
      "Epoch 245: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0297 - val_loss: 0.0252 - learning_rate: 0.0010\n",
      "Epoch 246/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0306\n",
      "Epoch 246: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0307 - val_loss: 0.0311 - learning_rate: 0.0010\n",
      "Epoch 247/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0297\n",
      "Epoch 247: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0298 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 248/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0306\n",
      "Epoch 248: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0306 - val_loss: 0.0262 - learning_rate: 0.0010\n",
      "Epoch 249/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0294\n",
      "Epoch 249: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0294 - val_loss: 0.0234 - learning_rate: 0.0010\n",
      "Epoch 250/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0301\n",
      "Epoch 250: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0301 - val_loss: 0.0317 - learning_rate: 0.0010\n",
      "Epoch 251/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0286\n",
      "Epoch 251: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0287 - val_loss: 0.0294 - learning_rate: 0.0010\n",
      "Epoch 252/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0289\n",
      "Epoch 252: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0289 - val_loss: 0.0270 - learning_rate: 0.0010\n",
      "Epoch 253/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0284\n",
      "Epoch 253: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0284 - val_loss: 0.0239 - learning_rate: 0.0010\n",
      "Epoch 254/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0281\n",
      "Epoch 254: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0281 - val_loss: 0.0240 - learning_rate: 0.0010\n",
      "Epoch 255/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0274\n",
      "Epoch 255: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0275 - val_loss: 0.0255 - learning_rate: 0.0010\n",
      "Epoch 256/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0282\n",
      "Epoch 256: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0282 - val_loss: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 257/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0293\n",
      "Epoch 257: val_loss improved from 0.02339 to 0.02305, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0293 - val_loss: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 258/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0304\n",
      "Epoch 258: val_loss improved from 0.02305 to 0.02301, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0304 - val_loss: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 259/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0282\n",
      "Epoch 259: val_loss did not improve from 0.02301\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0282 - val_loss: 0.0239 - learning_rate: 0.0010\n",
      "Epoch 260/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0284\n",
      "Epoch 260: val_loss did not improve from 0.02301\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0284 - val_loss: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 261/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0298\n",
      "Epoch 261: val_loss improved from 0.02301 to 0.02289, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0298 - val_loss: 0.0229 - learning_rate: 0.0010\n",
      "Epoch 262/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0295\n",
      "Epoch 262: val_loss did not improve from 0.02289\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0295 - val_loss: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 263/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0289\n",
      "Epoch 263: val_loss improved from 0.02289 to 0.02173, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0289 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 264/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0319\n",
      "Epoch 264: val_loss did not improve from 0.02173\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0318 - val_loss: 0.0299 - learning_rate: 0.0010\n",
      "Epoch 265/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0291\n",
      "Epoch 265: val_loss improved from 0.02173 to 0.02142, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0290 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 266/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0289\n",
      "Epoch 266: val_loss did not improve from 0.02142\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0290 - val_loss: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 267/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0283\n",
      "Epoch 267: val_loss did not improve from 0.02142\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0282 - val_loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 268/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0274\n",
      "Epoch 268: val_loss improved from 0.02142 to 0.02125, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0273 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 269/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0280\n",
      "Epoch 269: val_loss did not improve from 0.02125\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0281 - val_loss: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 270/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0278\n",
      "Epoch 270: val_loss did not improve from 0.02125\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0278 - val_loss: 0.0293 - learning_rate: 0.0010\n",
      "Epoch 271/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0293\n",
      "Epoch 271: val_loss did not improve from 0.02125\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0293 - val_loss: 0.0268 - learning_rate: 0.0010\n",
      "Epoch 272/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0271\n",
      "Epoch 272: val_loss did not improve from 0.02125\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0271 - val_loss: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 273/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0274\n",
      "Epoch 273: val_loss did not improve from 0.02125\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0273 - val_loss: 0.0249 - learning_rate: 0.0010\n",
      "Epoch 274/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0261\n",
      "Epoch 274: val_loss did not improve from 0.02125\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0261 - val_loss: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 275/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0253\n",
      "Epoch 275: val_loss improved from 0.02125 to 0.02101, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0254 - val_loss: 0.0210 - learning_rate: 0.0010\n",
      "Epoch 276/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0264\n",
      "Epoch 276: val_loss improved from 0.02101 to 0.01967, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0264 - val_loss: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 277/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0256\n",
      "Epoch 277: val_loss did not improve from 0.01967\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0257 - val_loss: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 278/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0266\n",
      "Epoch 278: val_loss did not improve from 0.01967\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0266 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 279/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0277\n",
      "Epoch 279: val_loss did not improve from 0.01967\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0278 - val_loss: 0.0277 - learning_rate: 0.0010\n",
      "Epoch 280/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0280\n",
      "Epoch 280: val_loss did not improve from 0.01967\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0280 - val_loss: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 281/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0275\n",
      "Epoch 281: val_loss did not improve from 0.01967\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0275 - val_loss: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 282/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0277\n",
      "Epoch 282: val_loss improved from 0.01967 to 0.01897, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0277 - val_loss: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 283/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0264\n",
      "Epoch 283: val_loss did not improve from 0.01897\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0265 - val_loss: 0.0232 - learning_rate: 0.0010\n",
      "Epoch 284/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0269\n",
      "Epoch 284: val_loss did not improve from 0.01897\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0269 - val_loss: 0.0270 - learning_rate: 0.0010\n",
      "Epoch 285/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0282\n",
      "Epoch 285: val_loss did not improve from 0.01897\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0281 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 286/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0255\n",
      "Epoch 286: val_loss did not improve from 0.01897\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0255 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 287/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0255\n",
      "Epoch 287: val_loss did not improve from 0.01897\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0255 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 288/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0250\n",
      "Epoch 288: val_loss did not improve from 0.01897\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0250 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 289/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0239\n",
      "Epoch 289: val_loss did not improve from 0.01897\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0240 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 290/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0253\n",
      "Epoch 290: val_loss did not improve from 0.01897\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0253 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 291/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0253\n",
      "Epoch 291: val_loss did not improve from 0.01897\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0254 - val_loss: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 292/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0252\n",
      "Epoch 292: val_loss did not improve from 0.01897\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0252 - val_loss: 0.0218 - learning_rate: 0.0010\n",
      "Epoch 293/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0248\n",
      "Epoch 293: val_loss did not improve from 0.01897\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0247 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 294/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0254\n",
      "Epoch 294: val_loss did not improve from 0.01897\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0255 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 295/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0253\n",
      "Epoch 295: val_loss did not improve from 0.01897\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0253 - val_loss: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 296/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0245\n",
      "Epoch 296: val_loss did not improve from 0.01897\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0245 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 297/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0249\n",
      "Epoch 297: val_loss did not improve from 0.01897\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0249 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 298/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0230\n",
      "Epoch 298: val_loss did not improve from 0.01897\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0230 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 299/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0234\n",
      "Epoch 299: val_loss improved from 0.01897 to 0.01872, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0234 - val_loss: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 300/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0242\n",
      "Epoch 300: val_loss did not improve from 0.01872\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0242 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 301/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0237\n",
      "Epoch 301: val_loss improved from 0.01872 to 0.01772, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0238 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 302/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0268\n",
      "Epoch 302: val_loss did not improve from 0.01772\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0269 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 303/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0250\n",
      "Epoch 303: val_loss did not improve from 0.01772\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0250 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 304/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0250\n",
      "Epoch 304: val_loss did not improve from 0.01772\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0250 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 305/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0245\n",
      "Epoch 305: val_loss did not improve from 0.01772\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0245 - val_loss: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 306/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0244\n",
      "Epoch 306: val_loss did not improve from 0.01772\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0244 - val_loss: 0.0276 - learning_rate: 0.0010\n",
      "Epoch 307/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0237\n",
      "Epoch 307: val_loss did not improve from 0.01772\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0237 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 308/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0242\n",
      "Epoch 308: val_loss improved from 0.01772 to 0.01644, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0242 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 309/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0264\n",
      "Epoch 309: val_loss did not improve from 0.01644\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0263 - val_loss: 0.0246 - learning_rate: 0.0010\n",
      "Epoch 310/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0256\n",
      "Epoch 310: val_loss did not improve from 0.01644\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0255 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 311/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0239\n",
      "Epoch 311: val_loss did not improve from 0.01644\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0239 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 312/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0238\n",
      "Epoch 312: val_loss did not improve from 0.01644\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0238 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 313/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0244\n",
      "Epoch 313: val_loss did not improve from 0.01644\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0244 - val_loss: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 314/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0240\n",
      "Epoch 314: val_loss improved from 0.01644 to 0.01576, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0240 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 315/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0244\n",
      "Epoch 315: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0244 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 316/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0229\n",
      "Epoch 316: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0229 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 317/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0249\n",
      "Epoch 317: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0249 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 318/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0230\n",
      "Epoch 318: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0230 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 319/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0235\n",
      "Epoch 319: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0234 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 320/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0223\n",
      "Epoch 320: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0224 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 321/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0227\n",
      "Epoch 321: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0227 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 322/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0224\n",
      "Epoch 322: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0224 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 323/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0226\n",
      "Epoch 323: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0226 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 324/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0221\n",
      "Epoch 324: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0221 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 325/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0216\n",
      "Epoch 325: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0216 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 326/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0218\n",
      "Epoch 326: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0219 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 327/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0214\n",
      "Epoch 327: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0214 - val_loss: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 328/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0206\n",
      "Epoch 328: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0207 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 329/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0228\n",
      "Epoch 329: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0228 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 330/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0224\n",
      "Epoch 330: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0224 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 331/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0231\n",
      "Epoch 331: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0230 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 332/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0212\n",
      "Epoch 332: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0212 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 333/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0212\n",
      "Epoch 333: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0213 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 334/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0217\n",
      "Epoch 334: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0217 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 335/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0224\n",
      "Epoch 335: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0224 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 336/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0224\n",
      "Epoch 336: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0224 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 337/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0205\n",
      "Epoch 337: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0206 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 338/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0210\n",
      "Epoch 338: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0210 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 339/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0201\n",
      "Epoch 339: val_loss did not improve from 0.01576\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0201 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 340/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0197\n",
      "Epoch 340: val_loss improved from 0.01576 to 0.01550, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0197 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 341/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0194\n",
      "Epoch 341: val_loss did not improve from 0.01550\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0195 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 342/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0204\n",
      "Epoch 342: val_loss did not improve from 0.01550\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0204 - val_loss: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 343/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0211\n",
      "Epoch 343: val_loss did not improve from 0.01550\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0211 - val_loss: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 344/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0227\n",
      "Epoch 344: val_loss did not improve from 0.01550\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0228 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 345/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0219\n",
      "Epoch 345: val_loss did not improve from 0.01550\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0219 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 346/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0211\n",
      "Epoch 346: val_loss did not improve from 0.01550\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0211 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 347/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0224\n",
      "Epoch 347: val_loss did not improve from 0.01550\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0224 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 348/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0214\n",
      "Epoch 348: val_loss improved from 0.01550 to 0.01539, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0214 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 349/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0208\n",
      "Epoch 349: val_loss did not improve from 0.01539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0208 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 350/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0216\n",
      "Epoch 350: val_loss did not improve from 0.01539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0216 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 351/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0203\n",
      "Epoch 351: val_loss improved from 0.01539 to 0.01430, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0203 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 352/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0202\n",
      "Epoch 352: val_loss did not improve from 0.01430\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0202 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 353/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0199\n",
      "Epoch 353: val_loss did not improve from 0.01430\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0199 - val_loss: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 354/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0209\n",
      "Epoch 354: val_loss did not improve from 0.01430\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0209 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 355/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0224\n",
      "Epoch 355: val_loss did not improve from 0.01430\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0224 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 356/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0223\n",
      "Epoch 356: val_loss did not improve from 0.01430\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0222 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 357/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0210\n",
      "Epoch 357: val_loss did not improve from 0.01430\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0210 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 358/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0202\n",
      "Epoch 358: val_loss did not improve from 0.01430\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0201 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 359/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0199\n",
      "Epoch 359: val_loss did not improve from 0.01430\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0198 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 360/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0183\n",
      "Epoch 360: val_loss did not improve from 0.01430\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0184 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 361/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0189\n",
      "Epoch 361: val_loss did not improve from 0.01430\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0189 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 362/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0189\n",
      "Epoch 362: val_loss did not improve from 0.01430\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0190 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 363/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0197\n",
      "Epoch 363: val_loss did not improve from 0.01430\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0197 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 364/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0191\n",
      "Epoch 364: val_loss did not improve from 0.01430\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0191 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 365/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0189\n",
      "Epoch 365: val_loss improved from 0.01430 to 0.01414, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0190 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 366/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0203\n",
      "Epoch 366: val_loss did not improve from 0.01414\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0203 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 367/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0203\n",
      "Epoch 367: val_loss did not improve from 0.01414\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0202 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 368/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0197\n",
      "Epoch 368: val_loss did not improve from 0.01414\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0197 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 369/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0188\n",
      "Epoch 369: val_loss improved from 0.01414 to 0.01396, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0189 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 370/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0186\n",
      "Epoch 370: val_loss did not improve from 0.01396\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0187 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 371/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0189\n",
      "Epoch 371: val_loss improved from 0.01396 to 0.01362, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0189 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 372/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0182\n",
      "Epoch 372: val_loss did not improve from 0.01362\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0183 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 373/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0193\n",
      "Epoch 373: val_loss did not improve from 0.01362\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0193 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 374/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0199\n",
      "Epoch 374: val_loss improved from 0.01362 to 0.01314, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0199 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 375/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0197\n",
      "Epoch 375: val_loss did not improve from 0.01314\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0197 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 376/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0194\n",
      "Epoch 376: val_loss did not improve from 0.01314\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0194 - val_loss: 0.0236 - learning_rate: 0.0010\n",
      "Epoch 377/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0197\n",
      "Epoch 377: val_loss did not improve from 0.01314\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0196 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 378/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0190\n",
      "Epoch 378: val_loss did not improve from 0.01314\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0190 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 379/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0190\n",
      "Epoch 379: val_loss did not improve from 0.01314\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0190 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 380/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0181\n",
      "Epoch 380: val_loss did not improve from 0.01314\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0181 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 381/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0187\n",
      "Epoch 381: val_loss did not improve from 0.01314\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0187 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 382/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0193\n",
      "Epoch 382: val_loss did not improve from 0.01314\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0194 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 383/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0196\n",
      "Epoch 383: val_loss did not improve from 0.01314\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0197 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 384/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0183\n",
      "Epoch 384: val_loss did not improve from 0.01314\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0184 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 385/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0201\n",
      "Epoch 385: val_loss did not improve from 0.01314\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0201 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 386/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0188\n",
      "Epoch 386: val_loss did not improve from 0.01314\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0188 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 387/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0188\n",
      "Epoch 387: val_loss did not improve from 0.01314\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0189 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 388/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0185\n",
      "Epoch 388: val_loss did not improve from 0.01314\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0185 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 389/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0191\n",
      "Epoch 389: val_loss did not improve from 0.01314\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0192 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 390/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0182\n",
      "Epoch 390: val_loss improved from 0.01314 to 0.01237, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0183 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 391/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0190\n",
      "Epoch 391: val_loss did not improve from 0.01237\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0190 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 392/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0191\n",
      "Epoch 392: val_loss did not improve from 0.01237\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0191 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 393/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0184\n",
      "Epoch 393: val_loss did not improve from 0.01237\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0185 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 394/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0182\n",
      "Epoch 394: val_loss improved from 0.01237 to 0.01224, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0182 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 395/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0195\n",
      "Epoch 395: val_loss did not improve from 0.01224\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0195 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 396/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0177\n",
      "Epoch 396: val_loss did not improve from 0.01224\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0178 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 397/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0193\n",
      "Epoch 397: val_loss did not improve from 0.01224\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0193 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 398/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0182\n",
      "Epoch 398: val_loss did not improve from 0.01224\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0183 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 399/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0179\n",
      "Epoch 399: val_loss did not improve from 0.01224\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0179 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 400/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0180\n",
      "Epoch 400: val_loss did not improve from 0.01224\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0180 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 401/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0193\n",
      "Epoch 401: val_loss did not improve from 0.01224\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0193 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 402/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0194\n",
      "Epoch 402: val_loss did not improve from 0.01224\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0194 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 403/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0195\n",
      "Epoch 403: val_loss did not improve from 0.01224\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0195 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 404/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0179\n",
      "Epoch 404: val_loss did not improve from 0.01224\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0179 - val_loss: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 405/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0183\n",
      "Epoch 405: val_loss did not improve from 0.01224\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0183 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 406/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0169\n",
      "Epoch 406: val_loss did not improve from 0.01224\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0170 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 407/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0187\n",
      "Epoch 407: val_loss did not improve from 0.01224\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0187 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 408/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0177\n",
      "Epoch 408: val_loss did not improve from 0.01224\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0176 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 409/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0162\n",
      "Epoch 409: val_loss did not improve from 0.01224\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0163 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 410/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0174\n",
      "Epoch 410: val_loss improved from 0.01224 to 0.01173, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0175 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 411/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0173\n",
      "Epoch 411: val_loss did not improve from 0.01173\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0174 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 412/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0168\n",
      "Epoch 412: val_loss did not improve from 0.01173\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0168 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 413/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0161\n",
      "Epoch 413: val_loss did not improve from 0.01173\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0161 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 414/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0160\n",
      "Epoch 414: val_loss did not improve from 0.01173\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0161 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 415/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0172\n",
      "Epoch 415: val_loss did not improve from 0.01173\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0172 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 416/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0169\n",
      "Epoch 416: val_loss did not improve from 0.01173\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0170 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 417/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0180\n",
      "Epoch 417: val_loss did not improve from 0.01173\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0180 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 418/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0169\n",
      "Epoch 418: val_loss did not improve from 0.01173\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0169 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 419/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0175\n",
      "Epoch 419: val_loss did not improve from 0.01173\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0175 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 420/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0174\n",
      "Epoch 420: val_loss did not improve from 0.01173\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0174 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 421/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0175\n",
      "Epoch 421: val_loss did not improve from 0.01173\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0175 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 422/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0172\n",
      "Epoch 422: val_loss did not improve from 0.01173\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0172 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 423/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0162\n",
      "Epoch 423: val_loss did not improve from 0.01173\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0163 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 424/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0166\n",
      "Epoch 424: val_loss did not improve from 0.01173\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0166 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 425/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0170\n",
      "Epoch 425: val_loss did not improve from 0.01173\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0170 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 426/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0164\n",
      "Epoch 426: val_loss did not improve from 0.01173\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0164 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 427/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0164\n",
      "Epoch 427: val_loss improved from 0.01173 to 0.01165, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0164 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 428/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0169\n",
      "Epoch 428: val_loss did not improve from 0.01165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0169 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 429/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0173\n",
      "Epoch 429: val_loss did not improve from 0.01165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0173 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 430/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0159\n",
      "Epoch 430: val_loss did not improve from 0.01165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0160 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 431/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0172\n",
      "Epoch 431: val_loss did not improve from 0.01165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0173 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 432/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0169\n",
      "Epoch 432: val_loss did not improve from 0.01165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0168 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 433/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0163\n",
      "Epoch 433: val_loss did not improve from 0.01165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0163 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 434/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0178\n",
      "Epoch 434: val_loss did not improve from 0.01165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0177 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 435/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0165\n",
      "Epoch 435: val_loss did not improve from 0.01165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0165 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 436/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0174\n",
      "Epoch 436: val_loss did not improve from 0.01165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0173 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 437/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0159\n",
      "Epoch 437: val_loss did not improve from 0.01165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0160 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 438/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0163\n",
      "Epoch 438: val_loss did not improve from 0.01165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0163 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 439/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0154\n",
      "Epoch 439: val_loss did not improve from 0.01165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0154 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 440/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0152\n",
      "Epoch 440: val_loss did not improve from 0.01165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0152 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 441/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0151\n",
      "Epoch 441: val_loss did not improve from 0.01165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0151 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 442/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0156\n",
      "Epoch 442: val_loss did not improve from 0.01165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0156 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 443/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0167\n",
      "Epoch 443: val_loss did not improve from 0.01165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0167 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 444/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0157\n",
      "Epoch 444: val_loss did not improve from 0.01165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0157 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 445/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0149\n",
      "Epoch 445: val_loss did not improve from 0.01165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0150 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 446/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0156\n",
      "Epoch 446: val_loss improved from 0.01165 to 0.01088, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0156 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 447/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0148\n",
      "Epoch 447: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0148 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 448/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0146\n",
      "Epoch 448: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0146 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 449/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0153\n",
      "Epoch 449: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0154 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 450/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0165\n",
      "Epoch 450: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0165 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 451/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0171\n",
      "Epoch 451: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0170 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 452/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0162\n",
      "Epoch 452: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0162 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 453/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0162\n",
      "Epoch 453: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0162 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 454/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0166\n",
      "Epoch 454: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0165 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 455/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0157\n",
      "Epoch 455: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0158 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 456/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0160\n",
      "Epoch 456: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0161 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 457/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0179\n",
      "Epoch 457: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0180 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 458/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0202\n",
      "Epoch 458: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0201 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 459/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0181\n",
      "Epoch 459: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0180 - val_loss: 0.0219 - learning_rate: 0.0010\n",
      "Epoch 460/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0175\n",
      "Epoch 460: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0176 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 461/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0168\n",
      "Epoch 461: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0167 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 462/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0151\n",
      "Epoch 462: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0151 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 463/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0153\n",
      "Epoch 463: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0153 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 464/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0147\n",
      "Epoch 464: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0147 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 465/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0146\n",
      "Epoch 465: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0147 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 466/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0160\n",
      "Epoch 466: val_loss did not improve from 0.01088\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0159 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 467/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0147\n",
      "Epoch 467: val_loss improved from 0.01088 to 0.01056, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0147 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 468/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0151\n",
      "Epoch 468: val_loss did not improve from 0.01056\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0151 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 469/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0143\n",
      "Epoch 469: val_loss did not improve from 0.01056\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0144 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 470/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0151\n",
      "Epoch 470: val_loss did not improve from 0.01056\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0151 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 471/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0150\n",
      "Epoch 471: val_loss did not improve from 0.01056\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0150 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 472/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0167\n",
      "Epoch 472: val_loss did not improve from 0.01056\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0166 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 473/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0172\n",
      "Epoch 473: val_loss did not improve from 0.01056\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0172 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 474/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0162\n",
      "Epoch 474: val_loss did not improve from 0.01056\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0163 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 475/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0158\n",
      "Epoch 475: val_loss improved from 0.01056 to 0.01037, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0158 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 476/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0156\n",
      "Epoch 476: val_loss improved from 0.01037 to 0.01020, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0156 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 477/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0150\n",
      "Epoch 477: val_loss did not improve from 0.01020\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0150 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 478/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0147\n",
      "Epoch 478: val_loss did not improve from 0.01020\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0148 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 479/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0142\n",
      "Epoch 479: val_loss did not improve from 0.01020\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0143 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 480/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0153\n",
      "Epoch 480: val_loss did not improve from 0.01020\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0152 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 481/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0146\n",
      "Epoch 481: val_loss did not improve from 0.01020\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0146 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 482/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0153\n",
      "Epoch 482: val_loss did not improve from 0.01020\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0154 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 483/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0163\n",
      "Epoch 483: val_loss did not improve from 0.01020\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0164 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 484/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0172\n",
      "Epoch 484: val_loss did not improve from 0.01020\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0172 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 485/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0156\n",
      "Epoch 485: val_loss did not improve from 0.01020\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0156 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 486/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0153\n",
      "Epoch 486: val_loss did not improve from 0.01020\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0154 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 487/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0158\n",
      "Epoch 487: val_loss did not improve from 0.01020\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0158 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 488/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0170\n",
      "Epoch 488: val_loss did not improve from 0.01020\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0170 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 489/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0164 \n",
      "Epoch 489: val_loss did not improve from 0.01020\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0164 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 490/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0161\n",
      "Epoch 490: val_loss did not improve from 0.01020\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0162 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 491/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0156\n",
      "Epoch 491: val_loss did not improve from 0.01020\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0156 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 492/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0152\n",
      "Epoch 492: val_loss improved from 0.01020 to 0.00981, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0152 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 493/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0148\n",
      "Epoch 493: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0148 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 494/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0151\n",
      "Epoch 494: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0151 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 495/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0159\n",
      "Epoch 495: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0159 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 496/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0146\n",
      "Epoch 496: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0147 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 497/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0147\n",
      "Epoch 497: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0147 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 498/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0143\n",
      "Epoch 498: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0143 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 499/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0149\n",
      "Epoch 499: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0149 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 500/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0146\n",
      "Epoch 500: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0146 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 501/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0145\n",
      "Epoch 501: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0146 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 502/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0150\n",
      "Epoch 502: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0149 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 503/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0148\n",
      "Epoch 503: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0148 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 504/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0151\n",
      "Epoch 504: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0151 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 505/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0139\n",
      "Epoch 505: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0139 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 506/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0146 \n",
      "Epoch 506: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0146 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 507/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0136\n",
      "Epoch 507: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0137 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 508/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0145\n",
      "Epoch 508: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0145 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 509/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0138\n",
      "Epoch 509: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0139 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 510/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0151\n",
      "Epoch 510: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0151 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 511/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0148\n",
      "Epoch 511: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0148 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 512/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0150\n",
      "Epoch 512: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0150 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 513/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0173\n",
      "Epoch 513: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0173 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 514/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0170\n",
      "Epoch 514: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0170 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 515/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0155\n",
      "Epoch 515: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0156 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 516/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0159\n",
      "Epoch 516: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0158 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 517/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0153\n",
      "Epoch 517: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0153 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 518/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0165\n",
      "Epoch 518: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0164 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 519/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0163 \n",
      "Epoch 519: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0163 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 520/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0148\n",
      "Epoch 520: val_loss did not improve from 0.00981\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0148 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 521/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0147 \n",
      "Epoch 521: val_loss improved from 0.00981 to 0.00952, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0147 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 522/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0143\n",
      "Epoch 522: val_loss did not improve from 0.00952\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0144 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 523/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0145\n",
      "Epoch 523: val_loss did not improve from 0.00952\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0145 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 524/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0141\n",
      "Epoch 524: val_loss did not improve from 0.00952\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0141 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 525/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0132\n",
      "Epoch 525: val_loss did not improve from 0.00952\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0132 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 526/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0141\n",
      "Epoch 526: val_loss did not improve from 0.00952\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0141 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 527/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0137\n",
      "Epoch 527: val_loss did not improve from 0.00952\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0137 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 528/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0138\n",
      "Epoch 528: val_loss did not improve from 0.00952\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0138 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 529/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0142\n",
      "Epoch 529: val_loss did not improve from 0.00952\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0142 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 530/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0146\n",
      "Epoch 530: val_loss did not improve from 0.00952\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0146 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 531/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0148\n",
      "Epoch 531: val_loss did not improve from 0.00952\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0148 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 532/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0145\n",
      "Epoch 532: val_loss did not improve from 0.00952\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0145 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 533/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0138\n",
      "Epoch 533: val_loss did not improve from 0.00952\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0137 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 534/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0138\n",
      "Epoch 534: val_loss improved from 0.00952 to 0.00932, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0138 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 535/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0145\n",
      "Epoch 535: val_loss did not improve from 0.00932\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0144 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 536/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0142\n",
      "Epoch 536: val_loss did not improve from 0.00932\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0142 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 537/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0139\n",
      "Epoch 537: val_loss did not improve from 0.00932\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0139 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 538/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0136\n",
      "Epoch 538: val_loss did not improve from 0.00932\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0137 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 539/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0135\n",
      "Epoch 539: val_loss did not improve from 0.00932\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0135 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 540/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0131\n",
      "Epoch 540: val_loss improved from 0.00932 to 0.00901, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0130 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 541/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0134\n",
      "Epoch 541: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0134 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 542/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0133\n",
      "Epoch 542: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0133 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 543/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0132\n",
      "Epoch 543: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0132 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 544/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0145\n",
      "Epoch 544: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0145 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 545/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0137\n",
      "Epoch 545: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0138 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 546/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0133\n",
      "Epoch 546: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0134 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 547/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0139\n",
      "Epoch 547: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0139 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 548/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0130\n",
      "Epoch 548: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0130 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 549/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0125\n",
      "Epoch 549: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0126 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 550/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0126\n",
      "Epoch 550: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0126 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 551/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0138\n",
      "Epoch 551: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0139 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 552/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0142\n",
      "Epoch 552: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0143 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 553/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0136\n",
      "Epoch 553: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0136 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 554/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0131\n",
      "Epoch 554: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0131 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 555/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0135\n",
      "Epoch 555: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0135 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 556/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0128\n",
      "Epoch 556: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0128 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 557/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0142\n",
      "Epoch 557: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0142 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 558/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0138\n",
      "Epoch 558: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0139 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 559/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0144\n",
      "Epoch 559: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0144 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 560/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0154\n",
      "Epoch 560: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0153 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 561/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0146\n",
      "Epoch 561: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0147 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 562/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0154\n",
      "Epoch 562: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0154 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 563/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0143\n",
      "Epoch 563: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0143 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 564/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0128\n",
      "Epoch 564: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0129 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 565/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0132\n",
      "Epoch 565: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0132 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 566/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0130\n",
      "Epoch 566: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0130 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 567/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0135\n",
      "Epoch 567: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0135 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 568/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0134\n",
      "Epoch 568: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0134 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 569/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0142\n",
      "Epoch 569: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0142 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 570/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0134\n",
      "Epoch 570: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0135 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 571/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0144\n",
      "Epoch 571: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0143 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 572/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0131\n",
      "Epoch 572: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0131 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 573/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0130\n",
      "Epoch 573: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0131 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 574/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0129\n",
      "Epoch 574: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0129 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 575/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0127\n",
      "Epoch 575: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0127 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 576/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0125\n",
      "Epoch 576: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0125 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 577/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0125\n",
      "Epoch 577: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0126 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 578/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0122\n",
      "Epoch 578: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0123 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 579/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0131\n",
      "Epoch 579: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0131 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 580/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0129\n",
      "Epoch 580: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0129 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 581/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0126\n",
      "Epoch 581: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0127 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 582/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0131\n",
      "Epoch 582: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0131 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 583/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0138\n",
      "Epoch 583: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0138 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 584/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0133\n",
      "Epoch 584: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0133 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 585/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0132 \n",
      "Epoch 585: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0132 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 586/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0136\n",
      "Epoch 586: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0136 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 587/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0126\n",
      "Epoch 587: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0126 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 588/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0124\n",
      "Epoch 588: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0124 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 589/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0126\n",
      "Epoch 589: val_loss did not improve from 0.00901\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0126 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 590/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0122\n",
      "Epoch 590: val_loss improved from 0.00901 to 0.00886, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0123 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 591/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0131\n",
      "Epoch 591: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0131 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 592/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0133\n",
      "Epoch 592: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0134 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 593/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0140\n",
      "Epoch 593: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0140 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 594/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0146\n",
      "Epoch 594: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0146 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 595/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0136\n",
      "Epoch 595: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0136 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 596/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0139\n",
      "Epoch 596: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0138 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 597/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0131 \n",
      "Epoch 597: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0131 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 598/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0141\n",
      "Epoch 598: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0140 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 599/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0123\n",
      "Epoch 599: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0123 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 600/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0132\n",
      "Epoch 600: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0132 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 601/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0126\n",
      "Epoch 601: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0126 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 602/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0129\n",
      "Epoch 602: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0129 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 603/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0127\n",
      "Epoch 603: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0128 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 604/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0133\n",
      "Epoch 604: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0133 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 605/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0129\n",
      "Epoch 605: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0129 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 606/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0133\n",
      "Epoch 606: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0132 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 607/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0124\n",
      "Epoch 607: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0125 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 608/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0129\n",
      "Epoch 608: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0129 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 609/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0144\n",
      "Epoch 609: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0144 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 610/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0140\n",
      "Epoch 610: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0139 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 611/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0126\n",
      "Epoch 611: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0126 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 612/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0120\n",
      "Epoch 612: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0120 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 613/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0122\n",
      "Epoch 613: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0123 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 614/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0118\n",
      "Epoch 614: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0118 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 615/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0126\n",
      "Epoch 615: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0126 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 616/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0148\n",
      "Epoch 616: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0148 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 617/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0130\n",
      "Epoch 617: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0130 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 618/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0138\n",
      "Epoch 618: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0138 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 619/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0140\n",
      "Epoch 619: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0140 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 620/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0140\n",
      "Epoch 620: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0139 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 621/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0125\n",
      "Epoch 621: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0126 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 622/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0125\n",
      "Epoch 622: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0126 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 623/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0125\n",
      "Epoch 623: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0125 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 624/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0129\n",
      "Epoch 624: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0129 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 625/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0128\n",
      "Epoch 625: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0128 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 626/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0134\n",
      "Epoch 626: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0134 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 627/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0123\n",
      "Epoch 627: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0123 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 628/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0121\n",
      "Epoch 628: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0122 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 629/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0127 \n",
      "Epoch 629: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0127 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 630/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0127\n",
      "Epoch 630: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0127 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 631/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0125\n",
      "Epoch 631: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0125 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 632/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0120\n",
      "Epoch 632: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0120 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 633/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0119\n",
      "Epoch 633: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0119 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 634/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0125\n",
      "Epoch 634: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0125 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 635/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0112\n",
      "Epoch 635: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0113 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 636/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0131\n",
      "Epoch 636: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0131 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 637/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0120\n",
      "Epoch 637: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0120 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 638/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0121\n",
      "Epoch 638: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0121 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 639/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0131\n",
      "Epoch 639: val_loss improved from 0.00886 to 0.00867, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0131 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 640/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0123\n",
      "Epoch 640: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0123 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 641/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0125\n",
      "Epoch 641: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0125 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 642/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0118\n",
      "Epoch 642: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0119 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 643/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0125\n",
      "Epoch 643: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0125 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 644/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0125\n",
      "Epoch 644: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0125 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 645/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0126\n",
      "Epoch 645: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0126 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 646/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0127\n",
      "Epoch 646: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0127 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 647/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0129\n",
      "Epoch 647: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0129 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 648/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0122\n",
      "Epoch 648: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0122 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 649/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0124 \n",
      "Epoch 649: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0124 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 650/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0123\n",
      "Epoch 650: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0123 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 651/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0121\n",
      "Epoch 651: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0121 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 652/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0119\n",
      "Epoch 652: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0119 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 653/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0115\n",
      "Epoch 653: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0116 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 654/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0124 \n",
      "Epoch 654: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0124 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 655/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0125\n",
      "Epoch 655: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0125 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 656/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0127\n",
      "Epoch 656: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0126 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 657/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0119\n",
      "Epoch 657: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0119 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 658/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0124\n",
      "Epoch 658: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0124 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 659/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0121\n",
      "Epoch 659: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0121 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 660/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0121\n",
      "Epoch 660: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0121 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 661/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0118\n",
      "Epoch 661: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0119 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 662/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0116\n",
      "Epoch 662: val_loss did not improve from 0.00867\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0117 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 663/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0116\n",
      "Epoch 663: val_loss improved from 0.00867 to 0.00857, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0116 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 664/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0119\n",
      "Epoch 664: val_loss did not improve from 0.00857\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0119 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 665/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0113\n",
      "Epoch 665: val_loss did not improve from 0.00857\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0113 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 666/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0117\n",
      "Epoch 666: val_loss did not improve from 0.00857\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0117 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 667/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0117\n",
      "Epoch 667: val_loss did not improve from 0.00857\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0117 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 668/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0117\n",
      "Epoch 668: val_loss did not improve from 0.00857\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0118 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 669/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0117\n",
      "Epoch 669: val_loss did not improve from 0.00857\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0117 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 670/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0124\n",
      "Epoch 670: val_loss did not improve from 0.00857\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0123 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 671/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0125\n",
      "Epoch 671: val_loss did not improve from 0.00857\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0125 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 672/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0122\n",
      "Epoch 672: val_loss did not improve from 0.00857\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0122 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 673/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0123\n",
      "Epoch 673: val_loss improved from 0.00857 to 0.00849, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0123 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 674/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0123\n",
      "Epoch 674: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0123 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 675/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0120\n",
      "Epoch 675: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0121 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 676/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0123\n",
      "Epoch 676: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0123 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 677/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0124\n",
      "Epoch 677: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0124 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 678/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0119\n",
      "Epoch 678: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0119 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 679/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0113\n",
      "Epoch 679: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0113 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 680/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0122\n",
      "Epoch 680: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0122 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 681/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0114\n",
      "Epoch 681: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0114 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 682/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0114\n",
      "Epoch 682: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0114 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 683/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0116\n",
      "Epoch 683: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0117 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 684/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0122\n",
      "Epoch 684: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0122 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 685/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0120\n",
      "Epoch 685: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0120 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 686/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0123\n",
      "Epoch 686: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0123 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 687/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0130\n",
      "Epoch 687: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0131 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 688/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0132 \n",
      "Epoch 688: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0132 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 689/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0120\n",
      "Epoch 689: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0120 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 690/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0115\n",
      "Epoch 690: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0115 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 691/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0111\n",
      "Epoch 691: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0111 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 692/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0114\n",
      "Epoch 692: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0114 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 693/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0112\n",
      "Epoch 693: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0113 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 694/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0115\n",
      "Epoch 694: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0116 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 695/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0111\n",
      "Epoch 695: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0111 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 696/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0110\n",
      "Epoch 696: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0111 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 697/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0117\n",
      "Epoch 697: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0117 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 698/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0114\n",
      "Epoch 698: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0115 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 699/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0128\n",
      "Epoch 699: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0128 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 700/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0122\n",
      "Epoch 700: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0123 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 701/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0127\n",
      "Epoch 701: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0127 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 702/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0125\n",
      "Epoch 702: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0125 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 703/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0118\n",
      "Epoch 703: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0119 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 704/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0128\n",
      "Epoch 704: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0127 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 705/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0117\n",
      "Epoch 705: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0117 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 706/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0110 \n",
      "Epoch 706: val_loss did not improve from 0.00849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0110 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 707/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0114\n",
      "Epoch 707: val_loss improved from 0.00849 to 0.00842, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0114 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 708/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0122\n",
      "Epoch 708: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0122 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 709/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0117\n",
      "Epoch 709: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0117 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 710/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0124\n",
      "Epoch 710: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0124 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 711/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0114\n",
      "Epoch 711: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0114 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 712/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0112\n",
      "Epoch 712: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0113 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 713/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0124\n",
      "Epoch 713: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0123 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 714/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0119\n",
      "Epoch 714: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0118 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 715/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0113\n",
      "Epoch 715: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0114 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 716/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0120\n",
      "Epoch 716: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0120 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 717/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0110\n",
      "Epoch 717: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0111 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 718/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0109\n",
      "Epoch 718: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0109 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 719/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0125\n",
      "Epoch 719: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0125 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 720/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0114\n",
      "Epoch 720: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0114 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 721/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0122\n",
      "Epoch 721: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0123 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 722/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0124\n",
      "Epoch 722: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0124 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 723/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0130\n",
      "Epoch 723: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0130 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 724/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0134\n",
      "Epoch 724: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0134 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 725/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0125\n",
      "Epoch 725: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0125 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 726/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0118\n",
      "Epoch 726: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0118 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 727/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0114\n",
      "Epoch 727: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0113 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 728/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0109\n",
      "Epoch 728: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0109 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 729/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0114\n",
      "Epoch 729: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0114 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 730/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0111\n",
      "Epoch 730: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0111 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 731/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0107\n",
      "Epoch 731: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0107 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 732/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0119\n",
      "Epoch 732: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0118 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 733/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0112\n",
      "Epoch 733: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0112 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 734/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0112\n",
      "Epoch 734: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0112 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 735/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0117 \n",
      "Epoch 735: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0117 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 736/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0106\n",
      "Epoch 736: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0106 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 737/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0117\n",
      "Epoch 737: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0117 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 738/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0120\n",
      "Epoch 738: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0120 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 739/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0116\n",
      "Epoch 739: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0116 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 740/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0121\n",
      "Epoch 740: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0121 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 741/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0120\n",
      "Epoch 741: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0120 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 742/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0114\n",
      "Epoch 742: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0114 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 743/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0114\n",
      "Epoch 743: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0114 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 744/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0116\n",
      "Epoch 744: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0116 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 745/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0115\n",
      "Epoch 745: val_loss did not improve from 0.00842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0115 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 746/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0115\n",
      "Epoch 746: val_loss improved from 0.00842 to 0.00803, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0115 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 747/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0110\n",
      "Epoch 747: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0110 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 748/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0104\n",
      "Epoch 748: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0104 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 749/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0104\n",
      "Epoch 749: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0104 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 750/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0116\n",
      "Epoch 750: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0115 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 751/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0116\n",
      "Epoch 751: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0116 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 752/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0113\n",
      "Epoch 752: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0113 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 753/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0120\n",
      "Epoch 753: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0120 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 754/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0120\n",
      "Epoch 754: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0121 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 755/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0112\n",
      "Epoch 755: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0113 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 756/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0113\n",
      "Epoch 756: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0113 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 757/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0113\n",
      "Epoch 757: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0113 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 758/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0118\n",
      "Epoch 758: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0118 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 759/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0105\n",
      "Epoch 759: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0105 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 760/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0104 \n",
      "Epoch 760: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0104 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 761/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0107\n",
      "Epoch 761: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0108 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 762/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0123\n",
      "Epoch 762: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0124 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 763/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0192\n",
      "Epoch 763: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0193 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 764/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0181\n",
      "Epoch 764: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0181 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 765/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0197\n",
      "Epoch 765: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0197 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 766/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0164\n",
      "Epoch 766: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0165 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 767/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0164\n",
      "Epoch 767: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0163 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 768/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0153\n",
      "Epoch 768: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0153 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 769/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0144\n",
      "Epoch 769: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0145 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 770/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0132\n",
      "Epoch 770: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0132 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 771/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0119\n",
      "Epoch 771: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0119 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 772/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0115\n",
      "Epoch 772: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0115 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 773/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0112\n",
      "Epoch 773: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0112 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 774/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0113\n",
      "Epoch 774: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0113 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 775/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0119\n",
      "Epoch 775: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0119 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 776/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0118\n",
      "Epoch 776: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0118 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 777/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0117\n",
      "Epoch 777: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0116 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 778/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0109\n",
      "Epoch 778: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0109 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 779/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0109\n",
      "Epoch 779: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0110 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 780/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0101\n",
      "Epoch 780: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0102 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 781/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0113\n",
      "Epoch 781: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0113 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 782/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0110\n",
      "Epoch 782: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0110 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 783/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0112\n",
      "Epoch 783: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0112 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 784/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0111\n",
      "Epoch 784: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0111 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 785/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0106\n",
      "Epoch 785: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0106 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 786/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0111\n",
      "Epoch 786: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0111 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 787/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0109\n",
      "Epoch 787: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0109 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 788/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0107\n",
      "Epoch 788: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0107 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 789/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0106\n",
      "Epoch 789: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0106 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 790/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0102 \n",
      "Epoch 790: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0102 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 791/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0103\n",
      "Epoch 791: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0104 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 792/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0107\n",
      "Epoch 792: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0108 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 793/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0115\n",
      "Epoch 793: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0114 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 794/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0100\n",
      "Epoch 794: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0100 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 795/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0101\n",
      "Epoch 795: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0102 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 796/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0112\n",
      "Epoch 796: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0112 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 797/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0110\n",
      "Epoch 797: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0110 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 798/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0116\n",
      "Epoch 798: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0116 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 799/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0119\n",
      "Epoch 799: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0118 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 800/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0106\n",
      "Epoch 800: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0106 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 801/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0104\n",
      "Epoch 801: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0104 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 802/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0110\n",
      "Epoch 802: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0109 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 803/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0112\n",
      "Epoch 803: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0112 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 804/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0114\n",
      "Epoch 804: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0114 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 805/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0113\n",
      "Epoch 805: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0113 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 806/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0113\n",
      "Epoch 806: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0113 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 807/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0109\n",
      "Epoch 807: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0109 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 808/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0104\n",
      "Epoch 808: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0104 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 809/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0102\n",
      "Epoch 809: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0102 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 810/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0104\n",
      "Epoch 810: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0104 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 811/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0105\n",
      "Epoch 811: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0105 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 812/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0110\n",
      "Epoch 812: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0110 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 813/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0100\n",
      "Epoch 813: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0100 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 814/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0108\n",
      "Epoch 814: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0108 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 815/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0104\n",
      "Epoch 815: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0104 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 816/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0121\n",
      "Epoch 816: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0120 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 817/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0110\n",
      "Epoch 817: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0110 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 818/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0107\n",
      "Epoch 818: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0107 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 819/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0105\n",
      "Epoch 819: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0106 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 820/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0110\n",
      "Epoch 820: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0109 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 821/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0101\n",
      "Epoch 821: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0101 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 822/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0106\n",
      "Epoch 822: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0106 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 823/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0105\n",
      "Epoch 823: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0106 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 824/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0110\n",
      "Epoch 824: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0110 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 825/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0104\n",
      "Epoch 825: val_loss did not improve from 0.00803\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0104 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 826/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0106\n",
      "Epoch 826: val_loss improved from 0.00803 to 0.00789, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0106 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 827/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0106\n",
      "Epoch 827: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0106 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 828/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0104\n",
      "Epoch 828: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0104 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 829/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0102\n",
      "Epoch 829: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0103 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 830/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0109\n",
      "Epoch 830: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0109 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 831/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0112\n",
      "Epoch 831: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0113 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 832/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0110\n",
      "Epoch 832: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0110 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 833/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0104\n",
      "Epoch 833: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0104 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 834/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0107\n",
      "Epoch 834: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0107 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 835/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0111\n",
      "Epoch 835: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0111 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 836/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0105\n",
      "Epoch 836: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0105 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 837/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0112\n",
      "Epoch 837: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0112 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 838/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0111\n",
      "Epoch 838: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0110 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 839/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0104\n",
      "Epoch 839: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0104 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 840/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0104\n",
      "Epoch 840: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0104 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 841/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0107\n",
      "Epoch 841: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0106 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 842/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0104\n",
      "Epoch 842: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0104 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 843/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0105\n",
      "Epoch 843: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0105 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 844/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0109\n",
      "Epoch 844: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0109 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 845/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0110\n",
      "Epoch 845: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0110 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 846/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0104\n",
      "Epoch 846: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0104 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 847/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0102\n",
      "Epoch 847: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0102 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 848/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0101\n",
      "Epoch 848: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0101 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 849/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0101\n",
      "Epoch 849: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0101 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 850/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0103\n",
      "Epoch 850: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0103 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 851/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0104\n",
      "Epoch 851: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0104 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 852/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0109\n",
      "Epoch 852: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0108 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 853/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0105\n",
      "Epoch 853: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0105 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 854/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0098\n",
      "Epoch 854: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0098 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 855/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0098\n",
      "Epoch 855: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0099 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 856/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0097\n",
      "Epoch 856: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0098 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 857/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0099\n",
      "Epoch 857: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0099 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 858/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0101\n",
      "Epoch 858: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0101 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 859/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0102\n",
      "Epoch 859: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0102 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 860/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0096\n",
      "Epoch 860: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0096 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 861/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0092\n",
      "Epoch 861: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0092 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 862/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0095\n",
      "Epoch 862: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0096 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 863/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0099\n",
      "Epoch 863: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0099 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 864/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0103\n",
      "Epoch 864: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0104 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 865/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0102\n",
      "Epoch 865: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0102 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 866/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0101\n",
      "Epoch 866: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0101 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 867/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0101\n",
      "Epoch 867: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0102 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 868/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0108\n",
      "Epoch 868: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0108 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 869/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0107\n",
      "Epoch 869: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0106 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 870/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0097\n",
      "Epoch 870: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0097 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 871/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0097\n",
      "Epoch 871: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0097 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 872/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0098\n",
      "Epoch 872: val_loss did not improve from 0.00789\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0099 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 873/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0100\n",
      "Epoch 873: val_loss improved from 0.00789 to 0.00746, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0100 - val_loss: 0.0075 - learning_rate: 0.0010\n",
      "Epoch 874/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0100\n",
      "Epoch 874: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0100 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 875/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0104\n",
      "Epoch 875: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0104 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 876/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0101\n",
      "Epoch 876: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0102 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 877/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0116\n",
      "Epoch 877: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0116 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 878/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0108\n",
      "Epoch 878: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0108 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 879/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0109\n",
      "Epoch 879: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0109 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 880/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0103\n",
      "Epoch 880: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0103 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 881/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0101\n",
      "Epoch 881: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0102 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 882/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0108\n",
      "Epoch 882: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0108 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 883/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0100\n",
      "Epoch 883: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0100 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 884/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0099\n",
      "Epoch 884: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0099 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 885/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0093\n",
      "Epoch 885: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0094 - val_loss: 0.0078 - learning_rate: 0.0010\n",
      "Epoch 886/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0102\n",
      "Epoch 886: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0102 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 887/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0098\n",
      "Epoch 887: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0098 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 888/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0101\n",
      "Epoch 888: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0101 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 889/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0104\n",
      "Epoch 889: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0104 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 890/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0100\n",
      "Epoch 890: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0100 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 891/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0106\n",
      "Epoch 891: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0106 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 892/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0187 \n",
      "Epoch 892: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0185 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 893/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0146\n",
      "Epoch 893: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0146 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 894/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0151\n",
      "Epoch 894: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0150 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 895/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0133\n",
      "Epoch 895: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0133 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 896/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0112\n",
      "Epoch 896: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0112 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 897/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0114\n",
      "Epoch 897: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0114 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 898/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0111\n",
      "Epoch 898: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0111 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 899/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0109\n",
      "Epoch 899: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0109 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 900/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0104\n",
      "Epoch 900: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0104 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 901/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0109\n",
      "Epoch 901: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0109 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 902/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0104\n",
      "Epoch 902: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0104 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 903/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0099\n",
      "Epoch 903: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0100 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 904/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0109\n",
      "Epoch 904: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0109 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 905/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0112\n",
      "Epoch 905: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0112 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 906/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0105\n",
      "Epoch 906: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0105 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 907/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0098\n",
      "Epoch 907: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0098 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 908/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0102\n",
      "Epoch 908: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0102 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 909/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0095\n",
      "Epoch 909: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0095 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 910/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0103\n",
      "Epoch 910: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0102 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 911/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0098\n",
      "Epoch 911: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0099 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 912/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0104\n",
      "Epoch 912: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0104 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 913/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0096 \n",
      "Epoch 913: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0096 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 914/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0095\n",
      "Epoch 914: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0095 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 915/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0094\n",
      "Epoch 915: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0095 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 916/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0094\n",
      "Epoch 916: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0094 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 917/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0090 \n",
      "Epoch 917: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0091 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 918/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0094\n",
      "Epoch 918: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0094 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 919/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0091\n",
      "Epoch 919: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0092 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 920/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0091\n",
      "Epoch 920: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0091 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 921/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0099\n",
      "Epoch 921: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0099 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 922/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0095\n",
      "Epoch 922: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0095 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 923/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0091\n",
      "Epoch 923: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0091 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 924/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0092\n",
      "Epoch 924: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0092 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 925/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0097\n",
      "Epoch 925: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0098 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 926/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0099\n",
      "Epoch 926: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0099 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 927/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0104\n",
      "Epoch 927: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0104 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 928/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0107 \n",
      "Epoch 928: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0107 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 929/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0106\n",
      "Epoch 929: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0106 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 930/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0101\n",
      "Epoch 930: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0101 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 931/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0099\n",
      "Epoch 931: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0099 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 932/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0100\n",
      "Epoch 932: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0100 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 933/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0101\n",
      "Epoch 933: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0101 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 934/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0104\n",
      "Epoch 934: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0104 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 935/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0104\n",
      "Epoch 935: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0104 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 936/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0102\n",
      "Epoch 936: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0102 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 937/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0097\n",
      "Epoch 937: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0097 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 938/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0094\n",
      "Epoch 938: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0094 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 939/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0091 \n",
      "Epoch 939: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0092 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 940/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0098\n",
      "Epoch 940: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0098 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 941/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0102\n",
      "Epoch 941: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0102 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 942/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0103\n",
      "Epoch 942: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0103 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 943/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0100\n",
      "Epoch 943: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0100 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 944/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0096\n",
      "Epoch 944: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0095 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 945/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0097\n",
      "Epoch 945: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0097 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 946/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0094\n",
      "Epoch 946: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0094 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 947/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0091\n",
      "Epoch 947: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0092 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 948/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0096\n",
      "Epoch 948: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0096 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 949/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0099\n",
      "Epoch 949: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0099 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 950/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0093\n",
      "Epoch 950: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0093 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 951/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0100\n",
      "Epoch 951: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0100 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 952/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0100 \n",
      "Epoch 952: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0100 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 953/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0099\n",
      "Epoch 953: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0099 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 954/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0101\n",
      "Epoch 954: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0102 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 955/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0100\n",
      "Epoch 955: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0100 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 956/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0094\n",
      "Epoch 956: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0094 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 957/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0092\n",
      "Epoch 957: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0092 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 958/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0093\n",
      "Epoch 958: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0093 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 959/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0093\n",
      "Epoch 959: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0093 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 960/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0093\n",
      "Epoch 960: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0094 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 961/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0099 \n",
      "Epoch 961: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0099 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 962/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0099\n",
      "Epoch 962: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0099 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 963/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0096\n",
      "Epoch 963: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0096 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 964/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0096\n",
      "Epoch 964: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0096 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 965/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0092\n",
      "Epoch 965: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0092 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 966/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0098\n",
      "Epoch 966: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0098 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 967/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0098\n",
      "Epoch 967: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0098 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 968/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0094\n",
      "Epoch 968: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0095 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 969/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0092\n",
      "Epoch 969: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0092 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 970/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0092\n",
      "Epoch 970: val_loss did not improve from 0.00746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0092 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 971/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0097\n",
      "Epoch 971: val_loss improved from 0.00746 to 0.00742, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0098 - val_loss: 0.0074 - learning_rate: 0.0010\n",
      "Epoch 972/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0092\n",
      "Epoch 972: val_loss did not improve from 0.00742\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0092 - val_loss: 0.0080 - learning_rate: 0.0010\n",
      "Epoch 973/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0091\n",
      "Epoch 973: val_loss improved from 0.00742 to 0.00709, saving model to ./result_folder_no_misc/lstm_ts_4.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0091 - val_loss: 0.0071 - learning_rate: 0.0010\n",
      "Epoch 974/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0093\n",
      "Epoch 974: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0093 - val_loss: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 975/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0092\n",
      "Epoch 975: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0093 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 976/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0100\n",
      "Epoch 976: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0100 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 977/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0098\n",
      "Epoch 977: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0098 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 978/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0096\n",
      "Epoch 978: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0097 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 979/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0098\n",
      "Epoch 979: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0098 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 980/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0093\n",
      "Epoch 980: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0093 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 981/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0093\n",
      "Epoch 981: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0093 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 982/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0091\n",
      "Epoch 982: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0092 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 983/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0094\n",
      "Epoch 983: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0095 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 984/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0096\n",
      "Epoch 984: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0097 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 985/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0098\n",
      "Epoch 985: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0098 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 986/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0097\n",
      "Epoch 986: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0097 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 987/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0097\n",
      "Epoch 987: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0097 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 988/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0089\n",
      "Epoch 988: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0090 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 989/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0087\n",
      "Epoch 989: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0087 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 990/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0087\n",
      "Epoch 990: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0087 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 991/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0096\n",
      "Epoch 991: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0096 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 992/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0097\n",
      "Epoch 992: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0097 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 993/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0092\n",
      "Epoch 993: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0092 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 994/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0094\n",
      "Epoch 994: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0094 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 995/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0101\n",
      "Epoch 995: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0101 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 996/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0091\n",
      "Epoch 996: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0091 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 997/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0098\n",
      "Epoch 997: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0098 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 998/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0091\n",
      "Epoch 998: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0091 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 999/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0094\n",
      "Epoch 999: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0094 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 1000/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0098\n",
      "Epoch 1000: val_loss did not improve from 0.00709\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0098 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 973.\n",
      "EUA\n",
      "0.09606200690054188\n",
      "Oil\n",
      "0.13540361441795729\n",
      "Coal\n",
      "0.042118577982214016\n",
      "NG\n",
      "0.04456076966049362\n",
      "USEU\n",
      "0.09955138727911127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 180/180 [01:35<00:00,  1.89it/s]\n",
      "100%|| 180/180 [05:44<00:00,  1.91s/it]\n",
      "/home/honggeunjo/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 2.0496\n",
      "Epoch 1: val_loss improved from inf to 0.60252, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 213ms/step - loss: 1.9864 - val_loss: 0.6025 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.6111\n",
      "Epoch 2: val_loss did not improve from 0.60252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.6084 - val_loss: 0.6724 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.4805\n",
      "Epoch 3: val_loss improved from 0.60252 to 0.37480, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.4794 - val_loss: 0.3748 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.4247\n",
      "Epoch 4: val_loss improved from 0.37480 to 0.35688, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.4243 - val_loss: 0.3569 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.3977\n",
      "Epoch 5: val_loss did not improve from 0.35688\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - loss: 0.3975 - val_loss: 0.3668 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.3871\n",
      "Epoch 6: val_loss improved from 0.35688 to 0.34798, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.3868 - val_loss: 0.3480 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.3752\n",
      "Epoch 7: val_loss improved from 0.34798 to 0.33611, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.3749 - val_loss: 0.3361 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.3669\n",
      "Epoch 8: val_loss improved from 0.33611 to 0.33556, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.3667 - val_loss: 0.3356 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.3570\n",
      "Epoch 9: val_loss improved from 0.33556 to 0.32508, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.3569 - val_loss: 0.3251 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.3506\n",
      "Epoch 10: val_loss improved from 0.32508 to 0.32112, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.3504 - val_loss: 0.3211 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.3444\n",
      "Epoch 11: val_loss improved from 0.32112 to 0.31427, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.3440 - val_loss: 0.3143 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.3344\n",
      "Epoch 12: val_loss improved from 0.31427 to 0.30839, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.3342 - val_loss: 0.3084 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3248\n",
      "Epoch 13: val_loss improved from 0.30839 to 0.30234, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.3247 - val_loss: 0.3023 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.3204\n",
      "Epoch 14: val_loss improved from 0.30234 to 0.29226, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - loss: 0.3202 - val_loss: 0.2923 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.3137\n",
      "Epoch 15: val_loss improved from 0.29226 to 0.28801, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - loss: 0.3134 - val_loss: 0.2880 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.3083\n",
      "Epoch 16: val_loss improved from 0.28801 to 0.28282, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.3081 - val_loss: 0.2828 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.2982\n",
      "Epoch 17: val_loss did not improve from 0.28282\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.2982 - val_loss: 0.2834 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.2897\n",
      "Epoch 18: val_loss improved from 0.28282 to 0.26971, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.2897 - val_loss: 0.2697 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.2829\n",
      "Epoch 19: val_loss improved from 0.26971 to 0.26379, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.2828 - val_loss: 0.2638 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.2783\n",
      "Epoch 20: val_loss improved from 0.26379 to 0.26045, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.2782 - val_loss: 0.2604 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.2742\n",
      "Epoch 21: val_loss improved from 0.26045 to 0.25344, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.2740 - val_loss: 0.2534 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.2682\n",
      "Epoch 22: val_loss improved from 0.25344 to 0.25191, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.2680 - val_loss: 0.2519 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.2616\n",
      "Epoch 23: val_loss improved from 0.25191 to 0.24324, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.2614 - val_loss: 0.2432 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.2537\n",
      "Epoch 24: val_loss improved from 0.24324 to 0.23664, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.2537 - val_loss: 0.2366 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.2510\n",
      "Epoch 25: val_loss improved from 0.23664 to 0.23097, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.2508 - val_loss: 0.2310 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.2422\n",
      "Epoch 26: val_loss did not improve from 0.23097\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.2422 - val_loss: 0.2329 - learning_rate: 0.0010\n",
      "Epoch 27/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.2386\n",
      "Epoch 27: val_loss improved from 0.23097 to 0.22367, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.2384 - val_loss: 0.2237 - learning_rate: 0.0010\n",
      "Epoch 28/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.2326\n",
      "Epoch 28: val_loss improved from 0.22367 to 0.21407, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.2326 - val_loss: 0.2141 - learning_rate: 0.0010\n",
      "Epoch 29/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.2293\n",
      "Epoch 29: val_loss improved from 0.21407 to 0.21233, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.2293 - val_loss: 0.2123 - learning_rate: 0.0010\n",
      "Epoch 30/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.2238\n",
      "Epoch 30: val_loss did not improve from 0.21233\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.2238 - val_loss: 0.2176 - learning_rate: 0.0010\n",
      "Epoch 31/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.2219\n",
      "Epoch 31: val_loss improved from 0.21233 to 0.19908, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.2217 - val_loss: 0.1991 - learning_rate: 0.0010\n",
      "Epoch 32/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.2144\n",
      "Epoch 32: val_loss did not improve from 0.19908\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.2144 - val_loss: 0.2019 - learning_rate: 0.0010\n",
      "Epoch 33/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.2121\n",
      "Epoch 33: val_loss did not improve from 0.19908\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.2121 - val_loss: 0.1997 - learning_rate: 0.0010\n",
      "Epoch 34/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.2086\n",
      "Epoch 34: val_loss improved from 0.19908 to 0.19099, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - loss: 0.2084 - val_loss: 0.1910 - learning_rate: 0.0010\n",
      "Epoch 35/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.2019\n",
      "Epoch 35: val_loss improved from 0.19099 to 0.18911, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.2019 - val_loss: 0.1891 - learning_rate: 0.0010\n",
      "Epoch 36/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.2010\n",
      "Epoch 36: val_loss improved from 0.18911 to 0.18277, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.2010 - val_loss: 0.1828 - learning_rate: 0.0010\n",
      "Epoch 37/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.1964\n",
      "Epoch 37: val_loss improved from 0.18277 to 0.18229, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.1963 - val_loss: 0.1823 - learning_rate: 0.0010\n",
      "Epoch 38/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.1914\n",
      "Epoch 38: val_loss improved from 0.18229 to 0.17582, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - loss: 0.1914 - val_loss: 0.1758 - learning_rate: 0.0010\n",
      "Epoch 39/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.1873\n",
      "Epoch 39: val_loss improved from 0.17582 to 0.17208, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.1872 - val_loss: 0.1721 - learning_rate: 0.0010\n",
      "Epoch 40/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.1833\n",
      "Epoch 40: val_loss did not improve from 0.17208\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1833 - val_loss: 0.1821 - learning_rate: 0.0010\n",
      "Epoch 41/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.1786\n",
      "Epoch 41: val_loss improved from 0.17208 to 0.16831, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.1786 - val_loss: 0.1683 - learning_rate: 0.0010\n",
      "Epoch 42/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.1758\n",
      "Epoch 42: val_loss did not improve from 0.16831\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1758 - val_loss: 0.1692 - learning_rate: 0.0010\n",
      "Epoch 43/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.1740\n",
      "Epoch 43: val_loss improved from 0.16831 to 0.16122, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.1740 - val_loss: 0.1612 - learning_rate: 0.0010\n",
      "Epoch 44/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.1705\n",
      "Epoch 44: val_loss did not improve from 0.16122\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1705 - val_loss: 0.1616 - learning_rate: 0.0010\n",
      "Epoch 45/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.1668\n",
      "Epoch 45: val_loss did not improve from 0.16122\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1668 - val_loss: 0.1621 - learning_rate: 0.0010\n",
      "Epoch 46/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.1645\n",
      "Epoch 46: val_loss improved from 0.16122 to 0.15918, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.1644 - val_loss: 0.1592 - learning_rate: 0.0010\n",
      "Epoch 47/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.1630\n",
      "Epoch 47: val_loss improved from 0.15918 to 0.15197, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.1629 - val_loss: 0.1520 - learning_rate: 0.0010\n",
      "Epoch 48/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.1617\n",
      "Epoch 48: val_loss improved from 0.15197 to 0.15148, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.1615 - val_loss: 0.1515 - learning_rate: 0.0010\n",
      "Epoch 49/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.1582\n",
      "Epoch 49: val_loss improved from 0.15148 to 0.14436, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.1580 - val_loss: 0.1444 - learning_rate: 0.0010\n",
      "Epoch 50/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.1548\n",
      "Epoch 50: val_loss did not improve from 0.14436\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.1548 - val_loss: 0.1464 - learning_rate: 0.0010\n",
      "Epoch 51/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.1508\n",
      "Epoch 51: val_loss did not improve from 0.14436\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.1508 - val_loss: 0.1481 - learning_rate: 0.0010\n",
      "Epoch 52/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.1482\n",
      "Epoch 52: val_loss did not improve from 0.14436\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.1482 - val_loss: 0.1457 - learning_rate: 0.0010\n",
      "Epoch 53/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.1463\n",
      "Epoch 53: val_loss improved from 0.14436 to 0.13662, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1462 - val_loss: 0.1366 - learning_rate: 0.0010\n",
      "Epoch 54/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1438\n",
      "Epoch 54: val_loss improved from 0.13662 to 0.13051, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.1439 - val_loss: 0.1305 - learning_rate: 0.0010\n",
      "Epoch 55/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.1429\n",
      "Epoch 55: val_loss did not improve from 0.13051\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1429 - val_loss: 0.1308 - learning_rate: 0.0010\n",
      "Epoch 56/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.1415\n",
      "Epoch 56: val_loss improved from 0.13051 to 0.12581, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.1413 - val_loss: 0.1258 - learning_rate: 0.0010\n",
      "Epoch 57/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.1356\n",
      "Epoch 57: val_loss did not improve from 0.12581\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.1357 - val_loss: 0.1284 - learning_rate: 0.0010\n",
      "Epoch 58/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1364\n",
      "Epoch 58: val_loss did not improve from 0.12581\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1364 - val_loss: 0.1270 - learning_rate: 0.0010\n",
      "Epoch 59/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.1336\n",
      "Epoch 59: val_loss improved from 0.12581 to 0.12526, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.1334 - val_loss: 0.1253 - learning_rate: 0.0010\n",
      "Epoch 60/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.1313\n",
      "Epoch 60: val_loss improved from 0.12526 to 0.11905, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.1313 - val_loss: 0.1190 - learning_rate: 0.0010\n",
      "Epoch 61/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.1315\n",
      "Epoch 61: val_loss did not improve from 0.11905\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1315 - val_loss: 0.1203 - learning_rate: 0.0010\n",
      "Epoch 62/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.1287\n",
      "Epoch 62: val_loss did not improve from 0.11905\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1286 - val_loss: 0.1245 - learning_rate: 0.0010\n",
      "Epoch 63/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.1266\n",
      "Epoch 63: val_loss improved from 0.11905 to 0.11809, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.1266 - val_loss: 0.1181 - learning_rate: 0.0010\n",
      "Epoch 64/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.1246\n",
      "Epoch 64: val_loss improved from 0.11809 to 0.11476, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.1246 - val_loss: 0.1148 - learning_rate: 0.0010\n",
      "Epoch 65/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.1207\n",
      "Epoch 65: val_loss did not improve from 0.11476\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.1208 - val_loss: 0.1220 - learning_rate: 0.0010\n",
      "Epoch 66/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.1205\n",
      "Epoch 66: val_loss improved from 0.11476 to 0.10932, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.1205 - val_loss: 0.1093 - learning_rate: 0.0010\n",
      "Epoch 67/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.1173\n",
      "Epoch 67: val_loss did not improve from 0.10932\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1173 - val_loss: 0.1128 - learning_rate: 0.0010\n",
      "Epoch 68/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.1160\n",
      "Epoch 68: val_loss did not improve from 0.10932\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1161 - val_loss: 0.1122 - learning_rate: 0.0010\n",
      "Epoch 69/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.1163\n",
      "Epoch 69: val_loss did not improve from 0.10932\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.1163 - val_loss: 0.1174 - learning_rate: 0.0010\n",
      "Epoch 70/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.1158\n",
      "Epoch 70: val_loss did not improve from 0.10932\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.1157 - val_loss: 0.1095 - learning_rate: 0.0010\n",
      "Epoch 71/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.1135\n",
      "Epoch 71: val_loss improved from 0.10932 to 0.10611, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.1135 - val_loss: 0.1061 - learning_rate: 0.0010\n",
      "Epoch 72/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.1121\n",
      "Epoch 72: val_loss did not improve from 0.10611\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.1121 - val_loss: 0.1067 - learning_rate: 0.0010\n",
      "Epoch 73/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.1087\n",
      "Epoch 73: val_loss improved from 0.10611 to 0.10044, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.1088 - val_loss: 0.1004 - learning_rate: 0.0010\n",
      "Epoch 74/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.1093\n",
      "Epoch 74: val_loss did not improve from 0.10044\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.1092 - val_loss: 0.1094 - learning_rate: 0.0010\n",
      "Epoch 75/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.1078\n",
      "Epoch 75: val_loss did not improve from 0.10044\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1078 - val_loss: 0.1063 - learning_rate: 0.0010\n",
      "Epoch 76/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.1081\n",
      "Epoch 76: val_loss did not improve from 0.10044\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.1079 - val_loss: 0.1026 - learning_rate: 0.0010\n",
      "Epoch 77/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.1043\n",
      "Epoch 77: val_loss did not improve from 0.10044\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1044 - val_loss: 0.1018 - learning_rate: 0.0010\n",
      "Epoch 78/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.1032\n",
      "Epoch 78: val_loss did not improve from 0.10044\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1032 - val_loss: 0.1050 - learning_rate: 0.0010\n",
      "Epoch 79/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.1030\n",
      "Epoch 79: val_loss improved from 0.10044 to 0.09611, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.1030 - val_loss: 0.0961 - learning_rate: 0.0010\n",
      "Epoch 80/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0998\n",
      "Epoch 80: val_loss improved from 0.09611 to 0.09603, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0998 - val_loss: 0.0960 - learning_rate: 0.0010\n",
      "Epoch 81/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.1003\n",
      "Epoch 81: val_loss improved from 0.09603 to 0.09290, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.1002 - val_loss: 0.0929 - learning_rate: 0.0010\n",
      "Epoch 82/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0963\n",
      "Epoch 82: val_loss did not improve from 0.09290\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0963 - val_loss: 0.1018 - learning_rate: 0.0010\n",
      "Epoch 83/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0965\n",
      "Epoch 83: val_loss improved from 0.09290 to 0.09019, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0965 - val_loss: 0.0902 - learning_rate: 0.0010\n",
      "Epoch 84/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0960\n",
      "Epoch 84: val_loss improved from 0.09019 to 0.08846, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0961 - val_loss: 0.0885 - learning_rate: 0.0010\n",
      "Epoch 85/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0968\n",
      "Epoch 85: val_loss did not improve from 0.08846\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0969 - val_loss: 0.0960 - learning_rate: 0.0010\n",
      "Epoch 86/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0960\n",
      "Epoch 86: val_loss did not improve from 0.08846\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0961 - val_loss: 0.0979 - learning_rate: 0.0010\n",
      "Epoch 87/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0945\n",
      "Epoch 87: val_loss did not improve from 0.08846\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0945 - val_loss: 0.0942 - learning_rate: 0.0010\n",
      "Epoch 88/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0926\n",
      "Epoch 88: val_loss improved from 0.08846 to 0.08819, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0926 - val_loss: 0.0882 - learning_rate: 0.0010\n",
      "Epoch 89/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0905\n",
      "Epoch 89: val_loss did not improve from 0.08819\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0905 - val_loss: 0.0889 - learning_rate: 0.0010\n",
      "Epoch 90/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0889\n",
      "Epoch 90: val_loss did not improve from 0.08819\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0890 - val_loss: 0.0920 - learning_rate: 0.0010\n",
      "Epoch 91/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0873\n",
      "Epoch 91: val_loss improved from 0.08819 to 0.08182, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0873 - val_loss: 0.0818 - learning_rate: 0.0010\n",
      "Epoch 92/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0882\n",
      "Epoch 92: val_loss improved from 0.08182 to 0.08099, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0882 - val_loss: 0.0810 - learning_rate: 0.0010\n",
      "Epoch 93/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0879\n",
      "Epoch 93: val_loss did not improve from 0.08099\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0879 - val_loss: 0.0895 - learning_rate: 0.0010\n",
      "Epoch 94/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0857\n",
      "Epoch 94: val_loss did not improve from 0.08099\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0858 - val_loss: 0.0828 - learning_rate: 0.0010\n",
      "Epoch 95/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0850\n",
      "Epoch 95: val_loss did not improve from 0.08099\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0850 - val_loss: 0.0821 - learning_rate: 0.0010\n",
      "Epoch 96/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0862\n",
      "Epoch 96: val_loss improved from 0.08099 to 0.07857, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0862 - val_loss: 0.0786 - learning_rate: 0.0010\n",
      "Epoch 97/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0858\n",
      "Epoch 97: val_loss did not improve from 0.07857\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0858 - val_loss: 0.0790 - learning_rate: 0.0010\n",
      "Epoch 98/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0833\n",
      "Epoch 98: val_loss improved from 0.07857 to 0.07535, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0833 - val_loss: 0.0753 - learning_rate: 0.0010\n",
      "Epoch 99/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0840\n",
      "Epoch 99: val_loss improved from 0.07535 to 0.07489, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0839 - val_loss: 0.0749 - learning_rate: 0.0010\n",
      "Epoch 100/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0814\n",
      "Epoch 100: val_loss did not improve from 0.07489\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0814 - val_loss: 0.0752 - learning_rate: 0.0010\n",
      "Epoch 101/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0804\n",
      "Epoch 101: val_loss did not improve from 0.07489\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0804 - val_loss: 0.0756 - learning_rate: 0.0010\n",
      "Epoch 102/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0796\n",
      "Epoch 102: val_loss did not improve from 0.07489\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0797 - val_loss: 0.0775 - learning_rate: 0.0010\n",
      "Epoch 103/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0793\n",
      "Epoch 103: val_loss improved from 0.07489 to 0.07346, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0793 - val_loss: 0.0735 - learning_rate: 0.0010\n",
      "Epoch 104/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0780\n",
      "Epoch 104: val_loss improved from 0.07346 to 0.07023, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0780 - val_loss: 0.0702 - learning_rate: 0.0010\n",
      "Epoch 105/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0789\n",
      "Epoch 105: val_loss improved from 0.07023 to 0.06730, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0788 - val_loss: 0.0673 - learning_rate: 0.0010\n",
      "Epoch 106/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0757\n",
      "Epoch 106: val_loss did not improve from 0.06730\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0757 - val_loss: 0.0797 - learning_rate: 0.0010\n",
      "Epoch 107/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0765\n",
      "Epoch 107: val_loss did not improve from 0.06730\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0765 - val_loss: 0.0716 - learning_rate: 0.0010\n",
      "Epoch 108/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0755\n",
      "Epoch 108: val_loss did not improve from 0.06730\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0755 - val_loss: 0.0694 - learning_rate: 0.0010\n",
      "Epoch 109/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0743\n",
      "Epoch 109: val_loss did not improve from 0.06730\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0743 - val_loss: 0.0704 - learning_rate: 0.0010\n",
      "Epoch 110/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0737\n",
      "Epoch 110: val_loss did not improve from 0.06730\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0738 - val_loss: 0.0815 - learning_rate: 0.0010\n",
      "Epoch 111/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0752\n",
      "Epoch 111: val_loss did not improve from 0.06730\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0752 - val_loss: 0.0677 - learning_rate: 0.0010\n",
      "Epoch 112/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0722\n",
      "Epoch 112: val_loss improved from 0.06730 to 0.06418, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0721 - val_loss: 0.0642 - learning_rate: 0.0010\n",
      "Epoch 113/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0708\n",
      "Epoch 113: val_loss did not improve from 0.06418\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0708 - val_loss: 0.0750 - learning_rate: 0.0010\n",
      "Epoch 114/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0704\n",
      "Epoch 114: val_loss did not improve from 0.06418\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0704 - val_loss: 0.0705 - learning_rate: 0.0010\n",
      "Epoch 115/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0698\n",
      "Epoch 115: val_loss did not improve from 0.06418\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0699 - val_loss: 0.0653 - learning_rate: 0.0010\n",
      "Epoch 116/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0698\n",
      "Epoch 116: val_loss did not improve from 0.06418\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0699 - val_loss: 0.0649 - learning_rate: 0.0010\n",
      "Epoch 117/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0698\n",
      "Epoch 117: val_loss did not improve from 0.06418\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0698 - val_loss: 0.0643 - learning_rate: 0.0010\n",
      "Epoch 118/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0699\n",
      "Epoch 118: val_loss did not improve from 0.06418\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0699 - val_loss: 0.0760 - learning_rate: 0.0010\n",
      "Epoch 119/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0700\n",
      "Epoch 119: val_loss did not improve from 0.06418\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0700 - val_loss: 0.0683 - learning_rate: 0.0010\n",
      "Epoch 120/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0673\n",
      "Epoch 120: val_loss improved from 0.06418 to 0.06186, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0674 - val_loss: 0.0619 - learning_rate: 0.0010\n",
      "Epoch 121/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0668\n",
      "Epoch 121: val_loss did not improve from 0.06186\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0668 - val_loss: 0.0680 - learning_rate: 0.0010\n",
      "Epoch 122/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0664\n",
      "Epoch 122: val_loss did not improve from 0.06186\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0664 - val_loss: 0.0633 - learning_rate: 0.0010\n",
      "Epoch 123/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0664\n",
      "Epoch 123: val_loss improved from 0.06186 to 0.06128, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0663 - val_loss: 0.0613 - learning_rate: 0.0010\n",
      "Epoch 124/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0637\n",
      "Epoch 124: val_loss did not improve from 0.06128\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0637 - val_loss: 0.0613 - learning_rate: 0.0010\n",
      "Epoch 125/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0644\n",
      "Epoch 125: val_loss did not improve from 0.06128\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0644 - val_loss: 0.0652 - learning_rate: 0.0010\n",
      "Epoch 126/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0637\n",
      "Epoch 126: val_loss improved from 0.06128 to 0.05644, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0636 - val_loss: 0.0564 - learning_rate: 0.0010\n",
      "Epoch 127/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0627\n",
      "Epoch 127: val_loss did not improve from 0.05644\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0628 - val_loss: 0.0606 - learning_rate: 0.0010\n",
      "Epoch 128/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0623\n",
      "Epoch 128: val_loss did not improve from 0.05644\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0624 - val_loss: 0.0721 - learning_rate: 0.0010\n",
      "Epoch 129/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0629\n",
      "Epoch 129: val_loss did not improve from 0.05644\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0629 - val_loss: 0.0645 - learning_rate: 0.0010\n",
      "Epoch 130/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0645\n",
      "Epoch 130: val_loss did not improve from 0.05644\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0644 - val_loss: 0.0592 - learning_rate: 0.0010\n",
      "Epoch 131/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0614\n",
      "Epoch 131: val_loss improved from 0.05644 to 0.05327, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0613 - val_loss: 0.0533 - learning_rate: 0.0010\n",
      "Epoch 132/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0598\n",
      "Epoch 132: val_loss did not improve from 0.05327\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0598 - val_loss: 0.0536 - learning_rate: 0.0010\n",
      "Epoch 133/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0589\n",
      "Epoch 133: val_loss did not improve from 0.05327\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0589 - val_loss: 0.0554 - learning_rate: 0.0010\n",
      "Epoch 134/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0583\n",
      "Epoch 134: val_loss did not improve from 0.05327\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0584 - val_loss: 0.0553 - learning_rate: 0.0010\n",
      "Epoch 135/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0581\n",
      "Epoch 135: val_loss did not improve from 0.05327\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0582 - val_loss: 0.0539 - learning_rate: 0.0010\n",
      "Epoch 136/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0615\n",
      "Epoch 136: val_loss did not improve from 0.05327\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0614 - val_loss: 0.0548 - learning_rate: 0.0010\n",
      "Epoch 137/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0590\n",
      "Epoch 137: val_loss did not improve from 0.05327\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0591 - val_loss: 0.0578 - learning_rate: 0.0010\n",
      "Epoch 138/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0595\n",
      "Epoch 138: val_loss improved from 0.05327 to 0.05211, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0594 - val_loss: 0.0521 - learning_rate: 0.0010\n",
      "Epoch 139/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0589\n",
      "Epoch 139: val_loss did not improve from 0.05211\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0588 - val_loss: 0.0561 - learning_rate: 0.0010\n",
      "Epoch 140/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0578\n",
      "Epoch 140: val_loss improved from 0.05211 to 0.04933, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0578 - val_loss: 0.0493 - learning_rate: 0.0010\n",
      "Epoch 141/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0561\n",
      "Epoch 141: val_loss did not improve from 0.04933\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0562 - val_loss: 0.0602 - learning_rate: 0.0010\n",
      "Epoch 142/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0574\n",
      "Epoch 142: val_loss did not improve from 0.04933\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0574 - val_loss: 0.0531 - learning_rate: 0.0010\n",
      "Epoch 143/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0576\n",
      "Epoch 143: val_loss did not improve from 0.04933\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0575 - val_loss: 0.0565 - learning_rate: 0.0010\n",
      "Epoch 144/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0568\n",
      "Epoch 144: val_loss did not improve from 0.04933\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0568 - val_loss: 0.0528 - learning_rate: 0.0010\n",
      "Epoch 145/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0559\n",
      "Epoch 145: val_loss did not improve from 0.04933\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0560 - val_loss: 0.0549 - learning_rate: 0.0010\n",
      "Epoch 146/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0543\n",
      "Epoch 146: val_loss did not improve from 0.04933\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0544 - val_loss: 0.0560 - learning_rate: 0.0010\n",
      "Epoch 147/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0539\n",
      "Epoch 147: val_loss improved from 0.04933 to 0.04924, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0539 - val_loss: 0.0492 - learning_rate: 0.0010\n",
      "Epoch 148/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0542\n",
      "Epoch 148: val_loss did not improve from 0.04924\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0543 - val_loss: 0.0525 - learning_rate: 0.0010\n",
      "Epoch 149/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0537\n",
      "Epoch 149: val_loss improved from 0.04924 to 0.04658, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0537 - val_loss: 0.0466 - learning_rate: 0.0010\n",
      "Epoch 150/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0528\n",
      "Epoch 150: val_loss did not improve from 0.04658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0528 - val_loss: 0.0470 - learning_rate: 0.0010\n",
      "Epoch 151/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0521\n",
      "Epoch 151: val_loss did not improve from 0.04658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0523 - val_loss: 0.0498 - learning_rate: 0.0010\n",
      "Epoch 152/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0540\n",
      "Epoch 152: val_loss did not improve from 0.04658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0540 - val_loss: 0.0515 - learning_rate: 0.0010\n",
      "Epoch 153/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0536\n",
      "Epoch 153: val_loss did not improve from 0.04658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0536 - val_loss: 0.0524 - learning_rate: 0.0010\n",
      "Epoch 154/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0536\n",
      "Epoch 154: val_loss did not improve from 0.04658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0535 - val_loss: 0.0615 - learning_rate: 0.0010\n",
      "Epoch 155/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0524\n",
      "Epoch 155: val_loss did not improve from 0.04658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0525 - val_loss: 0.0476 - learning_rate: 0.0010\n",
      "Epoch 156/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0519\n",
      "Epoch 156: val_loss did not improve from 0.04658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0520 - val_loss: 0.0475 - learning_rate: 0.0010\n",
      "Epoch 157/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0518\n",
      "Epoch 157: val_loss did not improve from 0.04658\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0517 - val_loss: 0.0495 - learning_rate: 0.0010\n",
      "Epoch 158/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0489\n",
      "Epoch 158: val_loss improved from 0.04658 to 0.04265, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0489 - val_loss: 0.0427 - learning_rate: 0.0010\n",
      "Epoch 159/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0487\n",
      "Epoch 159: val_loss did not improve from 0.04265\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0487 - val_loss: 0.0475 - learning_rate: 0.0010\n",
      "Epoch 160/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0493\n",
      "Epoch 160: val_loss did not improve from 0.04265\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0493 - val_loss: 0.0451 - learning_rate: 0.0010\n",
      "Epoch 161/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0488\n",
      "Epoch 161: val_loss did not improve from 0.04265\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0488 - val_loss: 0.0559 - learning_rate: 0.0010\n",
      "Epoch 162/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0492\n",
      "Epoch 162: val_loss did not improve from 0.04265\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0492 - val_loss: 0.0441 - learning_rate: 0.0010\n",
      "Epoch 163/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0475\n",
      "Epoch 163: val_loss did not improve from 0.04265\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0475 - val_loss: 0.0435 - learning_rate: 0.0010\n",
      "Epoch 164/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0468\n",
      "Epoch 164: val_loss did not improve from 0.04265\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0468 - val_loss: 0.0463 - learning_rate: 0.0010\n",
      "Epoch 165/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0483\n",
      "Epoch 165: val_loss did not improve from 0.04265\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0483 - val_loss: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 166/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0481\n",
      "Epoch 166: val_loss improved from 0.04265 to 0.04181, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0481 - val_loss: 0.0418 - learning_rate: 0.0010\n",
      "Epoch 167/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0464\n",
      "Epoch 167: val_loss did not improve from 0.04181\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0464 - val_loss: 0.0419 - learning_rate: 0.0010\n",
      "Epoch 168/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0456\n",
      "Epoch 168: val_loss improved from 0.04181 to 0.04143, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0457 - val_loss: 0.0414 - learning_rate: 0.0010\n",
      "Epoch 169/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0462\n",
      "Epoch 169: val_loss did not improve from 0.04143\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0463 - val_loss: 0.0451 - learning_rate: 0.0010\n",
      "Epoch 170/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0484\n",
      "Epoch 170: val_loss improved from 0.04143 to 0.04125, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0484 - val_loss: 0.0413 - learning_rate: 0.0010\n",
      "Epoch 171/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0467\n",
      "Epoch 171: val_loss improved from 0.04125 to 0.03830, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0467 - val_loss: 0.0383 - learning_rate: 0.0010\n",
      "Epoch 172/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0446\n",
      "Epoch 172: val_loss did not improve from 0.03830\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0446 - val_loss: 0.0386 - learning_rate: 0.0010\n",
      "Epoch 173/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0449\n",
      "Epoch 173: val_loss did not improve from 0.03830\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0449 - val_loss: 0.0522 - learning_rate: 0.0010\n",
      "Epoch 174/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0449\n",
      "Epoch 174: val_loss did not improve from 0.03830\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0449 - val_loss: 0.0444 - learning_rate: 0.0010\n",
      "Epoch 175/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0443\n",
      "Epoch 175: val_loss did not improve from 0.03830\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0443 - val_loss: 0.0388 - learning_rate: 0.0010\n",
      "Epoch 176/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0442\n",
      "Epoch 176: val_loss did not improve from 0.03830\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0442 - val_loss: 0.0408 - learning_rate: 0.0010\n",
      "Epoch 177/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0436\n",
      "Epoch 177: val_loss did not improve from 0.03830\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0436 - val_loss: 0.0438 - learning_rate: 0.0010\n",
      "Epoch 178/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0429\n",
      "Epoch 178: val_loss did not improve from 0.03830\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0430 - val_loss: 0.0395 - learning_rate: 0.0010\n",
      "Epoch 179/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0425\n",
      "Epoch 179: val_loss did not improve from 0.03830\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0425 - val_loss: 0.0392 - learning_rate: 0.0010\n",
      "Epoch 180/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0425\n",
      "Epoch 180: val_loss did not improve from 0.03830\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0425 - val_loss: 0.0398 - learning_rate: 0.0010\n",
      "Epoch 181/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0424\n",
      "Epoch 181: val_loss improved from 0.03830 to 0.03814, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0424 - val_loss: 0.0381 - learning_rate: 0.0010\n",
      "Epoch 182/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0412\n",
      "Epoch 182: val_loss did not improve from 0.03814\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0413 - val_loss: 0.0393 - learning_rate: 0.0010\n",
      "Epoch 183/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0418\n",
      "Epoch 183: val_loss did not improve from 0.03814\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0419 - val_loss: 0.0432 - learning_rate: 0.0010\n",
      "Epoch 184/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0434\n",
      "Epoch 184: val_loss did not improve from 0.03814\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0434 - val_loss: 0.0386 - learning_rate: 0.0010\n",
      "Epoch 185/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0422\n",
      "Epoch 185: val_loss did not improve from 0.03814\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0422 - val_loss: 0.0417 - learning_rate: 0.0010\n",
      "Epoch 186/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0408\n",
      "Epoch 186: val_loss did not improve from 0.03814\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0408 - val_loss: 0.0386 - learning_rate: 0.0010\n",
      "Epoch 187/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0403\n",
      "Epoch 187: val_loss improved from 0.03814 to 0.03655, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0403 - val_loss: 0.0365 - learning_rate: 0.0010\n",
      "Epoch 188/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0397\n",
      "Epoch 188: val_loss improved from 0.03655 to 0.03448, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0397 - val_loss: 0.0345 - learning_rate: 0.0010\n",
      "Epoch 189/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0398\n",
      "Epoch 189: val_loss did not improve from 0.03448\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0399 - val_loss: 0.0359 - learning_rate: 0.0010\n",
      "Epoch 190/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0392\n",
      "Epoch 190: val_loss did not improve from 0.03448\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0392 - val_loss: 0.0362 - learning_rate: 0.0010\n",
      "Epoch 191/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0398\n",
      "Epoch 191: val_loss improved from 0.03448 to 0.03371, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0398 - val_loss: 0.0337 - learning_rate: 0.0010\n",
      "Epoch 192/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0398\n",
      "Epoch 192: val_loss improved from 0.03371 to 0.03277, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0399 - val_loss: 0.0328 - learning_rate: 0.0010\n",
      "Epoch 193/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0401\n",
      "Epoch 193: val_loss did not improve from 0.03277\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0401 - val_loss: 0.0361 - learning_rate: 0.0010\n",
      "Epoch 194/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0395\n",
      "Epoch 194: val_loss did not improve from 0.03277\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0395 - val_loss: 0.0342 - learning_rate: 0.0010\n",
      "Epoch 195/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0382\n",
      "Epoch 195: val_loss did not improve from 0.03277\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0382 - val_loss: 0.0330 - learning_rate: 0.0010\n",
      "Epoch 196/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0389\n",
      "Epoch 196: val_loss improved from 0.03277 to 0.03242, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0389 - val_loss: 0.0324 - learning_rate: 0.0010\n",
      "Epoch 197/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0372\n",
      "Epoch 197: val_loss did not improve from 0.03242\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0372 - val_loss: 0.0363 - learning_rate: 0.0010\n",
      "Epoch 198/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0381\n",
      "Epoch 198: val_loss did not improve from 0.03242\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0382 - val_loss: 0.0335 - learning_rate: 0.0010\n",
      "Epoch 199/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0385\n",
      "Epoch 199: val_loss did not improve from 0.03242\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0385 - val_loss: 0.0337 - learning_rate: 0.0010\n",
      "Epoch 200/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0380\n",
      "Epoch 200: val_loss did not improve from 0.03242\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0380 - val_loss: 0.0341 - learning_rate: 0.0010\n",
      "Epoch 201/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0376\n",
      "Epoch 201: val_loss did not improve from 0.03242\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0376 - val_loss: 0.0386 - learning_rate: 0.0010\n",
      "Epoch 202/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0370\n",
      "Epoch 202: val_loss did not improve from 0.03242\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0371 - val_loss: 0.0366 - learning_rate: 0.0010\n",
      "Epoch 203/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0375\n",
      "Epoch 203: val_loss did not improve from 0.03242\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0375 - val_loss: 0.0337 - learning_rate: 0.0010\n",
      "Epoch 204/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0360\n",
      "Epoch 204: val_loss improved from 0.03242 to 0.03121, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0360 - val_loss: 0.0312 - learning_rate: 0.0010\n",
      "Epoch 205/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0351\n",
      "Epoch 205: val_loss did not improve from 0.03121\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0352 - val_loss: 0.0336 - learning_rate: 0.0010\n",
      "Epoch 206/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0339\n",
      "Epoch 206: val_loss did not improve from 0.03121\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0339 - val_loss: 0.0326 - learning_rate: 0.0010\n",
      "Epoch 207/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0351\n",
      "Epoch 207: val_loss did not improve from 0.03121\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0351 - val_loss: 0.0315 - learning_rate: 0.0010\n",
      "Epoch 208/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0366\n",
      "Epoch 208: val_loss did not improve from 0.03121\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0367 - val_loss: 0.0328 - learning_rate: 0.0010\n",
      "Epoch 209/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0368\n",
      "Epoch 209: val_loss did not improve from 0.03121\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0369 - val_loss: 0.0314 - learning_rate: 0.0010\n",
      "Epoch 210/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0368\n",
      "Epoch 210: val_loss did not improve from 0.03121\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0369 - val_loss: 0.0323 - learning_rate: 0.0010\n",
      "Epoch 211/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0367\n",
      "Epoch 211: val_loss did not improve from 0.03121\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0368 - val_loss: 0.0368 - learning_rate: 0.0010\n",
      "Epoch 212/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0355\n",
      "Epoch 212: val_loss improved from 0.03121 to 0.03045, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0356 - val_loss: 0.0305 - learning_rate: 0.0010\n",
      "Epoch 213/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0352\n",
      "Epoch 213: val_loss did not improve from 0.03045\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0352 - val_loss: 0.0320 - learning_rate: 0.0010\n",
      "Epoch 214/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0346\n",
      "Epoch 214: val_loss improved from 0.03045 to 0.03043, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0346 - val_loss: 0.0304 - learning_rate: 0.0010\n",
      "Epoch 215/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0355\n",
      "Epoch 215: val_loss improved from 0.03043 to 0.03007, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0355 - val_loss: 0.0301 - learning_rate: 0.0010\n",
      "Epoch 216/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0340\n",
      "Epoch 216: val_loss improved from 0.03007 to 0.02828, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0340 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 217/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0342\n",
      "Epoch 217: val_loss did not improve from 0.02828\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0342 - val_loss: 0.0296 - learning_rate: 0.0010\n",
      "Epoch 218/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0332\n",
      "Epoch 218: val_loss did not improve from 0.02828\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0332 - val_loss: 0.0310 - learning_rate: 0.0010\n",
      "Epoch 219/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0337\n",
      "Epoch 219: val_loss did not improve from 0.02828\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0336 - val_loss: 0.0297 - learning_rate: 0.0010\n",
      "Epoch 220/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0327\n",
      "Epoch 220: val_loss improved from 0.02828 to 0.02815, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0327 - val_loss: 0.0282 - learning_rate: 0.0010\n",
      "Epoch 221/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0340\n",
      "Epoch 221: val_loss improved from 0.02815 to 0.02780, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0340 - val_loss: 0.0278 - learning_rate: 0.0010\n",
      "Epoch 222/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0338\n",
      "Epoch 222: val_loss did not improve from 0.02780\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0338 - val_loss: 0.0334 - learning_rate: 0.0010\n",
      "Epoch 223/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0327\n",
      "Epoch 223: val_loss did not improve from 0.02780\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0328 - val_loss: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 224/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0333\n",
      "Epoch 224: val_loss did not improve from 0.02780\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0332 - val_loss: 0.0290 - learning_rate: 0.0010\n",
      "Epoch 225/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0322\n",
      "Epoch 225: val_loss did not improve from 0.02780\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0322 - val_loss: 0.0340 - learning_rate: 0.0010\n",
      "Epoch 226/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0334\n",
      "Epoch 226: val_loss did not improve from 0.02780\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0334 - val_loss: 0.0286 - learning_rate: 0.0010\n",
      "Epoch 227/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0325\n",
      "Epoch 227: val_loss did not improve from 0.02780\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0325 - val_loss: 0.0294 - learning_rate: 0.0010\n",
      "Epoch 228/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0330\n",
      "Epoch 228: val_loss did not improve from 0.02780\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0330 - val_loss: 0.0346 - learning_rate: 0.0010\n",
      "Epoch 229/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0340\n",
      "Epoch 229: val_loss did not improve from 0.02780\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0340 - val_loss: 0.0288 - learning_rate: 0.0010\n",
      "Epoch 230/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0310\n",
      "Epoch 230: val_loss did not improve from 0.02780\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0311 - val_loss: 0.0280 - learning_rate: 0.0010\n",
      "Epoch 231/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0315\n",
      "Epoch 231: val_loss did not improve from 0.02780\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0316 - val_loss: 0.0309 - learning_rate: 0.0010\n",
      "Epoch 232/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0316\n",
      "Epoch 232: val_loss did not improve from 0.02780\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0317 - val_loss: 0.0318 - learning_rate: 0.0010\n",
      "Epoch 233/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0326\n",
      "Epoch 233: val_loss did not improve from 0.02780\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0326 - val_loss: 0.0286 - learning_rate: 0.0010\n",
      "Epoch 234/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0311\n",
      "Epoch 234: val_loss improved from 0.02780 to 0.02631, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0311 - val_loss: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 235/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0308\n",
      "Epoch 235: val_loss did not improve from 0.02631\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0309 - val_loss: 0.0338 - learning_rate: 0.0010\n",
      "Epoch 236/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0322\n",
      "Epoch 236: val_loss did not improve from 0.02631\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0321 - val_loss: 0.0333 - learning_rate: 0.0010\n",
      "Epoch 237/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0305\n",
      "Epoch 237: val_loss did not improve from 0.02631\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0305 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 238/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0295\n",
      "Epoch 238: val_loss did not improve from 0.02631\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0295 - val_loss: 0.0273 - learning_rate: 0.0010\n",
      "Epoch 239/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0294\n",
      "Epoch 239: val_loss did not improve from 0.02631\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0295 - val_loss: 0.0290 - learning_rate: 0.0010\n",
      "Epoch 240/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0306\n",
      "Epoch 240: val_loss did not improve from 0.02631\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0306 - val_loss: 0.0310 - learning_rate: 0.0010\n",
      "Epoch 241/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0315\n",
      "Epoch 241: val_loss did not improve from 0.02631\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0315 - val_loss: 0.0277 - learning_rate: 0.0010\n",
      "Epoch 242/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0311\n",
      "Epoch 242: val_loss did not improve from 0.02631\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0311 - val_loss: 0.0357 - learning_rate: 0.0010\n",
      "Epoch 243/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0299\n",
      "Epoch 243: val_loss did not improve from 0.02631\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0300 - val_loss: 0.0267 - learning_rate: 0.0010\n",
      "Epoch 244/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0301\n",
      "Epoch 244: val_loss did not improve from 0.02631\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0302 - val_loss: 0.0296 - learning_rate: 0.0010\n",
      "Epoch 245/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0318\n",
      "Epoch 245: val_loss did not improve from 0.02631\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0320 - val_loss: 0.0272 - learning_rate: 0.0010\n",
      "Epoch 246/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0319\n",
      "Epoch 246: val_loss improved from 0.02631 to 0.02348, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0318 - val_loss: 0.0235 - learning_rate: 0.0010\n",
      "Epoch 247/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0307\n",
      "Epoch 247: val_loss did not improve from 0.02348\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0307 - val_loss: 0.0268 - learning_rate: 0.0010\n",
      "Epoch 248/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0304\n",
      "Epoch 248: val_loss did not improve from 0.02348\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0304 - val_loss: 0.0307 - learning_rate: 0.0010\n",
      "Epoch 249/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0303\n",
      "Epoch 249: val_loss did not improve from 0.02348\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0302 - val_loss: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 250/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0295\n",
      "Epoch 250: val_loss did not improve from 0.02348\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0295 - val_loss: 0.0339 - learning_rate: 0.0010\n",
      "Epoch 251/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0289\n",
      "Epoch 251: val_loss did not improve from 0.02348\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0289 - val_loss: 0.0383 - learning_rate: 0.0010\n",
      "Epoch 252/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0288\n",
      "Epoch 252: val_loss did not improve from 0.02348\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0288 - val_loss: 0.0298 - learning_rate: 0.0010\n",
      "Epoch 253/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0292\n",
      "Epoch 253: val_loss did not improve from 0.02348\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0292 - val_loss: 0.0316 - learning_rate: 0.0010\n",
      "Epoch 254/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0290\n",
      "Epoch 254: val_loss did not improve from 0.02348\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0290 - val_loss: 0.0306 - learning_rate: 0.0010\n",
      "Epoch 255/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0286\n",
      "Epoch 255: val_loss did not improve from 0.02348\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0286 - val_loss: 0.0258 - learning_rate: 0.0010\n",
      "Epoch 256/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0278\n",
      "Epoch 256: val_loss did not improve from 0.02348\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0278 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 257/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0288\n",
      "Epoch 257: val_loss improved from 0.02348 to 0.02236, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0288 - val_loss: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 258/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0290\n",
      "Epoch 258: val_loss improved from 0.02236 to 0.02167, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0290 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 259/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0290\n",
      "Epoch 259: val_loss did not improve from 0.02167\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0290 - val_loss: 0.0259 - learning_rate: 0.0010\n",
      "Epoch 260/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0321\n",
      "Epoch 260: val_loss did not improve from 0.02167\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0321 - val_loss: 0.0265 - learning_rate: 0.0010\n",
      "Epoch 261/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0291\n",
      "Epoch 261: val_loss did not improve from 0.02167\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0291 - val_loss: 0.0322 - learning_rate: 0.0010\n",
      "Epoch 262/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0292\n",
      "Epoch 262: val_loss did not improve from 0.02167\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0292 - val_loss: 0.0249 - learning_rate: 0.0010\n",
      "Epoch 263/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0271\n",
      "Epoch 263: val_loss did not improve from 0.02167\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0271 - val_loss: 0.0258 - learning_rate: 0.0010\n",
      "Epoch 264/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0261\n",
      "Epoch 264: val_loss did not improve from 0.02167\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0262 - val_loss: 0.0334 - learning_rate: 0.0010\n",
      "Epoch 265/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0270\n",
      "Epoch 265: val_loss did not improve from 0.02167\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0270 - val_loss: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 266/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0264\n",
      "Epoch 266: val_loss did not improve from 0.02167\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0265 - val_loss: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 267/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0268\n",
      "Epoch 267: val_loss did not improve from 0.02167\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0269 - val_loss: 0.0301 - learning_rate: 0.0010\n",
      "Epoch 268/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0272\n",
      "Epoch 268: val_loss did not improve from 0.02167\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0272 - val_loss: 0.0321 - learning_rate: 0.0010\n",
      "Epoch 269/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0267\n",
      "Epoch 269: val_loss did not improve from 0.02167\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0267 - val_loss: 0.0249 - learning_rate: 0.0010\n",
      "Epoch 270/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0258\n",
      "Epoch 270: val_loss did not improve from 0.02167\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0258 - val_loss: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 271/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0250\n",
      "Epoch 271: val_loss did not improve from 0.02167\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0250 - val_loss: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 272/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0251\n",
      "Epoch 272: val_loss did not improve from 0.02167\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0252 - val_loss: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 273/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0260\n",
      "Epoch 273: val_loss did not improve from 0.02167\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0261 - val_loss: 0.0218 - learning_rate: 0.0010\n",
      "Epoch 274/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0283\n",
      "Epoch 274: val_loss did not improve from 0.02167\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0283 - val_loss: 0.0236 - learning_rate: 0.0010\n",
      "Epoch 275/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0268\n",
      "Epoch 275: val_loss improved from 0.02167 to 0.02018, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0268 - val_loss: 0.0202 - learning_rate: 0.0010\n",
      "Epoch 276/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0250\n",
      "Epoch 276: val_loss did not improve from 0.02018\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0250 - val_loss: 0.0219 - learning_rate: 0.0010\n",
      "Epoch 277/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0251\n",
      "Epoch 277: val_loss did not improve from 0.02018\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0251 - val_loss: 0.0272 - learning_rate: 0.0010\n",
      "Epoch 278/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0248\n",
      "Epoch 278: val_loss did not improve from 0.02018\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0248 - val_loss: 0.0279 - learning_rate: 0.0010\n",
      "Epoch 279/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0250\n",
      "Epoch 279: val_loss did not improve from 0.02018\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0250 - val_loss: 0.0249 - learning_rate: 0.0010\n",
      "Epoch 280/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0245\n",
      "Epoch 280: val_loss did not improve from 0.02018\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0245 - val_loss: 0.0295 - learning_rate: 0.0010\n",
      "Epoch 281/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0243\n",
      "Epoch 281: val_loss did not improve from 0.02018\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0244 - val_loss: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 282/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0236\n",
      "Epoch 282: val_loss improved from 0.02018 to 0.01989, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0236 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 283/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0252\n",
      "Epoch 283: val_loss did not improve from 0.01989\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0251 - val_loss: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 284/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0259\n",
      "Epoch 284: val_loss did not improve from 0.01989\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0259 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 285/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0244\n",
      "Epoch 285: val_loss did not improve from 0.01989\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0245 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 286/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0234\n",
      "Epoch 286: val_loss did not improve from 0.01989\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0235 - val_loss: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 287/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0239\n",
      "Epoch 287: val_loss did not improve from 0.01989\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0239 - val_loss: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 288/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0230\n",
      "Epoch 288: val_loss did not improve from 0.01989\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0229 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 289/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0225\n",
      "Epoch 289: val_loss did not improve from 0.01989\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0225 - val_loss: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 290/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0232\n",
      "Epoch 290: val_loss did not improve from 0.01989\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0231 - val_loss: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 291/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0225\n",
      "Epoch 291: val_loss did not improve from 0.01989\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0225 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 292/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0218\n",
      "Epoch 292: val_loss did not improve from 0.01989\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0219 - val_loss: 0.0285 - learning_rate: 0.0010\n",
      "Epoch 293/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0239\n",
      "Epoch 293: val_loss did not improve from 0.01989\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0238 - val_loss: 0.0249 - learning_rate: 0.0010\n",
      "Epoch 294/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0230\n",
      "Epoch 294: val_loss did not improve from 0.01989\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0230 - val_loss: 0.0210 - learning_rate: 0.0010\n",
      "Epoch 295/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0233\n",
      "Epoch 295: val_loss did not improve from 0.01989\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0233 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 296/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0235\n",
      "Epoch 296: val_loss did not improve from 0.01989\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0236 - val_loss: 0.0210 - learning_rate: 0.0010\n",
      "Epoch 297/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0238\n",
      "Epoch 297: val_loss did not improve from 0.01989\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0238 - val_loss: 0.0202 - learning_rate: 0.0010\n",
      "Epoch 298/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0230\n",
      "Epoch 298: val_loss did not improve from 0.01989\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0230 - val_loss: 0.0343 - learning_rate: 0.0010\n",
      "Epoch 299/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0237\n",
      "Epoch 299: val_loss did not improve from 0.01989\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0237 - val_loss: 0.0279 - learning_rate: 0.0010\n",
      "Epoch 300/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0231\n",
      "Epoch 300: val_loss improved from 0.01989 to 0.01976, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.0231 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 301/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0241\n",
      "Epoch 301: val_loss did not improve from 0.01976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0241 - val_loss: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 302/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0230\n",
      "Epoch 302: val_loss did not improve from 0.01976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0231 - val_loss: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 303/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0238\n",
      "Epoch 303: val_loss did not improve from 0.01976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0238 - val_loss: 0.0269 - learning_rate: 0.0010\n",
      "Epoch 304/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0223\n",
      "Epoch 304: val_loss did not improve from 0.01976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0224 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 305/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0224\n",
      "Epoch 305: val_loss did not improve from 0.01976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0225 - val_loss: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 306/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0244\n",
      "Epoch 306: val_loss did not improve from 0.01976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0243 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 307/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0222\n",
      "Epoch 307: val_loss did not improve from 0.01976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0222 - val_loss: 0.0264 - learning_rate: 0.0010\n",
      "Epoch 308/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0219\n",
      "Epoch 308: val_loss did not improve from 0.01976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0219 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 309/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0231\n",
      "Epoch 309: val_loss improved from 0.01976 to 0.01756, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0231 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 310/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0224\n",
      "Epoch 310: val_loss did not improve from 0.01756\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0224 - val_loss: 0.0275 - learning_rate: 0.0010\n",
      "Epoch 311/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0233\n",
      "Epoch 311: val_loss did not improve from 0.01756\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0233 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 312/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0235\n",
      "Epoch 312: val_loss did not improve from 0.01756\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0235 - val_loss: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 313/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0226\n",
      "Epoch 313: val_loss did not improve from 0.01756\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0226 - val_loss: 0.0239 - learning_rate: 0.0010\n",
      "Epoch 314/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0218\n",
      "Epoch 314: val_loss did not improve from 0.01756\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0219 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 315/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0207\n",
      "Epoch 315: val_loss did not improve from 0.01756\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0208 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 316/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0206\n",
      "Epoch 316: val_loss did not improve from 0.01756\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0206 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 317/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0210\n",
      "Epoch 317: val_loss did not improve from 0.01756\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0211 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 318/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0219\n",
      "Epoch 318: val_loss did not improve from 0.01756\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0219 - val_loss: 0.0225 - learning_rate: 0.0010\n",
      "Epoch 319/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0228\n",
      "Epoch 319: val_loss did not improve from 0.01756\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0228 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 320/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0219\n",
      "Epoch 320: val_loss did not improve from 0.01756\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0220 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 321/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0227\n",
      "Epoch 321: val_loss did not improve from 0.01756\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0227 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 322/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0225\n",
      "Epoch 322: val_loss did not improve from 0.01756\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0225 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 323/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0208\n",
      "Epoch 323: val_loss did not improve from 0.01756\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0208 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 324/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0200\n",
      "Epoch 324: val_loss did not improve from 0.01756\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0200 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 325/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0205\n",
      "Epoch 325: val_loss improved from 0.01756 to 0.01694, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0205 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 326/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0217\n",
      "Epoch 326: val_loss did not improve from 0.01694\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0217 - val_loss: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 327/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0233\n",
      "Epoch 327: val_loss improved from 0.01694 to 0.01686, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0233 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 328/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0214\n",
      "Epoch 328: val_loss did not improve from 0.01686\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0215 - val_loss: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 329/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0215\n",
      "Epoch 329: val_loss did not improve from 0.01686\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0216 - val_loss: 0.0236 - learning_rate: 0.0010\n",
      "Epoch 330/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0221\n",
      "Epoch 330: val_loss did not improve from 0.01686\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0221 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 331/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0222\n",
      "Epoch 331: val_loss did not improve from 0.01686\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0222 - val_loss: 0.0269 - learning_rate: 0.0010\n",
      "Epoch 332/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0244\n",
      "Epoch 332: val_loss did not improve from 0.01686\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0243 - val_loss: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 333/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0208\n",
      "Epoch 333: val_loss did not improve from 0.01686\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0208 - val_loss: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 334/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0208\n",
      "Epoch 334: val_loss did not improve from 0.01686\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0209 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 335/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0200\n",
      "Epoch 335: val_loss did not improve from 0.01686\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0200 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 336/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0202\n",
      "Epoch 336: val_loss improved from 0.01686 to 0.01585, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0202 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 337/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0196\n",
      "Epoch 337: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0197 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 338/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0197\n",
      "Epoch 338: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0197 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 339/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0192\n",
      "Epoch 339: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0193 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 340/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0203\n",
      "Epoch 340: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0203 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 341/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0212\n",
      "Epoch 341: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0212 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 342/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0209\n",
      "Epoch 342: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0210 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 343/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0206\n",
      "Epoch 343: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0205 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 344/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0206\n",
      "Epoch 344: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0206 - val_loss: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 345/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0207\n",
      "Epoch 345: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0207 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 346/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0200\n",
      "Epoch 346: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0200 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 347/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0196\n",
      "Epoch 347: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0196 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 348/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0189\n",
      "Epoch 348: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0189 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 349/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0181\n",
      "Epoch 349: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0181 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 350/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0183\n",
      "Epoch 350: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0183 - val_loss: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 351/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0182\n",
      "Epoch 351: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0182 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 352/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0187\n",
      "Epoch 352: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0187 - val_loss: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 353/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0181\n",
      "Epoch 353: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0181 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 354/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0184\n",
      "Epoch 354: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0184 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 355/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0182\n",
      "Epoch 355: val_loss did not improve from 0.01585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0182 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 356/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0198\n",
      "Epoch 356: val_loss improved from 0.01585 to 0.01438, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0198 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 357/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0200\n",
      "Epoch 357: val_loss improved from 0.01438 to 0.01434, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - loss: 0.0199 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 358/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0177\n",
      "Epoch 358: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0178 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 359/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0205\n",
      "Epoch 359: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0204 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 360/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0200\n",
      "Epoch 360: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0200 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 361/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0199\n",
      "Epoch 361: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0199 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 362/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0194\n",
      "Epoch 362: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0195 - val_loss: 0.0239 - learning_rate: 0.0010\n",
      "Epoch 363/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0197\n",
      "Epoch 363: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0197 - val_loss: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 364/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0193\n",
      "Epoch 364: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0193 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 365/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0187\n",
      "Epoch 365: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0187 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 366/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0179\n",
      "Epoch 366: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0180 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 367/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0184\n",
      "Epoch 367: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0184 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 368/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0188\n",
      "Epoch 368: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0189 - val_loss: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 369/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0194\n",
      "Epoch 369: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0194 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 370/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0201\n",
      "Epoch 370: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0202 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 371/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0210\n",
      "Epoch 371: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0210 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 372/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0190\n",
      "Epoch 372: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0191 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 373/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0207\n",
      "Epoch 373: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0208 - val_loss: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 374/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0203\n",
      "Epoch 374: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0203 - val_loss: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 375/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0204\n",
      "Epoch 375: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0204 - val_loss: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 376/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0210\n",
      "Epoch 376: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0211 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 377/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0206\n",
      "Epoch 377: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0205 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 378/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0200\n",
      "Epoch 378: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0200 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 379/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0188\n",
      "Epoch 379: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0188 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 380/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0190\n",
      "Epoch 380: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0190 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 381/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0178\n",
      "Epoch 381: val_loss did not improve from 0.01434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0178 - val_loss: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 382/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0181\n",
      "Epoch 382: val_loss improved from 0.01434 to 0.01431, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0181 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 383/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0167\n",
      "Epoch 383: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0167 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 384/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0169\n",
      "Epoch 384: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0169 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 385/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0163\n",
      "Epoch 385: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0163 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 386/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0181\n",
      "Epoch 386: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0181 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 387/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0190\n",
      "Epoch 387: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0190 - val_loss: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 388/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0169\n",
      "Epoch 388: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0169 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 389/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0187\n",
      "Epoch 389: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0187 - val_loss: 0.0235 - learning_rate: 0.0010\n",
      "Epoch 390/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0186\n",
      "Epoch 390: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0187 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 391/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0177\n",
      "Epoch 391: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0177 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 392/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0178\n",
      "Epoch 392: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0179 - val_loss: 0.0245 - learning_rate: 0.0010\n",
      "Epoch 393/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0186\n",
      "Epoch 393: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0187 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 394/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0191\n",
      "Epoch 394: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0192 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 395/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0185\n",
      "Epoch 395: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0185 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 396/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0200\n",
      "Epoch 396: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0200 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 397/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0180\n",
      "Epoch 397: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0180 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 398/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0184\n",
      "Epoch 398: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0184 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 399/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0192\n",
      "Epoch 399: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0192 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 400/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0170\n",
      "Epoch 400: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0170 - val_loss: 0.0252 - learning_rate: 0.0010\n",
      "Epoch 401/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0171\n",
      "Epoch 401: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0171 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 402/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0163\n",
      "Epoch 402: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0163 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 403/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0159\n",
      "Epoch 403: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0160 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 404/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0176\n",
      "Epoch 404: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0177 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 405/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0164\n",
      "Epoch 405: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0165 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 406/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0173\n",
      "Epoch 406: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0173 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 407/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0184\n",
      "Epoch 407: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0183 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 408/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0168\n",
      "Epoch 408: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0169 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 409/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0162\n",
      "Epoch 409: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0163 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 410/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0163\n",
      "Epoch 410: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0163 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 411/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0210\n",
      "Epoch 411: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0210 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 412/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0192\n",
      "Epoch 412: val_loss did not improve from 0.01431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0193 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 413/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0184\n",
      "Epoch 413: val_loss improved from 0.01431 to 0.01334, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0185 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 414/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0171\n",
      "Epoch 414: val_loss did not improve from 0.01334\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0171 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 415/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0157\n",
      "Epoch 415: val_loss did not improve from 0.01334\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0157 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 416/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0170\n",
      "Epoch 416: val_loss did not improve from 0.01334\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0171 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 417/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0170\n",
      "Epoch 417: val_loss did not improve from 0.01334\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0170 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 418/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0182\n",
      "Epoch 418: val_loss did not improve from 0.01334\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0181 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 419/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0181\n",
      "Epoch 419: val_loss did not improve from 0.01334\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0181 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 420/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0169\n",
      "Epoch 420: val_loss did not improve from 0.01334\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0168 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 421/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0164\n",
      "Epoch 421: val_loss did not improve from 0.01334\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0164 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 422/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0163\n",
      "Epoch 422: val_loss did not improve from 0.01334\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0164 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 423/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0169\n",
      "Epoch 423: val_loss did not improve from 0.01334\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0168 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 424/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0156\n",
      "Epoch 424: val_loss did not improve from 0.01334\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0157 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 425/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0160\n",
      "Epoch 425: val_loss improved from 0.01334 to 0.01243, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0160 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 426/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0159\n",
      "Epoch 426: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0159 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 427/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0154\n",
      "Epoch 427: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0154 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 428/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0207\n",
      "Epoch 428: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0207 - val_loss: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 429/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0177\n",
      "Epoch 429: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0178 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 430/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0166\n",
      "Epoch 430: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0167 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 431/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0170\n",
      "Epoch 431: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0170 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 432/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0177\n",
      "Epoch 432: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0177 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 433/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0177\n",
      "Epoch 433: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0177 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 434/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0163\n",
      "Epoch 434: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0163 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 435/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0164\n",
      "Epoch 435: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0164 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 436/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0163\n",
      "Epoch 436: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0163 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 437/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0159\n",
      "Epoch 437: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0159 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 438/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0158\n",
      "Epoch 438: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0158 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 439/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0163\n",
      "Epoch 439: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0163 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 440/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0176\n",
      "Epoch 440: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0175 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 441/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0172\n",
      "Epoch 441: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0172 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 442/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0156\n",
      "Epoch 442: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0156 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 443/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0147\n",
      "Epoch 443: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0148 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 444/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0153\n",
      "Epoch 444: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0153 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 445/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0149\n",
      "Epoch 445: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0149 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 446/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0153\n",
      "Epoch 446: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0153 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 447/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0147\n",
      "Epoch 447: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0148 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 448/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0148\n",
      "Epoch 448: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0148 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 449/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0145\n",
      "Epoch 449: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0146 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 450/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0151\n",
      "Epoch 450: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0151 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 451/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0148\n",
      "Epoch 451: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0148 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 452/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0152\n",
      "Epoch 452: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0153 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 453/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0150\n",
      "Epoch 453: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0150 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 454/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0152\n",
      "Epoch 454: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0152 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 455/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0150\n",
      "Epoch 455: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0150 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 456/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0154\n",
      "Epoch 456: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0154 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 457/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0158\n",
      "Epoch 457: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0159 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 458/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0162\n",
      "Epoch 458: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0161 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 459/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0151\n",
      "Epoch 459: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0151 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 460/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0166\n",
      "Epoch 460: val_loss did not improve from 0.01243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0166 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 461/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0159\n",
      "Epoch 461: val_loss improved from 0.01243 to 0.01167, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0160 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 462/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0153\n",
      "Epoch 462: val_loss did not improve from 0.01167\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0153 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 463/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0162\n",
      "Epoch 463: val_loss did not improve from 0.01167\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0162 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 464/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0146\n",
      "Epoch 464: val_loss improved from 0.01167 to 0.01086, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0146 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 465/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0143\n",
      "Epoch 465: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0143 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 466/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0145\n",
      "Epoch 466: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0145 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 467/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0149\n",
      "Epoch 467: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0149 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 468/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0146\n",
      "Epoch 468: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0147 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 469/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0150\n",
      "Epoch 469: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0151 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 470/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0147\n",
      "Epoch 470: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0148 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 471/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0173\n",
      "Epoch 471: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0173 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 472/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0164\n",
      "Epoch 472: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0164 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 473/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0154\n",
      "Epoch 473: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0154 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 474/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0166\n",
      "Epoch 474: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0167 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 475/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0159\n",
      "Epoch 475: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0159 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 476/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0157\n",
      "Epoch 476: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0158 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 477/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0155\n",
      "Epoch 477: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0155 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 478/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0150\n",
      "Epoch 478: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0151 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 479/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0145\n",
      "Epoch 479: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0145 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 480/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0147\n",
      "Epoch 480: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0147 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 481/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0145\n",
      "Epoch 481: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0145 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 482/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0153\n",
      "Epoch 482: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0152 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 483/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0153\n",
      "Epoch 483: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0153 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 484/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0140\n",
      "Epoch 484: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0140 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 485/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0141\n",
      "Epoch 485: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0141 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 486/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0149\n",
      "Epoch 486: val_loss did not improve from 0.01086\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0150 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 487/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0144\n",
      "Epoch 487: val_loss improved from 0.01086 to 0.01040, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0144 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 488/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0147\n",
      "Epoch 488: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0147 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 489/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0140\n",
      "Epoch 489: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0140 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 490/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0145\n",
      "Epoch 490: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0145 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 491/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0145\n",
      "Epoch 491: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0145 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 492/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0136\n",
      "Epoch 492: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0136 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 493/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0140\n",
      "Epoch 493: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0140 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 494/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0145\n",
      "Epoch 494: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0145 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 495/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0141\n",
      "Epoch 495: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0141 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 496/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0147\n",
      "Epoch 496: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0147 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 497/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0156\n",
      "Epoch 497: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0156 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 498/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0152\n",
      "Epoch 498: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0152 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 499/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0195\n",
      "Epoch 499: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0195 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 500/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0175\n",
      "Epoch 500: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0175 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 501/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0155\n",
      "Epoch 501: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0155 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 502/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0149\n",
      "Epoch 502: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0149 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 503/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0144\n",
      "Epoch 503: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0144 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 504/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0148\n",
      "Epoch 504: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0148 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 505/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0137\n",
      "Epoch 505: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0137 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 506/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0135\n",
      "Epoch 506: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0135 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 507/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0132\n",
      "Epoch 507: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0133 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 508/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0141\n",
      "Epoch 508: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0141 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 509/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0139\n",
      "Epoch 509: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0139 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 510/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0138\n",
      "Epoch 510: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0138 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 511/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0139\n",
      "Epoch 511: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0139 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 512/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0151\n",
      "Epoch 512: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0151 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 513/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0143\n",
      "Epoch 513: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0144 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 514/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0141\n",
      "Epoch 514: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0142 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 515/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0138\n",
      "Epoch 515: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0139 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 516/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0152\n",
      "Epoch 516: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0152 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 517/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0144\n",
      "Epoch 517: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0144 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 518/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0143\n",
      "Epoch 518: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0143 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 519/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0142\n",
      "Epoch 519: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0142 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 520/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0130\n",
      "Epoch 520: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0130 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 521/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0125\n",
      "Epoch 521: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0126 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 522/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0133\n",
      "Epoch 522: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0132 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 523/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0128\n",
      "Epoch 523: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0128 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 524/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0130\n",
      "Epoch 524: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0130 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 525/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0140\n",
      "Epoch 525: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0140 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 526/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0141\n",
      "Epoch 526: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0140 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 527/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0138\n",
      "Epoch 527: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0138 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 528/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0135\n",
      "Epoch 528: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0135 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 529/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0137\n",
      "Epoch 529: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0137 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 530/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0138\n",
      "Epoch 530: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0139 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 531/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0141\n",
      "Epoch 531: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0141 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 532/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0132\n",
      "Epoch 532: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0132 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 533/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0127\n",
      "Epoch 533: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0128 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 534/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0131\n",
      "Epoch 534: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0132 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 535/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0129\n",
      "Epoch 535: val_loss did not improve from 0.01040\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0129 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 536/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0122\n",
      "Epoch 536: val_loss improved from 0.01040 to 0.01035, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - loss: 0.0122 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 537/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0124\n",
      "Epoch 537: val_loss did not improve from 0.01035\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0125 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 538/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0148\n",
      "Epoch 538: val_loss improved from 0.01035 to 0.00941, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0149 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 539/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0140\n",
      "Epoch 539: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0141 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 540/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0133\n",
      "Epoch 540: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0133 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 541/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0130\n",
      "Epoch 541: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0130 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 542/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0142\n",
      "Epoch 542: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0141 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 543/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0129\n",
      "Epoch 543: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0130 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 544/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0125\n",
      "Epoch 544: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0126 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 545/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0132\n",
      "Epoch 545: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0132 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 546/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0148\n",
      "Epoch 546: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0148 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 547/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0134\n",
      "Epoch 547: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0134 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 548/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0136\n",
      "Epoch 548: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0136 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 549/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0131\n",
      "Epoch 549: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0132 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 550/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0138\n",
      "Epoch 550: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0140 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 551/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0172\n",
      "Epoch 551: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0171 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 552/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0144\n",
      "Epoch 552: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0144 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 553/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0145\n",
      "Epoch 553: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0145 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 554/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0141\n",
      "Epoch 554: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0141 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 555/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0134\n",
      "Epoch 555: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0134 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 556/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0128\n",
      "Epoch 556: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0129 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 557/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0134\n",
      "Epoch 557: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0134 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 558/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0138\n",
      "Epoch 558: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0138 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 559/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0137\n",
      "Epoch 559: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0137 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 560/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0129\n",
      "Epoch 560: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0129 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 561/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0131\n",
      "Epoch 561: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0132 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 562/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0138\n",
      "Epoch 562: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0138 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 563/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0132\n",
      "Epoch 563: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0132 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 564/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0126\n",
      "Epoch 564: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0126 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 565/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0126\n",
      "Epoch 565: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0126 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 566/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0127\n",
      "Epoch 566: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0128 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 567/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0130\n",
      "Epoch 567: val_loss did not improve from 0.00941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0130 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 568/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0165\n",
      "Epoch 568: val_loss improved from 0.00941 to 0.00886, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0165 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 569/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0165\n",
      "Epoch 569: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0164 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 570/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0148\n",
      "Epoch 570: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0148 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 571/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0134\n",
      "Epoch 571: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0134 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 572/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0144\n",
      "Epoch 572: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0144 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 573/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0140\n",
      "Epoch 573: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0140 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 574/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0135\n",
      "Epoch 574: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0135 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 575/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0136\n",
      "Epoch 575: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0137 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 576/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0130\n",
      "Epoch 576: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0131 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 577/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0128\n",
      "Epoch 577: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0128 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 578/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0135\n",
      "Epoch 578: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0135 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 579/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0129\n",
      "Epoch 579: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0129 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 580/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0133\n",
      "Epoch 580: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0133 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 581/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0130\n",
      "Epoch 581: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0129 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 582/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0123\n",
      "Epoch 582: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0123 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 583/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0126\n",
      "Epoch 583: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0126 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 584/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0133\n",
      "Epoch 584: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0133 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 585/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0125\n",
      "Epoch 585: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0125 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 586/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0122\n",
      "Epoch 586: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0123 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 587/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0118\n",
      "Epoch 587: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0118 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 588/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0128\n",
      "Epoch 588: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0129 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 589/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0127\n",
      "Epoch 589: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0127 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 590/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0124\n",
      "Epoch 590: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0124 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 591/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0133\n",
      "Epoch 591: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0132 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 592/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0133\n",
      "Epoch 592: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0134 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 593/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0125\n",
      "Epoch 593: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0125 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 594/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0126\n",
      "Epoch 594: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0127 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 595/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0136\n",
      "Epoch 595: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0136 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 596/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0115\n",
      "Epoch 596: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0115 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 597/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0114\n",
      "Epoch 597: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0114 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 598/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0113\n",
      "Epoch 598: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0113 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 599/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0124\n",
      "Epoch 599: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0124 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 600/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0119\n",
      "Epoch 600: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0120 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 601/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0131\n",
      "Epoch 601: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0131 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 602/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0127\n",
      "Epoch 602: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0128 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 603/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0127\n",
      "Epoch 603: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0128 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 604/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0127\n",
      "Epoch 604: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0127 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 605/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0119\n",
      "Epoch 605: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0119 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 606/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0130\n",
      "Epoch 606: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0130 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 607/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0120\n",
      "Epoch 607: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0120 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 608/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0125\n",
      "Epoch 608: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0125 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 609/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0129\n",
      "Epoch 609: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0129 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 610/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0115\n",
      "Epoch 610: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0116 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 611/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0119\n",
      "Epoch 611: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0120 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 612/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0122\n",
      "Epoch 612: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0122 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 613/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0123\n",
      "Epoch 613: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0124 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 614/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0118\n",
      "Epoch 614: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0118 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 615/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0132\n",
      "Epoch 615: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0132 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 616/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0130\n",
      "Epoch 616: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0130 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 617/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0129\n",
      "Epoch 617: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0129 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 618/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0131\n",
      "Epoch 618: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0130 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 619/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0126\n",
      "Epoch 619: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0126 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 620/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0122\n",
      "Epoch 620: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0122 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 621/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0124\n",
      "Epoch 621: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0125 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 622/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0133\n",
      "Epoch 622: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0133 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 623/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0130\n",
      "Epoch 623: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0129 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 624/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0124\n",
      "Epoch 624: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0124 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 625/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0115\n",
      "Epoch 625: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0115 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 626/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0116\n",
      "Epoch 626: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0116 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 627/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0124\n",
      "Epoch 627: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0124 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 628/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0120\n",
      "Epoch 628: val_loss did not improve from 0.00886\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0121 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 629/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0135\n",
      "Epoch 629: val_loss improved from 0.00886 to 0.00882, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0135 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 630/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0128\n",
      "Epoch 630: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0128 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 631/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0124\n",
      "Epoch 631: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0124 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 632/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0114\n",
      "Epoch 632: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0114 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 633/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0122\n",
      "Epoch 633: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0122 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 634/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0126\n",
      "Epoch 634: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0126 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 635/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0124\n",
      "Epoch 635: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0124 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 636/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0156\n",
      "Epoch 636: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0155 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 637/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0133\n",
      "Epoch 637: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0133 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 638/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0140\n",
      "Epoch 638: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0141 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 639/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0137\n",
      "Epoch 639: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0137 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 640/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0131\n",
      "Epoch 640: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0131 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 641/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0131\n",
      "Epoch 641: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0131 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 642/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0126\n",
      "Epoch 642: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0125 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 643/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0115\n",
      "Epoch 643: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0115 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 644/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0123\n",
      "Epoch 644: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0123 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 645/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0121\n",
      "Epoch 645: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0121 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 646/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0115\n",
      "Epoch 646: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0115 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 647/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0111\n",
      "Epoch 647: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0111 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 648/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0115\n",
      "Epoch 648: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0115 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 649/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0117\n",
      "Epoch 649: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0117 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 650/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0116\n",
      "Epoch 650: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0116 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 651/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0120\n",
      "Epoch 651: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0120 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 652/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0137\n",
      "Epoch 652: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0136 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 653/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0158\n",
      "Epoch 653: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0157 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 654/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0136\n",
      "Epoch 654: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0135 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 655/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0124\n",
      "Epoch 655: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0124 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 656/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0123\n",
      "Epoch 656: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0123 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 657/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0120\n",
      "Epoch 657: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0120 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 658/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0121\n",
      "Epoch 658: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0122 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 659/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0124\n",
      "Epoch 659: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0124 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 660/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0124\n",
      "Epoch 660: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0125 - val_loss: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 661/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0128\n",
      "Epoch 661: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0128 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 662/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0121\n",
      "Epoch 662: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0121 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 663/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0125\n",
      "Epoch 663: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0126 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 664/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0133\n",
      "Epoch 664: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0133 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 665/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0123\n",
      "Epoch 665: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0123 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 666/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0120\n",
      "Epoch 666: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0121 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 667/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0121\n",
      "Epoch 667: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0122 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 668/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0118\n",
      "Epoch 668: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0119 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 669/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0121\n",
      "Epoch 669: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0121 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 670/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0119\n",
      "Epoch 670: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0120 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 671/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0132\n",
      "Epoch 671: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0133 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 672/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0141\n",
      "Epoch 672: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0141 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 673/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0131\n",
      "Epoch 673: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0131 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 674/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0145\n",
      "Epoch 674: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0147 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 675/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0166\n",
      "Epoch 675: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0165 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 676/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0139\n",
      "Epoch 676: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0139 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 677/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0133\n",
      "Epoch 677: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0133 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 678/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0126\n",
      "Epoch 678: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0126 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 679/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0120\n",
      "Epoch 679: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0121 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 680/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0115\n",
      "Epoch 680: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0115 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 681/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0124\n",
      "Epoch 681: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0124 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 682/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0123\n",
      "Epoch 682: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0123 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 683/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0114\n",
      "Epoch 683: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0115 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 684/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0116\n",
      "Epoch 684: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0116 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 685/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0113\n",
      "Epoch 685: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0113 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 686/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0111\n",
      "Epoch 686: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0111 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 687/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0109\n",
      "Epoch 687: val_loss did not improve from 0.00882\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0110 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 688/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0114\n",
      "Epoch 688: val_loss improved from 0.00882 to 0.00875, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0114 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 689/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0108\n",
      "Epoch 689: val_loss did not improve from 0.00875\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0108 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 690/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0108\n",
      "Epoch 690: val_loss did not improve from 0.00875\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0108 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 691/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0110\n",
      "Epoch 691: val_loss did not improve from 0.00875\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0111 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 692/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0111\n",
      "Epoch 692: val_loss did not improve from 0.00875\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0111 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 693/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0107\n",
      "Epoch 693: val_loss did not improve from 0.00875\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0107 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 694/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0112\n",
      "Epoch 694: val_loss did not improve from 0.00875\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0112 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 695/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0108\n",
      "Epoch 695: val_loss did not improve from 0.00875\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0109 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 696/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0109\n",
      "Epoch 696: val_loss did not improve from 0.00875\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0110 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 697/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0111\n",
      "Epoch 697: val_loss did not improve from 0.00875\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0111 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 698/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0106\n",
      "Epoch 698: val_loss did not improve from 0.00875\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0106 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 699/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0116\n",
      "Epoch 699: val_loss did not improve from 0.00875\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0115 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 700/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0112\n",
      "Epoch 700: val_loss improved from 0.00875 to 0.00858, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0112 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 701/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0112\n",
      "Epoch 701: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0113 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 702/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0115\n",
      "Epoch 702: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0115 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 703/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0119\n",
      "Epoch 703: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0120 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 704/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0115\n",
      "Epoch 704: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0116 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 705/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0123\n",
      "Epoch 705: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0122 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 706/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0114\n",
      "Epoch 706: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0113 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 707/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0111\n",
      "Epoch 707: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0111 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 708/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0104\n",
      "Epoch 708: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0104 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 709/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0108\n",
      "Epoch 709: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0108 - val_loss: 0.0090 - learning_rate: 0.0010\n",
      "Epoch 710/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0115\n",
      "Epoch 710: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0115 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 711/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0124\n",
      "Epoch 711: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0124 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 712/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0113\n",
      "Epoch 712: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0113 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 713/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0115\n",
      "Epoch 713: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0115 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 714/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0109\n",
      "Epoch 714: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0109 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 715/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0107\n",
      "Epoch 715: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0108 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 716/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0117\n",
      "Epoch 716: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0117 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 717/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0116\n",
      "Epoch 717: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0116 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 718/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0114\n",
      "Epoch 718: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0114 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 719/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0113\n",
      "Epoch 719: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0114 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 720/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0109\n",
      "Epoch 720: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0109 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 721/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0108\n",
      "Epoch 721: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0108 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 722/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0108\n",
      "Epoch 722: val_loss did not improve from 0.00858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0108 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 723/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0108\n",
      "Epoch 723: val_loss improved from 0.00858 to 0.00808, saving model to ./result_folder_no_misc/lstm_ts_5.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0108 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 724/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0111\n",
      "Epoch 724: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0111 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 725/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0113\n",
      "Epoch 725: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0113 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 726/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0115\n",
      "Epoch 726: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0115 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 727/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0113\n",
      "Epoch 727: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0113 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 728/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0112\n",
      "Epoch 728: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0112 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 729/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0112\n",
      "Epoch 729: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0112 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 730/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0107\n",
      "Epoch 730: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0107 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 731/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0110\n",
      "Epoch 731: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0110 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 732/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0108\n",
      "Epoch 732: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0108 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 733/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0107\n",
      "Epoch 733: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0107 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 734/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0113\n",
      "Epoch 734: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0113 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 735/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0108\n",
      "Epoch 735: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0108 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 736/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0100\n",
      "Epoch 736: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0100 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 737/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0106\n",
      "Epoch 737: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0106 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 738/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0108\n",
      "Epoch 738: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0108 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 739/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0105\n",
      "Epoch 739: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0105 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 740/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0105\n",
      "Epoch 740: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0105 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 741/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0107\n",
      "Epoch 741: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0107 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 742/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0119\n",
      "Epoch 742: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0119 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 743/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0107\n",
      "Epoch 743: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0108 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 744/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0107\n",
      "Epoch 744: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0107 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 745/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0112\n",
      "Epoch 745: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0112 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 746/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0105\n",
      "Epoch 746: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0105 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 747/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0108\n",
      "Epoch 747: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0109 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 748/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0109\n",
      "Epoch 748: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0109 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 749/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0110\n",
      "Epoch 749: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0110 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 750/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0107\n",
      "Epoch 750: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0107 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 751/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0106\n",
      "Epoch 751: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0106 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 752/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0101\n",
      "Epoch 752: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0101 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 753/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0099\n",
      "Epoch 753: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0099 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 754/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0099\n",
      "Epoch 754: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0099 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 755/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0108\n",
      "Epoch 755: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0108 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 756/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0106\n",
      "Epoch 756: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0106 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 757/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0109\n",
      "Epoch 757: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0109 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 758/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0122\n",
      "Epoch 758: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0122 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 759/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0123\n",
      "Epoch 759: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0123 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 760/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0105\n",
      "Epoch 760: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0106 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 761/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0103\n",
      "Epoch 761: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0103 - val_loss: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 762/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0101\n",
      "Epoch 762: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0101 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 763/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0097\n",
      "Epoch 763: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0097 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 764/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0100\n",
      "Epoch 764: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0100 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 765/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0103\n",
      "Epoch 765: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0103 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 766/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0104\n",
      "Epoch 766: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0104 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 767/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0104\n",
      "Epoch 767: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0104 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 768/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0101\n",
      "Epoch 768: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0101 - val_loss: 0.0087 - learning_rate: 0.0010\n",
      "Epoch 769/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0119\n",
      "Epoch 769: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0119 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 770/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0129\n",
      "Epoch 770: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0129 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 771/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0124\n",
      "Epoch 771: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0124 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 772/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0113\n",
      "Epoch 772: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0113 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 773/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0115\n",
      "Epoch 773: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0115 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 774/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0118\n",
      "Epoch 774: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0119 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 775/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0123\n",
      "Epoch 775: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0123 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 776/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0132\n",
      "Epoch 776: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0132 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 777/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0123\n",
      "Epoch 777: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0123 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 778/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0120\n",
      "Epoch 778: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0120 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 779/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0113\n",
      "Epoch 779: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0113 - val_loss: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 780/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0108\n",
      "Epoch 780: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0108 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 781/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0105\n",
      "Epoch 781: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0105 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 782/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0097\n",
      "Epoch 782: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0097 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 783/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0096\n",
      "Epoch 783: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0097 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 784/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0098\n",
      "Epoch 784: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0098 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 785/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0104\n",
      "Epoch 785: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0104 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 786/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0104\n",
      "Epoch 786: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0104 - val_loss: 0.0092 - learning_rate: 0.0010\n",
      "Epoch 787/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0102\n",
      "Epoch 787: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0102 - val_loss: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 788/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0112\n",
      "Epoch 788: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0113 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 789/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0109\n",
      "Epoch 789: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0109 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 790/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0107\n",
      "Epoch 790: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0108 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 791/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0104\n",
      "Epoch 791: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0105 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 792/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0103\n",
      "Epoch 792: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0104 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 793/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0111\n",
      "Epoch 793: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0111 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 794/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0105\n",
      "Epoch 794: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0105 - val_loss: 0.0091 - learning_rate: 0.0010\n",
      "Epoch 795/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0096\n",
      "Epoch 795: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0097 - val_loss: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 796/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0104\n",
      "Epoch 796: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0104 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 797/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0097\n",
      "Epoch 797: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0097 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 798/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0101\n",
      "Epoch 798: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0101 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 799/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0107\n",
      "Epoch 799: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0107 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 800/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0102\n",
      "Epoch 800: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0103 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 801/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0105\n",
      "Epoch 801: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0106 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 802/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0103\n",
      "Epoch 802: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0103 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 803/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0108\n",
      "Epoch 803: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0108 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 804/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0106\n",
      "Epoch 804: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0106 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 805/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0105\n",
      "Epoch 805: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0105 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 806/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0103\n",
      "Epoch 806: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0103 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 807/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0104\n",
      "Epoch 807: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0104 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 808/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0099\n",
      "Epoch 808: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0099 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 809/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0111\n",
      "Epoch 809: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0113 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 810/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0131\n",
      "Epoch 810: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.0131 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 811/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0120\n",
      "Epoch 811: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0120 - val_loss: 0.0085 - learning_rate: 0.0010\n",
      "Epoch 812/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0109\n",
      "Epoch 812: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0109 - val_loss: 0.0089 - learning_rate: 0.0010\n",
      "Epoch 813/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0109\n",
      "Epoch 813: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0109 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 814/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0109\n",
      "Epoch 814: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0109 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 815/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0103\n",
      "Epoch 815: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0103 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 816/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0103\n",
      "Epoch 816: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0103 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 817/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0102\n",
      "Epoch 817: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0102 - val_loss: 0.0083 - learning_rate: 0.0010\n",
      "Epoch 818/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0102\n",
      "Epoch 818: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0102 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 819/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0100\n",
      "Epoch 819: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0100 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 820/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0102\n",
      "Epoch 820: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0102 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 821/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0091\n",
      "Epoch 821: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0092 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 822/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0097\n",
      "Epoch 822: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0097 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 823/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0094\n",
      "Epoch 823: val_loss did not improve from 0.00808\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0095 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 823: early stopping\n",
      "Restoring model weights from the end of the best epoch: 723.\n",
      "EUA\n",
      "0.11146122753720722\n",
      "Oil\n",
      "0.1343086766296534\n",
      "Coal\n",
      "0.03577363874758355\n",
      "NG\n",
      "0.04981421068665845\n",
      "USEU\n",
      "0.08796561091744326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 180/180 [01:14<00:00,  2.41it/s]\n",
      "100%|| 180/180 [04:08<00:00,  1.38s/it]\n",
      "/home/honggeunjo/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 2.1853\n",
      "Epoch 1: val_loss improved from inf to 0.77391, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 228ms/step - loss: 2.1214 - val_loss: 0.7739 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.6227\n",
      "Epoch 2: val_loss improved from 0.77391 to 0.41823, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.6202 - val_loss: 0.4182 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.4884\n",
      "Epoch 3: val_loss improved from 0.41823 to 0.38992, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.4876 - val_loss: 0.3899 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.4352\n",
      "Epoch 4: val_loss improved from 0.38992 to 0.36368, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.4348 - val_loss: 0.3637 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.4129\n",
      "Epoch 5: val_loss improved from 0.36368 to 0.36253, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.4126 - val_loss: 0.3625 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.3954\n",
      "Epoch 6: val_loss improved from 0.36253 to 0.35610, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.3953 - val_loss: 0.3561 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.3860\n",
      "Epoch 7: val_loss improved from 0.35610 to 0.34243, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.3857 - val_loss: 0.3424 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.3792\n",
      "Epoch 8: val_loss did not improve from 0.34243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - loss: 0.3788 - val_loss: 0.3425 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.3678\n",
      "Epoch 9: val_loss did not improve from 0.34243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.3677 - val_loss: 0.3448 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.3611\n",
      "Epoch 10: val_loss improved from 0.34243 to 0.33446, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.3610 - val_loss: 0.3345 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.3528\n",
      "Epoch 11: val_loss improved from 0.33446 to 0.32179, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.3528 - val_loss: 0.3218 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.3473\n",
      "Epoch 12: val_loss improved from 0.32179 to 0.31592, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.3472 - val_loss: 0.3159 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3375\n",
      "Epoch 13: val_loss improved from 0.31592 to 0.31124, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.3376 - val_loss: 0.3112 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.3337\n",
      "Epoch 14: val_loss improved from 0.31124 to 0.30736, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.3336 - val_loss: 0.3074 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.3265\n",
      "Epoch 15: val_loss improved from 0.30736 to 0.29538, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.3263 - val_loss: 0.2954 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.3208\n",
      "Epoch 16: val_loss did not improve from 0.29538\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.3206 - val_loss: 0.3004 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.3123\n",
      "Epoch 17: val_loss improved from 0.29538 to 0.28493, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.3122 - val_loss: 0.2849 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.3070\n",
      "Epoch 18: val_loss did not improve from 0.28493\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.3068 - val_loss: 0.2867 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.3007\n",
      "Epoch 19: val_loss improved from 0.28493 to 0.28091, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.3006 - val_loss: 0.2809 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.2956\n",
      "Epoch 20: val_loss improved from 0.28091 to 0.26868, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.2954 - val_loss: 0.2687 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.2882\n",
      "Epoch 21: val_loss improved from 0.26868 to 0.26425, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.2881 - val_loss: 0.2642 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.2832\n",
      "Epoch 22: val_loss improved from 0.26425 to 0.26082, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.2831 - val_loss: 0.2608 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.2787\n",
      "Epoch 23: val_loss did not improve from 0.26082\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.2787 - val_loss: 0.2635 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.2730\n",
      "Epoch 24: val_loss improved from 0.26082 to 0.25008, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.2729 - val_loss: 0.2501 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.2643\n",
      "Epoch 25: val_loss improved from 0.25008 to 0.24398, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.2643 - val_loss: 0.2440 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.2610\n",
      "Epoch 26: val_loss did not improve from 0.24398\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - loss: 0.2608 - val_loss: 0.2448 - learning_rate: 0.0010\n",
      "Epoch 27/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.2527\n",
      "Epoch 27: val_loss improved from 0.24398 to 0.23387, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.2527 - val_loss: 0.2339 - learning_rate: 0.0010\n",
      "Epoch 28/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.2506\n",
      "Epoch 28: val_loss did not improve from 0.23387\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.2504 - val_loss: 0.2425 - learning_rate: 0.0010\n",
      "Epoch 29/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.2446\n",
      "Epoch 29: val_loss improved from 0.23387 to 0.22561, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.2446 - val_loss: 0.2256 - learning_rate: 0.0010\n",
      "Epoch 30/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.2363\n",
      "Epoch 30: val_loss improved from 0.22561 to 0.22182, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.2364 - val_loss: 0.2218 - learning_rate: 0.0010\n",
      "Epoch 31/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.2327\n",
      "Epoch 31: val_loss did not improve from 0.22182\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.2327 - val_loss: 0.2222 - learning_rate: 0.0010\n",
      "Epoch 32/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.2298\n",
      "Epoch 32: val_loss improved from 0.22182 to 0.21279, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.2297 - val_loss: 0.2128 - learning_rate: 0.0010\n",
      "Epoch 33/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.2260\n",
      "Epoch 33: val_loss improved from 0.21279 to 0.20906, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.2259 - val_loss: 0.2091 - learning_rate: 0.0010\n",
      "Epoch 34/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.2207\n",
      "Epoch 34: val_loss improved from 0.20906 to 0.20876, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.2206 - val_loss: 0.2088 - learning_rate: 0.0010\n",
      "Epoch 35/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.2158\n",
      "Epoch 35: val_loss improved from 0.20876 to 0.20149, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.2158 - val_loss: 0.2015 - learning_rate: 0.0010\n",
      "Epoch 36/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.2124\n",
      "Epoch 36: val_loss improved from 0.20149 to 0.19872, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.2123 - val_loss: 0.1987 - learning_rate: 0.0010\n",
      "Epoch 37/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.2072\n",
      "Epoch 37: val_loss improved from 0.19872 to 0.19476, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.2072 - val_loss: 0.1948 - learning_rate: 0.0010\n",
      "Epoch 38/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.2039\n",
      "Epoch 38: val_loss improved from 0.19476 to 0.18958, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.2040 - val_loss: 0.1896 - learning_rate: 0.0010\n",
      "Epoch 39/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.2015\n",
      "Epoch 39: val_loss did not improve from 0.18958\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.2014 - val_loss: 0.1907 - learning_rate: 0.0010\n",
      "Epoch 40/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.1971\n",
      "Epoch 40: val_loss improved from 0.18958 to 0.18332, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.1971 - val_loss: 0.1833 - learning_rate: 0.0010\n",
      "Epoch 41/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.1944\n",
      "Epoch 41: val_loss improved from 0.18332 to 0.17701, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.1943 - val_loss: 0.1770 - learning_rate: 0.0010\n",
      "Epoch 42/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.1916\n",
      "Epoch 42: val_loss improved from 0.17701 to 0.17693, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - loss: 0.1915 - val_loss: 0.1769 - learning_rate: 0.0010\n",
      "Epoch 43/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.1881\n",
      "Epoch 43: val_loss did not improve from 0.17693\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.1879 - val_loss: 0.1800 - learning_rate: 0.0010\n",
      "Epoch 44/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.1840\n",
      "Epoch 44: val_loss improved from 0.17693 to 0.17175, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.1840 - val_loss: 0.1718 - learning_rate: 0.0010\n",
      "Epoch 45/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.1804\n",
      "Epoch 45: val_loss improved from 0.17175 to 0.16670, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.1803 - val_loss: 0.1667 - learning_rate: 0.0010\n",
      "Epoch 46/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.1784\n",
      "Epoch 46: val_loss did not improve from 0.16670\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.1783 - val_loss: 0.1699 - learning_rate: 0.0010\n",
      "Epoch 47/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.1749\n",
      "Epoch 47: val_loss did not improve from 0.16670\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.1749 - val_loss: 0.1673 - learning_rate: 0.0010\n",
      "Epoch 48/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.1720\n",
      "Epoch 48: val_loss improved from 0.16670 to 0.16021, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.1720 - val_loss: 0.1602 - learning_rate: 0.0010\n",
      "Epoch 49/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.1684\n",
      "Epoch 49: val_loss improved from 0.16021 to 0.15622, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.1683 - val_loss: 0.1562 - learning_rate: 0.0010\n",
      "Epoch 50/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.1638\n",
      "Epoch 50: val_loss improved from 0.15622 to 0.15350, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.1637 - val_loss: 0.1535 - learning_rate: 0.0010\n",
      "Epoch 51/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.1616\n",
      "Epoch 51: val_loss did not improve from 0.15350\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.1616 - val_loss: 0.1578 - learning_rate: 0.0010\n",
      "Epoch 52/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.1586\n",
      "Epoch 52: val_loss improved from 0.15350 to 0.14932, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.1586 - val_loss: 0.1493 - learning_rate: 0.0010\n",
      "Epoch 53/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.1558\n",
      "Epoch 53: val_loss improved from 0.14932 to 0.14285, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.1558 - val_loss: 0.1428 - learning_rate: 0.0010\n",
      "Epoch 54/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.1530\n",
      "Epoch 54: val_loss did not improve from 0.14285\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.1531 - val_loss: 0.1547 - learning_rate: 0.0010\n",
      "Epoch 55/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.1521\n",
      "Epoch 55: val_loss improved from 0.14285 to 0.13819, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.1520 - val_loss: 0.1382 - learning_rate: 0.0010\n",
      "Epoch 56/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.1481\n",
      "Epoch 56: val_loss did not improve from 0.13819\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.1481 - val_loss: 0.1406 - learning_rate: 0.0010\n",
      "Epoch 57/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.1458\n",
      "Epoch 57: val_loss improved from 0.13819 to 0.13529, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.1458 - val_loss: 0.1353 - learning_rate: 0.0010\n",
      "Epoch 58/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.1439\n",
      "Epoch 58: val_loss improved from 0.13529 to 0.13325, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.1438 - val_loss: 0.1333 - learning_rate: 0.0010\n",
      "Epoch 59/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.1408\n",
      "Epoch 59: val_loss did not improve from 0.13325\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.1408 - val_loss: 0.1365 - learning_rate: 0.0010\n",
      "Epoch 60/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.1401\n",
      "Epoch 60: val_loss improved from 0.13325 to 0.13000, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.1402 - val_loss: 0.1300 - learning_rate: 0.0010\n",
      "Epoch 61/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.1383\n",
      "Epoch 61: val_loss improved from 0.13000 to 0.12800, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.1382 - val_loss: 0.1280 - learning_rate: 0.0010\n",
      "Epoch 62/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.1364\n",
      "Epoch 62: val_loss improved from 0.12800 to 0.12420, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.1363 - val_loss: 0.1242 - learning_rate: 0.0010\n",
      "Epoch 63/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.1353\n",
      "Epoch 63: val_loss improved from 0.12420 to 0.12414, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.1352 - val_loss: 0.1241 - learning_rate: 0.0010\n",
      "Epoch 64/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.1327\n",
      "Epoch 64: val_loss did not improve from 0.12414\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.1327 - val_loss: 0.1263 - learning_rate: 0.0010\n",
      "Epoch 65/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.1310\n",
      "Epoch 65: val_loss improved from 0.12414 to 0.11891, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - loss: 0.1309 - val_loss: 0.1189 - learning_rate: 0.0010\n",
      "Epoch 66/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.1296\n",
      "Epoch 66: val_loss improved from 0.11891 to 0.11835, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.1295 - val_loss: 0.1184 - learning_rate: 0.0010\n",
      "Epoch 67/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.1285\n",
      "Epoch 67: val_loss improved from 0.11835 to 0.11772, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.1286 - val_loss: 0.1177 - learning_rate: 0.0010\n",
      "Epoch 68/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.1278\n",
      "Epoch 68: val_loss did not improve from 0.11772\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.1277 - val_loss: 0.1246 - learning_rate: 0.0010\n",
      "Epoch 69/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.1249\n",
      "Epoch 69: val_loss improved from 0.11772 to 0.11672, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.1248 - val_loss: 0.1167 - learning_rate: 0.0010\n",
      "Epoch 70/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.1213\n",
      "Epoch 70: val_loss improved from 0.11672 to 0.11038, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.1214 - val_loss: 0.1104 - learning_rate: 0.0010\n",
      "Epoch 71/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.1205\n",
      "Epoch 71: val_loss improved from 0.11038 to 0.10911, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.1205 - val_loss: 0.1091 - learning_rate: 0.0010\n",
      "Epoch 72/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.1182\n",
      "Epoch 72: val_loss did not improve from 0.10911\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.1182 - val_loss: 0.1107 - learning_rate: 0.0010\n",
      "Epoch 73/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.1159\n",
      "Epoch 73: val_loss improved from 0.10911 to 0.10795, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.1159 - val_loss: 0.1079 - learning_rate: 0.0010\n",
      "Epoch 74/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.1140\n",
      "Epoch 74: val_loss improved from 0.10795 to 0.10376, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.1140 - val_loss: 0.1038 - learning_rate: 0.0010\n",
      "Epoch 75/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.1128\n",
      "Epoch 75: val_loss improved from 0.10376 to 0.10169, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.1129 - val_loss: 0.1017 - learning_rate: 0.0010\n",
      "Epoch 76/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.1128\n",
      "Epoch 76: val_loss did not improve from 0.10169\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1128 - val_loss: 0.1090 - learning_rate: 0.0010\n",
      "Epoch 77/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.1097\n",
      "Epoch 77: val_loss did not improve from 0.10169\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.1097 - val_loss: 0.1108 - learning_rate: 0.0010\n",
      "Epoch 78/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.1078\n",
      "Epoch 78: val_loss did not improve from 0.10169\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.1079 - val_loss: 0.1059 - learning_rate: 0.0010\n",
      "Epoch 79/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.1065\n",
      "Epoch 79: val_loss did not improve from 0.10169\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1065 - val_loss: 0.1022 - learning_rate: 0.0010\n",
      "Epoch 80/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.1058\n",
      "Epoch 80: val_loss improved from 0.10169 to 0.09663, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.1058 - val_loss: 0.0966 - learning_rate: 0.0010\n",
      "Epoch 81/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.1042\n",
      "Epoch 81: val_loss improved from 0.09663 to 0.09499, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.1041 - val_loss: 0.0950 - learning_rate: 0.0010\n",
      "Epoch 82/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.1022\n",
      "Epoch 82: val_loss did not improve from 0.09499\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.1022 - val_loss: 0.0976 - learning_rate: 0.0010\n",
      "Epoch 83/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.1021\n",
      "Epoch 83: val_loss improved from 0.09499 to 0.09423, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.1020 - val_loss: 0.0942 - learning_rate: 0.0010\n",
      "Epoch 84/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0994\n",
      "Epoch 84: val_loss improved from 0.09423 to 0.08975, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0994 - val_loss: 0.0898 - learning_rate: 0.0010\n",
      "Epoch 85/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0985\n",
      "Epoch 85: val_loss did not improve from 0.08975\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0986 - val_loss: 0.0926 - learning_rate: 0.0010\n",
      "Epoch 86/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0976\n",
      "Epoch 86: val_loss did not improve from 0.08975\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0976 - val_loss: 0.0945 - learning_rate: 0.0010\n",
      "Epoch 87/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0976\n",
      "Epoch 87: val_loss improved from 0.08975 to 0.08950, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - loss: 0.0976 - val_loss: 0.0895 - learning_rate: 0.0010\n",
      "Epoch 88/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0982\n",
      "Epoch 88: val_loss improved from 0.08950 to 0.08934, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0981 - val_loss: 0.0893 - learning_rate: 0.0010\n",
      "Epoch 89/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0966\n",
      "Epoch 89: val_loss improved from 0.08934 to 0.08603, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0966 - val_loss: 0.0860 - learning_rate: 0.0010\n",
      "Epoch 90/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0979\n",
      "Epoch 90: val_loss did not improve from 0.08603\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0978 - val_loss: 0.0919 - learning_rate: 0.0010\n",
      "Epoch 91/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0934\n",
      "Epoch 91: val_loss did not improve from 0.08603\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0934 - val_loss: 0.0891 - learning_rate: 0.0010\n",
      "Epoch 92/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0930\n",
      "Epoch 92: val_loss did not improve from 0.08603\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0929 - val_loss: 0.0909 - learning_rate: 0.0010\n",
      "Epoch 93/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0905\n",
      "Epoch 93: val_loss improved from 0.08603 to 0.08566, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0905 - val_loss: 0.0857 - learning_rate: 0.0010\n",
      "Epoch 94/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0909\n",
      "Epoch 94: val_loss improved from 0.08566 to 0.08393, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0909 - val_loss: 0.0839 - learning_rate: 0.0010\n",
      "Epoch 95/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0884\n",
      "Epoch 95: val_loss improved from 0.08393 to 0.08094, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0884 - val_loss: 0.0809 - learning_rate: 0.0010\n",
      "Epoch 96/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0873\n",
      "Epoch 96: val_loss improved from 0.08094 to 0.08033, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0872 - val_loss: 0.0803 - learning_rate: 0.0010\n",
      "Epoch 97/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0858\n",
      "Epoch 97: val_loss did not improve from 0.08033\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0858 - val_loss: 0.0837 - learning_rate: 0.0010\n",
      "Epoch 98/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0861\n",
      "Epoch 98: val_loss did not improve from 0.08033\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0860 - val_loss: 0.0886 - learning_rate: 0.0010\n",
      "Epoch 99/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0867\n",
      "Epoch 99: val_loss did not improve from 0.08033\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0866 - val_loss: 0.0848 - learning_rate: 0.0010\n",
      "Epoch 100/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0843\n",
      "Epoch 100: val_loss improved from 0.08033 to 0.07870, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0843 - val_loss: 0.0787 - learning_rate: 0.0010\n",
      "Epoch 101/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0821\n",
      "Epoch 101: val_loss did not improve from 0.07870\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0821 - val_loss: 0.0824 - learning_rate: 0.0010\n",
      "Epoch 102/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0814\n",
      "Epoch 102: val_loss improved from 0.07870 to 0.07626, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0814 - val_loss: 0.0763 - learning_rate: 0.0010\n",
      "Epoch 103/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0786\n",
      "Epoch 103: val_loss improved from 0.07626 to 0.07597, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0786 - val_loss: 0.0760 - learning_rate: 0.0010\n",
      "Epoch 104/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0790\n",
      "Epoch 104: val_loss improved from 0.07597 to 0.07416, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0790 - val_loss: 0.0742 - learning_rate: 0.0010\n",
      "Epoch 105/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0783\n",
      "Epoch 105: val_loss did not improve from 0.07416\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0784 - val_loss: 0.0776 - learning_rate: 0.0010\n",
      "Epoch 106/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0799\n",
      "Epoch 106: val_loss improved from 0.07416 to 0.07296, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0798 - val_loss: 0.0730 - learning_rate: 0.0010\n",
      "Epoch 107/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0773\n",
      "Epoch 107: val_loss improved from 0.07296 to 0.07246, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0773 - val_loss: 0.0725 - learning_rate: 0.0010\n",
      "Epoch 108/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0755\n",
      "Epoch 108: val_loss improved from 0.07246 to 0.06982, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0755 - val_loss: 0.0698 - learning_rate: 0.0010\n",
      "Epoch 109/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0760\n",
      "Epoch 109: val_loss did not improve from 0.06982\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0761 - val_loss: 0.0718 - learning_rate: 0.0010\n",
      "Epoch 110/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0753\n",
      "Epoch 110: val_loss did not improve from 0.06982\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0753 - val_loss: 0.0739 - learning_rate: 0.0010\n",
      "Epoch 111/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0745\n",
      "Epoch 111: val_loss did not improve from 0.06982\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0744 - val_loss: 0.0701 - learning_rate: 0.0010\n",
      "Epoch 112/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0724\n",
      "Epoch 112: val_loss improved from 0.06982 to 0.06959, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0725 - val_loss: 0.0696 - learning_rate: 0.0010\n",
      "Epoch 113/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0723\n",
      "Epoch 113: val_loss improved from 0.06959 to 0.06800, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0724 - val_loss: 0.0680 - learning_rate: 0.0010\n",
      "Epoch 114/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0729\n",
      "Epoch 114: val_loss improved from 0.06800 to 0.06437, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0729 - val_loss: 0.0644 - learning_rate: 0.0010\n",
      "Epoch 115/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0720\n",
      "Epoch 115: val_loss did not improve from 0.06437\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0720 - val_loss: 0.0672 - learning_rate: 0.0010\n",
      "Epoch 116/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0713\n",
      "Epoch 116: val_loss did not improve from 0.06437\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0712 - val_loss: 0.0729 - learning_rate: 0.0010\n",
      "Epoch 117/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0717\n",
      "Epoch 117: val_loss did not improve from 0.06437\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0717 - val_loss: 0.0648 - learning_rate: 0.0010\n",
      "Epoch 118/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0701\n",
      "Epoch 118: val_loss improved from 0.06437 to 0.06261, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0701 - val_loss: 0.0626 - learning_rate: 0.0010\n",
      "Epoch 119/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0699\n",
      "Epoch 119: val_loss did not improve from 0.06261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0699 - val_loss: 0.0686 - learning_rate: 0.0010\n",
      "Epoch 120/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0706\n",
      "Epoch 120: val_loss did not improve from 0.06261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0705 - val_loss: 0.0660 - learning_rate: 0.0010\n",
      "Epoch 121/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0698\n",
      "Epoch 121: val_loss did not improve from 0.06261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0697 - val_loss: 0.0694 - learning_rate: 0.0010\n",
      "Epoch 122/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0685\n",
      "Epoch 122: val_loss improved from 0.06261 to 0.05961, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0684 - val_loss: 0.0596 - learning_rate: 0.0010\n",
      "Epoch 123/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0665\n",
      "Epoch 123: val_loss did not improve from 0.05961\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0665 - val_loss: 0.0679 - learning_rate: 0.0010\n",
      "Epoch 124/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0672\n",
      "Epoch 124: val_loss did not improve from 0.05961\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0673 - val_loss: 0.0649 - learning_rate: 0.0010\n",
      "Epoch 125/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0651\n",
      "Epoch 125: val_loss did not improve from 0.05961\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0651 - val_loss: 0.0635 - learning_rate: 0.0010\n",
      "Epoch 126/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0651\n",
      "Epoch 126: val_loss did not improve from 0.05961\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - loss: 0.0650 - val_loss: 0.0597 - learning_rate: 0.0010\n",
      "Epoch 127/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0619\n",
      "Epoch 127: val_loss did not improve from 0.05961\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0620 - val_loss: 0.0622 - learning_rate: 0.0010\n",
      "Epoch 128/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0637\n",
      "Epoch 128: val_loss did not improve from 0.05961\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0636 - val_loss: 0.0599 - learning_rate: 0.0010\n",
      "Epoch 129/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0605\n",
      "Epoch 129: val_loss improved from 0.05961 to 0.05756, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0605 - val_loss: 0.0576 - learning_rate: 0.0010\n",
      "Epoch 130/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0613\n",
      "Epoch 130: val_loss improved from 0.05756 to 0.05622, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - loss: 0.0613 - val_loss: 0.0562 - learning_rate: 0.0010\n",
      "Epoch 131/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0615\n",
      "Epoch 131: val_loss did not improve from 0.05622\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0615 - val_loss: 0.0582 - learning_rate: 0.0010\n",
      "Epoch 132/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0613\n",
      "Epoch 132: val_loss did not improve from 0.05622\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0613 - val_loss: 0.0567 - learning_rate: 0.0010\n",
      "Epoch 133/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0603\n",
      "Epoch 133: val_loss did not improve from 0.05622\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0603 - val_loss: 0.0574 - learning_rate: 0.0010\n",
      "Epoch 134/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0592\n",
      "Epoch 134: val_loss did not improve from 0.05622\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0592 - val_loss: 0.0619 - learning_rate: 0.0010\n",
      "Epoch 135/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0585\n",
      "Epoch 135: val_loss improved from 0.05622 to 0.05402, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0586 - val_loss: 0.0540 - learning_rate: 0.0010\n",
      "Epoch 136/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0591\n",
      "Epoch 136: val_loss did not improve from 0.05402\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0591 - val_loss: 0.0577 - learning_rate: 0.0010\n",
      "Epoch 137/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0583\n",
      "Epoch 137: val_loss improved from 0.05402 to 0.05139, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0584 - val_loss: 0.0514 - learning_rate: 0.0010\n",
      "Epoch 138/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0599\n",
      "Epoch 138: val_loss did not improve from 0.05139\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0599 - val_loss: 0.0528 - learning_rate: 0.0010\n",
      "Epoch 139/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0595\n",
      "Epoch 139: val_loss did not improve from 0.05139\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0594 - val_loss: 0.0527 - learning_rate: 0.0010\n",
      "Epoch 140/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0575\n",
      "Epoch 140: val_loss did not improve from 0.05139\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0574 - val_loss: 0.0570 - learning_rate: 0.0010\n",
      "Epoch 141/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0572\n",
      "Epoch 141: val_loss did not improve from 0.05139\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0573 - val_loss: 0.0515 - learning_rate: 0.0010\n",
      "Epoch 142/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0579\n",
      "Epoch 142: val_loss did not improve from 0.05139\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0579 - val_loss: 0.0562 - learning_rate: 0.0010\n",
      "Epoch 143/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0562\n",
      "Epoch 143: val_loss did not improve from 0.05139\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0563 - val_loss: 0.0572 - learning_rate: 0.0010\n",
      "Epoch 144/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0567\n",
      "Epoch 144: val_loss did not improve from 0.05139\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0567 - val_loss: 0.0620 - learning_rate: 0.0010\n",
      "Epoch 145/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0552\n",
      "Epoch 145: val_loss did not improve from 0.05139\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0552 - val_loss: 0.0546 - learning_rate: 0.0010\n",
      "Epoch 146/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0560\n",
      "Epoch 146: val_loss did not improve from 0.05139\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0560 - val_loss: 0.0564 - learning_rate: 0.0010\n",
      "Epoch 147/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0558\n",
      "Epoch 147: val_loss improved from 0.05139 to 0.04849, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0557 - val_loss: 0.0485 - learning_rate: 0.0010\n",
      "Epoch 148/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0533\n",
      "Epoch 148: val_loss did not improve from 0.04849\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0533 - val_loss: 0.0552 - learning_rate: 0.0010\n",
      "Epoch 149/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0524\n",
      "Epoch 149: val_loss improved from 0.04849 to 0.04793, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0524 - val_loss: 0.0479 - learning_rate: 0.0010\n",
      "Epoch 150/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0527\n",
      "Epoch 150: val_loss did not improve from 0.04793\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0526 - val_loss: 0.0495 - learning_rate: 0.0010\n",
      "Epoch 151/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0517\n",
      "Epoch 151: val_loss did not improve from 0.04793\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - loss: 0.0516 - val_loss: 0.0544 - learning_rate: 0.0010\n",
      "Epoch 152/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0525\n",
      "Epoch 152: val_loss did not improve from 0.04793\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0524 - val_loss: 0.0511 - learning_rate: 0.0010\n",
      "Epoch 153/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0511\n",
      "Epoch 153: val_loss did not improve from 0.04793\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0511 - val_loss: 0.0512 - learning_rate: 0.0010\n",
      "Epoch 154/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0509\n",
      "Epoch 154: val_loss improved from 0.04793 to 0.04767, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0509 - val_loss: 0.0477 - learning_rate: 0.0010\n",
      "Epoch 155/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0504\n",
      "Epoch 155: val_loss did not improve from 0.04767\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0504 - val_loss: 0.0482 - learning_rate: 0.0010\n",
      "Epoch 156/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0503\n",
      "Epoch 156: val_loss did not improve from 0.04767\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - loss: 0.0503 - val_loss: 0.0486 - learning_rate: 0.0010\n",
      "Epoch 157/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0502\n",
      "Epoch 157: val_loss did not improve from 0.04767\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0502 - val_loss: 0.0477 - learning_rate: 0.0010\n",
      "Epoch 158/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0496\n",
      "Epoch 158: val_loss did not improve from 0.04767\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0496 - val_loss: 0.0485 - learning_rate: 0.0010\n",
      "Epoch 159/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0500\n",
      "Epoch 159: val_loss improved from 0.04767 to 0.04636, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0501 - val_loss: 0.0464 - learning_rate: 0.0010\n",
      "Epoch 160/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0496\n",
      "Epoch 160: val_loss improved from 0.04636 to 0.04528, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - loss: 0.0496 - val_loss: 0.0453 - learning_rate: 0.0010\n",
      "Epoch 161/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0495\n",
      "Epoch 161: val_loss did not improve from 0.04528\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0495 - val_loss: 0.0473 - learning_rate: 0.0010\n",
      "Epoch 162/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0478\n",
      "Epoch 162: val_loss improved from 0.04528 to 0.04429, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.0478 - val_loss: 0.0443 - learning_rate: 0.0010\n",
      "Epoch 163/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0469\n",
      "Epoch 163: val_loss did not improve from 0.04429\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0470 - val_loss: 0.0446 - learning_rate: 0.0010\n",
      "Epoch 164/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0486\n",
      "Epoch 164: val_loss did not improve from 0.04429\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0486 - val_loss: 0.0515 - learning_rate: 0.0010\n",
      "Epoch 165/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0477\n",
      "Epoch 165: val_loss did not improve from 0.04429\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0478 - val_loss: 0.0445 - learning_rate: 0.0010\n",
      "Epoch 166/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0469\n",
      "Epoch 166: val_loss did not improve from 0.04429\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0469 - val_loss: 0.0447 - learning_rate: 0.0010\n",
      "Epoch 167/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0455\n",
      "Epoch 167: val_loss improved from 0.04429 to 0.04089, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0455 - val_loss: 0.0409 - learning_rate: 0.0010\n",
      "Epoch 168/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0458\n",
      "Epoch 168: val_loss did not improve from 0.04089\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0458 - val_loss: 0.0417 - learning_rate: 0.0010\n",
      "Epoch 169/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0456\n",
      "Epoch 169: val_loss improved from 0.04089 to 0.04077, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0457 - val_loss: 0.0408 - learning_rate: 0.0010\n",
      "Epoch 170/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0458\n",
      "Epoch 170: val_loss did not improve from 0.04077\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0457 - val_loss: 0.0424 - learning_rate: 0.0010\n",
      "Epoch 171/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0444\n",
      "Epoch 171: val_loss did not improve from 0.04077\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0444 - val_loss: 0.0433 - learning_rate: 0.0010\n",
      "Epoch 172/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0437\n",
      "Epoch 172: val_loss did not improve from 0.04077\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0437 - val_loss: 0.0454 - learning_rate: 0.0010\n",
      "Epoch 173/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0431\n",
      "Epoch 173: val_loss improved from 0.04077 to 0.04020, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.0431 - val_loss: 0.0402 - learning_rate: 0.0010\n",
      "Epoch 174/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0431\n",
      "Epoch 174: val_loss did not improve from 0.04020\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0431 - val_loss: 0.0465 - learning_rate: 0.0010\n",
      "Epoch 175/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0432\n",
      "Epoch 175: val_loss did not improve from 0.04020\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0433 - val_loss: 0.0427 - learning_rate: 0.0010\n",
      "Epoch 176/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0441\n",
      "Epoch 176: val_loss improved from 0.04020 to 0.03823, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0441 - val_loss: 0.0382 - learning_rate: 0.0010\n",
      "Epoch 177/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0443\n",
      "Epoch 177: val_loss did not improve from 0.03823\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0442 - val_loss: 0.0457 - learning_rate: 0.0010\n",
      "Epoch 178/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0421\n",
      "Epoch 178: val_loss did not improve from 0.03823\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0421 - val_loss: 0.0426 - learning_rate: 0.0010\n",
      "Epoch 179/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0431\n",
      "Epoch 179: val_loss did not improve from 0.03823\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - loss: 0.0431 - val_loss: 0.0383 - learning_rate: 0.0010\n",
      "Epoch 180/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0426\n",
      "Epoch 180: val_loss did not improve from 0.03823\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0425 - val_loss: 0.0405 - learning_rate: 0.0010\n",
      "Epoch 181/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0424\n",
      "Epoch 181: val_loss improved from 0.03823 to 0.03666, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0424 - val_loss: 0.0367 - learning_rate: 0.0010\n",
      "Epoch 182/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0420\n",
      "Epoch 182: val_loss did not improve from 0.03666\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - loss: 0.0420 - val_loss: 0.0379 - learning_rate: 0.0010\n",
      "Epoch 183/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0407\n",
      "Epoch 183: val_loss did not improve from 0.03666\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0407 - val_loss: 0.0424 - learning_rate: 0.0010\n",
      "Epoch 184/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0404\n",
      "Epoch 184: val_loss improved from 0.03666 to 0.03649, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0405 - val_loss: 0.0365 - learning_rate: 0.0010\n",
      "Epoch 185/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0401\n",
      "Epoch 185: val_loss did not improve from 0.03649\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0401 - val_loss: 0.0370 - learning_rate: 0.0010\n",
      "Epoch 186/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0405\n",
      "Epoch 186: val_loss did not improve from 0.03649\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0405 - val_loss: 0.0391 - learning_rate: 0.0010\n",
      "Epoch 187/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0413\n",
      "Epoch 187: val_loss did not improve from 0.03649\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0412 - val_loss: 0.0428 - learning_rate: 0.0010\n",
      "Epoch 188/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0407\n",
      "Epoch 188: val_loss did not improve from 0.03649\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0407 - val_loss: 0.0373 - learning_rate: 0.0010\n",
      "Epoch 189/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0388\n",
      "Epoch 189: val_loss did not improve from 0.03649\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0389 - val_loss: 0.0380 - learning_rate: 0.0010\n",
      "Epoch 190/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0391\n",
      "Epoch 190: val_loss did not improve from 0.03649\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0391 - val_loss: 0.0450 - learning_rate: 0.0010\n",
      "Epoch 191/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0396\n",
      "Epoch 191: val_loss improved from 0.03649 to 0.03393, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0395 - val_loss: 0.0339 - learning_rate: 0.0010\n",
      "Epoch 192/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0390\n",
      "Epoch 192: val_loss did not improve from 0.03393\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - loss: 0.0389 - val_loss: 0.0382 - learning_rate: 0.0010\n",
      "Epoch 193/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0395\n",
      "Epoch 193: val_loss did not improve from 0.03393\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0394 - val_loss: 0.0402 - learning_rate: 0.0010\n",
      "Epoch 194/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0381\n",
      "Epoch 194: val_loss did not improve from 0.03393\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0381 - val_loss: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 195/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0372\n",
      "Epoch 195: val_loss improved from 0.03393 to 0.03340, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0372 - val_loss: 0.0334 - learning_rate: 0.0010\n",
      "Epoch 196/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0376\n",
      "Epoch 196: val_loss did not improve from 0.03340\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0376 - val_loss: 0.0356 - learning_rate: 0.0010\n",
      "Epoch 197/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0371\n",
      "Epoch 197: val_loss did not improve from 0.03340\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0371 - val_loss: 0.0350 - learning_rate: 0.0010\n",
      "Epoch 198/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0372\n",
      "Epoch 198: val_loss improved from 0.03340 to 0.03238, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0372 - val_loss: 0.0324 - learning_rate: 0.0010\n",
      "Epoch 199/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0366\n",
      "Epoch 199: val_loss did not improve from 0.03238\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0366 - val_loss: 0.0338 - learning_rate: 0.0010\n",
      "Epoch 200/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0365\n",
      "Epoch 200: val_loss did not improve from 0.03238\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0365 - val_loss: 0.0336 - learning_rate: 0.0010\n",
      "Epoch 201/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0361\n",
      "Epoch 201: val_loss improved from 0.03238 to 0.03204, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0361 - val_loss: 0.0320 - learning_rate: 0.0010\n",
      "Epoch 202/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0362\n",
      "Epoch 202: val_loss did not improve from 0.03204\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0362 - val_loss: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 203/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0365\n",
      "Epoch 203: val_loss did not improve from 0.03204\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0365 - val_loss: 0.0342 - learning_rate: 0.0010\n",
      "Epoch 204/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0370\n",
      "Epoch 204: val_loss improved from 0.03204 to 0.03038, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0369 - val_loss: 0.0304 - learning_rate: 0.0010\n",
      "Epoch 205/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0353\n",
      "Epoch 205: val_loss did not improve from 0.03038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0353 - val_loss: 0.0333 - learning_rate: 0.0010\n",
      "Epoch 206/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0348\n",
      "Epoch 206: val_loss did not improve from 0.03038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0349 - val_loss: 0.0335 - learning_rate: 0.0010\n",
      "Epoch 207/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0359\n",
      "Epoch 207: val_loss did not improve from 0.03038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0360 - val_loss: 0.0314 - learning_rate: 0.0010\n",
      "Epoch 208/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0354\n",
      "Epoch 208: val_loss did not improve from 0.03038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0354 - val_loss: 0.0313 - learning_rate: 0.0010\n",
      "Epoch 209/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0351\n",
      "Epoch 209: val_loss did not improve from 0.03038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0352 - val_loss: 0.0393 - learning_rate: 0.0010\n",
      "Epoch 210/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0347\n",
      "Epoch 210: val_loss did not improve from 0.03038\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0347 - val_loss: 0.0350 - learning_rate: 0.0010\n",
      "Epoch 211/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0335\n",
      "Epoch 211: val_loss improved from 0.03038 to 0.02977, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0335 - val_loss: 0.0298 - learning_rate: 0.0010\n",
      "Epoch 212/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0337\n",
      "Epoch 212: val_loss did not improve from 0.02977\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0337 - val_loss: 0.0336 - learning_rate: 0.0010\n",
      "Epoch 213/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0332\n",
      "Epoch 213: val_loss did not improve from 0.02977\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0332 - val_loss: 0.0330 - learning_rate: 0.0010\n",
      "Epoch 214/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0332\n",
      "Epoch 214: val_loss improved from 0.02977 to 0.02809, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0332 - val_loss: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 215/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0340\n",
      "Epoch 215: val_loss did not improve from 0.02809\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0340 - val_loss: 0.0382 - learning_rate: 0.0010\n",
      "Epoch 216/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0344\n",
      "Epoch 216: val_loss did not improve from 0.02809\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0345 - val_loss: 0.0342 - learning_rate: 0.0010\n",
      "Epoch 217/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0351\n",
      "Epoch 217: val_loss did not improve from 0.02809\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0351 - val_loss: 0.0409 - learning_rate: 0.0010\n",
      "Epoch 218/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0341\n",
      "Epoch 218: val_loss did not improve from 0.02809\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0341 - val_loss: 0.0337 - learning_rate: 0.0010\n",
      "Epoch 219/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0332\n",
      "Epoch 219: val_loss did not improve from 0.02809\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.0332 - val_loss: 0.0313 - learning_rate: 0.0010\n",
      "Epoch 220/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0330\n",
      "Epoch 220: val_loss did not improve from 0.02809\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0330 - val_loss: 0.0324 - learning_rate: 0.0010\n",
      "Epoch 221/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0326\n",
      "Epoch 221: val_loss did not improve from 0.02809\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0326 - val_loss: 0.0299 - learning_rate: 0.0010\n",
      "Epoch 222/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0326\n",
      "Epoch 222: val_loss did not improve from 0.02809\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0326 - val_loss: 0.0284 - learning_rate: 0.0010\n",
      "Epoch 223/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0319\n",
      "Epoch 223: val_loss did not improve from 0.02809\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0319 - val_loss: 0.0337 - learning_rate: 0.0010\n",
      "Epoch 224/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0320\n",
      "Epoch 224: val_loss improved from 0.02809 to 0.02744, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0319 - val_loss: 0.0274 - learning_rate: 0.0010\n",
      "Epoch 225/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0312\n",
      "Epoch 225: val_loss did not improve from 0.02744\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0312 - val_loss: 0.0313 - learning_rate: 0.0010\n",
      "Epoch 226/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0311\n",
      "Epoch 226: val_loss did not improve from 0.02744\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0312 - val_loss: 0.0302 - learning_rate: 0.0010\n",
      "Epoch 227/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0304\n",
      "Epoch 227: val_loss improved from 0.02744 to 0.02498, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.0305 - val_loss: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 228/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0311\n",
      "Epoch 228: val_loss did not improve from 0.02498\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0311 - val_loss: 0.0285 - learning_rate: 0.0010\n",
      "Epoch 229/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0315\n",
      "Epoch 229: val_loss did not improve from 0.02498\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0315 - val_loss: 0.0383 - learning_rate: 0.0010\n",
      "Epoch 230/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0317\n",
      "Epoch 230: val_loss did not improve from 0.02498\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0317 - val_loss: 0.0292 - learning_rate: 0.0010\n",
      "Epoch 231/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0316\n",
      "Epoch 231: val_loss did not improve from 0.02498\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0316 - val_loss: 0.0284 - learning_rate: 0.0010\n",
      "Epoch 232/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0303\n",
      "Epoch 232: val_loss did not improve from 0.02498\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0302 - val_loss: 0.0296 - learning_rate: 0.0010\n",
      "Epoch 233/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0300\n",
      "Epoch 233: val_loss did not improve from 0.02498\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0300 - val_loss: 0.0302 - learning_rate: 0.0010\n",
      "Epoch 234/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0291\n",
      "Epoch 234: val_loss did not improve from 0.02498\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0291 - val_loss: 0.0341 - learning_rate: 0.0010\n",
      "Epoch 235/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0297\n",
      "Epoch 235: val_loss did not improve from 0.02498\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0297 - val_loss: 0.0257 - learning_rate: 0.0010\n",
      "Epoch 236/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0295\n",
      "Epoch 236: val_loss did not improve from 0.02498\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0295 - val_loss: 0.0319 - learning_rate: 0.0010\n",
      "Epoch 237/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0303\n",
      "Epoch 237: val_loss did not improve from 0.02498\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0304 - val_loss: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 238/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0295\n",
      "Epoch 238: val_loss did not improve from 0.02498\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0295 - val_loss: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 239/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0284\n",
      "Epoch 239: val_loss did not improve from 0.02498\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0284 - val_loss: 0.0355 - learning_rate: 0.0010\n",
      "Epoch 240/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0291\n",
      "Epoch 240: val_loss did not improve from 0.02498\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0291 - val_loss: 0.0274 - learning_rate: 0.0010\n",
      "Epoch 241/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0290\n",
      "Epoch 241: val_loss did not improve from 0.02498\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0290 - val_loss: 0.0305 - learning_rate: 0.0010\n",
      "Epoch 242/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0285\n",
      "Epoch 242: val_loss did not improve from 0.02498\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0285 - val_loss: 0.0264 - learning_rate: 0.0010\n",
      "Epoch 243/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0282\n",
      "Epoch 243: val_loss improved from 0.02498 to 0.02390, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0282 - val_loss: 0.0239 - learning_rate: 0.0010\n",
      "Epoch 244/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0276\n",
      "Epoch 244: val_loss did not improve from 0.02390\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0276 - val_loss: 0.0326 - learning_rate: 0.0010\n",
      "Epoch 245/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0278\n",
      "Epoch 245: val_loss did not improve from 0.02390\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0278 - val_loss: 0.0257 - learning_rate: 0.0010\n",
      "Epoch 246/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0274\n",
      "Epoch 246: val_loss did not improve from 0.02390\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0275 - val_loss: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 247/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0308\n",
      "Epoch 247: val_loss did not improve from 0.02390\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0308 - val_loss: 0.0273 - learning_rate: 0.0010\n",
      "Epoch 248/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0287\n",
      "Epoch 248: val_loss did not improve from 0.02390\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0288 - val_loss: 0.0265 - learning_rate: 0.0010\n",
      "Epoch 249/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0285\n",
      "Epoch 249: val_loss did not improve from 0.02390\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0285 - val_loss: 0.0239 - learning_rate: 0.0010\n",
      "Epoch 250/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0291\n",
      "Epoch 250: val_loss did not improve from 0.02390\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0291 - val_loss: 0.0247 - learning_rate: 0.0010\n",
      "Epoch 251/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0286\n",
      "Epoch 251: val_loss did not improve from 0.02390\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - loss: 0.0285 - val_loss: 0.0247 - learning_rate: 0.0010\n",
      "Epoch 252/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0273\n",
      "Epoch 252: val_loss did not improve from 0.02390\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0274 - val_loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 253/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0271\n",
      "Epoch 253: val_loss did not improve from 0.02390\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0271 - val_loss: 0.0258 - learning_rate: 0.0010\n",
      "Epoch 254/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0269\n",
      "Epoch 254: val_loss did not improve from 0.02390\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - loss: 0.0269 - val_loss: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 255/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0265\n",
      "Epoch 255: val_loss improved from 0.02390 to 0.02247, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0265 - val_loss: 0.0225 - learning_rate: 0.0010\n",
      "Epoch 256/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0266\n",
      "Epoch 256: val_loss improved from 0.02247 to 0.02171, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0266 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 257/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0250\n",
      "Epoch 257: val_loss did not improve from 0.02171\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0251 - val_loss: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 258/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0250\n",
      "Epoch 258: val_loss did not improve from 0.02171\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0250 - val_loss: 0.0236 - learning_rate: 0.0010\n",
      "Epoch 259/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0246\n",
      "Epoch 259: val_loss did not improve from 0.02171\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0246 - val_loss: 0.0256 - learning_rate: 0.0010\n",
      "Epoch 260/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0256\n",
      "Epoch 260: val_loss did not improve from 0.02171\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 146ms/step - loss: 0.0256 - val_loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 261/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0248\n",
      "Epoch 261: val_loss did not improve from 0.02171\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 146ms/step - loss: 0.0249 - val_loss: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 262/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0256\n",
      "Epoch 262: val_loss did not improve from 0.02171\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0256 - val_loss: 0.0268 - learning_rate: 0.0010\n",
      "Epoch 263/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0249\n",
      "Epoch 263: val_loss did not improve from 0.02171\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0249 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 264/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0253\n",
      "Epoch 264: val_loss did not improve from 0.02171\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0253 - val_loss: 0.0247 - learning_rate: 0.0010\n",
      "Epoch 265/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0260\n",
      "Epoch 265: val_loss did not improve from 0.02171\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0260 - val_loss: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 266/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0253\n",
      "Epoch 266: val_loss did not improve from 0.02171\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0253 - val_loss: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 267/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0264\n",
      "Epoch 267: val_loss did not improve from 0.02171\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0264 - val_loss: 0.0267 - learning_rate: 0.0010\n",
      "Epoch 268/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0267\n",
      "Epoch 268: val_loss did not improve from 0.02171\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0266 - val_loss: 0.0300 - learning_rate: 0.0010\n",
      "Epoch 269/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0255\n",
      "Epoch 269: val_loss improved from 0.02171 to 0.02159, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0255 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 270/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0251\n",
      "Epoch 270: val_loss improved from 0.02159 to 0.01976, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0252 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 271/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0264\n",
      "Epoch 271: val_loss did not improve from 0.01976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0263 - val_loss: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 272/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0252\n",
      "Epoch 272: val_loss did not improve from 0.01976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0252 - val_loss: 0.0249 - learning_rate: 0.0010\n",
      "Epoch 273/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0266\n",
      "Epoch 273: val_loss did not improve from 0.01976\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0267 - val_loss: 0.0236 - learning_rate: 0.0010\n",
      "Epoch 274/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0263\n",
      "Epoch 274: val_loss improved from 0.01976 to 0.01955, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - loss: 0.0263 - val_loss: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 275/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0245\n",
      "Epoch 275: val_loss did not improve from 0.01955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0245 - val_loss: 0.0278 - learning_rate: 0.0010\n",
      "Epoch 276/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0234\n",
      "Epoch 276: val_loss did not improve from 0.01955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0234 - val_loss: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 277/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0238\n",
      "Epoch 277: val_loss did not improve from 0.01955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0238 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 278/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0230\n",
      "Epoch 278: val_loss did not improve from 0.01955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0230 - val_loss: 0.0219 - learning_rate: 0.0010\n",
      "Epoch 279/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0233\n",
      "Epoch 279: val_loss did not improve from 0.01955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - loss: 0.0233 - val_loss: 0.0210 - learning_rate: 0.0010\n",
      "Epoch 280/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0247\n",
      "Epoch 280: val_loss did not improve from 0.01955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0246 - val_loss: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 281/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0223\n",
      "Epoch 281: val_loss did not improve from 0.01955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - loss: 0.0224 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 282/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0232\n",
      "Epoch 282: val_loss did not improve from 0.01955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0232 - val_loss: 0.0206 - learning_rate: 0.0010\n",
      "Epoch 283/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0232\n",
      "Epoch 283: val_loss did not improve from 0.01955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0233 - val_loss: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 284/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0246\n",
      "Epoch 284: val_loss did not improve from 0.01955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0245 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 285/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0253\n",
      "Epoch 285: val_loss did not improve from 0.01955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0253 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 286/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0239\n",
      "Epoch 286: val_loss did not improve from 0.01955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0240 - val_loss: 0.0306 - learning_rate: 0.0010\n",
      "Epoch 287/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0250\n",
      "Epoch 287: val_loss did not improve from 0.01955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0250 - val_loss: 0.0330 - learning_rate: 0.0010\n",
      "Epoch 288/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0271\n",
      "Epoch 288: val_loss did not improve from 0.01955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0269 - val_loss: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 289/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0241\n",
      "Epoch 289: val_loss did not improve from 0.01955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0241 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 290/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0231\n",
      "Epoch 290: val_loss improved from 0.01955 to 0.01868, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0231 - val_loss: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 291/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0235\n",
      "Epoch 291: val_loss did not improve from 0.01868\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0235 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 292/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0227\n",
      "Epoch 292: val_loss did not improve from 0.01868\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0227 - val_loss: 0.0234 - learning_rate: 0.0010\n",
      "Epoch 293/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0241\n",
      "Epoch 293: val_loss did not improve from 0.01868\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0240 - val_loss: 0.0229 - learning_rate: 0.0010\n",
      "Epoch 294/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0234\n",
      "Epoch 294: val_loss did not improve from 0.01868\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0234 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 295/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0221\n",
      "Epoch 295: val_loss did not improve from 0.01868\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0222 - val_loss: 0.0225 - learning_rate: 0.0010\n",
      "Epoch 296/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0223\n",
      "Epoch 296: val_loss did not improve from 0.01868\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0223 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 297/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0223\n",
      "Epoch 297: val_loss did not improve from 0.01868\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0222 - val_loss: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 298/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0226\n",
      "Epoch 298: val_loss did not improve from 0.01868\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0226 - val_loss: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 299/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0230\n",
      "Epoch 299: val_loss did not improve from 0.01868\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0230 - val_loss: 0.0236 - learning_rate: 0.0010\n",
      "Epoch 300/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0227\n",
      "Epoch 300: val_loss did not improve from 0.01868\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - loss: 0.0227 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 301/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0219\n",
      "Epoch 301: val_loss did not improve from 0.01868\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 146ms/step - loss: 0.0220 - val_loss: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 302/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0242\n",
      "Epoch 302: val_loss improved from 0.01868 to 0.01802, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0241 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 303/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0242\n",
      "Epoch 303: val_loss did not improve from 0.01802\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0241 - val_loss: 0.0210 - learning_rate: 0.0010\n",
      "Epoch 304/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0216\n",
      "Epoch 304: val_loss did not improve from 0.01802\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0217 - val_loss: 0.0210 - learning_rate: 0.0010\n",
      "Epoch 305/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0227\n",
      "Epoch 305: val_loss did not improve from 0.01802\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0227 - val_loss: 0.0246 - learning_rate: 0.0010\n",
      "Epoch 306/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0223\n",
      "Epoch 306: val_loss did not improve from 0.01802\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0223 - val_loss: 0.0219 - learning_rate: 0.0010\n",
      "Epoch 307/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0222\n",
      "Epoch 307: val_loss improved from 0.01802 to 0.01792, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0222 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 308/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0224\n",
      "Epoch 308: val_loss did not improve from 0.01792\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0225 - val_loss: 0.0271 - learning_rate: 0.0010\n",
      "Epoch 309/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0245\n",
      "Epoch 309: val_loss did not improve from 0.01792\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - loss: 0.0243 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 310/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0220\n",
      "Epoch 310: val_loss did not improve from 0.01792\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0220 - val_loss: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 311/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0213\n",
      "Epoch 311: val_loss did not improve from 0.01792\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0213 - val_loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 312/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0212\n",
      "Epoch 312: val_loss did not improve from 0.01792\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0212 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 313/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0207\n",
      "Epoch 313: val_loss did not improve from 0.01792\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0207 - val_loss: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 314/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0205\n",
      "Epoch 314: val_loss did not improve from 0.01792\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0205 - val_loss: 0.0270 - learning_rate: 0.0010\n",
      "Epoch 315/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0201\n",
      "Epoch 315: val_loss did not improve from 0.01792\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0201 - val_loss: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 316/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0203\n",
      "Epoch 316: val_loss improved from 0.01792 to 0.01626, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0204 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 317/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0197\n",
      "Epoch 317: val_loss improved from 0.01626 to 0.01624, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0197 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 318/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0191\n",
      "Epoch 318: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0192 - val_loss: 0.0210 - learning_rate: 0.0010\n",
      "Epoch 319/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0200\n",
      "Epoch 319: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0201 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 320/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0207\n",
      "Epoch 320: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0207 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 321/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0197\n",
      "Epoch 321: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0197 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 322/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0199\n",
      "Epoch 322: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0199 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 323/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0208\n",
      "Epoch 323: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0208 - val_loss: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 324/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0203\n",
      "Epoch 324: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0203 - val_loss: 0.0219 - learning_rate: 0.0010\n",
      "Epoch 325/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0212\n",
      "Epoch 325: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0212 - val_loss: 0.0261 - learning_rate: 0.0010\n",
      "Epoch 326/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0220\n",
      "Epoch 326: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0220 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 327/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0231\n",
      "Epoch 327: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0232 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 328/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0228\n",
      "Epoch 328: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0227 - val_loss: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 329/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0212\n",
      "Epoch 329: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0212 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 330/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0204\n",
      "Epoch 330: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0204 - val_loss: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 331/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0202\n",
      "Epoch 331: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0202 - val_loss: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 332/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0192\n",
      "Epoch 332: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0192 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 333/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0189\n",
      "Epoch 333: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0189 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 334/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0196\n",
      "Epoch 334: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0196 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 335/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0201\n",
      "Epoch 335: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0200 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 336/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0189\n",
      "Epoch 336: val_loss did not improve from 0.01624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0190 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 337/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0196\n",
      "Epoch 337: val_loss improved from 0.01624 to 0.01595, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0196 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 338/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0188\n",
      "Epoch 338: val_loss did not improve from 0.01595\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0187 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 339/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0186\n",
      "Epoch 339: val_loss did not improve from 0.01595\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0186 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 340/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0183\n",
      "Epoch 340: val_loss did not improve from 0.01595\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0183 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 341/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0187\n",
      "Epoch 341: val_loss did not improve from 0.01595\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0187 - val_loss: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 342/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0192\n",
      "Epoch 342: val_loss did not improve from 0.01595\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0192 - val_loss: 0.0307 - learning_rate: 0.0010\n",
      "Epoch 343/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0203\n",
      "Epoch 343: val_loss did not improve from 0.01595\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0203 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 344/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0199\n",
      "Epoch 344: val_loss did not improve from 0.01595\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0199 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 345/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0198\n",
      "Epoch 345: val_loss did not improve from 0.01595\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0198 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 346/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0197\n",
      "Epoch 346: val_loss did not improve from 0.01595\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0198 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 347/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0192\n",
      "Epoch 347: val_loss did not improve from 0.01595\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0192 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 348/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0191\n",
      "Epoch 348: val_loss did not improve from 0.01595\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0191 - val_loss: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 349/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0184\n",
      "Epoch 349: val_loss did not improve from 0.01595\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0185 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 350/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0189\n",
      "Epoch 350: val_loss improved from 0.01595 to 0.01547, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0189 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 351/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0181\n",
      "Epoch 351: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0182 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 352/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0192\n",
      "Epoch 352: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - loss: 0.0192 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 353/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0192\n",
      "Epoch 353: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0192 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 354/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0191\n",
      "Epoch 354: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0191 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 355/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0185\n",
      "Epoch 355: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0185 - val_loss: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 356/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0186\n",
      "Epoch 356: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0186 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 357/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0174\n",
      "Epoch 357: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0174 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 358/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0176\n",
      "Epoch 358: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0176 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 359/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0172\n",
      "Epoch 359: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0173 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 360/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0176\n",
      "Epoch 360: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0176 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 361/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0178\n",
      "Epoch 361: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0178 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 362/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0187\n",
      "Epoch 362: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0187 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 363/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0183\n",
      "Epoch 363: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0183 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 364/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0182\n",
      "Epoch 364: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0182 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 365/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0177\n",
      "Epoch 365: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0177 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 366/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0181\n",
      "Epoch 366: val_loss improved from 0.01547 to 0.01541, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0182 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 367/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0179\n",
      "Epoch 367: val_loss did not improve from 0.01541\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0179 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 368/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0176\n",
      "Epoch 368: val_loss did not improve from 0.01541\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0176 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 369/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0175\n",
      "Epoch 369: val_loss did not improve from 0.01541\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0175 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 370/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0182\n",
      "Epoch 370: val_loss did not improve from 0.01541\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0182 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 371/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0172\n",
      "Epoch 371: val_loss improved from 0.01541 to 0.01528, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0172 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 372/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0176\n",
      "Epoch 372: val_loss did not improve from 0.01528\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0176 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 373/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0178\n",
      "Epoch 373: val_loss did not improve from 0.01528\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0178 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 374/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0167\n",
      "Epoch 374: val_loss did not improve from 0.01528\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0167 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 375/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0162\n",
      "Epoch 375: val_loss did not improve from 0.01528\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0163 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 376/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0160\n",
      "Epoch 376: val_loss did not improve from 0.01528\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0160 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 377/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0165\n",
      "Epoch 377: val_loss improved from 0.01528 to 0.01477, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0165 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 378/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0159\n",
      "Epoch 378: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0160 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 379/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0181\n",
      "Epoch 379: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0182 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 380/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0175\n",
      "Epoch 380: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0176 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 381/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0176\n",
      "Epoch 381: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0176 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 382/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0168\n",
      "Epoch 382: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0168 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 383/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0174\n",
      "Epoch 383: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0174 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 384/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0172\n",
      "Epoch 384: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0173 - val_loss: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 385/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0171\n",
      "Epoch 385: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0170 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 386/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0167\n",
      "Epoch 386: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0167 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 387/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0168\n",
      "Epoch 387: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0169 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 388/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0179\n",
      "Epoch 388: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0179 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 389/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0171\n",
      "Epoch 389: val_loss improved from 0.01477 to 0.01403, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - loss: 0.0171 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 390/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0166\n",
      "Epoch 390: val_loss did not improve from 0.01403\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0166 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 391/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0165\n",
      "Epoch 391: val_loss did not improve from 0.01403\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0165 - val_loss: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 392/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0159\n",
      "Epoch 392: val_loss did not improve from 0.01403\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0159 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 393/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0163\n",
      "Epoch 393: val_loss did not improve from 0.01403\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0163 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 394/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0158\n",
      "Epoch 394: val_loss did not improve from 0.01403\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0158 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 395/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0162\n",
      "Epoch 395: val_loss did not improve from 0.01403\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0162 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 396/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0166\n",
      "Epoch 396: val_loss did not improve from 0.01403\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0167 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 397/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0180\n",
      "Epoch 397: val_loss improved from 0.01403 to 0.01402, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0180 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 398/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0171\n",
      "Epoch 398: val_loss did not improve from 0.01402\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0171 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 399/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0177\n",
      "Epoch 399: val_loss did not improve from 0.01402\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0176 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 400/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0169\n",
      "Epoch 400: val_loss did not improve from 0.01402\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0169 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 401/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0163\n",
      "Epoch 401: val_loss did not improve from 0.01402\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0164 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 402/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0172\n",
      "Epoch 402: val_loss did not improve from 0.01402\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0172 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 403/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0175\n",
      "Epoch 403: val_loss did not improve from 0.01402\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0175 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 404/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0173\n",
      "Epoch 404: val_loss did not improve from 0.01402\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0173 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 405/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0168\n",
      "Epoch 405: val_loss did not improve from 0.01402\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0168 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 406/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0163\n",
      "Epoch 406: val_loss did not improve from 0.01402\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0163 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 407/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0159\n",
      "Epoch 407: val_loss did not improve from 0.01402\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0159 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 408/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0156\n",
      "Epoch 408: val_loss did not improve from 0.01402\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0156 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 409/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0158\n",
      "Epoch 409: val_loss did not improve from 0.01402\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0158 - val_loss: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 410/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0159\n",
      "Epoch 410: val_loss did not improve from 0.01402\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0159 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 411/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0159\n",
      "Epoch 411: val_loss did not improve from 0.01402\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0159 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 412/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0161\n",
      "Epoch 412: val_loss did not improve from 0.01402\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - loss: 0.0161 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 413/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0157\n",
      "Epoch 413: val_loss did not improve from 0.01402\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0157 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 414/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0149\n",
      "Epoch 414: val_loss improved from 0.01402 to 0.01378, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0149 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 415/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0155\n",
      "Epoch 415: val_loss did not improve from 0.01378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0155 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 416/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0151\n",
      "Epoch 416: val_loss did not improve from 0.01378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0151 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 417/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0168\n",
      "Epoch 417: val_loss did not improve from 0.01378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0167 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 418/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0156\n",
      "Epoch 418: val_loss did not improve from 0.01378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0157 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 419/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0159\n",
      "Epoch 419: val_loss did not improve from 0.01378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0159 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 420/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0169\n",
      "Epoch 420: val_loss did not improve from 0.01378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0169 - val_loss: 0.0218 - learning_rate: 0.0010\n",
      "Epoch 421/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0163\n",
      "Epoch 421: val_loss did not improve from 0.01378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0163 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 422/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0161\n",
      "Epoch 422: val_loss did not improve from 0.01378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0161 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 423/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0165\n",
      "Epoch 423: val_loss did not improve from 0.01378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0165 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 424/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0158\n",
      "Epoch 424: val_loss did not improve from 0.01378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0158 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 425/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0156\n",
      "Epoch 425: val_loss did not improve from 0.01378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0156 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 426/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0157\n",
      "Epoch 426: val_loss did not improve from 0.01378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0157 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 427/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0159\n",
      "Epoch 427: val_loss did not improve from 0.01378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0159 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 428/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0159\n",
      "Epoch 428: val_loss did not improve from 0.01378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0159 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 429/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0165\n",
      "Epoch 429: val_loss did not improve from 0.01378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0165 - val_loss: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 430/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0162\n",
      "Epoch 430: val_loss did not improve from 0.01378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0162 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 431/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0150\n",
      "Epoch 431: val_loss did not improve from 0.01378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0150 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 432/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0150\n",
      "Epoch 432: val_loss improved from 0.01378 to 0.01235, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - loss: 0.0150 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 433/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0157\n",
      "Epoch 433: val_loss did not improve from 0.01235\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0157 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 434/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0153\n",
      "Epoch 434: val_loss did not improve from 0.01235\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0153 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 435/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0153\n",
      "Epoch 435: val_loss did not improve from 0.01235\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0153 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 436/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0149\n",
      "Epoch 436: val_loss did not improve from 0.01235\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0149 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 437/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0144\n",
      "Epoch 437: val_loss did not improve from 0.01235\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0144 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 438/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0142\n",
      "Epoch 438: val_loss did not improve from 0.01235\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0143 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 439/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0138\n",
      "Epoch 439: val_loss did not improve from 0.01235\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - loss: 0.0138 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 440/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0150\n",
      "Epoch 440: val_loss did not improve from 0.01235\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - loss: 0.0150 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 441/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0150\n",
      "Epoch 441: val_loss did not improve from 0.01235\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0150 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 442/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0147\n",
      "Epoch 442: val_loss did not improve from 0.01235\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0147 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 443/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0149\n",
      "Epoch 443: val_loss improved from 0.01235 to 0.01198, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0149 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 444/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0153\n",
      "Epoch 444: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0153 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 445/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0155\n",
      "Epoch 445: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0155 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 446/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0155\n",
      "Epoch 446: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0155 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 447/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0148\n",
      "Epoch 447: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0148 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 448/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0148\n",
      "Epoch 448: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0148 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 449/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0141\n",
      "Epoch 449: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0141 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 450/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0143\n",
      "Epoch 450: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0143 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 451/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0146\n",
      "Epoch 451: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0146 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 452/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0160\n",
      "Epoch 452: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0160 - val_loss: 0.0188 - learning_rate: 0.0010\n",
      "Epoch 453/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0182\n",
      "Epoch 453: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0183 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 454/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0191\n",
      "Epoch 454: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0190 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 455/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0163\n",
      "Epoch 455: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - loss: 0.0163 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 456/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0151\n",
      "Epoch 456: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0151 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 457/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0148\n",
      "Epoch 457: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0148 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 458/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0164\n",
      "Epoch 458: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0164 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 459/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0146\n",
      "Epoch 459: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - loss: 0.0147 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 460/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0149\n",
      "Epoch 460: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0149 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 461/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0142\n",
      "Epoch 461: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0142 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 462/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0141\n",
      "Epoch 462: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0142 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 463/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0140\n",
      "Epoch 463: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0140 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 464/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0143\n",
      "Epoch 464: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0143 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 465/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0142\n",
      "Epoch 465: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0142 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 466/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0145\n",
      "Epoch 466: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0145 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 467/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0145\n",
      "Epoch 467: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0145 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 468/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0135\n",
      "Epoch 468: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0136 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 469/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0137\n",
      "Epoch 469: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0137 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 470/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0137\n",
      "Epoch 470: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0138 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 471/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0141\n",
      "Epoch 471: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0141 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 472/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0137\n",
      "Epoch 472: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0138 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 473/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0150\n",
      "Epoch 473: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0149 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 474/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0137\n",
      "Epoch 474: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0137 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 475/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0134\n",
      "Epoch 475: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0134 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 476/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0130\n",
      "Epoch 476: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0131 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 477/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0137\n",
      "Epoch 477: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0137 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 478/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0139\n",
      "Epoch 478: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0139 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 479/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0137\n",
      "Epoch 479: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0137 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 480/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0142\n",
      "Epoch 480: val_loss did not improve from 0.01198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0143 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 481/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0161\n",
      "Epoch 481: val_loss improved from 0.01198 to 0.01094, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - loss: 0.0160 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 482/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0148\n",
      "Epoch 482: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0148 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 483/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0150\n",
      "Epoch 483: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0150 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 484/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0146\n",
      "Epoch 484: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0147 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 485/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0151\n",
      "Epoch 485: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0151 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 486/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0137\n",
      "Epoch 486: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0137 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 487/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0148\n",
      "Epoch 487: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0148 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 488/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0145\n",
      "Epoch 488: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0146 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 489/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0156\n",
      "Epoch 489: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0156 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 490/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0142\n",
      "Epoch 490: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0142 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 491/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0141\n",
      "Epoch 491: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0141 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 492/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0152\n",
      "Epoch 492: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0151 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 493/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0139\n",
      "Epoch 493: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0140 - val_loss: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 494/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0134\n",
      "Epoch 494: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0133 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 495/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0129\n",
      "Epoch 495: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0130 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 496/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0134\n",
      "Epoch 496: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0134 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 497/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0130\n",
      "Epoch 497: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0131 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 498/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0147\n",
      "Epoch 498: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0147 - val_loss: 0.0202 - learning_rate: 0.0010\n",
      "Epoch 499/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0136\n",
      "Epoch 499: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0136 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 500/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0136\n",
      "Epoch 500: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0136 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 501/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0135\n",
      "Epoch 501: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - loss: 0.0136 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 502/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0141\n",
      "Epoch 502: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0141 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 503/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0135\n",
      "Epoch 503: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0135 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 504/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0131\n",
      "Epoch 504: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0131 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 505/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0134\n",
      "Epoch 505: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0134 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 506/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0133\n",
      "Epoch 506: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0133 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 507/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0126\n",
      "Epoch 507: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0126 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 508/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0129\n",
      "Epoch 508: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0129 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 509/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0132\n",
      "Epoch 509: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0133 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 510/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0137\n",
      "Epoch 510: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0138 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 511/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0138\n",
      "Epoch 511: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0138 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 512/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0132\n",
      "Epoch 512: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0133 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 513/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0130\n",
      "Epoch 513: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0130 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 514/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0127\n",
      "Epoch 514: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0128 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 515/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0135\n",
      "Epoch 515: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0135 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 516/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0131\n",
      "Epoch 516: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0131 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 517/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0132\n",
      "Epoch 517: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0133 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 518/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0128\n",
      "Epoch 518: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0128 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 519/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0133\n",
      "Epoch 519: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0133 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 520/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0141\n",
      "Epoch 520: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0142 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 521/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0151\n",
      "Epoch 521: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0151 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 522/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0151\n",
      "Epoch 522: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0151 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 523/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0161\n",
      "Epoch 523: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0160 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 524/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0144\n",
      "Epoch 524: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0144 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 525/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0135\n",
      "Epoch 525: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0135 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 526/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0125\n",
      "Epoch 526: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0125 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 527/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0123\n",
      "Epoch 527: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0123 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 528/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0130\n",
      "Epoch 528: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0130 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 529/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0126\n",
      "Epoch 529: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0126 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 530/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0147\n",
      "Epoch 530: val_loss did not improve from 0.01094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0147 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 531/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0150\n",
      "Epoch 531: val_loss improved from 0.01094 to 0.01061, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 146ms/step - loss: 0.0150 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 532/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0144\n",
      "Epoch 532: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0144 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 533/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0131\n",
      "Epoch 533: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0132 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 534/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0137\n",
      "Epoch 534: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - loss: 0.0137 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 535/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0140\n",
      "Epoch 535: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0140 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 536/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0141\n",
      "Epoch 536: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0142 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 537/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0136\n",
      "Epoch 537: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0135 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 538/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0128\n",
      "Epoch 538: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0128 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 539/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0125\n",
      "Epoch 539: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - loss: 0.0126 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 540/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0121\n",
      "Epoch 540: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - loss: 0.0122 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 541/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0121\n",
      "Epoch 541: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0121 - val_loss: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 542/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0128\n",
      "Epoch 542: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0127 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 543/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0134\n",
      "Epoch 543: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0134 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 544/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0133\n",
      "Epoch 544: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0133 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 545/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0129\n",
      "Epoch 545: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0130 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 546/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0137\n",
      "Epoch 546: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0137 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 547/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0148\n",
      "Epoch 547: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0147 - val_loss: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 548/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0129\n",
      "Epoch 548: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0129 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 549/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0133\n",
      "Epoch 549: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0133 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 550/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0129\n",
      "Epoch 550: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0128 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 551/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0123\n",
      "Epoch 551: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0123 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 552/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0121\n",
      "Epoch 552: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0122 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 553/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0124\n",
      "Epoch 553: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0125 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 554/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0126\n",
      "Epoch 554: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0126 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 555/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0126\n",
      "Epoch 555: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0126 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 556/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0128\n",
      "Epoch 556: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0128 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 557/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0124\n",
      "Epoch 557: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0124 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 558/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0130\n",
      "Epoch 558: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0130 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 559/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0161\n",
      "Epoch 559: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0162 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 560/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0172\n",
      "Epoch 560: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0172 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 561/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0178\n",
      "Epoch 561: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0177 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 562/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0152\n",
      "Epoch 562: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0152 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 563/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0149\n",
      "Epoch 563: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0150 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 564/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0145\n",
      "Epoch 564: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0145 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 565/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0140\n",
      "Epoch 565: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0140 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 566/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0140\n",
      "Epoch 566: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0140 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 567/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0142\n",
      "Epoch 567: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0142 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 568/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0140\n",
      "Epoch 568: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0139 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 569/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0133\n",
      "Epoch 569: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0133 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 570/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0129\n",
      "Epoch 570: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0129 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 571/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0132\n",
      "Epoch 571: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0132 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 572/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0126\n",
      "Epoch 572: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0126 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 573/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0127\n",
      "Epoch 573: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0128 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 574/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0136\n",
      "Epoch 574: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0137 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 575/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0138\n",
      "Epoch 575: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0138 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 576/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0132\n",
      "Epoch 576: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0131 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 577/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0127\n",
      "Epoch 577: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0128 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 578/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0131\n",
      "Epoch 578: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0132 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 579/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0144\n",
      "Epoch 579: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0144 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 580/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0139\n",
      "Epoch 580: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0139 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 581/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0140\n",
      "Epoch 581: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0140 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 582/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0128\n",
      "Epoch 582: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0128 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 583/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0124\n",
      "Epoch 583: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0125 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 584/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0122\n",
      "Epoch 584: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0122 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 585/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0121\n",
      "Epoch 585: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0121 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 586/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0116\n",
      "Epoch 586: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0117 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 587/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0120\n",
      "Epoch 587: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0120 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 588/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0124\n",
      "Epoch 588: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0124 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 589/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0126\n",
      "Epoch 589: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0126 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 590/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0116\n",
      "Epoch 590: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0116 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 591/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0117\n",
      "Epoch 591: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0117 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 592/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0116\n",
      "Epoch 592: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0117 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 593/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0133\n",
      "Epoch 593: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0133 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 594/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0140\n",
      "Epoch 594: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0140 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 595/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0139\n",
      "Epoch 595: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0139 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 596/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0133\n",
      "Epoch 596: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0133 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 597/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0123\n",
      "Epoch 597: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0123 - val_loss: 0.0219 - learning_rate: 0.0010\n",
      "Epoch 598/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0123\n",
      "Epoch 598: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0123 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 599/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0134\n",
      "Epoch 599: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0134 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 600/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0143\n",
      "Epoch 600: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0143 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 601/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0134\n",
      "Epoch 601: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0134 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 602/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0120\n",
      "Epoch 602: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0121 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 603/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0123\n",
      "Epoch 603: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0123 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 604/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0122\n",
      "Epoch 604: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0122 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 605/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0112\n",
      "Epoch 605: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0112 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 606/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0113\n",
      "Epoch 606: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0113 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 607/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0110\n",
      "Epoch 607: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0110 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 608/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0112\n",
      "Epoch 608: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - loss: 0.0112 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 609/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0114\n",
      "Epoch 609: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0115 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 610/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0123\n",
      "Epoch 610: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0123 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 611/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0118\n",
      "Epoch 611: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0118 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 612/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0124\n",
      "Epoch 612: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0124 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 613/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0122\n",
      "Epoch 613: val_loss did not improve from 0.01061\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0122 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 614/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0124\n",
      "Epoch 614: val_loss improved from 0.01061 to 0.01045, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0124 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 615/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0119\n",
      "Epoch 615: val_loss did not improve from 0.01045\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0119 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 616/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0123\n",
      "Epoch 616: val_loss did not improve from 0.01045\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0123 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 617/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0114\n",
      "Epoch 617: val_loss did not improve from 0.01045\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0115 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 618/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0110\n",
      "Epoch 618: val_loss did not improve from 0.01045\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0111 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 619/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0116\n",
      "Epoch 619: val_loss did not improve from 0.01045\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0116 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 620/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0119\n",
      "Epoch 620: val_loss did not improve from 0.01045\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0120 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 621/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0128\n",
      "Epoch 621: val_loss did not improve from 0.01045\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0128 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 622/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0119\n",
      "Epoch 622: val_loss did not improve from 0.01045\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0119 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 623/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0118\n",
      "Epoch 623: val_loss did not improve from 0.01045\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0118 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 624/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0125\n",
      "Epoch 624: val_loss did not improve from 0.01045\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0124 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 625/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0114\n",
      "Epoch 625: val_loss did not improve from 0.01045\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0114 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 626/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0110\n",
      "Epoch 626: val_loss did not improve from 0.01045\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0110 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 627/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0114\n",
      "Epoch 627: val_loss did not improve from 0.01045\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0114 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 628/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0122\n",
      "Epoch 628: val_loss did not improve from 0.01045\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0122 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 629/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0115\n",
      "Epoch 629: val_loss did not improve from 0.01045\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0115 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 630/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0121\n",
      "Epoch 630: val_loss improved from 0.01045 to 0.01032, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0121 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 631/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0125\n",
      "Epoch 631: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0125 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 632/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0117\n",
      "Epoch 632: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0117 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 633/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0116\n",
      "Epoch 633: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0116 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 634/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0126\n",
      "Epoch 634: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0126 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 635/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0125\n",
      "Epoch 635: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0124 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 636/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0117\n",
      "Epoch 636: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0117 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 637/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0117\n",
      "Epoch 637: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0117 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 638/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0117\n",
      "Epoch 638: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0117 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 639/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0117\n",
      "Epoch 639: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0117 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 640/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0120\n",
      "Epoch 640: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0120 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 641/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0118\n",
      "Epoch 641: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0118 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 642/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0120\n",
      "Epoch 642: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0119 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 643/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0120\n",
      "Epoch 643: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0120 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 644/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0112\n",
      "Epoch 644: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0113 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 645/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0104\n",
      "Epoch 645: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0104 - val_loss: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 646/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0115\n",
      "Epoch 646: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0115 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 647/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0112\n",
      "Epoch 647: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0112 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 648/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0115\n",
      "Epoch 648: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0116 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 649/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0136\n",
      "Epoch 649: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0137 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 650/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0141\n",
      "Epoch 650: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0141 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 651/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0136\n",
      "Epoch 651: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0137 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 652/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0145\n",
      "Epoch 652: val_loss did not improve from 0.01032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0144 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 653/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0141\n",
      "Epoch 653: val_loss improved from 0.01032 to 0.00968, saving model to ./result_folder_no_misc/lstm_ts_6.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0140 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 654/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0125\n",
      "Epoch 654: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0125 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 655/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0128\n",
      "Epoch 655: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0128 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 656/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0122\n",
      "Epoch 656: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0122 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 657/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0116\n",
      "Epoch 657: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0116 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 658/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0109\n",
      "Epoch 658: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0109 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 659/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0108\n",
      "Epoch 659: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0108 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 660/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0114\n",
      "Epoch 660: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0114 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 661/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0107\n",
      "Epoch 661: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.0107 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 662/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0106\n",
      "Epoch 662: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0106 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 663/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0108\n",
      "Epoch 663: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0108 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 664/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0114\n",
      "Epoch 664: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0114 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 665/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0117\n",
      "Epoch 665: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0117 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 666/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0113\n",
      "Epoch 666: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0113 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 667/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0123\n",
      "Epoch 667: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.0124 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 668/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0114\n",
      "Epoch 668: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - loss: 0.0114 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 669/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0115\n",
      "Epoch 669: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0115 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 670/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0110\n",
      "Epoch 670: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0111 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 671/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0117\n",
      "Epoch 671: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0117 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 672/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0113\n",
      "Epoch 672: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0113 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 673/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0105\n",
      "Epoch 673: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0105 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 674/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0103\n",
      "Epoch 674: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0104 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 675/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0115\n",
      "Epoch 675: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0115 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 676/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0117\n",
      "Epoch 676: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0117 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 677/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0118\n",
      "Epoch 677: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0118 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 678/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0120\n",
      "Epoch 678: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0120 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 679/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0112\n",
      "Epoch 679: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0112 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 680/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0123\n",
      "Epoch 680: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0124 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 681/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0124\n",
      "Epoch 681: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - loss: 0.0124 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 682/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0117\n",
      "Epoch 682: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0118 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 683/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0119\n",
      "Epoch 683: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0119 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 684/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0117\n",
      "Epoch 684: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0117 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 685/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0116\n",
      "Epoch 685: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0116 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 686/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0111\n",
      "Epoch 686: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0111 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 687/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0103\n",
      "Epoch 687: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0103 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 688/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0107\n",
      "Epoch 688: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0107 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 689/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0104\n",
      "Epoch 689: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0105 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 690/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0107\n",
      "Epoch 690: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0107 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 691/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0105\n",
      "Epoch 691: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0105 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 692/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0107\n",
      "Epoch 692: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0107 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 693/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0096\n",
      "Epoch 693: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0097 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 694/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0103\n",
      "Epoch 694: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0103 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 695/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0103\n",
      "Epoch 695: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0103 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 696/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0113\n",
      "Epoch 696: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0113 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 697/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0110\n",
      "Epoch 697: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0110 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 698/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0108\n",
      "Epoch 698: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0109 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 699/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0115\n",
      "Epoch 699: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0115 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 700/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0112\n",
      "Epoch 700: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.0112 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 701/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0098\n",
      "Epoch 701: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0099 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 702/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0103\n",
      "Epoch 702: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0104 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 703/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0101\n",
      "Epoch 703: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0102 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 704/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0132\n",
      "Epoch 704: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0132 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 705/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0134\n",
      "Epoch 705: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0134 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 706/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0146\n",
      "Epoch 706: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0146 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 707/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0145\n",
      "Epoch 707: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0145 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 708/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0136\n",
      "Epoch 708: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0136 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 709/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0133\n",
      "Epoch 709: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0132 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 710/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0120\n",
      "Epoch 710: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - loss: 0.0119 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 711/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0103\n",
      "Epoch 711: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.0104 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 712/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0099\n",
      "Epoch 712: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0099 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 713/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0106\n",
      "Epoch 713: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0106 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 714/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0112\n",
      "Epoch 714: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0112 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 715/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0101\n",
      "Epoch 715: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0101 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 716/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0114\n",
      "Epoch 716: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0114 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 717/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0109\n",
      "Epoch 717: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0109 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 718/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0113\n",
      "Epoch 718: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0112 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 719/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0110\n",
      "Epoch 719: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0110 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 720/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0244\n",
      "Epoch 720: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0254 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 721/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0492\n",
      "Epoch 721: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0489 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 722/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0380\n",
      "Epoch 722: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0380 - val_loss: 0.0258 - learning_rate: 0.0010\n",
      "Epoch 723/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0311\n",
      "Epoch 723: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.0311 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 724/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0271\n",
      "Epoch 724: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0271 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 725/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0251\n",
      "Epoch 725: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0251 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 726/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0231\n",
      "Epoch 726: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0230 - val_loss: 0.0188 - learning_rate: 0.0010\n",
      "Epoch 727/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0203\n",
      "Epoch 727: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0202 - val_loss: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 728/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0187\n",
      "Epoch 728: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0188 - val_loss: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 729/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0193\n",
      "Epoch 729: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0194 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 730/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0187\n",
      "Epoch 730: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0188 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 731/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0181\n",
      "Epoch 731: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0180 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 732/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0170\n",
      "Epoch 732: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0170 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 733/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0161\n",
      "Epoch 733: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0162 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 734/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0155\n",
      "Epoch 734: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0155 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 735/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0150\n",
      "Epoch 735: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0150 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 736/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0160\n",
      "Epoch 736: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0160 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 737/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0151\n",
      "Epoch 737: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0152 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 738/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0154\n",
      "Epoch 738: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0154 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 739/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0151\n",
      "Epoch 739: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0151 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 740/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0131\n",
      "Epoch 740: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0132 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 741/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0130\n",
      "Epoch 741: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.0130 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 742/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0132\n",
      "Epoch 742: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0132 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 743/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0136\n",
      "Epoch 743: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0137 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 744/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0132\n",
      "Epoch 744: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0132 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 745/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0134\n",
      "Epoch 745: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0134 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 746/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0134\n",
      "Epoch 746: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0134 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 747/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0129\n",
      "Epoch 747: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0129 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 748/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0135\n",
      "Epoch 748: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - loss: 0.0135 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 749/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0134\n",
      "Epoch 749: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.0134 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 750/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0133\n",
      "Epoch 750: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0133 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 751/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0126\n",
      "Epoch 751: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - loss: 0.0126 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 752/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0128\n",
      "Epoch 752: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.0127 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 753/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0122\n",
      "Epoch 753: val_loss did not improve from 0.00968\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0123 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 753: early stopping\n",
      "Restoring model weights from the end of the best epoch: 653.\n",
      "EUA\n",
      "0.10844545484948745\n",
      "Oil\n",
      "0.19923812194998647\n",
      "Coal\n",
      "0.04692420044082688\n",
      "NG\n",
      "0.04087432144378874\n",
      "USEU\n",
      "0.12466947589594433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 180/180 [01:19<00:00,  2.26it/s]\n",
      "100%|| 180/180 [04:23<00:00,  1.47s/it]\n",
      "/home/honggeunjo/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 1.8464\n",
      "Epoch 1: val_loss improved from inf to 1.01917, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 245ms/step - loss: 1.8091 - val_loss: 1.0192 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.6164\n",
      "Epoch 2: val_loss improved from 1.01917 to 0.69021, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.6146 - val_loss: 0.6902 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.4980\n",
      "Epoch 3: val_loss improved from 0.69021 to 0.46175, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.4965 - val_loss: 0.4618 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.4377\n",
      "Epoch 4: val_loss improved from 0.46175 to 0.40051, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.4374 - val_loss: 0.4005 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.4171\n",
      "Epoch 5: val_loss improved from 0.40051 to 0.36355, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.4166 - val_loss: 0.3635 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.3989\n",
      "Epoch 6: val_loss improved from 0.36355 to 0.35343, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.3985 - val_loss: 0.3534 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.3829\n",
      "Epoch 7: val_loss improved from 0.35343 to 0.34954, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.3830 - val_loss: 0.3495 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.3802\n",
      "Epoch 8: val_loss did not improve from 0.34954\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.3799 - val_loss: 0.3523 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.3707\n",
      "Epoch 9: val_loss improved from 0.34954 to 0.33941, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.3705 - val_loss: 0.3394 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.3616\n",
      "Epoch 10: val_loss improved from 0.33941 to 0.33130, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.3616 - val_loss: 0.3313 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.3575\n",
      "Epoch 11: val_loss improved from 0.33130 to 0.32894, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.3572 - val_loss: 0.3289 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.3464\n",
      "Epoch 12: val_loss improved from 0.32894 to 0.31588, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.3464 - val_loss: 0.3159 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.3398\n",
      "Epoch 13: val_loss improved from 0.31588 to 0.31169, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.3397 - val_loss: 0.3117 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.3340\n",
      "Epoch 14: val_loss improved from 0.31169 to 0.31036, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.3338 - val_loss: 0.3104 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.3246\n",
      "Epoch 15: val_loss improved from 0.31036 to 0.30039, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.3245 - val_loss: 0.3004 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.3174\n",
      "Epoch 16: val_loss did not improve from 0.30039\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.3173 - val_loss: 0.3036 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.3108\n",
      "Epoch 17: val_loss improved from 0.30039 to 0.29738, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.3107 - val_loss: 0.2974 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.3051\n",
      "Epoch 18: val_loss improved from 0.29738 to 0.29470, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.3049 - val_loss: 0.2947 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.2984\n",
      "Epoch 19: val_loss improved from 0.29470 to 0.28667, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.2982 - val_loss: 0.2867 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.2924\n",
      "Epoch 20: val_loss improved from 0.28667 to 0.27666, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.2924 - val_loss: 0.2767 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.2836\n",
      "Epoch 21: val_loss did not improve from 0.27666\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.2836 - val_loss: 0.2769 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.2773\n",
      "Epoch 22: val_loss improved from 0.27666 to 0.26333, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.2773 - val_loss: 0.2633 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.2747\n",
      "Epoch 23: val_loss improved from 0.26333 to 0.25418, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.2746 - val_loss: 0.2542 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.2683\n",
      "Epoch 24: val_loss did not improve from 0.25418\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.2683 - val_loss: 0.2571 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.2636\n",
      "Epoch 25: val_loss improved from 0.25418 to 0.24858, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.2635 - val_loss: 0.2486 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.2562\n",
      "Epoch 26: val_loss improved from 0.24858 to 0.24379, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.2562 - val_loss: 0.2438 - learning_rate: 0.0010\n",
      "Epoch 27/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.2517\n",
      "Epoch 27: val_loss improved from 0.24379 to 0.23816, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.2516 - val_loss: 0.2382 - learning_rate: 0.0010\n",
      "Epoch 28/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.2470\n",
      "Epoch 28: val_loss did not improve from 0.23816\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.2469 - val_loss: 0.2408 - learning_rate: 0.0010\n",
      "Epoch 29/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.2413\n",
      "Epoch 29: val_loss improved from 0.23816 to 0.23668, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.2412 - val_loss: 0.2367 - learning_rate: 0.0010\n",
      "Epoch 30/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.2347\n",
      "Epoch 30: val_loss improved from 0.23668 to 0.22234, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.2346 - val_loss: 0.2223 - learning_rate: 0.0010\n",
      "Epoch 31/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.2302\n",
      "Epoch 31: val_loss improved from 0.22234 to 0.22013, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.2302 - val_loss: 0.2201 - learning_rate: 0.0010\n",
      "Epoch 32/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.2278\n",
      "Epoch 32: val_loss did not improve from 0.22013\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.2276 - val_loss: 0.2218 - learning_rate: 0.0010\n",
      "Epoch 33/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.2218\n",
      "Epoch 33: val_loss improved from 0.22013 to 0.21385, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.2218 - val_loss: 0.2138 - learning_rate: 0.0010\n",
      "Epoch 34/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.2175\n",
      "Epoch 34: val_loss improved from 0.21385 to 0.21355, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.2175 - val_loss: 0.2135 - learning_rate: 0.0010\n",
      "Epoch 35/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.2125\n",
      "Epoch 35: val_loss improved from 0.21355 to 0.21058, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.2125 - val_loss: 0.2106 - learning_rate: 0.0010\n",
      "Epoch 36/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.2100\n",
      "Epoch 36: val_loss improved from 0.21058 to 0.20030, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.2100 - val_loss: 0.2003 - learning_rate: 0.0010\n",
      "Epoch 37/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.2059\n",
      "Epoch 37: val_loss did not improve from 0.20030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.2059 - val_loss: 0.2037 - learning_rate: 0.0010\n",
      "Epoch 38/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.2043\n",
      "Epoch 38: val_loss improved from 0.20030 to 0.19410, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.2042 - val_loss: 0.1941 - learning_rate: 0.0010\n",
      "Epoch 39/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.1989\n",
      "Epoch 39: val_loss improved from 0.19410 to 0.19299, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.1988 - val_loss: 0.1930 - learning_rate: 0.0010\n",
      "Epoch 40/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.1934\n",
      "Epoch 40: val_loss improved from 0.19299 to 0.18652, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.1933 - val_loss: 0.1865 - learning_rate: 0.0010\n",
      "Epoch 41/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.1893\n",
      "Epoch 41: val_loss improved from 0.18652 to 0.18471, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.1892 - val_loss: 0.1847 - learning_rate: 0.0010\n",
      "Epoch 42/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.1845\n",
      "Epoch 42: val_loss improved from 0.18471 to 0.17817, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.1845 - val_loss: 0.1782 - learning_rate: 0.0010\n",
      "Epoch 43/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.1807\n",
      "Epoch 43: val_loss improved from 0.17817 to 0.17631, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.1807 - val_loss: 0.1763 - learning_rate: 0.0010\n",
      "Epoch 44/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.1794\n",
      "Epoch 44: val_loss improved from 0.17631 to 0.17386, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.1794 - val_loss: 0.1739 - learning_rate: 0.0010\n",
      "Epoch 45/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.1757\n",
      "Epoch 45: val_loss did not improve from 0.17386\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.1757 - val_loss: 0.1773 - learning_rate: 0.0010\n",
      "Epoch 46/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.1719\n",
      "Epoch 46: val_loss improved from 0.17386 to 0.16886, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.1719 - val_loss: 0.1689 - learning_rate: 0.0010\n",
      "Epoch 47/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.1703\n",
      "Epoch 47: val_loss improved from 0.16886 to 0.16395, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.1702 - val_loss: 0.1640 - learning_rate: 0.0010\n",
      "Epoch 48/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.1650\n",
      "Epoch 48: val_loss improved from 0.16395 to 0.15744, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.1650 - val_loss: 0.1574 - learning_rate: 0.0010\n",
      "Epoch 49/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.1642\n",
      "Epoch 49: val_loss did not improve from 0.15744\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.1642 - val_loss: 0.1601 - learning_rate: 0.0010\n",
      "Epoch 50/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.1599\n",
      "Epoch 50: val_loss improved from 0.15744 to 0.15285, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.1598 - val_loss: 0.1528 - learning_rate: 0.0010\n",
      "Epoch 51/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.1572\n",
      "Epoch 51: val_loss did not improve from 0.15285\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.1571 - val_loss: 0.1564 - learning_rate: 0.0010\n",
      "Epoch 52/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.1552\n",
      "Epoch 52: val_loss improved from 0.15285 to 0.14708, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.1551 - val_loss: 0.1471 - learning_rate: 0.0010\n",
      "Epoch 53/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.1524\n",
      "Epoch 53: val_loss did not improve from 0.14708\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.1524 - val_loss: 0.1543 - learning_rate: 0.0010\n",
      "Epoch 54/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.1481\n",
      "Epoch 54: val_loss did not improve from 0.14708\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.1482 - val_loss: 0.1483 - learning_rate: 0.0010\n",
      "Epoch 55/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.1478\n",
      "Epoch 55: val_loss improved from 0.14708 to 0.14277, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.1478 - val_loss: 0.1428 - learning_rate: 0.0010\n",
      "Epoch 56/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.1464\n",
      "Epoch 56: val_loss improved from 0.14277 to 0.14169, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.1463 - val_loss: 0.1417 - learning_rate: 0.0010\n",
      "Epoch 57/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.1426\n",
      "Epoch 57: val_loss did not improve from 0.14169\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.1426 - val_loss: 0.1430 - learning_rate: 0.0010\n",
      "Epoch 58/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.1388\n",
      "Epoch 58: val_loss improved from 0.14169 to 0.14124, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.1389 - val_loss: 0.1412 - learning_rate: 0.0010\n",
      "Epoch 59/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.1379\n",
      "Epoch 59: val_loss did not improve from 0.14124\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.1379 - val_loss: 0.1429 - learning_rate: 0.0010\n",
      "Epoch 60/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.1361\n",
      "Epoch 60: val_loss improved from 0.14124 to 0.13120, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.1361 - val_loss: 0.1312 - learning_rate: 0.0010\n",
      "Epoch 61/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.1350\n",
      "Epoch 61: val_loss did not improve from 0.13120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.1349 - val_loss: 0.1406 - learning_rate: 0.0010\n",
      "Epoch 62/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.1322\n",
      "Epoch 62: val_loss did not improve from 0.13120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.1322 - val_loss: 0.1323 - learning_rate: 0.0010\n",
      "Epoch 63/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.1293\n",
      "Epoch 63: val_loss improved from 0.13120 to 0.12622, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.1293 - val_loss: 0.1262 - learning_rate: 0.0010\n",
      "Epoch 64/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.1275\n",
      "Epoch 64: val_loss did not improve from 0.12622\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.1276 - val_loss: 0.1263 - learning_rate: 0.0010\n",
      "Epoch 65/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.1262\n",
      "Epoch 65: val_loss improved from 0.12622 to 0.12566, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.1261 - val_loss: 0.1257 - learning_rate: 0.0010\n",
      "Epoch 66/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.1239\n",
      "Epoch 66: val_loss improved from 0.12566 to 0.11960, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.1239 - val_loss: 0.1196 - learning_rate: 0.0010\n",
      "Epoch 67/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.1221\n",
      "Epoch 67: val_loss did not improve from 0.11960\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.1220 - val_loss: 0.1332 - learning_rate: 0.0010\n",
      "Epoch 68/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.1208\n",
      "Epoch 68: val_loss did not improve from 0.11960\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.1207 - val_loss: 0.1205 - learning_rate: 0.0010\n",
      "Epoch 69/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.1183\n",
      "Epoch 69: val_loss improved from 0.11960 to 0.11543, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.1183 - val_loss: 0.1154 - learning_rate: 0.0010\n",
      "Epoch 70/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.1159\n",
      "Epoch 70: val_loss did not improve from 0.11543\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.1159 - val_loss: 0.1191 - learning_rate: 0.0010\n",
      "Epoch 71/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.1149\n",
      "Epoch 71: val_loss did not improve from 0.11543\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.1150 - val_loss: 0.1174 - learning_rate: 0.0010\n",
      "Epoch 72/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.1158\n",
      "Epoch 72: val_loss improved from 0.11543 to 0.11331, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.1158 - val_loss: 0.1133 - learning_rate: 0.0010\n",
      "Epoch 73/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.1118\n",
      "Epoch 73: val_loss improved from 0.11331 to 0.11057, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.1118 - val_loss: 0.1106 - learning_rate: 0.0010\n",
      "Epoch 74/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.1114\n",
      "Epoch 74: val_loss did not improve from 0.11057\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.1115 - val_loss: 0.1155 - learning_rate: 0.0010\n",
      "Epoch 75/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.1111\n",
      "Epoch 75: val_loss did not improve from 0.11057\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.1110 - val_loss: 0.1138 - learning_rate: 0.0010\n",
      "Epoch 76/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.1072\n",
      "Epoch 76: val_loss did not improve from 0.11057\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.1072 - val_loss: 0.1159 - learning_rate: 0.0010\n",
      "Epoch 77/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.1061\n",
      "Epoch 77: val_loss improved from 0.11057 to 0.10959, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.1061 - val_loss: 0.1096 - learning_rate: 0.0010\n",
      "Epoch 78/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.1052\n",
      "Epoch 78: val_loss did not improve from 0.10959\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.1052 - val_loss: 0.1210 - learning_rate: 0.0010\n",
      "Epoch 79/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.1022\n",
      "Epoch 79: val_loss improved from 0.10959 to 0.10755, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.1023 - val_loss: 0.1075 - learning_rate: 0.0010\n",
      "Epoch 80/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.1013\n",
      "Epoch 80: val_loss did not improve from 0.10755\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.1013 - val_loss: 0.1087 - learning_rate: 0.0010\n",
      "Epoch 81/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0998\n",
      "Epoch 81: val_loss improved from 0.10755 to 0.09948, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0999 - val_loss: 0.0995 - learning_rate: 0.0010\n",
      "Epoch 82/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0995\n",
      "Epoch 82: val_loss did not improve from 0.09948\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0995 - val_loss: 0.1050 - learning_rate: 0.0010\n",
      "Epoch 83/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0989\n",
      "Epoch 83: val_loss improved from 0.09948 to 0.09920, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0989 - val_loss: 0.0992 - learning_rate: 0.0010\n",
      "Epoch 84/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0973\n",
      "Epoch 84: val_loss did not improve from 0.09920\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0973 - val_loss: 0.1007 - learning_rate: 0.0010\n",
      "Epoch 85/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0951\n",
      "Epoch 85: val_loss did not improve from 0.09920\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0951 - val_loss: 0.0998 - learning_rate: 0.0010\n",
      "Epoch 86/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0943\n",
      "Epoch 86: val_loss did not improve from 0.09920\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0944 - val_loss: 0.1067 - learning_rate: 0.0010\n",
      "Epoch 87/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0919\n",
      "Epoch 87: val_loss did not improve from 0.09920\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0919 - val_loss: 0.1017 - learning_rate: 0.0010\n",
      "Epoch 88/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0917\n",
      "Epoch 88: val_loss improved from 0.09920 to 0.09566, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0917 - val_loss: 0.0957 - learning_rate: 0.0010\n",
      "Epoch 89/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0917\n",
      "Epoch 89: val_loss did not improve from 0.09566\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0917 - val_loss: 0.1068 - learning_rate: 0.0010\n",
      "Epoch 90/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0909\n",
      "Epoch 90: val_loss improved from 0.09566 to 0.09484, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0909 - val_loss: 0.0948 - learning_rate: 0.0010\n",
      "Epoch 91/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0899\n",
      "Epoch 91: val_loss did not improve from 0.09484\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0899 - val_loss: 0.1022 - learning_rate: 0.0010\n",
      "Epoch 92/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0884\n",
      "Epoch 92: val_loss did not improve from 0.09484\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0884 - val_loss: 0.0951 - learning_rate: 0.0010\n",
      "Epoch 93/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0888\n",
      "Epoch 93: val_loss improved from 0.09484 to 0.08871, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0887 - val_loss: 0.0887 - learning_rate: 0.0010\n",
      "Epoch 94/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0870\n",
      "Epoch 94: val_loss did not improve from 0.08871\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0870 - val_loss: 0.0946 - learning_rate: 0.0010\n",
      "Epoch 95/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0854\n",
      "Epoch 95: val_loss improved from 0.08871 to 0.08582, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0854 - val_loss: 0.0858 - learning_rate: 0.0010\n",
      "Epoch 96/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0837\n",
      "Epoch 96: val_loss improved from 0.08582 to 0.08325, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0837 - val_loss: 0.0833 - learning_rate: 0.0010\n",
      "Epoch 97/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0822\n",
      "Epoch 97: val_loss improved from 0.08325 to 0.08277, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0822 - val_loss: 0.0828 - learning_rate: 0.0010\n",
      "Epoch 98/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0817\n",
      "Epoch 98: val_loss did not improve from 0.08277\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0818 - val_loss: 0.0865 - learning_rate: 0.0010\n",
      "Epoch 99/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0803\n",
      "Epoch 99: val_loss improved from 0.08277 to 0.08241, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0804 - val_loss: 0.0824 - learning_rate: 0.0010\n",
      "Epoch 100/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0800\n",
      "Epoch 100: val_loss improved from 0.08241 to 0.07820, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0801 - val_loss: 0.0782 - learning_rate: 0.0010\n",
      "Epoch 101/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0804\n",
      "Epoch 101: val_loss did not improve from 0.07820\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0804 - val_loss: 0.0841 - learning_rate: 0.0010\n",
      "Epoch 102/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0788\n",
      "Epoch 102: val_loss did not improve from 0.07820\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0789 - val_loss: 0.0830 - learning_rate: 0.0010\n",
      "Epoch 103/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0772\n",
      "Epoch 103: val_loss did not improve from 0.07820\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0773 - val_loss: 0.0856 - learning_rate: 0.0010\n",
      "Epoch 104/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0763\n",
      "Epoch 104: val_loss did not improve from 0.07820\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0764 - val_loss: 0.0890 - learning_rate: 0.0010\n",
      "Epoch 105/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0770\n",
      "Epoch 105: val_loss did not improve from 0.07820\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0769 - val_loss: 0.0823 - learning_rate: 0.0010\n",
      "Epoch 106/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0756\n",
      "Epoch 106: val_loss did not improve from 0.07820\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0757 - val_loss: 0.0827 - learning_rate: 0.0010\n",
      "Epoch 107/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0752\n",
      "Epoch 107: val_loss improved from 0.07820 to 0.07576, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0752 - val_loss: 0.0758 - learning_rate: 0.0010\n",
      "Epoch 108/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0754\n",
      "Epoch 108: val_loss improved from 0.07576 to 0.07570, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0754 - val_loss: 0.0757 - learning_rate: 0.0010\n",
      "Epoch 109/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0761\n",
      "Epoch 109: val_loss did not improve from 0.07570\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0761 - val_loss: 0.0835 - learning_rate: 0.0010\n",
      "Epoch 110/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0737\n",
      "Epoch 110: val_loss improved from 0.07570 to 0.07060, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0737 - val_loss: 0.0706 - learning_rate: 0.0010\n",
      "Epoch 111/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0728\n",
      "Epoch 111: val_loss did not improve from 0.07060\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0728 - val_loss: 0.0735 - learning_rate: 0.0010\n",
      "Epoch 112/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0714\n",
      "Epoch 112: val_loss did not improve from 0.07060\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0714 - val_loss: 0.0777 - learning_rate: 0.0010\n",
      "Epoch 113/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0710\n",
      "Epoch 113: val_loss improved from 0.07060 to 0.06862, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0709 - val_loss: 0.0686 - learning_rate: 0.0010\n",
      "Epoch 114/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0694\n",
      "Epoch 114: val_loss did not improve from 0.06862\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0695 - val_loss: 0.0691 - learning_rate: 0.0010\n",
      "Epoch 115/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0702\n",
      "Epoch 115: val_loss did not improve from 0.06862\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0702 - val_loss: 0.0725 - learning_rate: 0.0010\n",
      "Epoch 116/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0690\n",
      "Epoch 116: val_loss did not improve from 0.06862\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0690 - val_loss: 0.0724 - learning_rate: 0.0010\n",
      "Epoch 117/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0681\n",
      "Epoch 117: val_loss did not improve from 0.06862\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0682 - val_loss: 0.0749 - learning_rate: 0.0010\n",
      "Epoch 118/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0679\n",
      "Epoch 118: val_loss did not improve from 0.06862\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0679 - val_loss: 0.0731 - learning_rate: 0.0010\n",
      "Epoch 119/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0680\n",
      "Epoch 119: val_loss improved from 0.06862 to 0.06822, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0680 - val_loss: 0.0682 - learning_rate: 0.0010\n",
      "Epoch 120/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0663\n",
      "Epoch 120: val_loss improved from 0.06822 to 0.06580, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0664 - val_loss: 0.0658 - learning_rate: 0.0010\n",
      "Epoch 121/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0658\n",
      "Epoch 121: val_loss improved from 0.06580 to 0.06463, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0658 - val_loss: 0.0646 - learning_rate: 0.0010\n",
      "Epoch 122/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0643\n",
      "Epoch 122: val_loss did not improve from 0.06463\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0643 - val_loss: 0.0647 - learning_rate: 0.0010\n",
      "Epoch 123/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0627\n",
      "Epoch 123: val_loss did not improve from 0.06463\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.0627 - val_loss: 0.0676 - learning_rate: 0.0010\n",
      "Epoch 124/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0626\n",
      "Epoch 124: val_loss did not improve from 0.06463\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0626 - val_loss: 0.0671 - learning_rate: 0.0010\n",
      "Epoch 125/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0625\n",
      "Epoch 125: val_loss did not improve from 0.06463\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0625 - val_loss: 0.0648 - learning_rate: 0.0010\n",
      "Epoch 126/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0626\n",
      "Epoch 126: val_loss did not improve from 0.06463\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - loss: 0.0626 - val_loss: 0.0661 - learning_rate: 0.0010\n",
      "Epoch 127/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0616\n",
      "Epoch 127: val_loss improved from 0.06463 to 0.06328, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0616 - val_loss: 0.0633 - learning_rate: 0.0010\n",
      "Epoch 128/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0604\n",
      "Epoch 128: val_loss improved from 0.06328 to 0.06238, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0605 - val_loss: 0.0624 - learning_rate: 0.0010\n",
      "Epoch 129/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0598\n",
      "Epoch 129: val_loss did not improve from 0.06238\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0598 - val_loss: 0.0645 - learning_rate: 0.0010\n",
      "Epoch 130/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0592\n",
      "Epoch 130: val_loss did not improve from 0.06238\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - loss: 0.0592 - val_loss: 0.0667 - learning_rate: 0.0010\n",
      "Epoch 131/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0587\n",
      "Epoch 131: val_loss did not improve from 0.06238\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0587 - val_loss: 0.0646 - learning_rate: 0.0010\n",
      "Epoch 132/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0587\n",
      "Epoch 132: val_loss improved from 0.06238 to 0.06115, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0588 - val_loss: 0.0612 - learning_rate: 0.0010\n",
      "Epoch 133/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0585\n",
      "Epoch 133: val_loss improved from 0.06115 to 0.05859, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0585 - val_loss: 0.0586 - learning_rate: 0.0010\n",
      "Epoch 134/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0595\n",
      "Epoch 134: val_loss did not improve from 0.05859\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.0595 - val_loss: 0.0841 - learning_rate: 0.0010\n",
      "Epoch 135/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0588\n",
      "Epoch 135: val_loss did not improve from 0.05859\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0588 - val_loss: 0.0777 - learning_rate: 0.0010\n",
      "Epoch 136/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0569\n",
      "Epoch 136: val_loss did not improve from 0.05859\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0569 - val_loss: 0.0589 - learning_rate: 0.0010\n",
      "Epoch 137/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0572\n",
      "Epoch 137: val_loss improved from 0.05859 to 0.05698, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0572 - val_loss: 0.0570 - learning_rate: 0.0010\n",
      "Epoch 138/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0563\n",
      "Epoch 138: val_loss did not improve from 0.05698\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0564 - val_loss: 0.0640 - learning_rate: 0.0010\n",
      "Epoch 139/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0557\n",
      "Epoch 139: val_loss did not improve from 0.05698\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0557 - val_loss: 0.0686 - learning_rate: 0.0010\n",
      "Epoch 140/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0555\n",
      "Epoch 140: val_loss did not improve from 0.05698\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0555 - val_loss: 0.0588 - learning_rate: 0.0010\n",
      "Epoch 141/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0552\n",
      "Epoch 141: val_loss did not improve from 0.05698\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0552 - val_loss: 0.0633 - learning_rate: 0.0010\n",
      "Epoch 142/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0535\n",
      "Epoch 142: val_loss did not improve from 0.05698\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0536 - val_loss: 0.0604 - learning_rate: 0.0010\n",
      "Epoch 143/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0540\n",
      "Epoch 143: val_loss did not improve from 0.05698\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0540 - val_loss: 0.0593 - learning_rate: 0.0010\n",
      "Epoch 144/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0543\n",
      "Epoch 144: val_loss improved from 0.05698 to 0.05469, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0543 - val_loss: 0.0547 - learning_rate: 0.0010\n",
      "Epoch 145/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0535\n",
      "Epoch 145: val_loss did not improve from 0.05469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0535 - val_loss: 0.0656 - learning_rate: 0.0010\n",
      "Epoch 146/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0516\n",
      "Epoch 146: val_loss improved from 0.05469 to 0.05260, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0517 - val_loss: 0.0526 - learning_rate: 0.0010\n",
      "Epoch 147/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0519\n",
      "Epoch 147: val_loss did not improve from 0.05260\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0519 - val_loss: 0.0634 - learning_rate: 0.0010\n",
      "Epoch 148/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0514\n",
      "Epoch 148: val_loss did not improve from 0.05260\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0515 - val_loss: 0.0546 - learning_rate: 0.0010\n",
      "Epoch 149/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0514\n",
      "Epoch 149: val_loss did not improve from 0.05260\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0513 - val_loss: 0.0609 - learning_rate: 0.0010\n",
      "Epoch 150/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0512\n",
      "Epoch 150: val_loss did not improve from 0.05260\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0512 - val_loss: 0.0714 - learning_rate: 0.0010\n",
      "Epoch 151/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0503\n",
      "Epoch 151: val_loss did not improve from 0.05260\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0503 - val_loss: 0.0577 - learning_rate: 0.0010\n",
      "Epoch 152/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0497\n",
      "Epoch 152: val_loss improved from 0.05260 to 0.05253, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0497 - val_loss: 0.0525 - learning_rate: 0.0010\n",
      "Epoch 153/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0493\n",
      "Epoch 153: val_loss did not improve from 0.05253\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0493 - val_loss: 0.0645 - learning_rate: 0.0010\n",
      "Epoch 154/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0495\n",
      "Epoch 154: val_loss did not improve from 0.05253\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0495 - val_loss: 0.0534 - learning_rate: 0.0010\n",
      "Epoch 155/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0495\n",
      "Epoch 155: val_loss improved from 0.05253 to 0.05067, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0495 - val_loss: 0.0507 - learning_rate: 0.0010\n",
      "Epoch 156/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0480\n",
      "Epoch 156: val_loss improved from 0.05067 to 0.04702, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0481 - val_loss: 0.0470 - learning_rate: 0.0010\n",
      "Epoch 157/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0490\n",
      "Epoch 157: val_loss did not improve from 0.04702\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0490 - val_loss: 0.0508 - learning_rate: 0.0010\n",
      "Epoch 158/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0482\n",
      "Epoch 158: val_loss did not improve from 0.04702\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0483 - val_loss: 0.0565 - learning_rate: 0.0010\n",
      "Epoch 159/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0477\n",
      "Epoch 159: val_loss did not improve from 0.04702\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0477 - val_loss: 0.0591 - learning_rate: 0.0010\n",
      "Epoch 160/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0479\n",
      "Epoch 160: val_loss did not improve from 0.04702\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0479 - val_loss: 0.0516 - learning_rate: 0.0010\n",
      "Epoch 161/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0482\n",
      "Epoch 161: val_loss did not improve from 0.04702\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0482 - val_loss: 0.0499 - learning_rate: 0.0010\n",
      "Epoch 162/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0467\n",
      "Epoch 162: val_loss did not improve from 0.04702\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0467 - val_loss: 0.0641 - learning_rate: 0.0010\n",
      "Epoch 163/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0452\n",
      "Epoch 163: val_loss did not improve from 0.04702\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0452 - val_loss: 0.0491 - learning_rate: 0.0010\n",
      "Epoch 164/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0446\n",
      "Epoch 164: val_loss did not improve from 0.04702\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0446 - val_loss: 0.0512 - learning_rate: 0.0010\n",
      "Epoch 165/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0454\n",
      "Epoch 165: val_loss did not improve from 0.04702\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0454 - val_loss: 0.0626 - learning_rate: 0.0010\n",
      "Epoch 166/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0472\n",
      "Epoch 166: val_loss did not improve from 0.04702\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0472 - val_loss: 0.0484 - learning_rate: 0.0010\n",
      "Epoch 167/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0457\n",
      "Epoch 167: val_loss improved from 0.04702 to 0.04497, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0457 - val_loss: 0.0450 - learning_rate: 0.0010\n",
      "Epoch 168/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0454\n",
      "Epoch 168: val_loss did not improve from 0.04497\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0454 - val_loss: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 169/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0443\n",
      "Epoch 169: val_loss did not improve from 0.04497\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0444 - val_loss: 0.0517 - learning_rate: 0.0010\n",
      "Epoch 170/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0435\n",
      "Epoch 170: val_loss improved from 0.04497 to 0.04304, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0435 - val_loss: 0.0430 - learning_rate: 0.0010\n",
      "Epoch 171/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0428\n",
      "Epoch 171: val_loss did not improve from 0.04304\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.0428 - val_loss: 0.0457 - learning_rate: 0.0010\n",
      "Epoch 172/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0433\n",
      "Epoch 172: val_loss did not improve from 0.04304\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0434 - val_loss: 0.0452 - learning_rate: 0.0010\n",
      "Epoch 173/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0429\n",
      "Epoch 173: val_loss did not improve from 0.04304\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0430 - val_loss: 0.0475 - learning_rate: 0.0010\n",
      "Epoch 174/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0420\n",
      "Epoch 174: val_loss improved from 0.04304 to 0.04205, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0420 - val_loss: 0.0420 - learning_rate: 0.0010\n",
      "Epoch 175/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0421\n",
      "Epoch 175: val_loss did not improve from 0.04205\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.0421 - val_loss: 0.0449 - learning_rate: 0.0010\n",
      "Epoch 176/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0418\n",
      "Epoch 176: val_loss did not improve from 0.04205\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0418 - val_loss: 0.0433 - learning_rate: 0.0010\n",
      "Epoch 177/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0414\n",
      "Epoch 177: val_loss did not improve from 0.04205\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0413 - val_loss: 0.0488 - learning_rate: 0.0010\n",
      "Epoch 178/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0415\n",
      "Epoch 178: val_loss did not improve from 0.04205\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0416 - val_loss: 0.0491 - learning_rate: 0.0010\n",
      "Epoch 179/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0408\n",
      "Epoch 179: val_loss did not improve from 0.04205\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0408 - val_loss: 0.0444 - learning_rate: 0.0010\n",
      "Epoch 180/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0413\n",
      "Epoch 180: val_loss did not improve from 0.04205\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0413 - val_loss: 0.0468 - learning_rate: 0.0010\n",
      "Epoch 181/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0404\n",
      "Epoch 181: val_loss did not improve from 0.04205\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0404 - val_loss: 0.0517 - learning_rate: 0.0010\n",
      "Epoch 182/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0393\n",
      "Epoch 182: val_loss did not improve from 0.04205\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0394 - val_loss: 0.0487 - learning_rate: 0.0010\n",
      "Epoch 183/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0397\n",
      "Epoch 183: val_loss did not improve from 0.04205\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0398 - val_loss: 0.0429 - learning_rate: 0.0010\n",
      "Epoch 184/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0394\n",
      "Epoch 184: val_loss improved from 0.04205 to 0.04056, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0394 - val_loss: 0.0406 - learning_rate: 0.0010\n",
      "Epoch 185/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0394\n",
      "Epoch 185: val_loss did not improve from 0.04056\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0394 - val_loss: 0.0457 - learning_rate: 0.0010\n",
      "Epoch 186/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0394\n",
      "Epoch 186: val_loss did not improve from 0.04056\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0394 - val_loss: 0.0492 - learning_rate: 0.0010\n",
      "Epoch 187/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0396\n",
      "Epoch 187: val_loss did not improve from 0.04056\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0397 - val_loss: 0.0426 - learning_rate: 0.0010\n",
      "Epoch 188/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0376\n",
      "Epoch 188: val_loss did not improve from 0.04056\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0376 - val_loss: 0.0429 - learning_rate: 0.0010\n",
      "Epoch 189/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0385\n",
      "Epoch 189: val_loss did not improve from 0.04056\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0385 - val_loss: 0.0454 - learning_rate: 0.0010\n",
      "Epoch 190/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0386\n",
      "Epoch 190: val_loss did not improve from 0.04056\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0387 - val_loss: 0.0482 - learning_rate: 0.0010\n",
      "Epoch 191/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0385\n",
      "Epoch 191: val_loss did not improve from 0.04056\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0385 - val_loss: 0.0475 - learning_rate: 0.0010\n",
      "Epoch 192/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0376\n",
      "Epoch 192: val_loss did not improve from 0.04056\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0376 - val_loss: 0.0406 - learning_rate: 0.0010\n",
      "Epoch 193/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0376\n",
      "Epoch 193: val_loss improved from 0.04056 to 0.03737, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0376 - val_loss: 0.0374 - learning_rate: 0.0010\n",
      "Epoch 194/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0363\n",
      "Epoch 194: val_loss did not improve from 0.03737\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0362 - val_loss: 0.0490 - learning_rate: 0.0010\n",
      "Epoch 195/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0363\n",
      "Epoch 195: val_loss did not improve from 0.03737\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0363 - val_loss: 0.0494 - learning_rate: 0.0010\n",
      "Epoch 196/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0378\n",
      "Epoch 196: val_loss improved from 0.03737 to 0.03669, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0377 - val_loss: 0.0367 - learning_rate: 0.0010\n",
      "Epoch 197/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0379\n",
      "Epoch 197: val_loss did not improve from 0.03669\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0378 - val_loss: 0.0421 - learning_rate: 0.0010\n",
      "Epoch 198/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0356\n",
      "Epoch 198: val_loss did not improve from 0.03669\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0356 - val_loss: 0.0421 - learning_rate: 0.0010\n",
      "Epoch 199/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0359\n",
      "Epoch 199: val_loss did not improve from 0.03669\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0358 - val_loss: 0.0473 - learning_rate: 0.0010\n",
      "Epoch 200/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0352\n",
      "Epoch 200: val_loss did not improve from 0.03669\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0353 - val_loss: 0.0409 - learning_rate: 0.0010\n",
      "Epoch 201/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0351\n",
      "Epoch 201: val_loss did not improve from 0.03669\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0351 - val_loss: 0.0464 - learning_rate: 0.0010\n",
      "Epoch 202/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0345\n",
      "Epoch 202: val_loss did not improve from 0.03669\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0345 - val_loss: 0.0440 - learning_rate: 0.0010\n",
      "Epoch 203/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0353\n",
      "Epoch 203: val_loss did not improve from 0.03669\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0353 - val_loss: 0.0388 - learning_rate: 0.0010\n",
      "Epoch 204/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0352\n",
      "Epoch 204: val_loss did not improve from 0.03669\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0352 - val_loss: 0.0400 - learning_rate: 0.0010\n",
      "Epoch 205/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0344\n",
      "Epoch 205: val_loss did not improve from 0.03669\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0344 - val_loss: 0.0430 - learning_rate: 0.0010\n",
      "Epoch 206/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0343\n",
      "Epoch 206: val_loss did not improve from 0.03669\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0343 - val_loss: 0.0445 - learning_rate: 0.0010\n",
      "Epoch 207/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0340\n",
      "Epoch 207: val_loss did not improve from 0.03669\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0340 - val_loss: 0.0450 - learning_rate: 0.0010\n",
      "Epoch 208/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0349\n",
      "Epoch 208: val_loss did not improve from 0.03669\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0349 - val_loss: 0.0401 - learning_rate: 0.0010\n",
      "Epoch 209/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0324\n",
      "Epoch 209: val_loss improved from 0.03669 to 0.03504, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0325 - val_loss: 0.0350 - learning_rate: 0.0010\n",
      "Epoch 210/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0325\n",
      "Epoch 210: val_loss did not improve from 0.03504\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0326 - val_loss: 0.0426 - learning_rate: 0.0010\n",
      "Epoch 211/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0330\n",
      "Epoch 211: val_loss did not improve from 0.03504\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0330 - val_loss: 0.0384 - learning_rate: 0.0010\n",
      "Epoch 212/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0321\n",
      "Epoch 212: val_loss did not improve from 0.03504\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0322 - val_loss: 0.0393 - learning_rate: 0.0010\n",
      "Epoch 213/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0318\n",
      "Epoch 213: val_loss did not improve from 0.03504\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0318 - val_loss: 0.0362 - learning_rate: 0.0010\n",
      "Epoch 214/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0321\n",
      "Epoch 214: val_loss did not improve from 0.03504\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0321 - val_loss: 0.0383 - learning_rate: 0.0010\n",
      "Epoch 215/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0316\n",
      "Epoch 215: val_loss did not improve from 0.03504\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0317 - val_loss: 0.0418 - learning_rate: 0.0010\n",
      "Epoch 216/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0325\n",
      "Epoch 216: val_loss did not improve from 0.03504\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0325 - val_loss: 0.0372 - learning_rate: 0.0010\n",
      "Epoch 217/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0307\n",
      "Epoch 217: val_loss did not improve from 0.03504\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0308 - val_loss: 0.0458 - learning_rate: 0.0010\n",
      "Epoch 218/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0315\n",
      "Epoch 218: val_loss did not improve from 0.03504\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0316 - val_loss: 0.0370 - learning_rate: 0.0010\n",
      "Epoch 219/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0317\n",
      "Epoch 219: val_loss improved from 0.03504 to 0.03349, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0317 - val_loss: 0.0335 - learning_rate: 0.0010\n",
      "Epoch 220/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0313\n",
      "Epoch 220: val_loss did not improve from 0.03349\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0314 - val_loss: 0.0383 - learning_rate: 0.0010\n",
      "Epoch 221/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0312\n",
      "Epoch 221: val_loss did not improve from 0.03349\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0312 - val_loss: 0.0383 - learning_rate: 0.0010\n",
      "Epoch 222/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0308\n",
      "Epoch 222: val_loss did not improve from 0.03349\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0308 - val_loss: 0.0399 - learning_rate: 0.0010\n",
      "Epoch 223/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0304\n",
      "Epoch 223: val_loss did not improve from 0.03349\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0304 - val_loss: 0.0374 - learning_rate: 0.0010\n",
      "Epoch 224/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0305\n",
      "Epoch 224: val_loss did not improve from 0.03349\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0306 - val_loss: 0.0428 - learning_rate: 0.0010\n",
      "Epoch 225/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0302\n",
      "Epoch 225: val_loss improved from 0.03349 to 0.03322, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0302 - val_loss: 0.0332 - learning_rate: 0.0010\n",
      "Epoch 226/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0298\n",
      "Epoch 226: val_loss did not improve from 0.03322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0298 - val_loss: 0.0378 - learning_rate: 0.0010\n",
      "Epoch 227/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0299\n",
      "Epoch 227: val_loss did not improve from 0.03322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0300 - val_loss: 0.0376 - learning_rate: 0.0010\n",
      "Epoch 228/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0297\n",
      "Epoch 228: val_loss did not improve from 0.03322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0297 - val_loss: 0.0367 - learning_rate: 0.0010\n",
      "Epoch 229/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0290\n",
      "Epoch 229: val_loss improved from 0.03322 to 0.03259, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0291 - val_loss: 0.0326 - learning_rate: 0.0010\n",
      "Epoch 230/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0306\n",
      "Epoch 230: val_loss did not improve from 0.03259\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0306 - val_loss: 0.0358 - learning_rate: 0.0010\n",
      "Epoch 231/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0302\n",
      "Epoch 231: val_loss did not improve from 0.03259\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0302 - val_loss: 0.0390 - learning_rate: 0.0010\n",
      "Epoch 232/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0296\n",
      "Epoch 232: val_loss did not improve from 0.03259\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0296 - val_loss: 0.0411 - learning_rate: 0.0010\n",
      "Epoch 233/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0290\n",
      "Epoch 233: val_loss did not improve from 0.03259\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0290 - val_loss: 0.0329 - learning_rate: 0.0010\n",
      "Epoch 234/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0282\n",
      "Epoch 234: val_loss improved from 0.03259 to 0.03153, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0282 - val_loss: 0.0315 - learning_rate: 0.0010\n",
      "Epoch 235/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0277\n",
      "Epoch 235: val_loss did not improve from 0.03153\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0277 - val_loss: 0.0442 - learning_rate: 0.0010\n",
      "Epoch 236/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0272\n",
      "Epoch 236: val_loss improved from 0.03153 to 0.03133, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0273 - val_loss: 0.0313 - learning_rate: 0.0010\n",
      "Epoch 237/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0276\n",
      "Epoch 237: val_loss did not improve from 0.03133\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0277 - val_loss: 0.0325 - learning_rate: 0.0010\n",
      "Epoch 238/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0288\n",
      "Epoch 238: val_loss did not improve from 0.03133\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0287 - val_loss: 0.0332 - learning_rate: 0.0010\n",
      "Epoch 239/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0283\n",
      "Epoch 239: val_loss improved from 0.03133 to 0.02844, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0284 - val_loss: 0.0284 - learning_rate: 0.0010\n",
      "Epoch 240/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0289\n",
      "Epoch 240: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0289 - val_loss: 0.0399 - learning_rate: 0.0010\n",
      "Epoch 241/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0286\n",
      "Epoch 241: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0286 - val_loss: 0.0545 - learning_rate: 0.0010\n",
      "Epoch 242/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0284\n",
      "Epoch 242: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0284 - val_loss: 0.0331 - learning_rate: 0.0010\n",
      "Epoch 243/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0280\n",
      "Epoch 243: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0280 - val_loss: 0.0375 - learning_rate: 0.0010\n",
      "Epoch 244/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0275\n",
      "Epoch 244: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0275 - val_loss: 0.0388 - learning_rate: 0.0010\n",
      "Epoch 245/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0278\n",
      "Epoch 245: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0278 - val_loss: 0.0329 - learning_rate: 0.0010\n",
      "Epoch 246/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0272\n",
      "Epoch 246: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0273 - val_loss: 0.0321 - learning_rate: 0.0010\n",
      "Epoch 247/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0289\n",
      "Epoch 247: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0289 - val_loss: 0.0358 - learning_rate: 0.0010\n",
      "Epoch 248/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0275\n",
      "Epoch 248: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0275 - val_loss: 0.0296 - learning_rate: 0.0010\n",
      "Epoch 249/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0267\n",
      "Epoch 249: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0267 - val_loss: 0.0366 - learning_rate: 0.0010\n",
      "Epoch 250/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0261\n",
      "Epoch 250: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.0262 - val_loss: 0.0352 - learning_rate: 0.0010\n",
      "Epoch 251/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0265\n",
      "Epoch 251: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0265 - val_loss: 0.0335 - learning_rate: 0.0010\n",
      "Epoch 252/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0250\n",
      "Epoch 252: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0251 - val_loss: 0.0311 - learning_rate: 0.0010\n",
      "Epoch 253/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0256\n",
      "Epoch 253: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0256 - val_loss: 0.0321 - learning_rate: 0.0010\n",
      "Epoch 254/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0257\n",
      "Epoch 254: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0257 - val_loss: 0.0388 - learning_rate: 0.0010\n",
      "Epoch 255/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0251\n",
      "Epoch 255: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0251 - val_loss: 0.0335 - learning_rate: 0.0010\n",
      "Epoch 256/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0267\n",
      "Epoch 256: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0267 - val_loss: 0.0334 - learning_rate: 0.0010\n",
      "Epoch 257/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0261\n",
      "Epoch 257: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0261 - val_loss: 0.0297 - learning_rate: 0.0010\n",
      "Epoch 258/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0253\n",
      "Epoch 258: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0253 - val_loss: 0.0298 - learning_rate: 0.0010\n",
      "Epoch 259/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0252\n",
      "Epoch 259: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0252 - val_loss: 0.0287 - learning_rate: 0.0010\n",
      "Epoch 260/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0245\n",
      "Epoch 260: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0246 - val_loss: 0.0364 - learning_rate: 0.0010\n",
      "Epoch 261/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0251\n",
      "Epoch 261: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0251 - val_loss: 0.0458 - learning_rate: 0.0010\n",
      "Epoch 262/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0263\n",
      "Epoch 262: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0263 - val_loss: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 263/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0242\n",
      "Epoch 263: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - loss: 0.0243 - val_loss: 0.0308 - learning_rate: 0.0010\n",
      "Epoch 264/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0238\n",
      "Epoch 264: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0238 - val_loss: 0.0312 - learning_rate: 0.0010\n",
      "Epoch 265/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0244\n",
      "Epoch 265: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0244 - val_loss: 0.0314 - learning_rate: 0.0010\n",
      "Epoch 266/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0250\n",
      "Epoch 266: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0250 - val_loss: 0.0354 - learning_rate: 0.0010\n",
      "Epoch 267/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0249\n",
      "Epoch 267: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0249 - val_loss: 0.0322 - learning_rate: 0.0010\n",
      "Epoch 268/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0251\n",
      "Epoch 268: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0251 - val_loss: 0.0393 - learning_rate: 0.0010\n",
      "Epoch 269/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0246\n",
      "Epoch 269: val_loss did not improve from 0.02844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0246 - val_loss: 0.0419 - learning_rate: 0.0010\n",
      "Epoch 270/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0243\n",
      "Epoch 270: val_loss improved from 0.02844 to 0.02811, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0243 - val_loss: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 271/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0236\n",
      "Epoch 271: val_loss did not improve from 0.02811\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - loss: 0.0236 - val_loss: 0.0289 - learning_rate: 0.0010\n",
      "Epoch 272/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0233\n",
      "Epoch 272: val_loss did not improve from 0.02811\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0233 - val_loss: 0.0316 - learning_rate: 0.0010\n",
      "Epoch 273/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0237\n",
      "Epoch 273: val_loss did not improve from 0.02811\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0238 - val_loss: 0.0294 - learning_rate: 0.0010\n",
      "Epoch 274/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0243\n",
      "Epoch 274: val_loss did not improve from 0.02811\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0244 - val_loss: 0.0340 - learning_rate: 0.0010\n",
      "Epoch 275/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0247\n",
      "Epoch 275: val_loss did not improve from 0.02811\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0246 - val_loss: 0.0327 - learning_rate: 0.0010\n",
      "Epoch 276/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0239\n",
      "Epoch 276: val_loss did not improve from 0.02811\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0240 - val_loss: 0.0387 - learning_rate: 0.0010\n",
      "Epoch 277/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0243\n",
      "Epoch 277: val_loss did not improve from 0.02811\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0244 - val_loss: 0.0341 - learning_rate: 0.0010\n",
      "Epoch 278/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0252\n",
      "Epoch 278: val_loss did not improve from 0.02811\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0252 - val_loss: 0.0316 - learning_rate: 0.0010\n",
      "Epoch 279/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0231\n",
      "Epoch 279: val_loss improved from 0.02811 to 0.02802, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0231 - val_loss: 0.0280 - learning_rate: 0.0010\n",
      "Epoch 280/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0232\n",
      "Epoch 280: val_loss improved from 0.02802 to 0.02753, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0232 - val_loss: 0.0275 - learning_rate: 0.0010\n",
      "Epoch 281/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0235\n",
      "Epoch 281: val_loss improved from 0.02753 to 0.02482, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0236 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 282/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0249\n",
      "Epoch 282: val_loss did not improve from 0.02482\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0251 - val_loss: 0.0317 - learning_rate: 0.0010\n",
      "Epoch 283/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0288\n",
      "Epoch 283: val_loss did not improve from 0.02482\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0287 - val_loss: 0.0466 - learning_rate: 0.0010\n",
      "Epoch 284/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0255\n",
      "Epoch 284: val_loss did not improve from 0.02482\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0254 - val_loss: 0.0269 - learning_rate: 0.0010\n",
      "Epoch 285/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0237\n",
      "Epoch 285: val_loss did not improve from 0.02482\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0237 - val_loss: 0.0299 - learning_rate: 0.0010\n",
      "Epoch 286/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0227\n",
      "Epoch 286: val_loss did not improve from 0.02482\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0227 - val_loss: 0.0333 - learning_rate: 0.0010\n",
      "Epoch 287/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0231\n",
      "Epoch 287: val_loss did not improve from 0.02482\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0231 - val_loss: 0.0334 - learning_rate: 0.0010\n",
      "Epoch 288/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0219\n",
      "Epoch 288: val_loss did not improve from 0.02482\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0219 - val_loss: 0.0310 - learning_rate: 0.0010\n",
      "Epoch 289/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0218\n",
      "Epoch 289: val_loss did not improve from 0.02482\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0218 - val_loss: 0.0292 - learning_rate: 0.0010\n",
      "Epoch 290/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0214\n",
      "Epoch 290: val_loss did not improve from 0.02482\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0214 - val_loss: 0.0360 - learning_rate: 0.0010\n",
      "Epoch 291/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0215\n",
      "Epoch 291: val_loss did not improve from 0.02482\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0215 - val_loss: 0.0292 - learning_rate: 0.0010\n",
      "Epoch 292/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0216\n",
      "Epoch 292: val_loss did not improve from 0.02482\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 145ms/step - loss: 0.0216 - val_loss: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 293/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0221\n",
      "Epoch 293: val_loss did not improve from 0.02482\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0221 - val_loss: 0.0273 - learning_rate: 0.0010\n",
      "Epoch 294/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0215\n",
      "Epoch 294: val_loss improved from 0.02482 to 0.02339, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0215 - val_loss: 0.0234 - learning_rate: 0.0010\n",
      "Epoch 295/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0205\n",
      "Epoch 295: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0205 - val_loss: 0.0290 - learning_rate: 0.0010\n",
      "Epoch 296/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0211\n",
      "Epoch 296: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0212 - val_loss: 0.0278 - learning_rate: 0.0010\n",
      "Epoch 297/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0218\n",
      "Epoch 297: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0218 - val_loss: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 298/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0225\n",
      "Epoch 298: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0225 - val_loss: 0.0318 - learning_rate: 0.0010\n",
      "Epoch 299/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0218\n",
      "Epoch 299: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0218 - val_loss: 0.0312 - learning_rate: 0.0010\n",
      "Epoch 300/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0218\n",
      "Epoch 300: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0218 - val_loss: 0.0342 - learning_rate: 0.0010\n",
      "Epoch 301/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0201\n",
      "Epoch 301: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0201 - val_loss: 0.0272 - learning_rate: 0.0010\n",
      "Epoch 302/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0218\n",
      "Epoch 302: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0218 - val_loss: 0.0311 - learning_rate: 0.0010\n",
      "Epoch 303/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0216\n",
      "Epoch 303: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0217 - val_loss: 0.0343 - learning_rate: 0.0010\n",
      "Epoch 304/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0206\n",
      "Epoch 304: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0207 - val_loss: 0.0266 - learning_rate: 0.0010\n",
      "Epoch 305/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0203\n",
      "Epoch 305: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - loss: 0.0203 - val_loss: 0.0274 - learning_rate: 0.0010\n",
      "Epoch 306/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0204\n",
      "Epoch 306: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0203 - val_loss: 0.0316 - learning_rate: 0.0010\n",
      "Epoch 307/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0205\n",
      "Epoch 307: val_loss did not improve from 0.02339\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0204 - val_loss: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 308/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0198\n",
      "Epoch 308: val_loss improved from 0.02339 to 0.02257, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0198 - val_loss: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 309/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0208\n",
      "Epoch 309: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0208 - val_loss: 0.0258 - learning_rate: 0.0010\n",
      "Epoch 310/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0203\n",
      "Epoch 310: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0203 - val_loss: 0.0275 - learning_rate: 0.0010\n",
      "Epoch 311/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0206\n",
      "Epoch 311: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0206 - val_loss: 0.0264 - learning_rate: 0.0010\n",
      "Epoch 312/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0212\n",
      "Epoch 312: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0213 - val_loss: 0.0256 - learning_rate: 0.0010\n",
      "Epoch 313/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0220\n",
      "Epoch 313: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0220 - val_loss: 0.0235 - learning_rate: 0.0010\n",
      "Epoch 314/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0207\n",
      "Epoch 314: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0207 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 315/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0195\n",
      "Epoch 315: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0195 - val_loss: 0.0328 - learning_rate: 0.0010\n",
      "Epoch 316/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0193\n",
      "Epoch 316: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0193 - val_loss: 0.0277 - learning_rate: 0.0010\n",
      "Epoch 317/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0201\n",
      "Epoch 317: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0201 - val_loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 318/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0201\n",
      "Epoch 318: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0201 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 319/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0201\n",
      "Epoch 319: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0201 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 320/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0189\n",
      "Epoch 320: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0189 - val_loss: 0.0310 - learning_rate: 0.0010\n",
      "Epoch 321/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0198\n",
      "Epoch 321: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0198 - val_loss: 0.0268 - learning_rate: 0.0010\n",
      "Epoch 322/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0181\n",
      "Epoch 322: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0181 - val_loss: 0.0286 - learning_rate: 0.0010\n",
      "Epoch 323/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0182\n",
      "Epoch 323: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - loss: 0.0182 - val_loss: 0.0340 - learning_rate: 0.0010\n",
      "Epoch 324/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0190\n",
      "Epoch 324: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0190 - val_loss: 0.0270 - learning_rate: 0.0010\n",
      "Epoch 325/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0182\n",
      "Epoch 325: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0182 - val_loss: 0.0234 - learning_rate: 0.0010\n",
      "Epoch 326/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0192\n",
      "Epoch 326: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0192 - val_loss: 0.0326 - learning_rate: 0.0010\n",
      "Epoch 327/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0182\n",
      "Epoch 327: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0182 - val_loss: 0.0328 - learning_rate: 0.0010\n",
      "Epoch 328/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0173\n",
      "Epoch 328: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0174 - val_loss: 0.0251 - learning_rate: 0.0010\n",
      "Epoch 329/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0185\n",
      "Epoch 329: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.0185 - val_loss: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 330/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0193\n",
      "Epoch 330: val_loss did not improve from 0.02257\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.0193 - val_loss: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 331/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0196\n",
      "Epoch 331: val_loss improved from 0.02257 to 0.02256, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0196 - val_loss: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 332/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0200\n",
      "Epoch 332: val_loss did not improve from 0.02256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0200 - val_loss: 0.0259 - learning_rate: 0.0010\n",
      "Epoch 333/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0184\n",
      "Epoch 333: val_loss did not improve from 0.02256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0184 - val_loss: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 334/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0185\n",
      "Epoch 334: val_loss did not improve from 0.02256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0186 - val_loss: 0.0305 - learning_rate: 0.0010\n",
      "Epoch 335/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0207\n",
      "Epoch 335: val_loss did not improve from 0.02256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0207 - val_loss: 0.0303 - learning_rate: 0.0010\n",
      "Epoch 336/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0203\n",
      "Epoch 336: val_loss improved from 0.02256 to 0.02028, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0203 - val_loss: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 337/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0189\n",
      "Epoch 337: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0189 - val_loss: 0.0267 - learning_rate: 0.0010\n",
      "Epoch 338/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0195\n",
      "Epoch 338: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0195 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 339/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0209\n",
      "Epoch 339: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0209 - val_loss: 0.0277 - learning_rate: 0.0010\n",
      "Epoch 340/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0198\n",
      "Epoch 340: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0198 - val_loss: 0.0257 - learning_rate: 0.0010\n",
      "Epoch 341/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0191\n",
      "Epoch 341: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0191 - val_loss: 0.0275 - learning_rate: 0.0010\n",
      "Epoch 342/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0191\n",
      "Epoch 342: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0191 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 343/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0181\n",
      "Epoch 343: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0181 - val_loss: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 344/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0186\n",
      "Epoch 344: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.0186 - val_loss: 0.0343 - learning_rate: 0.0010\n",
      "Epoch 345/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0181\n",
      "Epoch 345: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0181 - val_loss: 0.0296 - learning_rate: 0.0010\n",
      "Epoch 346/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0176\n",
      "Epoch 346: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0176 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 347/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0180\n",
      "Epoch 347: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0180 - val_loss: 0.0262 - learning_rate: 0.0010\n",
      "Epoch 348/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0174\n",
      "Epoch 348: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0175 - val_loss: 0.0252 - learning_rate: 0.0010\n",
      "Epoch 349/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0173\n",
      "Epoch 349: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0173 - val_loss: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 350/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0165\n",
      "Epoch 350: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0165 - val_loss: 0.0303 - learning_rate: 0.0010\n",
      "Epoch 351/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0174\n",
      "Epoch 351: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0174 - val_loss: 0.0290 - learning_rate: 0.0010\n",
      "Epoch 352/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0167\n",
      "Epoch 352: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0167 - val_loss: 0.0295 - learning_rate: 0.0010\n",
      "Epoch 353/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0167\n",
      "Epoch 353: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0167 - val_loss: 0.0318 - learning_rate: 0.0010\n",
      "Epoch 354/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0181\n",
      "Epoch 354: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0181 - val_loss: 0.0259 - learning_rate: 0.0010\n",
      "Epoch 355/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0180\n",
      "Epoch 355: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0180 - val_loss: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 356/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0175\n",
      "Epoch 356: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0175 - val_loss: 0.0234 - learning_rate: 0.0010\n",
      "Epoch 357/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0173\n",
      "Epoch 357: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.0173 - val_loss: 0.0300 - learning_rate: 0.0010\n",
      "Epoch 358/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0173\n",
      "Epoch 358: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0174 - val_loss: 0.0279 - learning_rate: 0.0010\n",
      "Epoch 359/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0175\n",
      "Epoch 359: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0176 - val_loss: 0.0261 - learning_rate: 0.0010\n",
      "Epoch 360/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0195\n",
      "Epoch 360: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0195 - val_loss: 0.0369 - learning_rate: 0.0010\n",
      "Epoch 361/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0185\n",
      "Epoch 361: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0185 - val_loss: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 362/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0184\n",
      "Epoch 362: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0185 - val_loss: 0.0395 - learning_rate: 0.0010\n",
      "Epoch 363/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0188\n",
      "Epoch 363: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0188 - val_loss: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 364/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0167\n",
      "Epoch 364: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0167 - val_loss: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 365/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0163\n",
      "Epoch 365: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0163 - val_loss: 0.0309 - learning_rate: 0.0010\n",
      "Epoch 366/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0160\n",
      "Epoch 366: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0161 - val_loss: 0.0293 - learning_rate: 0.0010\n",
      "Epoch 367/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0157\n",
      "Epoch 367: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0157 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 368/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0160\n",
      "Epoch 368: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - loss: 0.0160 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 369/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0167\n",
      "Epoch 369: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0167 - val_loss: 0.0272 - learning_rate: 0.0010\n",
      "Epoch 370/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0164\n",
      "Epoch 370: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0164 - val_loss: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 371/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0196\n",
      "Epoch 371: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0195 - val_loss: 0.0290 - learning_rate: 0.0010\n",
      "Epoch 372/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0182\n",
      "Epoch 372: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0182 - val_loss: 0.0293 - learning_rate: 0.0010\n",
      "Epoch 373/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0165\n",
      "Epoch 373: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0165 - val_loss: 0.0245 - learning_rate: 0.0010\n",
      "Epoch 374/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0163\n",
      "Epoch 374: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0163 - val_loss: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 375/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0161\n",
      "Epoch 375: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0161 - val_loss: 0.0245 - learning_rate: 0.0010\n",
      "Epoch 376/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0162\n",
      "Epoch 376: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0162 - val_loss: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 377/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0160\n",
      "Epoch 377: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0160 - val_loss: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 378/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0158\n",
      "Epoch 378: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0158 - val_loss: 0.0413 - learning_rate: 0.0010\n",
      "Epoch 379/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0163\n",
      "Epoch 379: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0163 - val_loss: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 380/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0158\n",
      "Epoch 380: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0158 - val_loss: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 381/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0148\n",
      "Epoch 381: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0149 - val_loss: 0.0272 - learning_rate: 0.0010\n",
      "Epoch 382/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0150\n",
      "Epoch 382: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0151 - val_loss: 0.0355 - learning_rate: 0.0010\n",
      "Epoch 383/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0154\n",
      "Epoch 383: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0154 - val_loss: 0.0268 - learning_rate: 0.0010\n",
      "Epoch 384/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0152\n",
      "Epoch 384: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0152 - val_loss: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 385/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0151\n",
      "Epoch 385: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0151 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 386/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0151\n",
      "Epoch 386: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0152 - val_loss: 0.0247 - learning_rate: 0.0010\n",
      "Epoch 387/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0158\n",
      "Epoch 387: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0159 - val_loss: 0.0308 - learning_rate: 0.0010\n",
      "Epoch 388/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0160\n",
      "Epoch 388: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0161 - val_loss: 0.0293 - learning_rate: 0.0010\n",
      "Epoch 389/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0161\n",
      "Epoch 389: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0161 - val_loss: 0.0246 - learning_rate: 0.0010\n",
      "Epoch 390/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0163\n",
      "Epoch 390: val_loss did not improve from 0.02028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0163 - val_loss: 0.0306 - learning_rate: 0.0010\n",
      "Epoch 391/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0158\n",
      "Epoch 391: val_loss improved from 0.02028 to 0.01851, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0158 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 392/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0161\n",
      "Epoch 392: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0161 - val_loss: 0.0225 - learning_rate: 0.0010\n",
      "Epoch 393/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0155\n",
      "Epoch 393: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0155 - val_loss: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 394/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0158\n",
      "Epoch 394: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0158 - val_loss: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 395/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0150\n",
      "Epoch 395: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.0150 - val_loss: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 396/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0161\n",
      "Epoch 396: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0162 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 397/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0169\n",
      "Epoch 397: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0169 - val_loss: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 398/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0157\n",
      "Epoch 398: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0157 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 399/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0159\n",
      "Epoch 399: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0159 - val_loss: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 400/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0165\n",
      "Epoch 400: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0165 - val_loss: 0.0219 - learning_rate: 0.0010\n",
      "Epoch 401/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0154\n",
      "Epoch 401: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0155 - val_loss: 0.0264 - learning_rate: 0.0010\n",
      "Epoch 402/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0149\n",
      "Epoch 402: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0150 - val_loss: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 403/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0144\n",
      "Epoch 403: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0145 - val_loss: 0.0239 - learning_rate: 0.0010\n",
      "Epoch 404/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0148\n",
      "Epoch 404: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0148 - val_loss: 0.0264 - learning_rate: 0.0010\n",
      "Epoch 405/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0150\n",
      "Epoch 405: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0150 - val_loss: 0.0272 - learning_rate: 0.0010\n",
      "Epoch 406/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0145\n",
      "Epoch 406: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0145 - val_loss: 0.0249 - learning_rate: 0.0010\n",
      "Epoch 407/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0136\n",
      "Epoch 407: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0136 - val_loss: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 408/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0147\n",
      "Epoch 408: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0147 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 409/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0152\n",
      "Epoch 409: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0152 - val_loss: 0.0219 - learning_rate: 0.0010\n",
      "Epoch 410/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0158\n",
      "Epoch 410: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0158 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 411/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0155\n",
      "Epoch 411: val_loss improved from 0.01851 to 0.01723, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0155 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 412/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0161\n",
      "Epoch 412: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0161 - val_loss: 0.0260 - learning_rate: 0.0010\n",
      "Epoch 413/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0152\n",
      "Epoch 413: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.0152 - val_loss: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 414/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0153\n",
      "Epoch 414: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0154 - val_loss: 0.0307 - learning_rate: 0.0010\n",
      "Epoch 415/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0166\n",
      "Epoch 415: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0167 - val_loss: 0.0292 - learning_rate: 0.0010\n",
      "Epoch 416/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0175\n",
      "Epoch 416: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0175 - val_loss: 0.0298 - learning_rate: 0.0010\n",
      "Epoch 417/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0175\n",
      "Epoch 417: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0175 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 418/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0188\n",
      "Epoch 418: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0187 - val_loss: 0.0266 - learning_rate: 0.0010\n",
      "Epoch 419/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0167\n",
      "Epoch 419: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0167 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 420/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0163\n",
      "Epoch 420: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0163 - val_loss: 0.0259 - learning_rate: 0.0010\n",
      "Epoch 421/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0148\n",
      "Epoch 421: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0148 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 422/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0155\n",
      "Epoch 422: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0154 - val_loss: 0.0300 - learning_rate: 0.0010\n",
      "Epoch 423/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0146\n",
      "Epoch 423: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0146 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 424/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0150\n",
      "Epoch 424: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0150 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 425/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0146\n",
      "Epoch 425: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0146 - val_loss: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 426/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0147\n",
      "Epoch 426: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0148 - val_loss: 0.0270 - learning_rate: 0.0010\n",
      "Epoch 427/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0144\n",
      "Epoch 427: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0144 - val_loss: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 428/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0138\n",
      "Epoch 428: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0139 - val_loss: 0.0245 - learning_rate: 0.0010\n",
      "Epoch 429/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0145\n",
      "Epoch 429: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0146 - val_loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 430/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0151\n",
      "Epoch 430: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0151 - val_loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 431/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0156\n",
      "Epoch 431: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0156 - val_loss: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 432/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0143\n",
      "Epoch 432: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0144 - val_loss: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 433/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0146\n",
      "Epoch 433: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0146 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 434/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0151\n",
      "Epoch 434: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0152 - val_loss: 0.0240 - learning_rate: 0.0010\n",
      "Epoch 435/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0149\n",
      "Epoch 435: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0149 - val_loss: 0.0293 - learning_rate: 0.0010\n",
      "Epoch 436/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0141\n",
      "Epoch 436: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0141 - val_loss: 0.0188 - learning_rate: 0.0010\n",
      "Epoch 437/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0137\n",
      "Epoch 437: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0138 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 438/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0141\n",
      "Epoch 438: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0141 - val_loss: 0.0219 - learning_rate: 0.0010\n",
      "Epoch 439/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0144\n",
      "Epoch 439: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0144 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 440/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0136\n",
      "Epoch 440: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0136 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 441/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0142\n",
      "Epoch 441: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0142 - val_loss: 0.0371 - learning_rate: 0.0010\n",
      "Epoch 442/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0141\n",
      "Epoch 442: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0142 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 443/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0143\n",
      "Epoch 443: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0143 - val_loss: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 444/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0141\n",
      "Epoch 444: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0141 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 445/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0131\n",
      "Epoch 445: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0132 - val_loss: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 446/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0138\n",
      "Epoch 446: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0138 - val_loss: 0.0232 - learning_rate: 0.0010\n",
      "Epoch 447/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0143\n",
      "Epoch 447: val_loss did not improve from 0.01723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0144 - val_loss: 0.0234 - learning_rate: 0.0010\n",
      "Epoch 448/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0150\n",
      "Epoch 448: val_loss improved from 0.01723 to 0.01509, saving model to ./result_folder_no_misc/lstm_ts_7.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0150 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 449/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0146\n",
      "Epoch 449: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0146 - val_loss: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 450/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0136\n",
      "Epoch 450: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0136 - val_loss: 0.0247 - learning_rate: 0.0010\n",
      "Epoch 451/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0135\n",
      "Epoch 451: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0135 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 452/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0125\n",
      "Epoch 452: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0126 - val_loss: 0.0235 - learning_rate: 0.0010\n",
      "Epoch 453/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0144\n",
      "Epoch 453: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0144 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 454/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0138\n",
      "Epoch 454: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0138 - val_loss: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 455/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0132\n",
      "Epoch 455: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0132 - val_loss: 0.0297 - learning_rate: 0.0010\n",
      "Epoch 456/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0138\n",
      "Epoch 456: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0138 - val_loss: 0.0261 - learning_rate: 0.0010\n",
      "Epoch 457/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0143\n",
      "Epoch 457: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0143 - val_loss: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 458/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0135\n",
      "Epoch 458: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0136 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 459/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0131\n",
      "Epoch 459: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0132 - val_loss: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 460/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0136\n",
      "Epoch 460: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0136 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 461/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0136\n",
      "Epoch 461: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0136 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 462/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0146\n",
      "Epoch 462: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0146 - val_loss: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 463/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0140\n",
      "Epoch 463: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0140 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 464/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0135\n",
      "Epoch 464: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0135 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 465/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0141\n",
      "Epoch 465: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0141 - val_loss: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 466/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0138\n",
      "Epoch 466: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0138 - val_loss: 0.0249 - learning_rate: 0.0010\n",
      "Epoch 467/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0134\n",
      "Epoch 467: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0134 - val_loss: 0.0251 - learning_rate: 0.0010\n",
      "Epoch 468/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0134\n",
      "Epoch 468: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0134 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 469/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0133\n",
      "Epoch 469: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0133 - val_loss: 0.0275 - learning_rate: 0.0010\n",
      "Epoch 470/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0141\n",
      "Epoch 470: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0141 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 471/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0136\n",
      "Epoch 471: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0136 - val_loss: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 472/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0131\n",
      "Epoch 472: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0131 - val_loss: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 473/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0126\n",
      "Epoch 473: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0126 - val_loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 474/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0131\n",
      "Epoch 474: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0131 - val_loss: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 475/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0127\n",
      "Epoch 475: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0128 - val_loss: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 476/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0133\n",
      "Epoch 476: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0133 - val_loss: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 477/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0137\n",
      "Epoch 477: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0137 - val_loss: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 478/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0149\n",
      "Epoch 478: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.0149 - val_loss: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 479/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0143\n",
      "Epoch 479: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0143 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 480/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0143\n",
      "Epoch 480: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0143 - val_loss: 0.0287 - learning_rate: 0.0010\n",
      "Epoch 481/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0134\n",
      "Epoch 481: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.0135 - val_loss: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 482/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0130\n",
      "Epoch 482: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0131 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 483/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0132\n",
      "Epoch 483: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0132 - val_loss: 0.0247 - learning_rate: 0.0010\n",
      "Epoch 484/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0134\n",
      "Epoch 484: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.0135 - val_loss: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 485/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0151\n",
      "Epoch 485: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0151 - val_loss: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 486/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0141\n",
      "Epoch 486: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0141 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 487/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0138\n",
      "Epoch 487: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0138 - val_loss: 0.0357 - learning_rate: 0.0010\n",
      "Epoch 488/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0131\n",
      "Epoch 488: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0132 - val_loss: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 489/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0140\n",
      "Epoch 489: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0140 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 490/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0127\n",
      "Epoch 490: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0127 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 491/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0130\n",
      "Epoch 491: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0130 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 492/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0132\n",
      "Epoch 492: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0132 - val_loss: 0.0301 - learning_rate: 0.0010\n",
      "Epoch 493/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0137\n",
      "Epoch 493: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0137 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 494/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0134\n",
      "Epoch 494: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0134 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 495/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0134\n",
      "Epoch 495: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0134 - val_loss: 0.0240 - learning_rate: 0.0010\n",
      "Epoch 496/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0137\n",
      "Epoch 496: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0137 - val_loss: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 497/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0142\n",
      "Epoch 497: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0142 - val_loss: 0.0232 - learning_rate: 0.0010\n",
      "Epoch 498/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0138\n",
      "Epoch 498: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0138 - val_loss: 0.0259 - learning_rate: 0.0010\n",
      "Epoch 499/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0138\n",
      "Epoch 499: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0139 - val_loss: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 500/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0149\n",
      "Epoch 500: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0149 - val_loss: 0.0286 - learning_rate: 0.0010\n",
      "Epoch 501/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0146\n",
      "Epoch 501: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0146 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 502/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0134\n",
      "Epoch 502: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0134 - val_loss: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 503/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0132\n",
      "Epoch 503: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0132 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 504/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0139\n",
      "Epoch 504: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0138 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 505/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0127\n",
      "Epoch 505: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0128 - val_loss: 0.0225 - learning_rate: 0.0010\n",
      "Epoch 506/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0119\n",
      "Epoch 506: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0119 - val_loss: 0.0219 - learning_rate: 0.0010\n",
      "Epoch 507/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0117\n",
      "Epoch 507: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0117 - val_loss: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 508/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0119\n",
      "Epoch 508: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0120 - val_loss: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 509/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0124\n",
      "Epoch 509: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0124 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 510/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0131\n",
      "Epoch 510: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0131 - val_loss: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 511/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0123\n",
      "Epoch 511: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0123 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 512/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0126\n",
      "Epoch 512: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0127 - val_loss: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 513/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0135\n",
      "Epoch 513: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0135 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 514/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0129\n",
      "Epoch 514: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0129 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 515/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0133\n",
      "Epoch 515: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0133 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 516/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0124\n",
      "Epoch 516: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0124 - val_loss: 0.0280 - learning_rate: 0.0010\n",
      "Epoch 517/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0122\n",
      "Epoch 517: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0122 - val_loss: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 518/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0118\n",
      "Epoch 518: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0119 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 519/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0122\n",
      "Epoch 519: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0122 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 520/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0122\n",
      "Epoch 520: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0123 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 521/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0138\n",
      "Epoch 521: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0138 - val_loss: 0.0188 - learning_rate: 0.0010\n",
      "Epoch 522/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0144\n",
      "Epoch 522: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0144 - val_loss: 0.0298 - learning_rate: 0.0010\n",
      "Epoch 523/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0136\n",
      "Epoch 523: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0136 - val_loss: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 524/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0132\n",
      "Epoch 524: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0132 - val_loss: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 525/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0151\n",
      "Epoch 525: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.0150 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 526/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0145\n",
      "Epoch 526: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0145 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 527/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0158\n",
      "Epoch 527: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0158 - val_loss: 0.0295 - learning_rate: 0.0010\n",
      "Epoch 528/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0151\n",
      "Epoch 528: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0151 - val_loss: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 529/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0150\n",
      "Epoch 529: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0150 - val_loss: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 530/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0139\n",
      "Epoch 530: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0139 - val_loss: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 531/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0138\n",
      "Epoch 531: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0137 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 532/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0128\n",
      "Epoch 532: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0128 - val_loss: 0.0210 - learning_rate: 0.0010\n",
      "Epoch 533/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0125\n",
      "Epoch 533: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0126 - val_loss: 0.0303 - learning_rate: 0.0010\n",
      "Epoch 534/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0133\n",
      "Epoch 534: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0133 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 535/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0138\n",
      "Epoch 535: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0138 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 536/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0143\n",
      "Epoch 536: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - loss: 0.0143 - val_loss: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 537/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0145\n",
      "Epoch 537: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0144 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 538/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0139\n",
      "Epoch 538: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0139 - val_loss: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 539/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0129\n",
      "Epoch 539: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0129 - val_loss: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 540/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0130\n",
      "Epoch 540: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0130 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 541/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0132\n",
      "Epoch 541: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.0132 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 542/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0137\n",
      "Epoch 542: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0137 - val_loss: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 543/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0128\n",
      "Epoch 543: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.0128 - val_loss: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 544/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0126\n",
      "Epoch 544: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0126 - val_loss: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 545/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0131\n",
      "Epoch 545: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0132 - val_loss: 0.0240 - learning_rate: 0.0010\n",
      "Epoch 546/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0138\n",
      "Epoch 546: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0138 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 547/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0127\n",
      "Epoch 547: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0127 - val_loss: 0.0235 - learning_rate: 0.0010\n",
      "Epoch 548/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0124\n",
      "Epoch 548: val_loss did not improve from 0.01509\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0125 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 548: early stopping\n",
      "Restoring model weights from the end of the best epoch: 448.\n",
      "EUA\n",
      "0.1710376116941316\n",
      "Oil\n",
      "0.2318937830380561\n",
      "Coal\n",
      "0.08387419416571651\n",
      "NG\n",
      "0.062296258671428156\n",
      "USEU\n",
      "0.10862847852215948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 180/180 [01:19<00:00,  2.26it/s]\n",
      "100%|| 180/180 [04:15<00:00,  1.42s/it]\n",
      "/home/honggeunjo/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 1.8806\n",
      "Epoch 1: val_loss improved from inf to 0.40071, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 256ms/step - loss: 1.8378 - val_loss: 0.4007 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.6320\n",
      "Epoch 2: val_loss did not improve from 0.40071\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.6280 - val_loss: 0.4017 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.4870\n",
      "Epoch 3: val_loss improved from 0.40071 to 0.38011, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.4860 - val_loss: 0.3801 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.4424\n",
      "Epoch 4: val_loss improved from 0.38011 to 0.36949, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.4414 - val_loss: 0.3695 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.4155\n",
      "Epoch 5: val_loss improved from 0.36949 to 0.35460, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.4152 - val_loss: 0.3546 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.4012\n",
      "Epoch 6: val_loss improved from 0.35460 to 0.34920, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.4012 - val_loss: 0.3492 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.3919\n",
      "Epoch 7: val_loss improved from 0.34920 to 0.34551, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.3917 - val_loss: 0.3455 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.3790\n",
      "Epoch 8: val_loss improved from 0.34551 to 0.34010, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.3790 - val_loss: 0.3401 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.3723\n",
      "Epoch 9: val_loss improved from 0.34010 to 0.33313, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.3720 - val_loss: 0.3331 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.3640\n",
      "Epoch 10: val_loss improved from 0.33313 to 0.33162, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.3638 - val_loss: 0.3316 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.3556\n",
      "Epoch 11: val_loss improved from 0.33162 to 0.32435, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.3555 - val_loss: 0.3244 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.3491\n",
      "Epoch 12: val_loss improved from 0.32435 to 0.31582, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.3490 - val_loss: 0.3158 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.3400\n",
      "Epoch 13: val_loss improved from 0.31582 to 0.31340, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.3399 - val_loss: 0.3134 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.3339\n",
      "Epoch 14: val_loss improved from 0.31340 to 0.30702, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.3338 - val_loss: 0.3070 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.3279\n",
      "Epoch 15: val_loss improved from 0.30702 to 0.30175, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.3276 - val_loss: 0.3017 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.3222\n",
      "Epoch 16: val_loss improved from 0.30175 to 0.29526, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.3220 - val_loss: 0.2953 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.3152\n",
      "Epoch 17: val_loss improved from 0.29526 to 0.28378, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.3149 - val_loss: 0.2838 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.3077\n",
      "Epoch 18: val_loss did not improve from 0.28378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.3075 - val_loss: 0.2910 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.3008\n",
      "Epoch 19: val_loss improved from 0.28378 to 0.27427, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.3007 - val_loss: 0.2743 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.2917\n",
      "Epoch 20: val_loss improved from 0.27427 to 0.26759, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.2917 - val_loss: 0.2676 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.2886\n",
      "Epoch 21: val_loss did not improve from 0.26759\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.2886 - val_loss: 0.2701 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.2814\n",
      "Epoch 22: val_loss improved from 0.26759 to 0.25673, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.2815 - val_loss: 0.2567 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.2784\n",
      "Epoch 23: val_loss improved from 0.25673 to 0.25429, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.2782 - val_loss: 0.2543 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.2708\n",
      "Epoch 24: val_loss improved from 0.25429 to 0.24899, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.2707 - val_loss: 0.2490 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.2634\n",
      "Epoch 25: val_loss did not improve from 0.24899\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.2634 - val_loss: 0.2506 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.2567\n",
      "Epoch 26: val_loss improved from 0.24899 to 0.24066, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.2567 - val_loss: 0.2407 - learning_rate: 0.0010\n",
      "Epoch 27/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.2504\n",
      "Epoch 27: val_loss improved from 0.24066 to 0.23484, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.2504 - val_loss: 0.2348 - learning_rate: 0.0010\n",
      "Epoch 28/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.2478\n",
      "Epoch 28: val_loss improved from 0.23484 to 0.22744, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.2477 - val_loss: 0.2274 - learning_rate: 0.0010\n",
      "Epoch 29/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.2413\n",
      "Epoch 29: val_loss improved from 0.22744 to 0.22265, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.2414 - val_loss: 0.2226 - learning_rate: 0.0010\n",
      "Epoch 30/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.2382\n",
      "Epoch 30: val_loss improved from 0.22265 to 0.22084, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.2382 - val_loss: 0.2208 - learning_rate: 0.0010\n",
      "Epoch 31/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.2312\n",
      "Epoch 31: val_loss improved from 0.22084 to 0.21875, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.2312 - val_loss: 0.2188 - learning_rate: 0.0010\n",
      "Epoch 32/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.2266\n",
      "Epoch 32: val_loss improved from 0.21875 to 0.21336, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.2265 - val_loss: 0.2134 - learning_rate: 0.0010\n",
      "Epoch 33/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.2234\n",
      "Epoch 33: val_loss improved from 0.21336 to 0.20786, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.2233 - val_loss: 0.2079 - learning_rate: 0.0010\n",
      "Epoch 34/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.2188\n",
      "Epoch 34: val_loss did not improve from 0.20786\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.2187 - val_loss: 0.2138 - learning_rate: 0.0010\n",
      "Epoch 35/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.2142\n",
      "Epoch 35: val_loss improved from 0.20786 to 0.19838, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.2141 - val_loss: 0.1984 - learning_rate: 0.0010\n",
      "Epoch 36/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.2090\n",
      "Epoch 36: val_loss improved from 0.19838 to 0.19097, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.2091 - val_loss: 0.1910 - learning_rate: 0.0010\n",
      "Epoch 37/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.2067\n",
      "Epoch 37: val_loss improved from 0.19097 to 0.18795, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.2066 - val_loss: 0.1880 - learning_rate: 0.0010\n",
      "Epoch 38/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.2005\n",
      "Epoch 38: val_loss improved from 0.18795 to 0.18744, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.2005 - val_loss: 0.1874 - learning_rate: 0.0010\n",
      "Epoch 39/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.1978\n",
      "Epoch 39: val_loss improved from 0.18744 to 0.18111, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.1977 - val_loss: 0.1811 - learning_rate: 0.0010\n",
      "Epoch 40/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.1936\n",
      "Epoch 40: val_loss improved from 0.18111 to 0.18015, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.1935 - val_loss: 0.1801 - learning_rate: 0.0010\n",
      "Epoch 41/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.1908\n",
      "Epoch 41: val_loss did not improve from 0.18015\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.1908 - val_loss: 0.1836 - learning_rate: 0.0010\n",
      "Epoch 42/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.1887\n",
      "Epoch 42: val_loss improved from 0.18015 to 0.17266, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.1886 - val_loss: 0.1727 - learning_rate: 0.0010\n",
      "Epoch 43/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.1837\n",
      "Epoch 43: val_loss improved from 0.17266 to 0.17171, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.1837 - val_loss: 0.1717 - learning_rate: 0.0010\n",
      "Epoch 44/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.1779\n",
      "Epoch 44: val_loss improved from 0.17171 to 0.16611, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.1779 - val_loss: 0.1661 - learning_rate: 0.0010\n",
      "Epoch 45/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.1763\n",
      "Epoch 45: val_loss improved from 0.16611 to 0.16116, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.1763 - val_loss: 0.1612 - learning_rate: 0.0010\n",
      "Epoch 46/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.1713\n",
      "Epoch 46: val_loss improved from 0.16116 to 0.15726, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.1713 - val_loss: 0.1573 - learning_rate: 0.0010\n",
      "Epoch 47/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.1697\n",
      "Epoch 47: val_loss improved from 0.15726 to 0.15594, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.1696 - val_loss: 0.1559 - learning_rate: 0.0010\n",
      "Epoch 48/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.1659\n",
      "Epoch 48: val_loss improved from 0.15594 to 0.15531, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.1658 - val_loss: 0.1553 - learning_rate: 0.0010\n",
      "Epoch 49/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.1641\n",
      "Epoch 49: val_loss improved from 0.15531 to 0.15167, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.1641 - val_loss: 0.1517 - learning_rate: 0.0010\n",
      "Epoch 50/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.1620\n",
      "Epoch 50: val_loss improved from 0.15167 to 0.14648, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.1620 - val_loss: 0.1465 - learning_rate: 0.0010\n",
      "Epoch 51/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.1605\n",
      "Epoch 51: val_loss improved from 0.14648 to 0.14536, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.1604 - val_loss: 0.1454 - learning_rate: 0.0010\n",
      "Epoch 52/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.1549\n",
      "Epoch 52: val_loss improved from 0.14536 to 0.14100, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.1549 - val_loss: 0.1410 - learning_rate: 0.0010\n",
      "Epoch 53/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.1510\n",
      "Epoch 53: val_loss improved from 0.14100 to 0.14018, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.1509 - val_loss: 0.1402 - learning_rate: 0.0010\n",
      "Epoch 54/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.1485\n",
      "Epoch 54: val_loss improved from 0.14018 to 0.13924, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1485 - val_loss: 0.1392 - learning_rate: 0.0010\n",
      "Epoch 55/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.1458\n",
      "Epoch 55: val_loss improved from 0.13924 to 0.13348, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.1458 - val_loss: 0.1335 - learning_rate: 0.0010\n",
      "Epoch 56/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.1426\n",
      "Epoch 56: val_loss did not improve from 0.13348\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.1427 - val_loss: 0.1345 - learning_rate: 0.0010\n",
      "Epoch 57/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.1440\n",
      "Epoch 57: val_loss did not improve from 0.13348\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.1440 - val_loss: 0.1377 - learning_rate: 0.0010\n",
      "Epoch 58/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.1421\n",
      "Epoch 58: val_loss improved from 0.13348 to 0.13068, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.1420 - val_loss: 0.1307 - learning_rate: 0.0010\n",
      "Epoch 59/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.1387\n",
      "Epoch 59: val_loss improved from 0.13068 to 0.12812, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.1386 - val_loss: 0.1281 - learning_rate: 0.0010\n",
      "Epoch 60/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.1349\n",
      "Epoch 60: val_loss improved from 0.12812 to 0.12555, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1348 - val_loss: 0.1255 - learning_rate: 0.0010\n",
      "Epoch 61/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.1320\n",
      "Epoch 61: val_loss did not improve from 0.12555\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.1320 - val_loss: 0.1263 - learning_rate: 0.0010\n",
      "Epoch 62/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.1301\n",
      "Epoch 62: val_loss improved from 0.12555 to 0.12007, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.1300 - val_loss: 0.1201 - learning_rate: 0.0010\n",
      "Epoch 63/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.1260\n",
      "Epoch 63: val_loss improved from 0.12007 to 0.11919, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.1261 - val_loss: 0.1192 - learning_rate: 0.0010\n",
      "Epoch 64/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.1260\n",
      "Epoch 64: val_loss improved from 0.11919 to 0.11763, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.1260 - val_loss: 0.1176 - learning_rate: 0.0010\n",
      "Epoch 65/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.1232\n",
      "Epoch 65: val_loss improved from 0.11763 to 0.11337, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1233 - val_loss: 0.1134 - learning_rate: 0.0010\n",
      "Epoch 66/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.1221\n",
      "Epoch 66: val_loss did not improve from 0.11337\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.1222 - val_loss: 0.1146 - learning_rate: 0.0010\n",
      "Epoch 67/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.1216\n",
      "Epoch 67: val_loss did not improve from 0.11337\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.1215 - val_loss: 0.1167 - learning_rate: 0.0010\n",
      "Epoch 68/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.1193\n",
      "Epoch 68: val_loss improved from 0.11337 to 0.11287, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.1193 - val_loss: 0.1129 - learning_rate: 0.0010\n",
      "Epoch 69/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.1165\n",
      "Epoch 69: val_loss improved from 0.11287 to 0.10717, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.1166 - val_loss: 0.1072 - learning_rate: 0.0010\n",
      "Epoch 70/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.1147\n",
      "Epoch 70: val_loss improved from 0.10717 to 0.10613, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.1147 - val_loss: 0.1061 - learning_rate: 0.0010\n",
      "Epoch 71/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.1143\n",
      "Epoch 71: val_loss improved from 0.10613 to 0.10274, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1143 - val_loss: 0.1027 - learning_rate: 0.0010\n",
      "Epoch 72/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.1122\n",
      "Epoch 72: val_loss did not improve from 0.10274\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.1122 - val_loss: 0.1038 - learning_rate: 0.0010\n",
      "Epoch 73/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.1104\n",
      "Epoch 73: val_loss improved from 0.10274 to 0.09926, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.1105 - val_loss: 0.0993 - learning_rate: 0.0010\n",
      "Epoch 74/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.1087\n",
      "Epoch 74: val_loss improved from 0.09926 to 0.09837, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.1087 - val_loss: 0.0984 - learning_rate: 0.0010\n",
      "Epoch 75/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.1079\n",
      "Epoch 75: val_loss did not improve from 0.09837\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.1079 - val_loss: 0.0988 - learning_rate: 0.0010\n",
      "Epoch 76/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.1064\n",
      "Epoch 76: val_loss did not improve from 0.09837\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.1064 - val_loss: 0.1070 - learning_rate: 0.0010\n",
      "Epoch 77/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.1051\n",
      "Epoch 77: val_loss did not improve from 0.09837\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.1050 - val_loss: 0.0993 - learning_rate: 0.0010\n",
      "Epoch 78/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.1022\n",
      "Epoch 78: val_loss improved from 0.09837 to 0.09776, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.1022 - val_loss: 0.0978 - learning_rate: 0.0010\n",
      "Epoch 79/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.1023\n",
      "Epoch 79: val_loss improved from 0.09776 to 0.09752, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.1023 - val_loss: 0.0975 - learning_rate: 0.0010\n",
      "Epoch 80/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0992\n",
      "Epoch 80: val_loss did not improve from 0.09752\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0991 - val_loss: 0.1026 - learning_rate: 0.0010\n",
      "Epoch 81/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0988\n",
      "Epoch 81: val_loss improved from 0.09752 to 0.09513, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0988 - val_loss: 0.0951 - learning_rate: 0.0010\n",
      "Epoch 82/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0968\n",
      "Epoch 82: val_loss did not improve from 0.09513\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0968 - val_loss: 0.0990 - learning_rate: 0.0010\n",
      "Epoch 83/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0971\n",
      "Epoch 83: val_loss improved from 0.09513 to 0.08838, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0971 - val_loss: 0.0884 - learning_rate: 0.0010\n",
      "Epoch 84/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0952\n",
      "Epoch 84: val_loss improved from 0.08838 to 0.08487, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0952 - val_loss: 0.0849 - learning_rate: 0.0010\n",
      "Epoch 85/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0945\n",
      "Epoch 85: val_loss improved from 0.08487 to 0.08394, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0944 - val_loss: 0.0839 - learning_rate: 0.0010\n",
      "Epoch 86/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0922\n",
      "Epoch 86: val_loss did not improve from 0.08394\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0921 - val_loss: 0.0862 - learning_rate: 0.0010\n",
      "Epoch 87/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0895\n",
      "Epoch 87: val_loss did not improve from 0.08394\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0895 - val_loss: 0.0860 - learning_rate: 0.0010\n",
      "Epoch 88/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0894\n",
      "Epoch 88: val_loss improved from 0.08394 to 0.08371, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0894 - val_loss: 0.0837 - learning_rate: 0.0010\n",
      "Epoch 89/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0897\n",
      "Epoch 89: val_loss improved from 0.08371 to 0.08366, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0898 - val_loss: 0.0837 - learning_rate: 0.0010\n",
      "Epoch 90/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0873\n",
      "Epoch 90: val_loss improved from 0.08366 to 0.08240, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0873 - val_loss: 0.0824 - learning_rate: 0.0010\n",
      "Epoch 91/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0853\n",
      "Epoch 91: val_loss improved from 0.08240 to 0.08224, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0853 - val_loss: 0.0822 - learning_rate: 0.0010\n",
      "Epoch 92/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0847\n",
      "Epoch 92: val_loss improved from 0.08224 to 0.07977, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0847 - val_loss: 0.0798 - learning_rate: 0.0010\n",
      "Epoch 93/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0846\n",
      "Epoch 93: val_loss did not improve from 0.07977\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0848 - val_loss: 0.0828 - learning_rate: 0.0010\n",
      "Epoch 94/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0845\n",
      "Epoch 94: val_loss improved from 0.07977 to 0.07747, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0845 - val_loss: 0.0775 - learning_rate: 0.0010\n",
      "Epoch 95/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0825\n",
      "Epoch 95: val_loss improved from 0.07747 to 0.07639, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0825 - val_loss: 0.0764 - learning_rate: 0.0010\n",
      "Epoch 96/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0795\n",
      "Epoch 96: val_loss did not improve from 0.07639\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0795 - val_loss: 0.0806 - learning_rate: 0.0010\n",
      "Epoch 97/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0791\n",
      "Epoch 97: val_loss improved from 0.07639 to 0.07272, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0791 - val_loss: 0.0727 - learning_rate: 0.0010\n",
      "Epoch 98/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0794\n",
      "Epoch 98: val_loss improved from 0.07272 to 0.07208, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0794 - val_loss: 0.0721 - learning_rate: 0.0010\n",
      "Epoch 99/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0779\n",
      "Epoch 99: val_loss did not improve from 0.07208\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0780 - val_loss: 0.0731 - learning_rate: 0.0010\n",
      "Epoch 100/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0788\n",
      "Epoch 100: val_loss improved from 0.07208 to 0.06939, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0788 - val_loss: 0.0694 - learning_rate: 0.0010\n",
      "Epoch 101/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0780\n",
      "Epoch 101: val_loss did not improve from 0.06939\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0780 - val_loss: 0.0802 - learning_rate: 0.0010\n",
      "Epoch 102/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0768\n",
      "Epoch 102: val_loss did not improve from 0.06939\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0767 - val_loss: 0.0730 - learning_rate: 0.0010\n",
      "Epoch 103/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0757\n",
      "Epoch 103: val_loss did not improve from 0.06939\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0757 - val_loss: 0.0707 - learning_rate: 0.0010\n",
      "Epoch 104/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0752\n",
      "Epoch 104: val_loss did not improve from 0.06939\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0752 - val_loss: 0.0719 - learning_rate: 0.0010\n",
      "Epoch 105/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0736\n",
      "Epoch 105: val_loss improved from 0.06939 to 0.06703, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0736 - val_loss: 0.0670 - learning_rate: 0.0010\n",
      "Epoch 106/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0716\n",
      "Epoch 106: val_loss improved from 0.06703 to 0.06680, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0717 - val_loss: 0.0668 - learning_rate: 0.0010\n",
      "Epoch 107/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0719\n",
      "Epoch 107: val_loss improved from 0.06680 to 0.06671, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0719 - val_loss: 0.0667 - learning_rate: 0.0010\n",
      "Epoch 108/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0721\n",
      "Epoch 108: val_loss improved from 0.06671 to 0.06590, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0720 - val_loss: 0.0659 - learning_rate: 0.0010\n",
      "Epoch 109/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0693\n",
      "Epoch 109: val_loss improved from 0.06590 to 0.06541, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0693 - val_loss: 0.0654 - learning_rate: 0.0010\n",
      "Epoch 110/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0703\n",
      "Epoch 110: val_loss did not improve from 0.06541\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0703 - val_loss: 0.0703 - learning_rate: 0.0010\n",
      "Epoch 111/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0693\n",
      "Epoch 111: val_loss did not improve from 0.06541\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0693 - val_loss: 0.0656 - learning_rate: 0.0010\n",
      "Epoch 112/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0699\n",
      "Epoch 112: val_loss improved from 0.06541 to 0.06468, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0699 - val_loss: 0.0647 - learning_rate: 0.0010\n",
      "Epoch 113/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0680\n",
      "Epoch 113: val_loss did not improve from 0.06468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0680 - val_loss: 0.0686 - learning_rate: 0.0010\n",
      "Epoch 114/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0674\n",
      "Epoch 114: val_loss did not improve from 0.06468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0674 - val_loss: 0.0672 - learning_rate: 0.0010\n",
      "Epoch 115/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0682\n",
      "Epoch 115: val_loss improved from 0.06468 to 0.06009, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0682 - val_loss: 0.0601 - learning_rate: 0.0010\n",
      "Epoch 116/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0656\n",
      "Epoch 116: val_loss improved from 0.06009 to 0.05842, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0656 - val_loss: 0.0584 - learning_rate: 0.0010\n",
      "Epoch 117/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0648\n",
      "Epoch 117: val_loss did not improve from 0.05842\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0648 - val_loss: 0.0614 - learning_rate: 0.0010\n",
      "Epoch 118/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0643\n",
      "Epoch 118: val_loss improved from 0.05842 to 0.05662, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0643 - val_loss: 0.0566 - learning_rate: 0.0010\n",
      "Epoch 119/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0627\n",
      "Epoch 119: val_loss did not improve from 0.05662\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0627 - val_loss: 0.0602 - learning_rate: 0.0010\n",
      "Epoch 120/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0636\n",
      "Epoch 120: val_loss did not improve from 0.05662\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0636 - val_loss: 0.0575 - learning_rate: 0.0010\n",
      "Epoch 121/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0636\n",
      "Epoch 121: val_loss improved from 0.05662 to 0.05652, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0635 - val_loss: 0.0565 - learning_rate: 0.0010\n",
      "Epoch 122/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0613\n",
      "Epoch 122: val_loss did not improve from 0.05652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0613 - val_loss: 0.0600 - learning_rate: 0.0010\n",
      "Epoch 123/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0613\n",
      "Epoch 123: val_loss did not improve from 0.05652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0613 - val_loss: 0.0565 - learning_rate: 0.0010\n",
      "Epoch 124/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0605\n",
      "Epoch 124: val_loss improved from 0.05652 to 0.05539, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0605 - val_loss: 0.0554 - learning_rate: 0.0010\n",
      "Epoch 125/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0597\n",
      "Epoch 125: val_loss did not improve from 0.05539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0596 - val_loss: 0.0563 - learning_rate: 0.0010\n",
      "Epoch 126/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0592\n",
      "Epoch 126: val_loss did not improve from 0.05539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0592 - val_loss: 0.0564 - learning_rate: 0.0010\n",
      "Epoch 127/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0600\n",
      "Epoch 127: val_loss did not improve from 0.05539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0600 - val_loss: 0.0559 - learning_rate: 0.0010\n",
      "Epoch 128/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0577\n",
      "Epoch 128: val_loss did not improve from 0.05539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0577 - val_loss: 0.0554 - learning_rate: 0.0010\n",
      "Epoch 129/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0583\n",
      "Epoch 129: val_loss improved from 0.05539 to 0.05255, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0583 - val_loss: 0.0526 - learning_rate: 0.0010\n",
      "Epoch 130/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0564\n",
      "Epoch 130: val_loss improved from 0.05255 to 0.05124, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0564 - val_loss: 0.0512 - learning_rate: 0.0010\n",
      "Epoch 131/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0543\n",
      "Epoch 131: val_loss did not improve from 0.05124\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0544 - val_loss: 0.0532 - learning_rate: 0.0010\n",
      "Epoch 132/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0552\n",
      "Epoch 132: val_loss improved from 0.05124 to 0.04885, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0553 - val_loss: 0.0489 - learning_rate: 0.0010\n",
      "Epoch 133/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0552\n",
      "Epoch 133: val_loss did not improve from 0.04885\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0551 - val_loss: 0.0548 - learning_rate: 0.0010\n",
      "Epoch 134/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0544\n",
      "Epoch 134: val_loss did not improve from 0.04885\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0544 - val_loss: 0.0509 - learning_rate: 0.0010\n",
      "Epoch 135/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0534\n",
      "Epoch 135: val_loss did not improve from 0.04885\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0534 - val_loss: 0.0552 - learning_rate: 0.0010\n",
      "Epoch 136/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0542\n",
      "Epoch 136: val_loss did not improve from 0.04885\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0541 - val_loss: 0.0539 - learning_rate: 0.0010\n",
      "Epoch 137/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0522\n",
      "Epoch 137: val_loss did not improve from 0.04885\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0522 - val_loss: 0.0494 - learning_rate: 0.0010\n",
      "Epoch 138/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0525\n",
      "Epoch 138: val_loss did not improve from 0.04885\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0525 - val_loss: 0.0512 - learning_rate: 0.0010\n",
      "Epoch 139/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0525\n",
      "Epoch 139: val_loss improved from 0.04885 to 0.04828, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0525 - val_loss: 0.0483 - learning_rate: 0.0010\n",
      "Epoch 140/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0506\n",
      "Epoch 140: val_loss did not improve from 0.04828\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0506 - val_loss: 0.0560 - learning_rate: 0.0010\n",
      "Epoch 141/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0514\n",
      "Epoch 141: val_loss did not improve from 0.04828\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0515 - val_loss: 0.0502 - learning_rate: 0.0010\n",
      "Epoch 142/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0509\n",
      "Epoch 142: val_loss improved from 0.04828 to 0.04780, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0510 - val_loss: 0.0478 - learning_rate: 0.0010\n",
      "Epoch 143/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0526\n",
      "Epoch 143: val_loss did not improve from 0.04780\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0526 - val_loss: 0.0483 - learning_rate: 0.0010\n",
      "Epoch 144/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0512\n",
      "Epoch 144: val_loss improved from 0.04780 to 0.04712, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0512 - val_loss: 0.0471 - learning_rate: 0.0010\n",
      "Epoch 145/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0512\n",
      "Epoch 145: val_loss improved from 0.04712 to 0.04654, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0511 - val_loss: 0.0465 - learning_rate: 0.0010\n",
      "Epoch 146/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0498\n",
      "Epoch 146: val_loss improved from 0.04654 to 0.04475, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0499 - val_loss: 0.0447 - learning_rate: 0.0010\n",
      "Epoch 147/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0505\n",
      "Epoch 147: val_loss improved from 0.04475 to 0.04381, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0504 - val_loss: 0.0438 - learning_rate: 0.0010\n",
      "Epoch 148/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0487\n",
      "Epoch 148: val_loss improved from 0.04381 to 0.04378, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0487 - val_loss: 0.0438 - learning_rate: 0.0010\n",
      "Epoch 149/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0479\n",
      "Epoch 149: val_loss did not improve from 0.04378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0479 - val_loss: 0.0465 - learning_rate: 0.0010\n",
      "Epoch 150/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0472\n",
      "Epoch 150: val_loss did not improve from 0.04378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0472 - val_loss: 0.0442 - learning_rate: 0.0010\n",
      "Epoch 151/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0483\n",
      "Epoch 151: val_loss did not improve from 0.04378\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0482 - val_loss: 0.0454 - learning_rate: 0.0010\n",
      "Epoch 152/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0482\n",
      "Epoch 152: val_loss improved from 0.04378 to 0.04154, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0481 - val_loss: 0.0415 - learning_rate: 0.0010\n",
      "Epoch 153/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0460\n",
      "Epoch 153: val_loss did not improve from 0.04154\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0460 - val_loss: 0.0502 - learning_rate: 0.0010\n",
      "Epoch 154/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0465\n",
      "Epoch 154: val_loss did not improve from 0.04154\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0465 - val_loss: 0.0489 - learning_rate: 0.0010\n",
      "Epoch 155/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0452\n",
      "Epoch 155: val_loss did not improve from 0.04154\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0451 - val_loss: 0.0434 - learning_rate: 0.0010\n",
      "Epoch 156/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0445\n",
      "Epoch 156: val_loss improved from 0.04154 to 0.04146, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0445 - val_loss: 0.0415 - learning_rate: 0.0010\n",
      "Epoch 157/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0451\n",
      "Epoch 157: val_loss did not improve from 0.04146\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0451 - val_loss: 0.0423 - learning_rate: 0.0010\n",
      "Epoch 158/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0441\n",
      "Epoch 158: val_loss improved from 0.04146 to 0.03955, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0441 - val_loss: 0.0395 - learning_rate: 0.0010\n",
      "Epoch 159/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0438\n",
      "Epoch 159: val_loss did not improve from 0.03955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0438 - val_loss: 0.0434 - learning_rate: 0.0010\n",
      "Epoch 160/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0438\n",
      "Epoch 160: val_loss did not improve from 0.03955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0438 - val_loss: 0.0416 - learning_rate: 0.0010\n",
      "Epoch 161/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0439\n",
      "Epoch 161: val_loss improved from 0.03955 to 0.03904, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0439 - val_loss: 0.0390 - learning_rate: 0.0010\n",
      "Epoch 162/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0424\n",
      "Epoch 162: val_loss improved from 0.03904 to 0.03867, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0425 - val_loss: 0.0387 - learning_rate: 0.0010\n",
      "Epoch 163/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0422\n",
      "Epoch 163: val_loss improved from 0.03867 to 0.03626, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0422 - val_loss: 0.0363 - learning_rate: 0.0010\n",
      "Epoch 164/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0424\n",
      "Epoch 164: val_loss improved from 0.03626 to 0.03593, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0424 - val_loss: 0.0359 - learning_rate: 0.0010\n",
      "Epoch 165/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0436\n",
      "Epoch 165: val_loss did not improve from 0.03593\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0438 - val_loss: 0.0371 - learning_rate: 0.0010\n",
      "Epoch 166/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0456\n",
      "Epoch 166: val_loss did not improve from 0.03593\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0456 - val_loss: 0.0399 - learning_rate: 0.0010\n",
      "Epoch 167/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0446\n",
      "Epoch 167: val_loss did not improve from 0.03593\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0445 - val_loss: 0.0382 - learning_rate: 0.0010\n",
      "Epoch 168/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0430\n",
      "Epoch 168: val_loss did not improve from 0.03593\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0430 - val_loss: 0.0380 - learning_rate: 0.0010\n",
      "Epoch 169/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0431\n",
      "Epoch 169: val_loss did not improve from 0.03593\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0431 - val_loss: 0.0466 - learning_rate: 0.0010\n",
      "Epoch 170/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0421\n",
      "Epoch 170: val_loss did not improve from 0.03593\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0420 - val_loss: 0.0450 - learning_rate: 0.0010\n",
      "Epoch 171/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0416\n",
      "Epoch 171: val_loss did not improve from 0.03593\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0416 - val_loss: 0.0421 - learning_rate: 0.0010\n",
      "Epoch 172/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0408\n",
      "Epoch 172: val_loss improved from 0.03593 to 0.03537, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0408 - val_loss: 0.0354 - learning_rate: 0.0010\n",
      "Epoch 173/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0386\n",
      "Epoch 173: val_loss improved from 0.03537 to 0.03522, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0387 - val_loss: 0.0352 - learning_rate: 0.0010\n",
      "Epoch 174/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0394\n",
      "Epoch 174: val_loss improved from 0.03522 to 0.03449, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0394 - val_loss: 0.0345 - learning_rate: 0.0010\n",
      "Epoch 175/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0386\n",
      "Epoch 175: val_loss did not improve from 0.03449\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0386 - val_loss: 0.0378 - learning_rate: 0.0010\n",
      "Epoch 176/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0384\n",
      "Epoch 176: val_loss did not improve from 0.03449\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0385 - val_loss: 0.0412 - learning_rate: 0.0010\n",
      "Epoch 177/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0398\n",
      "Epoch 177: val_loss did not improve from 0.03449\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0397 - val_loss: 0.0395 - learning_rate: 0.0010\n",
      "Epoch 178/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0379\n",
      "Epoch 178: val_loss improved from 0.03449 to 0.03429, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0379 - val_loss: 0.0343 - learning_rate: 0.0010\n",
      "Epoch 179/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0384\n",
      "Epoch 179: val_loss improved from 0.03429 to 0.03337, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0384 - val_loss: 0.0334 - learning_rate: 0.0010\n",
      "Epoch 180/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0380\n",
      "Epoch 180: val_loss did not improve from 0.03337\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0381 - val_loss: 0.0391 - learning_rate: 0.0010\n",
      "Epoch 181/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0373\n",
      "Epoch 181: val_loss did not improve from 0.03337\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0373 - val_loss: 0.0385 - learning_rate: 0.0010\n",
      "Epoch 182/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0374\n",
      "Epoch 182: val_loss did not improve from 0.03337\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0374 - val_loss: 0.0377 - learning_rate: 0.0010\n",
      "Epoch 183/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0369\n",
      "Epoch 183: val_loss did not improve from 0.03337\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0369 - val_loss: 0.0344 - learning_rate: 0.0010\n",
      "Epoch 184/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0373\n",
      "Epoch 184: val_loss improved from 0.03337 to 0.03245, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0373 - val_loss: 0.0324 - learning_rate: 0.0010\n",
      "Epoch 185/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0376\n",
      "Epoch 185: val_loss did not improve from 0.03245\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0376 - val_loss: 0.0390 - learning_rate: 0.0010\n",
      "Epoch 186/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0371\n",
      "Epoch 186: val_loss did not improve from 0.03245\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0371 - val_loss: 0.0397 - learning_rate: 0.0010\n",
      "Epoch 187/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0364\n",
      "Epoch 187: val_loss did not improve from 0.03245\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0365 - val_loss: 0.0362 - learning_rate: 0.0010\n",
      "Epoch 188/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0355\n",
      "Epoch 188: val_loss did not improve from 0.03245\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0356 - val_loss: 0.0330 - learning_rate: 0.0010\n",
      "Epoch 189/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0351\n",
      "Epoch 189: val_loss improved from 0.03245 to 0.03124, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0351 - val_loss: 0.0312 - learning_rate: 0.0010\n",
      "Epoch 190/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0347\n",
      "Epoch 190: val_loss did not improve from 0.03124\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0348 - val_loss: 0.0331 - learning_rate: 0.0010\n",
      "Epoch 191/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0346\n",
      "Epoch 191: val_loss did not improve from 0.03124\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0346 - val_loss: 0.0345 - learning_rate: 0.0010\n",
      "Epoch 192/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0348\n",
      "Epoch 192: val_loss did not improve from 0.03124\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0347 - val_loss: 0.0314 - learning_rate: 0.0010\n",
      "Epoch 193/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0345\n",
      "Epoch 193: val_loss improved from 0.03124 to 0.03103, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0345 - val_loss: 0.0310 - learning_rate: 0.0010\n",
      "Epoch 194/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0341\n",
      "Epoch 194: val_loss improved from 0.03103 to 0.02972, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0341 - val_loss: 0.0297 - learning_rate: 0.0010\n",
      "Epoch 195/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0351\n",
      "Epoch 195: val_loss did not improve from 0.02972\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0351 - val_loss: 0.0314 - learning_rate: 0.0010\n",
      "Epoch 196/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0338\n",
      "Epoch 196: val_loss did not improve from 0.02972\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0338 - val_loss: 0.0322 - learning_rate: 0.0010\n",
      "Epoch 197/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0332\n",
      "Epoch 197: val_loss did not improve from 0.02972\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0333 - val_loss: 0.0304 - learning_rate: 0.0010\n",
      "Epoch 198/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0338\n",
      "Epoch 198: val_loss improved from 0.02972 to 0.02963, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0338 - val_loss: 0.0296 - learning_rate: 0.0010\n",
      "Epoch 199/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0342\n",
      "Epoch 199: val_loss did not improve from 0.02963\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0342 - val_loss: 0.0322 - learning_rate: 0.0010\n",
      "Epoch 200/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0339\n",
      "Epoch 200: val_loss did not improve from 0.02963\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0339 - val_loss: 0.0309 - learning_rate: 0.0010\n",
      "Epoch 201/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0334\n",
      "Epoch 201: val_loss did not improve from 0.02963\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0334 - val_loss: 0.0331 - learning_rate: 0.0010\n",
      "Epoch 202/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0335\n",
      "Epoch 202: val_loss improved from 0.02963 to 0.02861, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0334 - val_loss: 0.0286 - learning_rate: 0.0010\n",
      "Epoch 203/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0331\n",
      "Epoch 203: val_loss did not improve from 0.02861\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0331 - val_loss: 0.0290 - learning_rate: 0.0010\n",
      "Epoch 204/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0321\n",
      "Epoch 204: val_loss did not improve from 0.02861\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0321 - val_loss: 0.0309 - learning_rate: 0.0010\n",
      "Epoch 205/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0326\n",
      "Epoch 205: val_loss did not improve from 0.02861\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0325 - val_loss: 0.0317 - learning_rate: 0.0010\n",
      "Epoch 206/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0329\n",
      "Epoch 206: val_loss did not improve from 0.02861\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0329 - val_loss: 0.0326 - learning_rate: 0.0010\n",
      "Epoch 207/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0317\n",
      "Epoch 207: val_loss did not improve from 0.02861\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0317 - val_loss: 0.0325 - learning_rate: 0.0010\n",
      "Epoch 208/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0305\n",
      "Epoch 208: val_loss did not improve from 0.02861\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0305 - val_loss: 0.0318 - learning_rate: 0.0010\n",
      "Epoch 209/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0302\n",
      "Epoch 209: val_loss did not improve from 0.02861\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0303 - val_loss: 0.0315 - learning_rate: 0.0010\n",
      "Epoch 210/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0309\n",
      "Epoch 210: val_loss did not improve from 0.02861\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0309 - val_loss: 0.0339 - learning_rate: 0.0010\n",
      "Epoch 211/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0306\n",
      "Epoch 211: val_loss did not improve from 0.02861\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0306 - val_loss: 0.0321 - learning_rate: 0.0010\n",
      "Epoch 212/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0302\n",
      "Epoch 212: val_loss improved from 0.02861 to 0.02801, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0303 - val_loss: 0.0280 - learning_rate: 0.0010\n",
      "Epoch 213/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0307\n",
      "Epoch 213: val_loss improved from 0.02801 to 0.02646, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0307 - val_loss: 0.0265 - learning_rate: 0.0010\n",
      "Epoch 214/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0308\n",
      "Epoch 214: val_loss did not improve from 0.02646\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0308 - val_loss: 0.0348 - learning_rate: 0.0010\n",
      "Epoch 215/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0308\n",
      "Epoch 215: val_loss did not improve from 0.02646\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0308 - val_loss: 0.0285 - learning_rate: 0.0010\n",
      "Epoch 216/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0297\n",
      "Epoch 216: val_loss did not improve from 0.02646\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0297 - val_loss: 0.0301 - learning_rate: 0.0010\n",
      "Epoch 217/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0298\n",
      "Epoch 217: val_loss did not improve from 0.02646\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0298 - val_loss: 0.0341 - learning_rate: 0.0010\n",
      "Epoch 218/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0301\n",
      "Epoch 218: val_loss did not improve from 0.02646\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0302 - val_loss: 0.0294 - learning_rate: 0.0010\n",
      "Epoch 219/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0304\n",
      "Epoch 219: val_loss improved from 0.02646 to 0.02505, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0304 - val_loss: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 220/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0294\n",
      "Epoch 220: val_loss did not improve from 0.02505\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0294 - val_loss: 0.0255 - learning_rate: 0.0010\n",
      "Epoch 221/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0295\n",
      "Epoch 221: val_loss did not improve from 0.02505\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0295 - val_loss: 0.0310 - learning_rate: 0.0010\n",
      "Epoch 222/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0295\n",
      "Epoch 222: val_loss did not improve from 0.02505\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0295 - val_loss: 0.0344 - learning_rate: 0.0010\n",
      "Epoch 223/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0300\n",
      "Epoch 223: val_loss improved from 0.02505 to 0.02319, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0300 - val_loss: 0.0232 - learning_rate: 0.0010\n",
      "Epoch 224/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0281\n",
      "Epoch 224: val_loss did not improve from 0.02319\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0281 - val_loss: 0.0264 - learning_rate: 0.0010\n",
      "Epoch 225/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0275\n",
      "Epoch 225: val_loss did not improve from 0.02319\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0275 - val_loss: 0.0258 - learning_rate: 0.0010\n",
      "Epoch 226/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0275\n",
      "Epoch 226: val_loss did not improve from 0.02319\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0275 - val_loss: 0.0237 - learning_rate: 0.0010\n",
      "Epoch 227/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0271\n",
      "Epoch 227: val_loss improved from 0.02319 to 0.02303, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0271 - val_loss: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 228/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0277\n",
      "Epoch 228: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0277 - val_loss: 0.0256 - learning_rate: 0.0010\n",
      "Epoch 229/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0274\n",
      "Epoch 229: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0273 - val_loss: 0.0260 - learning_rate: 0.0010\n",
      "Epoch 230/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0275\n",
      "Epoch 230: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0275 - val_loss: 0.0265 - learning_rate: 0.0010\n",
      "Epoch 231/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0276\n",
      "Epoch 231: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0276 - val_loss: 0.0285 - learning_rate: 0.0010\n",
      "Epoch 232/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0273\n",
      "Epoch 232: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0273 - val_loss: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 233/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0268\n",
      "Epoch 233: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0269 - val_loss: 0.0249 - learning_rate: 0.0010\n",
      "Epoch 234/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0284\n",
      "Epoch 234: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0284 - val_loss: 0.0255 - learning_rate: 0.0010\n",
      "Epoch 235/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0273\n",
      "Epoch 235: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0274 - val_loss: 0.0257 - learning_rate: 0.0010\n",
      "Epoch 236/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0273\n",
      "Epoch 236: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0273 - val_loss: 0.0282 - learning_rate: 0.0010\n",
      "Epoch 237/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0271\n",
      "Epoch 237: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0271 - val_loss: 0.0234 - learning_rate: 0.0010\n",
      "Epoch 238/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0264\n",
      "Epoch 238: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0264 - val_loss: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 239/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0250\n",
      "Epoch 239: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0250 - val_loss: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 240/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0251\n",
      "Epoch 240: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0252 - val_loss: 0.0249 - learning_rate: 0.0010\n",
      "Epoch 241/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0255\n",
      "Epoch 241: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0255 - val_loss: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 242/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0254\n",
      "Epoch 242: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0253 - val_loss: 0.0265 - learning_rate: 0.0010\n",
      "Epoch 243/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0254\n",
      "Epoch 243: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0254 - val_loss: 0.0259 - learning_rate: 0.0010\n",
      "Epoch 244/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0258\n",
      "Epoch 244: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0258 - val_loss: 0.0257 - learning_rate: 0.0010\n",
      "Epoch 245/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0243\n",
      "Epoch 245: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0244 - val_loss: 0.0267 - learning_rate: 0.0010\n",
      "Epoch 246/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0252\n",
      "Epoch 246: val_loss did not improve from 0.02303\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0251 - val_loss: 0.0239 - learning_rate: 0.0010\n",
      "Epoch 247/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0248\n",
      "Epoch 247: val_loss improved from 0.02303 to 0.02212, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0248 - val_loss: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 248/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0249\n",
      "Epoch 248: val_loss did not improve from 0.02212\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0250 - val_loss: 0.0229 - learning_rate: 0.0010\n",
      "Epoch 249/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0263\n",
      "Epoch 249: val_loss did not improve from 0.02212\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0263 - val_loss: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 250/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0254\n",
      "Epoch 250: val_loss did not improve from 0.02212\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0254 - val_loss: 0.0260 - learning_rate: 0.0010\n",
      "Epoch 251/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0251\n",
      "Epoch 251: val_loss did not improve from 0.02212\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0251 - val_loss: 0.0246 - learning_rate: 0.0010\n",
      "Epoch 252/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0246\n",
      "Epoch 252: val_loss did not improve from 0.02212\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0246 - val_loss: 0.0240 - learning_rate: 0.0010\n",
      "Epoch 253/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0249\n",
      "Epoch 253: val_loss improved from 0.02212 to 0.02013, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0249 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 254/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0246\n",
      "Epoch 254: val_loss did not improve from 0.02013\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0245 - val_loss: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 255/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0231\n",
      "Epoch 255: val_loss did not improve from 0.02013\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0231 - val_loss: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 256/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0232\n",
      "Epoch 256: val_loss did not improve from 0.02013\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0232 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 257/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0241\n",
      "Epoch 257: val_loss did not improve from 0.02013\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0242 - val_loss: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 258/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0247\n",
      "Epoch 258: val_loss did not improve from 0.02013\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0247 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 259/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0243\n",
      "Epoch 259: val_loss did not improve from 0.02013\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0242 - val_loss: 0.0206 - learning_rate: 0.0010\n",
      "Epoch 260/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0237\n",
      "Epoch 260: val_loss improved from 0.02013 to 0.01932, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0237 - val_loss: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 261/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0233\n",
      "Epoch 261: val_loss did not improve from 0.01932\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0234 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 262/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0242\n",
      "Epoch 262: val_loss improved from 0.01932 to 0.01866, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0242 - val_loss: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 263/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0237\n",
      "Epoch 263: val_loss did not improve from 0.01866\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0237 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 264/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0235\n",
      "Epoch 264: val_loss improved from 0.01866 to 0.01851, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0235 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 265/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0231\n",
      "Epoch 265: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0231 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 266/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0229\n",
      "Epoch 266: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0229 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 267/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0230\n",
      "Epoch 267: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0230 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 268/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0227\n",
      "Epoch 268: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0227 - val_loss: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 269/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0237\n",
      "Epoch 269: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0237 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 270/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0239\n",
      "Epoch 270: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0238 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 271/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0234\n",
      "Epoch 271: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0234 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 272/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0219\n",
      "Epoch 272: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0219 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 273/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0220\n",
      "Epoch 273: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0220 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 274/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0218\n",
      "Epoch 274: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0218 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 275/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0215\n",
      "Epoch 275: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0215 - val_loss: 0.0265 - learning_rate: 0.0010\n",
      "Epoch 276/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0214\n",
      "Epoch 276: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0215 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 277/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0224\n",
      "Epoch 277: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0224 - val_loss: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 278/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0219\n",
      "Epoch 278: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0220 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 279/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0239\n",
      "Epoch 279: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0240 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 280/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0244\n",
      "Epoch 280: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0244 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 281/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0236\n",
      "Epoch 281: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0236 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 282/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0222\n",
      "Epoch 282: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0222 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 283/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0230\n",
      "Epoch 283: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0229 - val_loss: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 284/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0208\n",
      "Epoch 284: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0208 - val_loss: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 285/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0209\n",
      "Epoch 285: val_loss did not improve from 0.01851\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.0209 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 286/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0212\n",
      "Epoch 286: val_loss improved from 0.01851 to 0.01641, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0212 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 287/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0207\n",
      "Epoch 287: val_loss did not improve from 0.01641\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0208 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 288/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0192\n",
      "Epoch 288: val_loss did not improve from 0.01641\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0193 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 289/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0202\n",
      "Epoch 289: val_loss did not improve from 0.01641\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0203 - val_loss: 0.0236 - learning_rate: 0.0010\n",
      "Epoch 290/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0214\n",
      "Epoch 290: val_loss did not improve from 0.01641\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0214 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 291/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0199\n",
      "Epoch 291: val_loss improved from 0.01641 to 0.01619, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0199 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 292/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0202\n",
      "Epoch 292: val_loss did not improve from 0.01619\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0201 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 293/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0211\n",
      "Epoch 293: val_loss did not improve from 0.01619\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0211 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 294/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0195\n",
      "Epoch 294: val_loss did not improve from 0.01619\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0196 - val_loss: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 295/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0193\n",
      "Epoch 295: val_loss did not improve from 0.01619\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0194 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 296/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0195\n",
      "Epoch 296: val_loss improved from 0.01619 to 0.01613, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0194 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 297/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0194\n",
      "Epoch 297: val_loss did not improve from 0.01613\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0194 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 298/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0206\n",
      "Epoch 298: val_loss did not improve from 0.01613\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0206 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 299/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0212\n",
      "Epoch 299: val_loss did not improve from 0.01613\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0212 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 300/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0200\n",
      "Epoch 300: val_loss did not improve from 0.01613\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0200 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 301/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0197\n",
      "Epoch 301: val_loss did not improve from 0.01613\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0197 - val_loss: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 302/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0189\n",
      "Epoch 302: val_loss did not improve from 0.01613\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0189 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 303/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0191\n",
      "Epoch 303: val_loss improved from 0.01613 to 0.01539, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0191 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 304/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0191\n",
      "Epoch 304: val_loss did not improve from 0.01539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0191 - val_loss: 0.0232 - learning_rate: 0.0010\n",
      "Epoch 305/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0190\n",
      "Epoch 305: val_loss did not improve from 0.01539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0191 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 306/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0185\n",
      "Epoch 306: val_loss did not improve from 0.01539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0186 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 307/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0196\n",
      "Epoch 307: val_loss did not improve from 0.01539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0196 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 308/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0191\n",
      "Epoch 308: val_loss did not improve from 0.01539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0191 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 309/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0203\n",
      "Epoch 309: val_loss did not improve from 0.01539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0203 - val_loss: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 310/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0198\n",
      "Epoch 310: val_loss did not improve from 0.01539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0198 - val_loss: 0.0258 - learning_rate: 0.0010\n",
      "Epoch 311/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0192\n",
      "Epoch 311: val_loss did not improve from 0.01539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0192 - val_loss: 0.0232 - learning_rate: 0.0010\n",
      "Epoch 312/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0194\n",
      "Epoch 312: val_loss did not improve from 0.01539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0195 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 313/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0202\n",
      "Epoch 313: val_loss did not improve from 0.01539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0202 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 314/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0192\n",
      "Epoch 314: val_loss did not improve from 0.01539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0192 - val_loss: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 315/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0201\n",
      "Epoch 315: val_loss did not improve from 0.01539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0201 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 316/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0188\n",
      "Epoch 316: val_loss improved from 0.01539 to 0.01468, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0189 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 317/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0187\n",
      "Epoch 317: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0187 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 318/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0174\n",
      "Epoch 318: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0175 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 319/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0182\n",
      "Epoch 319: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0182 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 320/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0192\n",
      "Epoch 320: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0192 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 321/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0185\n",
      "Epoch 321: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0186 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 322/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0195\n",
      "Epoch 322: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0195 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 323/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0198\n",
      "Epoch 323: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0198 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 324/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0191\n",
      "Epoch 324: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0192 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 325/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0191\n",
      "Epoch 325: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0191 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 326/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0193\n",
      "Epoch 326: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0192 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 327/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0192\n",
      "Epoch 327: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0193 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 328/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0205\n",
      "Epoch 328: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0205 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 329/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0189\n",
      "Epoch 329: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0189 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 330/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0180\n",
      "Epoch 330: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0181 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 331/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0191\n",
      "Epoch 331: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0191 - val_loss: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 332/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0187\n",
      "Epoch 332: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0187 - val_loss: 0.0240 - learning_rate: 0.0010\n",
      "Epoch 333/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0187\n",
      "Epoch 333: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0187 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 334/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0175\n",
      "Epoch 334: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0175 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 335/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0170\n",
      "Epoch 335: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0170 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 336/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0165\n",
      "Epoch 336: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0165 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 337/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0167\n",
      "Epoch 337: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0167 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 338/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0168\n",
      "Epoch 338: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0169 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 339/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0178\n",
      "Epoch 339: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0178 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 340/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0188\n",
      "Epoch 340: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0187 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 341/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0174\n",
      "Epoch 341: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0174 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 342/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0166\n",
      "Epoch 342: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0167 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 343/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0173\n",
      "Epoch 343: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0173 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 344/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0163\n",
      "Epoch 344: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0163 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 345/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0159\n",
      "Epoch 345: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0160 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 346/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0170\n",
      "Epoch 346: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0170 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 347/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0177\n",
      "Epoch 347: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0177 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 348/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0168\n",
      "Epoch 348: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0168 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 349/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0166\n",
      "Epoch 349: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0167 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 350/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0168\n",
      "Epoch 350: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0169 - val_loss: 0.0246 - learning_rate: 0.0010\n",
      "Epoch 351/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0171\n",
      "Epoch 351: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0171 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 352/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0174\n",
      "Epoch 352: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0174 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 353/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0170\n",
      "Epoch 353: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0170 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 354/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0164\n",
      "Epoch 354: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0164 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 355/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0166\n",
      "Epoch 355: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0166 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 356/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0164\n",
      "Epoch 356: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0164 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 357/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0164\n",
      "Epoch 357: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0164 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 358/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0160\n",
      "Epoch 358: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0159 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 359/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0156\n",
      "Epoch 359: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0156 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 360/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0153\n",
      "Epoch 360: val_loss did not improve from 0.01468\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0153 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 361/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0173\n",
      "Epoch 361: val_loss improved from 0.01468 to 0.01451, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0172 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 362/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0159\n",
      "Epoch 362: val_loss did not improve from 0.01451\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0159 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 363/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0155\n",
      "Epoch 363: val_loss did not improve from 0.01451\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0155 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 364/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0166\n",
      "Epoch 364: val_loss did not improve from 0.01451\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0166 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 365/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0166\n",
      "Epoch 365: val_loss did not improve from 0.01451\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0166 - val_loss: 0.0229 - learning_rate: 0.0010\n",
      "Epoch 366/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0165\n",
      "Epoch 366: val_loss did not improve from 0.01451\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0165 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 367/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0163\n",
      "Epoch 367: val_loss did not improve from 0.01451\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0164 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 368/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0166\n",
      "Epoch 368: val_loss did not improve from 0.01451\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0166 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 369/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0149\n",
      "Epoch 369: val_loss did not improve from 0.01451\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0150 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 370/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0154\n",
      "Epoch 370: val_loss did not improve from 0.01451\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0154 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 371/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0162\n",
      "Epoch 371: val_loss did not improve from 0.01451\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0162 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 372/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0155\n",
      "Epoch 372: val_loss improved from 0.01451 to 0.01374, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0155 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 373/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0160\n",
      "Epoch 373: val_loss did not improve from 0.01374\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0160 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 374/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0156\n",
      "Epoch 374: val_loss did not improve from 0.01374\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0156 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 375/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0151\n",
      "Epoch 375: val_loss did not improve from 0.01374\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0152 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 376/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0164\n",
      "Epoch 376: val_loss did not improve from 0.01374\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0164 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 377/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0164\n",
      "Epoch 377: val_loss did not improve from 0.01374\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0163 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 378/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0160\n",
      "Epoch 378: val_loss did not improve from 0.01374\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0160 - val_loss: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 379/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0150\n",
      "Epoch 379: val_loss did not improve from 0.01374\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0150 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 380/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0152\n",
      "Epoch 380: val_loss did not improve from 0.01374\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0152 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 381/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0152\n",
      "Epoch 381: val_loss did not improve from 0.01374\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0152 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 382/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0161\n",
      "Epoch 382: val_loss did not improve from 0.01374\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0161 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 383/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0157\n",
      "Epoch 383: val_loss did not improve from 0.01374\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0157 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 384/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0149\n",
      "Epoch 384: val_loss improved from 0.01374 to 0.01261, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0150 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 385/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0174\n",
      "Epoch 385: val_loss did not improve from 0.01261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0175 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 386/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0172\n",
      "Epoch 386: val_loss did not improve from 0.01261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0172 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 387/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0170\n",
      "Epoch 387: val_loss did not improve from 0.01261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0170 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 388/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0154\n",
      "Epoch 388: val_loss did not improve from 0.01261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0154 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 389/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0149\n",
      "Epoch 389: val_loss did not improve from 0.01261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0150 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 390/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0150\n",
      "Epoch 390: val_loss did not improve from 0.01261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0150 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 391/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0150\n",
      "Epoch 391: val_loss did not improve from 0.01261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0150 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 392/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0146\n",
      "Epoch 392: val_loss did not improve from 0.01261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0146 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 393/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0150\n",
      "Epoch 393: val_loss did not improve from 0.01261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0150 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 394/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0152\n",
      "Epoch 394: val_loss did not improve from 0.01261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0152 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 395/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0162\n",
      "Epoch 395: val_loss did not improve from 0.01261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0162 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 396/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0152\n",
      "Epoch 396: val_loss did not improve from 0.01261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0152 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 397/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0149\n",
      "Epoch 397: val_loss did not improve from 0.01261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0150 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 398/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0159\n",
      "Epoch 398: val_loss did not improve from 0.01261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0159 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 399/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0151\n",
      "Epoch 399: val_loss did not improve from 0.01261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0151 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 400/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0154\n",
      "Epoch 400: val_loss did not improve from 0.01261\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0154 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 401/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0138\n",
      "Epoch 401: val_loss improved from 0.01261 to 0.01252, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0138 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 402/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0155\n",
      "Epoch 402: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0156 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 403/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0152\n",
      "Epoch 403: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0152 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 404/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0164\n",
      "Epoch 404: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0164 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 405/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0160\n",
      "Epoch 405: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0161 - val_loss: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 406/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0165\n",
      "Epoch 406: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0165 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 407/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0156\n",
      "Epoch 407: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0156 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 408/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0150\n",
      "Epoch 408: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0150 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 409/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0147\n",
      "Epoch 409: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0147 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 410/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0145\n",
      "Epoch 410: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0145 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 411/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0148\n",
      "Epoch 411: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0148 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 412/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0143\n",
      "Epoch 412: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0144 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 413/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0148\n",
      "Epoch 413: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0148 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 414/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0138\n",
      "Epoch 414: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0138 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 415/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0146\n",
      "Epoch 415: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0146 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 416/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0142\n",
      "Epoch 416: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0143 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 417/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0137\n",
      "Epoch 417: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0137 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 418/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0154\n",
      "Epoch 418: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0154 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 419/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0139\n",
      "Epoch 419: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0139 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 420/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0146\n",
      "Epoch 420: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0146 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 421/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0150\n",
      "Epoch 421: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0150 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 422/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0151\n",
      "Epoch 422: val_loss did not improve from 0.01252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0151 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 423/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0142\n",
      "Epoch 423: val_loss improved from 0.01252 to 0.01219, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0143 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 424/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0143\n",
      "Epoch 424: val_loss did not improve from 0.01219\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0143 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 425/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0137\n",
      "Epoch 425: val_loss did not improve from 0.01219\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0138 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 426/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0132\n",
      "Epoch 426: val_loss did not improve from 0.01219\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0132 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 427/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0129\n",
      "Epoch 427: val_loss did not improve from 0.01219\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0130 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 428/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0145\n",
      "Epoch 428: val_loss did not improve from 0.01219\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0145 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 429/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0138\n",
      "Epoch 429: val_loss did not improve from 0.01219\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0138 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 430/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0140\n",
      "Epoch 430: val_loss did not improve from 0.01219\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0140 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 431/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0137\n",
      "Epoch 431: val_loss did not improve from 0.01219\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0137 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 432/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0148\n",
      "Epoch 432: val_loss did not improve from 0.01219\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0148 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 433/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0144\n",
      "Epoch 433: val_loss did not improve from 0.01219\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0145 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 434/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0139\n",
      "Epoch 434: val_loss did not improve from 0.01219\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0139 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 435/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0136\n",
      "Epoch 435: val_loss did not improve from 0.01219\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0136 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 436/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0135\n",
      "Epoch 436: val_loss did not improve from 0.01219\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0136 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 437/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0143\n",
      "Epoch 437: val_loss did not improve from 0.01219\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0143 - val_loss: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 438/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0143\n",
      "Epoch 438: val_loss did not improve from 0.01219\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0143 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 439/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0140\n",
      "Epoch 439: val_loss improved from 0.01219 to 0.01151, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0141 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 440/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0142\n",
      "Epoch 440: val_loss did not improve from 0.01151\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0143 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 441/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0152\n",
      "Epoch 441: val_loss did not improve from 0.01151\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0152 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 442/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0145\n",
      "Epoch 442: val_loss did not improve from 0.01151\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0145 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 443/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0138\n",
      "Epoch 443: val_loss did not improve from 0.01151\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0138 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 444/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0141\n",
      "Epoch 444: val_loss did not improve from 0.01151\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0141 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 445/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0146\n",
      "Epoch 445: val_loss did not improve from 0.01151\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0146 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 446/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0136\n",
      "Epoch 446: val_loss did not improve from 0.01151\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0136 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 447/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0126\n",
      "Epoch 447: val_loss improved from 0.01151 to 0.01147, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0127 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 448/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0141\n",
      "Epoch 448: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0141 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 449/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0139\n",
      "Epoch 449: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0139 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 450/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0140\n",
      "Epoch 450: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0139 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 451/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0133\n",
      "Epoch 451: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0133 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 452/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0141\n",
      "Epoch 452: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0141 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 453/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0141\n",
      "Epoch 453: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0142 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 454/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0150\n",
      "Epoch 454: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0150 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 455/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0147\n",
      "Epoch 455: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0147 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 456/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0134\n",
      "Epoch 456: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0134 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 457/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0134\n",
      "Epoch 457: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0134 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 458/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0133\n",
      "Epoch 458: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0134 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 459/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0132\n",
      "Epoch 459: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0133 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 460/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0129\n",
      "Epoch 460: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0129 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 461/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0130\n",
      "Epoch 461: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0130 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 462/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0124\n",
      "Epoch 462: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0124 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 463/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0132\n",
      "Epoch 463: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0132 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 464/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0133\n",
      "Epoch 464: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0133 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 465/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0128\n",
      "Epoch 465: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0129 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 466/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0130\n",
      "Epoch 466: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0131 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 467/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0147\n",
      "Epoch 467: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0147 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 468/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0140\n",
      "Epoch 468: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0139 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 469/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0135\n",
      "Epoch 469: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0135 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 470/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0130\n",
      "Epoch 470: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0130 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 471/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0132\n",
      "Epoch 471: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0132 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 472/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0135\n",
      "Epoch 472: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0135 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 473/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0136\n",
      "Epoch 473: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0136 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 474/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0137\n",
      "Epoch 474: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0137 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 475/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0133\n",
      "Epoch 475: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0133 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 476/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0128\n",
      "Epoch 476: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0128 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 477/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0130\n",
      "Epoch 477: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0130 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 478/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0135\n",
      "Epoch 478: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0135 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 479/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0152\n",
      "Epoch 479: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0151 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 480/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0137\n",
      "Epoch 480: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0137 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 481/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0129\n",
      "Epoch 481: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0129 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 482/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0125\n",
      "Epoch 482: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0125 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 483/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0127\n",
      "Epoch 483: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0127 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 484/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0144\n",
      "Epoch 484: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0144 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 485/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0144\n",
      "Epoch 485: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0144 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 486/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0130\n",
      "Epoch 486: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0130 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 487/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0126\n",
      "Epoch 487: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0127 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 488/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0138\n",
      "Epoch 488: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0138 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 489/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0139\n",
      "Epoch 489: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0139 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 490/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0150\n",
      "Epoch 490: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0150 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 491/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0140\n",
      "Epoch 491: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0140 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 492/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0141\n",
      "Epoch 492: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0141 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 493/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0140\n",
      "Epoch 493: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0140 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 494/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0129\n",
      "Epoch 494: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0130 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 495/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0131\n",
      "Epoch 495: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0131 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 496/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0130\n",
      "Epoch 496: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0130 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 497/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0129\n",
      "Epoch 497: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0130 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 498/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0130\n",
      "Epoch 498: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0130 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 499/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0124\n",
      "Epoch 499: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0124 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 500/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0131\n",
      "Epoch 500: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0131 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 501/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0130\n",
      "Epoch 501: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0130 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 502/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0133\n",
      "Epoch 502: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0133 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 503/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0123\n",
      "Epoch 503: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0123 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 504/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0140\n",
      "Epoch 504: val_loss did not improve from 0.01147\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0141 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 505/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0133\n",
      "Epoch 505: val_loss improved from 0.01147 to 0.01076, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0134 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 506/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0149\n",
      "Epoch 506: val_loss did not improve from 0.01076\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0148 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 507/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0132\n",
      "Epoch 507: val_loss did not improve from 0.01076\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0132 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 508/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0136\n",
      "Epoch 508: val_loss did not improve from 0.01076\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0136 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 509/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0126\n",
      "Epoch 509: val_loss did not improve from 0.01076\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0126 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 510/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0125\n",
      "Epoch 510: val_loss did not improve from 0.01076\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0125 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 511/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0121\n",
      "Epoch 511: val_loss did not improve from 0.01076\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0121 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 512/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0115\n",
      "Epoch 512: val_loss did not improve from 0.01076\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0116 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 513/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0127\n",
      "Epoch 513: val_loss did not improve from 0.01076\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0127 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 514/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0130\n",
      "Epoch 514: val_loss did not improve from 0.01076\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0130 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 515/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0128\n",
      "Epoch 515: val_loss did not improve from 0.01076\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0128 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 516/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0123\n",
      "Epoch 516: val_loss improved from 0.01076 to 0.01034, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0124 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 517/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0130\n",
      "Epoch 517: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0130 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 518/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0125\n",
      "Epoch 518: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0126 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 519/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0128\n",
      "Epoch 519: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0128 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 520/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0151\n",
      "Epoch 520: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0152 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 521/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0150\n",
      "Epoch 521: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0151 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 522/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0148\n",
      "Epoch 522: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0148 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 523/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0138\n",
      "Epoch 523: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0138 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 524/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0149\n",
      "Epoch 524: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0148 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 525/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0142\n",
      "Epoch 525: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0145 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 526/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0400\n",
      "Epoch 526: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0393 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 527/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0250\n",
      "Epoch 527: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0250 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 528/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0236\n",
      "Epoch 528: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0235 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 529/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0213\n",
      "Epoch 529: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0212 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 530/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0177\n",
      "Epoch 530: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0177 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 531/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0180\n",
      "Epoch 531: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0180 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 532/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0162\n",
      "Epoch 532: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0162 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 533/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0157\n",
      "Epoch 533: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0158 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 534/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0159\n",
      "Epoch 534: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0159 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 535/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0151\n",
      "Epoch 535: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0151 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 536/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0149\n",
      "Epoch 536: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0149 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 537/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0151\n",
      "Epoch 537: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0151 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 538/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0158\n",
      "Epoch 538: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0158 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 539/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0145\n",
      "Epoch 539: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0145 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 540/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0141\n",
      "Epoch 540: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0141 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 541/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0142\n",
      "Epoch 541: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0142 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 542/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0142\n",
      "Epoch 542: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0142 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 543/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0143\n",
      "Epoch 543: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0143 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 544/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0137\n",
      "Epoch 544: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0138 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 545/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0134\n",
      "Epoch 545: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0134 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 546/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0123\n",
      "Epoch 546: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0123 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 547/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0129\n",
      "Epoch 547: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0129 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 548/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0120\n",
      "Epoch 548: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0121 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 549/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0119\n",
      "Epoch 549: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0119 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 550/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0119\n",
      "Epoch 550: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0120 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 551/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0129\n",
      "Epoch 551: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0129 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 552/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0126\n",
      "Epoch 552: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0127 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 553/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0120\n",
      "Epoch 553: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0120 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 554/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0121\n",
      "Epoch 554: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0121 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 555/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0125\n",
      "Epoch 555: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0125 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 556/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0127\n",
      "Epoch 556: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0127 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 557/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0119\n",
      "Epoch 557: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0120 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 558/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0126\n",
      "Epoch 558: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0126 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 559/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0122\n",
      "Epoch 559: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0122 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 560/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0124\n",
      "Epoch 560: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0124 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 561/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0128\n",
      "Epoch 561: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0128 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 562/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0131\n",
      "Epoch 562: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0132 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 563/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0134\n",
      "Epoch 563: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0134 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 564/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0155\n",
      "Epoch 564: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0155 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 565/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0136\n",
      "Epoch 565: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0136 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 566/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0133\n",
      "Epoch 566: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0133 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 567/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0126\n",
      "Epoch 567: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0126 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 568/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0120\n",
      "Epoch 568: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0120 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 569/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0121\n",
      "Epoch 569: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0122 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 570/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0124\n",
      "Epoch 570: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0124 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 571/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0124\n",
      "Epoch 571: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0124 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 572/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0129\n",
      "Epoch 572: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0128 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 573/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0116\n",
      "Epoch 573: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0116 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 574/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0114\n",
      "Epoch 574: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0114 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 575/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0116\n",
      "Epoch 575: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0117 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 576/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0131\n",
      "Epoch 576: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0131 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 577/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0114\n",
      "Epoch 577: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0115 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 578/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0118\n",
      "Epoch 578: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0118 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 579/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0132\n",
      "Epoch 579: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0132 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 580/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0122\n",
      "Epoch 580: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0121 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 581/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0125\n",
      "Epoch 581: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0125 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 582/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0115\n",
      "Epoch 582: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0115 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 583/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0123\n",
      "Epoch 583: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0123 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 584/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0114\n",
      "Epoch 584: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0115 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 585/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0117\n",
      "Epoch 585: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0117 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 586/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0120\n",
      "Epoch 586: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0120 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 587/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0107\n",
      "Epoch 587: val_loss did not improve from 0.01034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0108 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 588/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0125\n",
      "Epoch 588: val_loss improved from 0.01034 to 0.01030, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0125 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 589/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0118\n",
      "Epoch 589: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0118 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 590/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0115\n",
      "Epoch 590: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0116 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 591/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0116\n",
      "Epoch 591: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0116 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 592/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0120\n",
      "Epoch 592: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0121 - val_loss: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 593/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0125\n",
      "Epoch 593: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0126 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 594/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0125\n",
      "Epoch 594: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0126 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 595/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0141\n",
      "Epoch 595: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0141 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 596/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0137\n",
      "Epoch 596: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0136 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 597/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0122\n",
      "Epoch 597: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0122 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 598/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0120\n",
      "Epoch 598: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0121 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 599/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0187\n",
      "Epoch 599: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0190 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 600/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0343\n",
      "Epoch 600: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0348 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 601/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0380\n",
      "Epoch 601: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.0380 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 602/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0322\n",
      "Epoch 602: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0322 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 603/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0284\n",
      "Epoch 603: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0283 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 604/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0235\n",
      "Epoch 604: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0235 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 605/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0204\n",
      "Epoch 605: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0204 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 606/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0184\n",
      "Epoch 606: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0184 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 607/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0180\n",
      "Epoch 607: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0180 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 608/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0165\n",
      "Epoch 608: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0165 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 609/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0153\n",
      "Epoch 609: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0153 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 610/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0155\n",
      "Epoch 610: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - loss: 0.0155 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 611/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0151\n",
      "Epoch 611: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0151 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 612/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0141\n",
      "Epoch 612: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0142 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 613/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0142\n",
      "Epoch 613: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0142 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 614/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0147\n",
      "Epoch 614: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0147 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 615/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0132\n",
      "Epoch 615: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0133 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 616/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0136\n",
      "Epoch 616: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0136 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 617/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0130\n",
      "Epoch 617: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0131 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 618/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0131\n",
      "Epoch 618: val_loss did not improve from 0.01030\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0130 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 619/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0129\n",
      "Epoch 619: val_loss improved from 0.01030 to 0.00994, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0129 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 620/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0121\n",
      "Epoch 620: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0121 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 621/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0128\n",
      "Epoch 621: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0128 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 622/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0132\n",
      "Epoch 622: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0132 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 623/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0135\n",
      "Epoch 623: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0136 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 624/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0134\n",
      "Epoch 624: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0134 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 625/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0126\n",
      "Epoch 625: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0127 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 626/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0132\n",
      "Epoch 626: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0131 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 627/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0129\n",
      "Epoch 627: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.0129 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 628/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0128\n",
      "Epoch 628: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.0128 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 629/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0127\n",
      "Epoch 629: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.0128 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 630/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0117\n",
      "Epoch 630: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0118 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 631/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0115\n",
      "Epoch 631: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - loss: 0.0115 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 632/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0130\n",
      "Epoch 632: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0129 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 633/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0125\n",
      "Epoch 633: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - loss: 0.0125 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 634/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0121\n",
      "Epoch 634: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0121 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 635/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0112\n",
      "Epoch 635: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0113 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 636/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0111\n",
      "Epoch 636: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0111 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 637/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0117\n",
      "Epoch 637: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.0117 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 638/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0117\n",
      "Epoch 638: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0117 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 639/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0123\n",
      "Epoch 639: val_loss did not improve from 0.00994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - loss: 0.0123 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 640/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0116\n",
      "Epoch 640: val_loss improved from 0.00994 to 0.00944, saving model to ./result_folder_no_misc/lstm_ts_8.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0116 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 641/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0118\n",
      "Epoch 641: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0119 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 642/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0125\n",
      "Epoch 642: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - loss: 0.0125 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 643/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0116\n",
      "Epoch 643: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0117 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 644/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0117\n",
      "Epoch 644: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0117 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 645/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0107\n",
      "Epoch 645: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0107 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 646/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0109\n",
      "Epoch 646: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0109 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 647/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0105\n",
      "Epoch 647: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0105 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 648/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0106\n",
      "Epoch 648: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0107 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 649/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0106\n",
      "Epoch 649: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0107 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 650/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0116\n",
      "Epoch 650: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0116 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 651/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0108\n",
      "Epoch 651: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0108 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 652/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0106\n",
      "Epoch 652: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0106 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 653/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0104\n",
      "Epoch 653: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0104 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 654/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0108\n",
      "Epoch 654: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0108 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 655/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0108\n",
      "Epoch 655: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0108 - val_loss: 0.0097 - learning_rate: 0.0010\n",
      "Epoch 656/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0109\n",
      "Epoch 656: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0109 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 657/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0117\n",
      "Epoch 657: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0117 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 658/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0143\n",
      "Epoch 658: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0143 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 659/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0129\n",
      "Epoch 659: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0129 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 660/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0120\n",
      "Epoch 660: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0120 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 661/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0122\n",
      "Epoch 661: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0122 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 662/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0117\n",
      "Epoch 662: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0117 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 663/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0110\n",
      "Epoch 663: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0110 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 664/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0108\n",
      "Epoch 664: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - loss: 0.0108 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 665/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0167\n",
      "Epoch 665: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0175 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 666/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0583\n",
      "Epoch 666: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0587 - val_loss: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 667/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0524\n",
      "Epoch 667: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 166ms/step - loss: 0.0524 - val_loss: 0.0306 - learning_rate: 0.0010\n",
      "Epoch 668/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0481\n",
      "Epoch 668: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0479 - val_loss: 0.0308 - learning_rate: 0.0010\n",
      "Epoch 669/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0401\n",
      "Epoch 669: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0398 - val_loss: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 670/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0317\n",
      "Epoch 670: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0316 - val_loss: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 671/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0287\n",
      "Epoch 671: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0287 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 672/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0269\n",
      "Epoch 672: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0268 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 673/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0240\n",
      "Epoch 673: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0240 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 674/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0223\n",
      "Epoch 674: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0223 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 675/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0215\n",
      "Epoch 675: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0214 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 676/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0203\n",
      "Epoch 676: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0204 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 677/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0195\n",
      "Epoch 677: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0196 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 678/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0187\n",
      "Epoch 678: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0187 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 679/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0181\n",
      "Epoch 679: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0180 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 680/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0177\n",
      "Epoch 680: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0177 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 681/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0171\n",
      "Epoch 681: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0171 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 682/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0168\n",
      "Epoch 682: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0169 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 683/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0163\n",
      "Epoch 683: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0163 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 684/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0161\n",
      "Epoch 684: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0161 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 685/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0159\n",
      "Epoch 685: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0159 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 686/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0153\n",
      "Epoch 686: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0153 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 687/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0154\n",
      "Epoch 687: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0154 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 688/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0146\n",
      "Epoch 688: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0146 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 689/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0154\n",
      "Epoch 689: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0154 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 690/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0152\n",
      "Epoch 690: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0152 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 691/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0148\n",
      "Epoch 691: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0148 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 692/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0147\n",
      "Epoch 692: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0147 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 693/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0144\n",
      "Epoch 693: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0144 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 694/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0135\n",
      "Epoch 694: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0135 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 695/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0139\n",
      "Epoch 695: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0139 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 696/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0136\n",
      "Epoch 696: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0137 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 697/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0140\n",
      "Epoch 697: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0140 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 698/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0135\n",
      "Epoch 698: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - loss: 0.0135 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 699/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0134\n",
      "Epoch 699: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.0134 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 700/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0136\n",
      "Epoch 700: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 0.0136 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 701/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0135\n",
      "Epoch 701: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0135 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 702/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0139\n",
      "Epoch 702: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0139 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 703/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0143\n",
      "Epoch 703: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0143 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 704/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0142\n",
      "Epoch 704: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0142 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 705/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0135\n",
      "Epoch 705: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0134 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 706/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0129\n",
      "Epoch 706: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0129 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 707/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0125\n",
      "Epoch 707: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0125 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 708/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0125\n",
      "Epoch 708: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0125 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 709/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0126\n",
      "Epoch 709: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0126 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 710/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0122\n",
      "Epoch 710: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0122 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 711/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0123\n",
      "Epoch 711: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0123 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 712/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0114\n",
      "Epoch 712: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0115 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 713/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0125\n",
      "Epoch 713: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0125 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 714/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0122\n",
      "Epoch 714: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0122 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 715/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0116\n",
      "Epoch 715: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0116 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 716/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0118\n",
      "Epoch 716: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0118 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 717/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0121\n",
      "Epoch 717: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0121 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 718/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0118\n",
      "Epoch 718: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0118 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 719/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0118\n",
      "Epoch 719: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0118 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 720/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0112\n",
      "Epoch 720: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0112 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 721/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0116\n",
      "Epoch 721: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - loss: 0.0116 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 722/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0113\n",
      "Epoch 722: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0113 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 723/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0120\n",
      "Epoch 723: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0120 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 724/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0127\n",
      "Epoch 724: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0127 - val_loss: 0.0103 - learning_rate: 0.0010\n",
      "Epoch 725/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0118\n",
      "Epoch 725: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0118 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 726/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0112\n",
      "Epoch 726: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0112 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 727/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0122\n",
      "Epoch 727: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0122 - val_loss: 0.0104 - learning_rate: 0.0010\n",
      "Epoch 728/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0130\n",
      "Epoch 728: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0130 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 729/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0168\n",
      "Epoch 729: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0168 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 730/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0180\n",
      "Epoch 730: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0180 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 731/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0168\n",
      "Epoch 731: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0168 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 732/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0147\n",
      "Epoch 732: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0146 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 733/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0137\n",
      "Epoch 733: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0137 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 734/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0132\n",
      "Epoch 734: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0132 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 735/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0123\n",
      "Epoch 735: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0123 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 736/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0119\n",
      "Epoch 736: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0120 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 737/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0121\n",
      "Epoch 737: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0121 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 738/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0129\n",
      "Epoch 738: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0129 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 739/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0124\n",
      "Epoch 739: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0124 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 740/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0116\n",
      "Epoch 740: val_loss did not improve from 0.00944\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0116 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 740: early stopping\n",
      "Restoring model weights from the end of the best epoch: 640.\n",
      "EUA\n",
      "0.23773495969268635\n",
      "Oil\n",
      "0.17397727240332103\n",
      "Coal\n",
      "0.03535992504890327\n",
      "NG\n",
      "0.08478885897872296\n",
      "USEU\n",
      "0.22140802301348614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 180/180 [01:19<00:00,  2.26it/s]\n",
      "100%|| 180/180 [04:07<00:00,  1.38s/it]\n",
      "/home/honggeunjo/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 2.2493\n",
      "Epoch 1: val_loss improved from inf to 0.76560, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 285ms/step - loss: 2.1844 - val_loss: 0.7656 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.6521\n",
      "Epoch 2: val_loss improved from 0.76560 to 0.40304, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.6486 - val_loss: 0.4030 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.4943\n",
      "Epoch 3: val_loss improved from 0.40304 to 0.39903, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.4932 - val_loss: 0.3990 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.4458\n",
      "Epoch 4: val_loss improved from 0.39903 to 0.37990, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.4450 - val_loss: 0.3799 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.4124\n",
      "Epoch 5: val_loss improved from 0.37990 to 0.36641, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.4124 - val_loss: 0.3664 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.4001\n",
      "Epoch 6: val_loss improved from 0.36641 to 0.35651, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.4000 - val_loss: 0.3565 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.3907\n",
      "Epoch 7: val_loss did not improve from 0.35651\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.3907 - val_loss: 0.3600 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.3826\n",
      "Epoch 8: val_loss improved from 0.35651 to 0.35597, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.3824 - val_loss: 0.3560 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.3775\n",
      "Epoch 9: val_loss improved from 0.35597 to 0.34492, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.3772 - val_loss: 0.3449 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.3662\n",
      "Epoch 10: val_loss did not improve from 0.34492\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.3661 - val_loss: 0.3472 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.3589\n",
      "Epoch 11: val_loss improved from 0.34492 to 0.33066, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.3588 - val_loss: 0.3307 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.3510\n",
      "Epoch 12: val_loss did not improve from 0.33066\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.3509 - val_loss: 0.3311 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.3438\n",
      "Epoch 13: val_loss improved from 0.33066 to 0.31483, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.3437 - val_loss: 0.3148 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.3370\n",
      "Epoch 14: val_loss improved from 0.31483 to 0.30967, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.3371 - val_loss: 0.3097 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.3336\n",
      "Epoch 15: val_loss did not improve from 0.30967\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.3334 - val_loss: 0.3126 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.3256\n",
      "Epoch 16: val_loss did not improve from 0.30967\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.3254 - val_loss: 0.3122 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.3185\n",
      "Epoch 17: val_loss improved from 0.30967 to 0.29952, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.3183 - val_loss: 0.2995 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.3123\n",
      "Epoch 18: val_loss improved from 0.29952 to 0.29243, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.3122 - val_loss: 0.2924 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.3048\n",
      "Epoch 19: val_loss improved from 0.29243 to 0.28674, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.3049 - val_loss: 0.2867 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.2995\n",
      "Epoch 20: val_loss improved from 0.28674 to 0.27829, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.2993 - val_loss: 0.2783 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.2937\n",
      "Epoch 21: val_loss improved from 0.27829 to 0.27756, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.2936 - val_loss: 0.2776 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.2876\n",
      "Epoch 22: val_loss improved from 0.27756 to 0.27291, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.2875 - val_loss: 0.2729 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.2851\n",
      "Epoch 23: val_loss improved from 0.27291 to 0.26202, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.2849 - val_loss: 0.2620 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.2777\n",
      "Epoch 24: val_loss improved from 0.26202 to 0.25825, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.2776 - val_loss: 0.2583 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.2718\n",
      "Epoch 25: val_loss improved from 0.25825 to 0.25815, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.2716 - val_loss: 0.2582 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.2647\n",
      "Epoch 26: val_loss improved from 0.25815 to 0.25509, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.2646 - val_loss: 0.2551 - learning_rate: 0.0010\n",
      "Epoch 27/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.2590\n",
      "Epoch 27: val_loss improved from 0.25509 to 0.24597, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.2591 - val_loss: 0.2460 - learning_rate: 0.0010\n",
      "Epoch 28/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.2552\n",
      "Epoch 28: val_loss improved from 0.24597 to 0.24316, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.2552 - val_loss: 0.2432 - learning_rate: 0.0010\n",
      "Epoch 29/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.2507\n",
      "Epoch 29: val_loss improved from 0.24316 to 0.23785, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.2506 - val_loss: 0.2378 - learning_rate: 0.0010\n",
      "Epoch 30/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.2450\n",
      "Epoch 30: val_loss improved from 0.23785 to 0.23012, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.2450 - val_loss: 0.2301 - learning_rate: 0.0010\n",
      "Epoch 31/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.2409\n",
      "Epoch 31: val_loss improved from 0.23012 to 0.22580, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.2408 - val_loss: 0.2258 - learning_rate: 0.0010\n",
      "Epoch 32/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.2335\n",
      "Epoch 32: val_loss improved from 0.22580 to 0.22269, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.2336 - val_loss: 0.2227 - learning_rate: 0.0010\n",
      "Epoch 33/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.2318\n",
      "Epoch 33: val_loss improved from 0.22269 to 0.22145, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.2317 - val_loss: 0.2214 - learning_rate: 0.0010\n",
      "Epoch 34/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.2249\n",
      "Epoch 34: val_loss improved from 0.22145 to 0.21683, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.2249 - val_loss: 0.2168 - learning_rate: 0.0010\n",
      "Epoch 35/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.2209\n",
      "Epoch 35: val_loss improved from 0.21683 to 0.20949, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.2208 - val_loss: 0.2095 - learning_rate: 0.0010\n",
      "Epoch 36/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.2165\n",
      "Epoch 36: val_loss did not improve from 0.20949\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.2165 - val_loss: 0.2128 - learning_rate: 0.0010\n",
      "Epoch 37/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.2128\n",
      "Epoch 37: val_loss did not improve from 0.20949\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.2127 - val_loss: 0.2127 - learning_rate: 0.0010\n",
      "Epoch 38/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.2107\n",
      "Epoch 38: val_loss improved from 0.20949 to 0.20319, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.2105 - val_loss: 0.2032 - learning_rate: 0.0010\n",
      "Epoch 39/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.2061\n",
      "Epoch 39: val_loss improved from 0.20319 to 0.20126, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.2061 - val_loss: 0.2013 - learning_rate: 0.0010\n",
      "Epoch 40/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.2020\n",
      "Epoch 40: val_loss improved from 0.20126 to 0.19071, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.2019 - val_loss: 0.1907 - learning_rate: 0.0010\n",
      "Epoch 41/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.1998\n",
      "Epoch 41: val_loss improved from 0.19071 to 0.18999, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.1997 - val_loss: 0.1900 - learning_rate: 0.0010\n",
      "Epoch 42/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.1940\n",
      "Epoch 42: val_loss improved from 0.18999 to 0.18690, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.1939 - val_loss: 0.1869 - learning_rate: 0.0010\n",
      "Epoch 43/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.1905\n",
      "Epoch 43: val_loss improved from 0.18690 to 0.18226, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.1905 - val_loss: 0.1823 - learning_rate: 0.0010\n",
      "Epoch 44/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.1867\n",
      "Epoch 44: val_loss improved from 0.18226 to 0.18028, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.1867 - val_loss: 0.1803 - learning_rate: 0.0010\n",
      "Epoch 45/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.1836\n",
      "Epoch 45: val_loss improved from 0.18028 to 0.17790, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.1836 - val_loss: 0.1779 - learning_rate: 0.0010\n",
      "Epoch 46/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.1812\n",
      "Epoch 46: val_loss did not improve from 0.17790\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.1812 - val_loss: 0.1854 - learning_rate: 0.0010\n",
      "Epoch 47/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.1781\n",
      "Epoch 47: val_loss improved from 0.17790 to 0.16482, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.1780 - val_loss: 0.1648 - learning_rate: 0.0010\n",
      "Epoch 48/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.1751\n",
      "Epoch 48: val_loss did not improve from 0.16482\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.1751 - val_loss: 0.1749 - learning_rate: 0.0010\n",
      "Epoch 49/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.1749\n",
      "Epoch 49: val_loss improved from 0.16482 to 0.16356, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.1747 - val_loss: 0.1636 - learning_rate: 0.0010\n",
      "Epoch 50/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.1675\n",
      "Epoch 50: val_loss improved from 0.16356 to 0.16000, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.1675 - val_loss: 0.1600 - learning_rate: 0.0010\n",
      "Epoch 51/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.1653\n",
      "Epoch 51: val_loss did not improve from 0.16000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.1652 - val_loss: 0.1683 - learning_rate: 0.0010\n",
      "Epoch 52/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.1632\n",
      "Epoch 52: val_loss did not improve from 0.16000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.1632 - val_loss: 0.1603 - learning_rate: 0.0010\n",
      "Epoch 53/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.1591\n",
      "Epoch 53: val_loss improved from 0.16000 to 0.15662, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.1591 - val_loss: 0.1566 - learning_rate: 0.0010\n",
      "Epoch 54/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.1561\n",
      "Epoch 54: val_loss did not improve from 0.15662\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.1561 - val_loss: 0.1568 - learning_rate: 0.0010\n",
      "Epoch 55/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.1551\n",
      "Epoch 55: val_loss improved from 0.15662 to 0.14633, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.1549 - val_loss: 0.1463 - learning_rate: 0.0010\n",
      "Epoch 56/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.1507\n",
      "Epoch 56: val_loss improved from 0.14633 to 0.14367, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.1507 - val_loss: 0.1437 - learning_rate: 0.0010\n",
      "Epoch 57/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.1485\n",
      "Epoch 57: val_loss did not improve from 0.14367\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.1484 - val_loss: 0.1583 - learning_rate: 0.0010\n",
      "Epoch 58/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.1481\n",
      "Epoch 58: val_loss improved from 0.14367 to 0.14135, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.1480 - val_loss: 0.1413 - learning_rate: 0.0010\n",
      "Epoch 59/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.1449\n",
      "Epoch 59: val_loss improved from 0.14135 to 0.14032, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.1449 - val_loss: 0.1403 - learning_rate: 0.0010\n",
      "Epoch 60/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.1418\n",
      "Epoch 60: val_loss improved from 0.14032 to 0.13669, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.1417 - val_loss: 0.1367 - learning_rate: 0.0010\n",
      "Epoch 61/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.1382\n",
      "Epoch 61: val_loss improved from 0.13669 to 0.13172, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.1383 - val_loss: 0.1317 - learning_rate: 0.0010\n",
      "Epoch 62/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.1370\n",
      "Epoch 62: val_loss improved from 0.13172 to 0.12907, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.1370 - val_loss: 0.1291 - learning_rate: 0.0010\n",
      "Epoch 63/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.1351\n",
      "Epoch 63: val_loss improved from 0.12907 to 0.12624, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.1351 - val_loss: 0.1262 - learning_rate: 0.0010\n",
      "Epoch 64/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.1334\n",
      "Epoch 64: val_loss improved from 0.12624 to 0.12595, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.1333 - val_loss: 0.1259 - learning_rate: 0.0010\n",
      "Epoch 65/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.1307\n",
      "Epoch 65: val_loss did not improve from 0.12595\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.1307 - val_loss: 0.1280 - learning_rate: 0.0010\n",
      "Epoch 66/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.1291\n",
      "Epoch 66: val_loss improved from 0.12595 to 0.12275, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.1290 - val_loss: 0.1228 - learning_rate: 0.0010\n",
      "Epoch 67/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.1270\n",
      "Epoch 67: val_loss did not improve from 0.12275\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.1269 - val_loss: 0.1310 - learning_rate: 0.0010\n",
      "Epoch 68/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.1244\n",
      "Epoch 68: val_loss improved from 0.12275 to 0.12123, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.1244 - val_loss: 0.1212 - learning_rate: 0.0010\n",
      "Epoch 69/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.1222\n",
      "Epoch 69: val_loss improved from 0.12123 to 0.11847, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.1222 - val_loss: 0.1185 - learning_rate: 0.0010\n",
      "Epoch 70/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.1198\n",
      "Epoch 70: val_loss improved from 0.11847 to 0.11448, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.1198 - val_loss: 0.1145 - learning_rate: 0.0010\n",
      "Epoch 71/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.1187\n",
      "Epoch 71: val_loss did not improve from 0.11448\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.1187 - val_loss: 0.1164 - learning_rate: 0.0010\n",
      "Epoch 72/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.1177\n",
      "Epoch 72: val_loss did not improve from 0.11448\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.1177 - val_loss: 0.1165 - learning_rate: 0.0010\n",
      "Epoch 73/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.1170\n",
      "Epoch 73: val_loss improved from 0.11448 to 0.11031, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.1170 - val_loss: 0.1103 - learning_rate: 0.0010\n",
      "Epoch 74/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.1151\n",
      "Epoch 74: val_loss improved from 0.11031 to 0.10621, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.1151 - val_loss: 0.1062 - learning_rate: 0.0010\n",
      "Epoch 75/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.1125\n",
      "Epoch 75: val_loss did not improve from 0.10621\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.1125 - val_loss: 0.1101 - learning_rate: 0.0010\n",
      "Epoch 76/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.1117\n",
      "Epoch 76: val_loss did not improve from 0.10621\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.1116 - val_loss: 0.1151 - learning_rate: 0.0010\n",
      "Epoch 77/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.1103\n",
      "Epoch 77: val_loss improved from 0.10621 to 0.10315, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.1103 - val_loss: 0.1031 - learning_rate: 0.0010\n",
      "Epoch 78/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.1084\n",
      "Epoch 78: val_loss did not improve from 0.10315\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.1083 - val_loss: 0.1050 - learning_rate: 0.0010\n",
      "Epoch 79/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.1055\n",
      "Epoch 79: val_loss did not improve from 0.10315\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.1055 - val_loss: 0.1089 - learning_rate: 0.0010\n",
      "Epoch 80/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.1047\n",
      "Epoch 80: val_loss improved from 0.10315 to 0.09994, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.1047 - val_loss: 0.0999 - learning_rate: 0.0010\n",
      "Epoch 81/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.1033\n",
      "Epoch 81: val_loss improved from 0.09994 to 0.09813, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.1034 - val_loss: 0.0981 - learning_rate: 0.0010\n",
      "Epoch 82/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.1036\n",
      "Epoch 82: val_loss did not improve from 0.09813\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.1036 - val_loss: 0.1040 - learning_rate: 0.0010\n",
      "Epoch 83/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.1046\n",
      "Epoch 83: val_loss did not improve from 0.09813\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.1045 - val_loss: 0.1033 - learning_rate: 0.0010\n",
      "Epoch 84/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.1004\n",
      "Epoch 84: val_loss did not improve from 0.09813\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.1005 - val_loss: 0.1049 - learning_rate: 0.0010\n",
      "Epoch 85/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0994\n",
      "Epoch 85: val_loss improved from 0.09813 to 0.09692, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0994 - val_loss: 0.0969 - learning_rate: 0.0010\n",
      "Epoch 86/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0980\n",
      "Epoch 86: val_loss improved from 0.09692 to 0.09678, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0980 - val_loss: 0.0968 - learning_rate: 0.0010\n",
      "Epoch 87/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0970\n",
      "Epoch 87: val_loss did not improve from 0.09678\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0969 - val_loss: 0.0971 - learning_rate: 0.0010\n",
      "Epoch 88/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0945\n",
      "Epoch 88: val_loss did not improve from 0.09678\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0945 - val_loss: 0.0996 - learning_rate: 0.0010\n",
      "Epoch 89/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0935\n",
      "Epoch 89: val_loss improved from 0.09678 to 0.09516, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0934 - val_loss: 0.0952 - learning_rate: 0.0010\n",
      "Epoch 90/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0922\n",
      "Epoch 90: val_loss improved from 0.09516 to 0.08793, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0922 - val_loss: 0.0879 - learning_rate: 0.0010\n",
      "Epoch 91/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0918\n",
      "Epoch 91: val_loss did not improve from 0.08793\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0918 - val_loss: 0.0894 - learning_rate: 0.0010\n",
      "Epoch 92/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0915\n",
      "Epoch 92: val_loss did not improve from 0.08793\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0915 - val_loss: 0.0975 - learning_rate: 0.0010\n",
      "Epoch 93/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0894\n",
      "Epoch 93: val_loss improved from 0.08793 to 0.08547, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0894 - val_loss: 0.0855 - learning_rate: 0.0010\n",
      "Epoch 94/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0891\n",
      "Epoch 94: val_loss did not improve from 0.08547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0891 - val_loss: 0.0878 - learning_rate: 0.0010\n",
      "Epoch 95/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0878\n",
      "Epoch 95: val_loss improved from 0.08547 to 0.08486, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0878 - val_loss: 0.0849 - learning_rate: 0.0010\n",
      "Epoch 96/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0863\n",
      "Epoch 96: val_loss did not improve from 0.08486\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0863 - val_loss: 0.0943 - learning_rate: 0.0010\n",
      "Epoch 97/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0866\n",
      "Epoch 97: val_loss improved from 0.08486 to 0.08424, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0865 - val_loss: 0.0842 - learning_rate: 0.0010\n",
      "Epoch 98/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0845\n",
      "Epoch 98: val_loss improved from 0.08424 to 0.07994, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0845 - val_loss: 0.0799 - learning_rate: 0.0010\n",
      "Epoch 99/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0839\n",
      "Epoch 99: val_loss did not improve from 0.07994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0839 - val_loss: 0.0971 - learning_rate: 0.0010\n",
      "Epoch 100/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0836\n",
      "Epoch 100: val_loss did not improve from 0.07994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0835 - val_loss: 0.0900 - learning_rate: 0.0010\n",
      "Epoch 101/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0817\n",
      "Epoch 101: val_loss did not improve from 0.07994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0817 - val_loss: 0.0825 - learning_rate: 0.0010\n",
      "Epoch 102/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0804\n",
      "Epoch 102: val_loss improved from 0.07994 to 0.07568, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0804 - val_loss: 0.0757 - learning_rate: 0.0010\n",
      "Epoch 103/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0806\n",
      "Epoch 103: val_loss did not improve from 0.07568\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0806 - val_loss: 0.0798 - learning_rate: 0.0010\n",
      "Epoch 104/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0804\n",
      "Epoch 104: val_loss did not improve from 0.07568\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0804 - val_loss: 0.0967 - learning_rate: 0.0010\n",
      "Epoch 105/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0795\n",
      "Epoch 105: val_loss improved from 0.07568 to 0.07249, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0795 - val_loss: 0.0725 - learning_rate: 0.0010\n",
      "Epoch 106/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0778\n",
      "Epoch 106: val_loss did not improve from 0.07249\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0777 - val_loss: 0.0729 - learning_rate: 0.0010\n",
      "Epoch 107/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0756\n",
      "Epoch 107: val_loss did not improve from 0.07249\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0756 - val_loss: 0.0739 - learning_rate: 0.0010\n",
      "Epoch 108/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0748\n",
      "Epoch 108: val_loss did not improve from 0.07249\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0749 - val_loss: 0.0845 - learning_rate: 0.0010\n",
      "Epoch 109/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0753\n",
      "Epoch 109: val_loss did not improve from 0.07249\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0754 - val_loss: 0.0770 - learning_rate: 0.0010\n",
      "Epoch 110/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0734\n",
      "Epoch 110: val_loss did not improve from 0.07249\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0734 - val_loss: 0.0743 - learning_rate: 0.0010\n",
      "Epoch 111/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0739\n",
      "Epoch 111: val_loss improved from 0.07249 to 0.06935, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0739 - val_loss: 0.0693 - learning_rate: 0.0010\n",
      "Epoch 112/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0709\n",
      "Epoch 112: val_loss improved from 0.06935 to 0.06663, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0709 - val_loss: 0.0666 - learning_rate: 0.0010\n",
      "Epoch 113/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0715\n",
      "Epoch 113: val_loss did not improve from 0.06663\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0715 - val_loss: 0.0701 - learning_rate: 0.0010\n",
      "Epoch 114/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0721\n",
      "Epoch 114: val_loss did not improve from 0.06663\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0721 - val_loss: 0.0735 - learning_rate: 0.0010\n",
      "Epoch 115/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0729\n",
      "Epoch 115: val_loss improved from 0.06663 to 0.06480, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0728 - val_loss: 0.0648 - learning_rate: 0.0010\n",
      "Epoch 116/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0709\n",
      "Epoch 116: val_loss did not improve from 0.06480\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0709 - val_loss: 0.0701 - learning_rate: 0.0010\n",
      "Epoch 117/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0686\n",
      "Epoch 117: val_loss did not improve from 0.06480\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0685 - val_loss: 0.0691 - learning_rate: 0.0010\n",
      "Epoch 118/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0671\n",
      "Epoch 118: val_loss improved from 0.06480 to 0.06463, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0671 - val_loss: 0.0646 - learning_rate: 0.0010\n",
      "Epoch 119/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0661\n",
      "Epoch 119: val_loss did not improve from 0.06463\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0661 - val_loss: 0.0650 - learning_rate: 0.0010\n",
      "Epoch 120/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0659\n",
      "Epoch 120: val_loss improved from 0.06463 to 0.06191, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0659 - val_loss: 0.0619 - learning_rate: 0.0010\n",
      "Epoch 121/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0668\n",
      "Epoch 121: val_loss did not improve from 0.06191\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0668 - val_loss: 0.0659 - learning_rate: 0.0010\n",
      "Epoch 122/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0661\n",
      "Epoch 122: val_loss did not improve from 0.06191\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0661 - val_loss: 0.0744 - learning_rate: 0.0010\n",
      "Epoch 123/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0641\n",
      "Epoch 123: val_loss did not improve from 0.06191\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0642 - val_loss: 0.0682 - learning_rate: 0.0010\n",
      "Epoch 124/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0632\n",
      "Epoch 124: val_loss did not improve from 0.06191\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0632 - val_loss: 0.0649 - learning_rate: 0.0010\n",
      "Epoch 125/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0643\n",
      "Epoch 125: val_loss did not improve from 0.06191\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0643 - val_loss: 0.0633 - learning_rate: 0.0010\n",
      "Epoch 126/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0629\n",
      "Epoch 126: val_loss did not improve from 0.06191\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0629 - val_loss: 0.0668 - learning_rate: 0.0010\n",
      "Epoch 127/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0614\n",
      "Epoch 127: val_loss did not improve from 0.06191\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0615 - val_loss: 0.0695 - learning_rate: 0.0010\n",
      "Epoch 128/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0626\n",
      "Epoch 128: val_loss improved from 0.06191 to 0.06024, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0625 - val_loss: 0.0602 - learning_rate: 0.0010\n",
      "Epoch 129/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0607\n",
      "Epoch 129: val_loss did not improve from 0.06024\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0607 - val_loss: 0.0612 - learning_rate: 0.0010\n",
      "Epoch 130/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0593\n",
      "Epoch 130: val_loss did not improve from 0.06024\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0593 - val_loss: 0.0609 - learning_rate: 0.0010\n",
      "Epoch 131/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0596\n",
      "Epoch 131: val_loss improved from 0.06024 to 0.06004, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0596 - val_loss: 0.0600 - learning_rate: 0.0010\n",
      "Epoch 132/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0580\n",
      "Epoch 132: val_loss improved from 0.06004 to 0.05835, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0581 - val_loss: 0.0584 - learning_rate: 0.0010\n",
      "Epoch 133/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0583\n",
      "Epoch 133: val_loss did not improve from 0.05835\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0584 - val_loss: 0.0595 - learning_rate: 0.0010\n",
      "Epoch 134/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0580\n",
      "Epoch 134: val_loss improved from 0.05835 to 0.05607, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0580 - val_loss: 0.0561 - learning_rate: 0.0010\n",
      "Epoch 135/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0577\n",
      "Epoch 135: val_loss did not improve from 0.05607\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0577 - val_loss: 0.0577 - learning_rate: 0.0010\n",
      "Epoch 136/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0566\n",
      "Epoch 136: val_loss did not improve from 0.05607\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0566 - val_loss: 0.0619 - learning_rate: 0.0010\n",
      "Epoch 137/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0565\n",
      "Epoch 137: val_loss improved from 0.05607 to 0.05359, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0565 - val_loss: 0.0536 - learning_rate: 0.0010\n",
      "Epoch 138/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0565\n",
      "Epoch 138: val_loss did not improve from 0.05359\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0565 - val_loss: 0.0607 - learning_rate: 0.0010\n",
      "Epoch 139/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0564\n",
      "Epoch 139: val_loss did not improve from 0.05359\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0563 - val_loss: 0.0610 - learning_rate: 0.0010\n",
      "Epoch 140/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0554\n",
      "Epoch 140: val_loss did not improve from 0.05359\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0554 - val_loss: 0.0673 - learning_rate: 0.0010\n",
      "Epoch 141/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0551\n",
      "Epoch 141: val_loss did not improve from 0.05359\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0551 - val_loss: 0.0609 - learning_rate: 0.0010\n",
      "Epoch 142/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0554\n",
      "Epoch 142: val_loss improved from 0.05359 to 0.05162, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0553 - val_loss: 0.0516 - learning_rate: 0.0010\n",
      "Epoch 143/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0546\n",
      "Epoch 143: val_loss did not improve from 0.05162\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0545 - val_loss: 0.0549 - learning_rate: 0.0010\n",
      "Epoch 144/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0516\n",
      "Epoch 144: val_loss improved from 0.05162 to 0.05093, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0517 - val_loss: 0.0509 - learning_rate: 0.0010\n",
      "Epoch 145/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0537\n",
      "Epoch 145: val_loss did not improve from 0.05093\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0537 - val_loss: 0.0547 - learning_rate: 0.0010\n",
      "Epoch 146/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0529\n",
      "Epoch 146: val_loss did not improve from 0.05093\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0529 - val_loss: 0.0519 - learning_rate: 0.0010\n",
      "Epoch 147/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0523\n",
      "Epoch 147: val_loss improved from 0.05093 to 0.04815, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0523 - val_loss: 0.0482 - learning_rate: 0.0010\n",
      "Epoch 148/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0522\n",
      "Epoch 148: val_loss improved from 0.04815 to 0.04719, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0521 - val_loss: 0.0472 - learning_rate: 0.0010\n",
      "Epoch 149/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0516\n",
      "Epoch 149: val_loss did not improve from 0.04719\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0517 - val_loss: 0.0571 - learning_rate: 0.0010\n",
      "Epoch 150/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0518\n",
      "Epoch 150: val_loss did not improve from 0.04719\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0518 - val_loss: 0.0485 - learning_rate: 0.0010\n",
      "Epoch 151/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0506\n",
      "Epoch 151: val_loss did not improve from 0.04719\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0506 - val_loss: 0.0576 - learning_rate: 0.0010\n",
      "Epoch 152/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0499\n",
      "Epoch 152: val_loss did not improve from 0.04719\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0499 - val_loss: 0.0610 - learning_rate: 0.0010\n",
      "Epoch 153/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0505\n",
      "Epoch 153: val_loss did not improve from 0.04719\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0505 - val_loss: 0.0588 - learning_rate: 0.0010\n",
      "Epoch 154/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0509\n",
      "Epoch 154: val_loss did not improve from 0.04719\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0510 - val_loss: 0.0487 - learning_rate: 0.0010\n",
      "Epoch 155/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0495\n",
      "Epoch 155: val_loss did not improve from 0.04719\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0496 - val_loss: 0.0549 - learning_rate: 0.0010\n",
      "Epoch 156/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0496\n",
      "Epoch 156: val_loss did not improve from 0.04719\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0496 - val_loss: 0.0526 - learning_rate: 0.0010\n",
      "Epoch 157/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0471\n",
      "Epoch 157: val_loss did not improve from 0.04719\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0471 - val_loss: 0.0488 - learning_rate: 0.0010\n",
      "Epoch 158/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0475\n",
      "Epoch 158: val_loss did not improve from 0.04719\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0475 - val_loss: 0.0513 - learning_rate: 0.0010\n",
      "Epoch 159/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0475\n",
      "Epoch 159: val_loss did not improve from 0.04719\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0475 - val_loss: 0.0481 - learning_rate: 0.0010\n",
      "Epoch 160/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0467\n",
      "Epoch 160: val_loss improved from 0.04719 to 0.04557, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0467 - val_loss: 0.0456 - learning_rate: 0.0010\n",
      "Epoch 161/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0472\n",
      "Epoch 161: val_loss did not improve from 0.04557\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0473 - val_loss: 0.0478 - learning_rate: 0.0010\n",
      "Epoch 162/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0480\n",
      "Epoch 162: val_loss did not improve from 0.04557\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0480 - val_loss: 0.0490 - learning_rate: 0.0010\n",
      "Epoch 163/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0470\n",
      "Epoch 163: val_loss did not improve from 0.04557\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0470 - val_loss: 0.0482 - learning_rate: 0.0010\n",
      "Epoch 164/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0458\n",
      "Epoch 164: val_loss improved from 0.04557 to 0.04262, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0458 - val_loss: 0.0426 - learning_rate: 0.0010\n",
      "Epoch 165/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0462\n",
      "Epoch 165: val_loss improved from 0.04262 to 0.04163, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0462 - val_loss: 0.0416 - learning_rate: 0.0010\n",
      "Epoch 166/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0448\n",
      "Epoch 166: val_loss did not improve from 0.04163\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0447 - val_loss: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 167/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0439\n",
      "Epoch 167: val_loss did not improve from 0.04163\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0439 - val_loss: 0.0427 - learning_rate: 0.0010\n",
      "Epoch 168/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0436\n",
      "Epoch 168: val_loss did not improve from 0.04163\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0437 - val_loss: 0.0467 - learning_rate: 0.0010\n",
      "Epoch 169/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0443\n",
      "Epoch 169: val_loss did not improve from 0.04163\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0443 - val_loss: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 170/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0438\n",
      "Epoch 170: val_loss did not improve from 0.04163\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0438 - val_loss: 0.0455 - learning_rate: 0.0010\n",
      "Epoch 171/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0430\n",
      "Epoch 171: val_loss improved from 0.04163 to 0.04092, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0430 - val_loss: 0.0409 - learning_rate: 0.0010\n",
      "Epoch 172/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0421\n",
      "Epoch 172: val_loss did not improve from 0.04092\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0422 - val_loss: 0.0420 - learning_rate: 0.0010\n",
      "Epoch 173/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0436\n",
      "Epoch 173: val_loss did not improve from 0.04092\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0436 - val_loss: 0.0571 - learning_rate: 0.0010\n",
      "Epoch 174/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0428\n",
      "Epoch 174: val_loss did not improve from 0.04092\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0428 - val_loss: 0.0429 - learning_rate: 0.0010\n",
      "Epoch 175/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0422\n",
      "Epoch 175: val_loss did not improve from 0.04092\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0422 - val_loss: 0.0442 - learning_rate: 0.0010\n",
      "Epoch 176/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0417\n",
      "Epoch 176: val_loss did not improve from 0.04092\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0417 - val_loss: 0.0436 - learning_rate: 0.0010\n",
      "Epoch 177/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0439\n",
      "Epoch 177: val_loss did not improve from 0.04092\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0438 - val_loss: 0.0419 - learning_rate: 0.0010\n",
      "Epoch 178/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0413\n",
      "Epoch 178: val_loss improved from 0.04092 to 0.03830, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0413 - val_loss: 0.0383 - learning_rate: 0.0010\n",
      "Epoch 179/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0398\n",
      "Epoch 179: val_loss did not improve from 0.03830\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0399 - val_loss: 0.0453 - learning_rate: 0.0010\n",
      "Epoch 180/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0403\n",
      "Epoch 180: val_loss did not improve from 0.03830\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0403 - val_loss: 0.0453 - learning_rate: 0.0010\n",
      "Epoch 181/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0399\n",
      "Epoch 181: val_loss did not improve from 0.03830\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0400 - val_loss: 0.0393 - learning_rate: 0.0010\n",
      "Epoch 182/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0394\n",
      "Epoch 182: val_loss improved from 0.03830 to 0.03739, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0394 - val_loss: 0.0374 - learning_rate: 0.0010\n",
      "Epoch 183/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0389\n",
      "Epoch 183: val_loss did not improve from 0.03739\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0389 - val_loss: 0.0472 - learning_rate: 0.0010\n",
      "Epoch 184/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0389\n",
      "Epoch 184: val_loss did not improve from 0.03739\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0389 - val_loss: 0.0392 - learning_rate: 0.0010\n",
      "Epoch 185/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0390\n",
      "Epoch 185: val_loss improved from 0.03739 to 0.03554, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0389 - val_loss: 0.0355 - learning_rate: 0.0010\n",
      "Epoch 186/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0387\n",
      "Epoch 186: val_loss did not improve from 0.03554\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0387 - val_loss: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 187/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0383\n",
      "Epoch 187: val_loss did not improve from 0.03554\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0383 - val_loss: 0.0397 - learning_rate: 0.0010\n",
      "Epoch 188/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0387\n",
      "Epoch 188: val_loss did not improve from 0.03554\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0387 - val_loss: 0.0377 - learning_rate: 0.0010\n",
      "Epoch 189/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0383\n",
      "Epoch 189: val_loss did not improve from 0.03554\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0383 - val_loss: 0.0460 - learning_rate: 0.0010\n",
      "Epoch 190/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0375\n",
      "Epoch 190: val_loss did not improve from 0.03554\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0375 - val_loss: 0.0382 - learning_rate: 0.0010\n",
      "Epoch 191/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0373\n",
      "Epoch 191: val_loss did not improve from 0.03554\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0373 - val_loss: 0.0367 - learning_rate: 0.0010\n",
      "Epoch 192/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0366\n",
      "Epoch 192: val_loss improved from 0.03554 to 0.03462, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0368 - val_loss: 0.0346 - learning_rate: 0.0010\n",
      "Epoch 193/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0370\n",
      "Epoch 193: val_loss did not improve from 0.03462\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0370 - val_loss: 0.0355 - learning_rate: 0.0010\n",
      "Epoch 194/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0362\n",
      "Epoch 194: val_loss did not improve from 0.03462\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0362 - val_loss: 0.0358 - learning_rate: 0.0010\n",
      "Epoch 195/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0366\n",
      "Epoch 195: val_loss improved from 0.03462 to 0.03250, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0366 - val_loss: 0.0325 - learning_rate: 0.0010\n",
      "Epoch 196/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0362\n",
      "Epoch 196: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0362 - val_loss: 0.0368 - learning_rate: 0.0010\n",
      "Epoch 197/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0364\n",
      "Epoch 197: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0364 - val_loss: 0.0417 - learning_rate: 0.0010\n",
      "Epoch 198/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0361\n",
      "Epoch 198: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0361 - val_loss: 0.0370 - learning_rate: 0.0010\n",
      "Epoch 199/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0369\n",
      "Epoch 199: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0369 - val_loss: 0.0451 - learning_rate: 0.0010\n",
      "Epoch 200/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0349\n",
      "Epoch 200: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0349 - val_loss: 0.0372 - learning_rate: 0.0010\n",
      "Epoch 201/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0348\n",
      "Epoch 201: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0348 - val_loss: 0.0418 - learning_rate: 0.0010\n",
      "Epoch 202/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0343\n",
      "Epoch 202: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0344 - val_loss: 0.0352 - learning_rate: 0.0010\n",
      "Epoch 203/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0343\n",
      "Epoch 203: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0343 - val_loss: 0.0342 - learning_rate: 0.0010\n",
      "Epoch 204/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0340\n",
      "Epoch 204: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0340 - val_loss: 0.0396 - learning_rate: 0.0010\n",
      "Epoch 205/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0335\n",
      "Epoch 205: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0335 - val_loss: 0.0361 - learning_rate: 0.0010\n",
      "Epoch 206/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0327\n",
      "Epoch 206: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0328 - val_loss: 0.0335 - learning_rate: 0.0010\n",
      "Epoch 207/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0331\n",
      "Epoch 207: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0332 - val_loss: 0.0340 - learning_rate: 0.0010\n",
      "Epoch 208/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0330\n",
      "Epoch 208: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0331 - val_loss: 0.0357 - learning_rate: 0.0010\n",
      "Epoch 209/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0336\n",
      "Epoch 209: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0337 - val_loss: 0.0364 - learning_rate: 0.0010\n",
      "Epoch 210/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0339\n",
      "Epoch 210: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0339 - val_loss: 0.0357 - learning_rate: 0.0010\n",
      "Epoch 211/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0342\n",
      "Epoch 211: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0342 - val_loss: 0.0325 - learning_rate: 0.0010\n",
      "Epoch 212/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0331\n",
      "Epoch 212: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0331 - val_loss: 0.0366 - learning_rate: 0.0010\n",
      "Epoch 213/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0319\n",
      "Epoch 213: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0319 - val_loss: 0.0383 - learning_rate: 0.0010\n",
      "Epoch 214/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0336\n",
      "Epoch 214: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0336 - val_loss: 0.0379 - learning_rate: 0.0010\n",
      "Epoch 215/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0321\n",
      "Epoch 215: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0322 - val_loss: 0.0384 - learning_rate: 0.0010\n",
      "Epoch 216/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0329\n",
      "Epoch 216: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0329 - val_loss: 0.0345 - learning_rate: 0.0010\n",
      "Epoch 217/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0321\n",
      "Epoch 217: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0321 - val_loss: 0.0348 - learning_rate: 0.0010\n",
      "Epoch 218/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0316\n",
      "Epoch 218: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0317 - val_loss: 0.0361 - learning_rate: 0.0010\n",
      "Epoch 219/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0313\n",
      "Epoch 219: val_loss did not improve from 0.03250\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0314 - val_loss: 0.0339 - learning_rate: 0.0010\n",
      "Epoch 220/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0339\n",
      "Epoch 220: val_loss improved from 0.03250 to 0.02939, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0339 - val_loss: 0.0294 - learning_rate: 0.0010\n",
      "Epoch 221/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0318\n",
      "Epoch 221: val_loss did not improve from 0.02939\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0318 - val_loss: 0.0481 - learning_rate: 0.0010\n",
      "Epoch 222/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0315\n",
      "Epoch 222: val_loss did not improve from 0.02939\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0315 - val_loss: 0.0364 - learning_rate: 0.0010\n",
      "Epoch 223/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0303\n",
      "Epoch 223: val_loss did not improve from 0.02939\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0303 - val_loss: 0.0320 - learning_rate: 0.0010\n",
      "Epoch 224/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0299\n",
      "Epoch 224: val_loss improved from 0.02939 to 0.02738, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0299 - val_loss: 0.0274 - learning_rate: 0.0010\n",
      "Epoch 225/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0310\n",
      "Epoch 225: val_loss did not improve from 0.02738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0310 - val_loss: 0.0290 - learning_rate: 0.0010\n",
      "Epoch 226/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0305\n",
      "Epoch 226: val_loss did not improve from 0.02738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0305 - val_loss: 0.0371 - learning_rate: 0.0010\n",
      "Epoch 227/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0306\n",
      "Epoch 227: val_loss did not improve from 0.02738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0306 - val_loss: 0.0378 - learning_rate: 0.0010\n",
      "Epoch 228/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0292\n",
      "Epoch 228: val_loss did not improve from 0.02738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0292 - val_loss: 0.0301 - learning_rate: 0.0010\n",
      "Epoch 229/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0294\n",
      "Epoch 229: val_loss did not improve from 0.02738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0294 - val_loss: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 230/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0316\n",
      "Epoch 230: val_loss did not improve from 0.02738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0316 - val_loss: 0.0340 - learning_rate: 0.0010\n",
      "Epoch 231/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0322\n",
      "Epoch 231: val_loss did not improve from 0.02738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0322 - val_loss: 0.0331 - learning_rate: 0.0010\n",
      "Epoch 232/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0315\n",
      "Epoch 232: val_loss did not improve from 0.02738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0316 - val_loss: 0.0331 - learning_rate: 0.0010\n",
      "Epoch 233/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0299\n",
      "Epoch 233: val_loss did not improve from 0.02738\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0299 - val_loss: 0.0327 - learning_rate: 0.0010\n",
      "Epoch 234/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0292\n",
      "Epoch 234: val_loss improved from 0.02738 to 0.02534, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0292 - val_loss: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 235/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0294\n",
      "Epoch 235: val_loss did not improve from 0.02534\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - loss: 0.0294 - val_loss: 0.0259 - learning_rate: 0.0010\n",
      "Epoch 236/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0279\n",
      "Epoch 236: val_loss did not improve from 0.02534\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0279 - val_loss: 0.0341 - learning_rate: 0.0010\n",
      "Epoch 237/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0281\n",
      "Epoch 237: val_loss did not improve from 0.02534\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0281 - val_loss: 0.0275 - learning_rate: 0.0010\n",
      "Epoch 238/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0272\n",
      "Epoch 238: val_loss did not improve from 0.02534\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0273 - val_loss: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 239/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0276\n",
      "Epoch 239: val_loss did not improve from 0.02534\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0277 - val_loss: 0.0302 - learning_rate: 0.0010\n",
      "Epoch 240/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0271\n",
      "Epoch 240: val_loss did not improve from 0.02534\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0271 - val_loss: 0.0295 - learning_rate: 0.0010\n",
      "Epoch 241/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0270\n",
      "Epoch 241: val_loss did not improve from 0.02534\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0270 - val_loss: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 242/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0266\n",
      "Epoch 242: val_loss did not improve from 0.02534\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0267 - val_loss: 0.0284 - learning_rate: 0.0010\n",
      "Epoch 243/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0272\n",
      "Epoch 243: val_loss did not improve from 0.02534\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0272 - val_loss: 0.0337 - learning_rate: 0.0010\n",
      "Epoch 244/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0279\n",
      "Epoch 244: val_loss did not improve from 0.02534\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0279 - val_loss: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 245/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0259\n",
      "Epoch 245: val_loss did not improve from 0.02534\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0260 - val_loss: 0.0318 - learning_rate: 0.0010\n",
      "Epoch 246/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0258\n",
      "Epoch 246: val_loss did not improve from 0.02534\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0258 - val_loss: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 247/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0259\n",
      "Epoch 247: val_loss improved from 0.02534 to 0.02406, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0260 - val_loss: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 248/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0264\n",
      "Epoch 248: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0264 - val_loss: 0.0286 - learning_rate: 0.0010\n",
      "Epoch 249/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0267\n",
      "Epoch 249: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0266 - val_loss: 0.0299 - learning_rate: 0.0010\n",
      "Epoch 250/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0264\n",
      "Epoch 250: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0264 - val_loss: 0.0256 - learning_rate: 0.0010\n",
      "Epoch 251/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0253\n",
      "Epoch 251: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0253 - val_loss: 0.0282 - learning_rate: 0.0010\n",
      "Epoch 252/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0258\n",
      "Epoch 252: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0259 - val_loss: 0.0292 - learning_rate: 0.0010\n",
      "Epoch 253/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0258\n",
      "Epoch 253: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0259 - val_loss: 0.0293 - learning_rate: 0.0010\n",
      "Epoch 254/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0274\n",
      "Epoch 254: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0274 - val_loss: 0.0282 - learning_rate: 0.0010\n",
      "Epoch 255/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0253\n",
      "Epoch 255: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0254 - val_loss: 0.0260 - learning_rate: 0.0010\n",
      "Epoch 256/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0258\n",
      "Epoch 256: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0259 - val_loss: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 257/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0261\n",
      "Epoch 257: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0261 - val_loss: 0.0321 - learning_rate: 0.0010\n",
      "Epoch 258/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0255\n",
      "Epoch 258: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0254 - val_loss: 0.0306 - learning_rate: 0.0010\n",
      "Epoch 259/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0251\n",
      "Epoch 259: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0250 - val_loss: 0.0290 - learning_rate: 0.0010\n",
      "Epoch 260/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0239\n",
      "Epoch 260: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0239 - val_loss: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 261/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0238\n",
      "Epoch 261: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0239 - val_loss: 0.0307 - learning_rate: 0.0010\n",
      "Epoch 262/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0239\n",
      "Epoch 262: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0239 - val_loss: 0.0315 - learning_rate: 0.0010\n",
      "Epoch 263/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0238\n",
      "Epoch 263: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0238 - val_loss: 0.0262 - learning_rate: 0.0010\n",
      "Epoch 264/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0238\n",
      "Epoch 264: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0238 - val_loss: 0.0247 - learning_rate: 0.0010\n",
      "Epoch 265/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0237\n",
      "Epoch 265: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0238 - val_loss: 0.0312 - learning_rate: 0.0010\n",
      "Epoch 266/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0253\n",
      "Epoch 266: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0253 - val_loss: 0.0247 - learning_rate: 0.0010\n",
      "Epoch 267/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0253\n",
      "Epoch 267: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0253 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 268/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0248\n",
      "Epoch 268: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0249 - val_loss: 0.0268 - learning_rate: 0.0010\n",
      "Epoch 269/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0252\n",
      "Epoch 269: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0252 - val_loss: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 270/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0251\n",
      "Epoch 270: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0250 - val_loss: 0.0363 - learning_rate: 0.0010\n",
      "Epoch 271/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0231\n",
      "Epoch 271: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0231 - val_loss: 0.0297 - learning_rate: 0.0010\n",
      "Epoch 272/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0223\n",
      "Epoch 272: val_loss did not improve from 0.02406\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0223 - val_loss: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 273/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0241\n",
      "Epoch 273: val_loss improved from 0.02406 to 0.02335, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0240 - val_loss: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 274/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0224\n",
      "Epoch 274: val_loss did not improve from 0.02335\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0224 - val_loss: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 275/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0224\n",
      "Epoch 275: val_loss improved from 0.02335 to 0.02273, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0224 - val_loss: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 276/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0223\n",
      "Epoch 276: val_loss did not improve from 0.02273\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0224 - val_loss: 0.0298 - learning_rate: 0.0010\n",
      "Epoch 277/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0224\n",
      "Epoch 277: val_loss did not improve from 0.02273\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0225 - val_loss: 0.0272 - learning_rate: 0.0010\n",
      "Epoch 278/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0232\n",
      "Epoch 278: val_loss did not improve from 0.02273\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0232 - val_loss: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 279/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0230\n",
      "Epoch 279: val_loss did not improve from 0.02273\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0230 - val_loss: 0.0304 - learning_rate: 0.0010\n",
      "Epoch 280/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0223\n",
      "Epoch 280: val_loss did not improve from 0.02273\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0223 - val_loss: 0.0311 - learning_rate: 0.0010\n",
      "Epoch 281/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0227\n",
      "Epoch 281: val_loss did not improve from 0.02273\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0227 - val_loss: 0.0295 - learning_rate: 0.0010\n",
      "Epoch 282/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0226\n",
      "Epoch 282: val_loss did not improve from 0.02273\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0226 - val_loss: 0.0265 - learning_rate: 0.0010\n",
      "Epoch 283/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0225\n",
      "Epoch 283: val_loss improved from 0.02273 to 0.02270, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0225 - val_loss: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 284/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0229\n",
      "Epoch 284: val_loss did not improve from 0.02270\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0230 - val_loss: 0.0256 - learning_rate: 0.0010\n",
      "Epoch 285/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0227\n",
      "Epoch 285: val_loss did not improve from 0.02270\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0227 - val_loss: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 286/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0225\n",
      "Epoch 286: val_loss did not improve from 0.02270\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0225 - val_loss: 0.0257 - learning_rate: 0.0010\n",
      "Epoch 287/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0236\n",
      "Epoch 287: val_loss did not improve from 0.02270\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0235 - val_loss: 0.0266 - learning_rate: 0.0010\n",
      "Epoch 288/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0217\n",
      "Epoch 288: val_loss did not improve from 0.02270\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0217 - val_loss: 0.0311 - learning_rate: 0.0010\n",
      "Epoch 289/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0216\n",
      "Epoch 289: val_loss improved from 0.02270 to 0.02232, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0216 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 290/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0213\n",
      "Epoch 290: val_loss did not improve from 0.02232\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0214 - val_loss: 0.0311 - learning_rate: 0.0010\n",
      "Epoch 291/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0220\n",
      "Epoch 291: val_loss did not improve from 0.02232\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0220 - val_loss: 0.0235 - learning_rate: 0.0010\n",
      "Epoch 292/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0214\n",
      "Epoch 292: val_loss improved from 0.02232 to 0.02071, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0214 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 293/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0215\n",
      "Epoch 293: val_loss did not improve from 0.02071\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0216 - val_loss: 0.0225 - learning_rate: 0.0010\n",
      "Epoch 294/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0219\n",
      "Epoch 294: val_loss did not improve from 0.02071\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0219 - val_loss: 0.0316 - learning_rate: 0.0010\n",
      "Epoch 295/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0223\n",
      "Epoch 295: val_loss improved from 0.02071 to 0.01999, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0223 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 296/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0222\n",
      "Epoch 296: val_loss did not improve from 0.01999\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0222 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 297/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0214\n",
      "Epoch 297: val_loss did not improve from 0.01999\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0215 - val_loss: 0.0295 - learning_rate: 0.0010\n",
      "Epoch 298/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0217\n",
      "Epoch 298: val_loss did not improve from 0.01999\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0217 - val_loss: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 299/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0209\n",
      "Epoch 299: val_loss did not improve from 0.01999\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0208 - val_loss: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 300/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0205\n",
      "Epoch 300: val_loss improved from 0.01999 to 0.01869, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0205 - val_loss: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 301/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0207\n",
      "Epoch 301: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0207 - val_loss: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 302/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0213\n",
      "Epoch 302: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0213 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 303/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0214\n",
      "Epoch 303: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0214 - val_loss: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 304/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0213\n",
      "Epoch 304: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0213 - val_loss: 0.0235 - learning_rate: 0.0010\n",
      "Epoch 305/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0205\n",
      "Epoch 305: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0205 - val_loss: 0.0257 - learning_rate: 0.0010\n",
      "Epoch 306/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0198\n",
      "Epoch 306: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0198 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 307/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0209\n",
      "Epoch 307: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0209 - val_loss: 0.0225 - learning_rate: 0.0010\n",
      "Epoch 308/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0209\n",
      "Epoch 308: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0209 - val_loss: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 309/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0223\n",
      "Epoch 309: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0222 - val_loss: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 310/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0204\n",
      "Epoch 310: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0205 - val_loss: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 311/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0199\n",
      "Epoch 311: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0199 - val_loss: 0.0237 - learning_rate: 0.0010\n",
      "Epoch 312/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0195\n",
      "Epoch 312: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0196 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 313/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0194\n",
      "Epoch 313: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0194 - val_loss: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 314/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0206\n",
      "Epoch 314: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0206 - val_loss: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 315/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0198\n",
      "Epoch 315: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0198 - val_loss: 0.0265 - learning_rate: 0.0010\n",
      "Epoch 316/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0190\n",
      "Epoch 316: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0190 - val_loss: 0.0252 - learning_rate: 0.0010\n",
      "Epoch 317/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0193\n",
      "Epoch 317: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - loss: 0.0193 - val_loss: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 318/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0190\n",
      "Epoch 318: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0191 - val_loss: 0.0259 - learning_rate: 0.0010\n",
      "Epoch 319/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0195\n",
      "Epoch 319: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0195 - val_loss: 0.0206 - learning_rate: 0.0010\n",
      "Epoch 320/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0193\n",
      "Epoch 320: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0193 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 321/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0188\n",
      "Epoch 321: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0188 - val_loss: 0.0286 - learning_rate: 0.0010\n",
      "Epoch 322/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0205\n",
      "Epoch 322: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 0.0205 - val_loss: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 323/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0199\n",
      "Epoch 323: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0200 - val_loss: 0.0225 - learning_rate: 0.0010\n",
      "Epoch 324/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0188\n",
      "Epoch 324: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0188 - val_loss: 0.0249 - learning_rate: 0.0010\n",
      "Epoch 325/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0180\n",
      "Epoch 325: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0181 - val_loss: 0.0268 - learning_rate: 0.0010\n",
      "Epoch 326/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0195\n",
      "Epoch 326: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0195 - val_loss: 0.0301 - learning_rate: 0.0010\n",
      "Epoch 327/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0193\n",
      "Epoch 327: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0194 - val_loss: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 328/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0201\n",
      "Epoch 328: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0202 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 329/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0205\n",
      "Epoch 329: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0205 - val_loss: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 330/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0189\n",
      "Epoch 330: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0189 - val_loss: 0.0249 - learning_rate: 0.0010\n",
      "Epoch 331/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0184\n",
      "Epoch 331: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0184 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 332/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0185\n",
      "Epoch 332: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0185 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 333/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0178\n",
      "Epoch 333: val_loss did not improve from 0.01869\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0179 - val_loss: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 334/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0175\n",
      "Epoch 334: val_loss improved from 0.01869 to 0.01841, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0176 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 335/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0194\n",
      "Epoch 335: val_loss did not improve from 0.01841\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0194 - val_loss: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 336/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0192\n",
      "Epoch 336: val_loss did not improve from 0.01841\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0192 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 337/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0188\n",
      "Epoch 337: val_loss did not improve from 0.01841\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0188 - val_loss: 0.0240 - learning_rate: 0.0010\n",
      "Epoch 338/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0173\n",
      "Epoch 338: val_loss did not improve from 0.01841\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0174 - val_loss: 0.0286 - learning_rate: 0.0010\n",
      "Epoch 339/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0179\n",
      "Epoch 339: val_loss did not improve from 0.01841\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0180 - val_loss: 0.0267 - learning_rate: 0.0010\n",
      "Epoch 340/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0176\n",
      "Epoch 340: val_loss did not improve from 0.01841\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0176 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 341/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0171\n",
      "Epoch 341: val_loss did not improve from 0.01841\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0171 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 342/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0175\n",
      "Epoch 342: val_loss did not improve from 0.01841\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0175 - val_loss: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 343/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0170\n",
      "Epoch 343: val_loss did not improve from 0.01841\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0170 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 344/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0185\n",
      "Epoch 344: val_loss improved from 0.01841 to 0.01829, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0184 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 345/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0178\n",
      "Epoch 345: val_loss did not improve from 0.01829\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0179 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 346/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0173\n",
      "Epoch 346: val_loss improved from 0.01829 to 0.01825, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0174 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 347/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0169\n",
      "Epoch 347: val_loss did not improve from 0.01825\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0169 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 348/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0174\n",
      "Epoch 348: val_loss did not improve from 0.01825\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0174 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 349/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0180\n",
      "Epoch 349: val_loss did not improve from 0.01825\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0180 - val_loss: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 350/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0181\n",
      "Epoch 350: val_loss did not improve from 0.01825\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0181 - val_loss: 0.0262 - learning_rate: 0.0010\n",
      "Epoch 351/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0182\n",
      "Epoch 351: val_loss improved from 0.01825 to 0.01611, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0181 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 352/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0174\n",
      "Epoch 352: val_loss improved from 0.01611 to 0.01584, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0174 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 353/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0172\n",
      "Epoch 353: val_loss did not improve from 0.01584\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0173 - val_loss: 0.0206 - learning_rate: 0.0010\n",
      "Epoch 354/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0169\n",
      "Epoch 354: val_loss did not improve from 0.01584\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0169 - val_loss: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 355/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0174\n",
      "Epoch 355: val_loss did not improve from 0.01584\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0174 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 356/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0174\n",
      "Epoch 356: val_loss did not improve from 0.01584\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0174 - val_loss: 0.0218 - learning_rate: 0.0010\n",
      "Epoch 357/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0174\n",
      "Epoch 357: val_loss did not improve from 0.01584\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0174 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 358/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0174\n",
      "Epoch 358: val_loss did not improve from 0.01584\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0175 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 359/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0177\n",
      "Epoch 359: val_loss did not improve from 0.01584\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0177 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 360/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0178\n",
      "Epoch 360: val_loss did not improve from 0.01584\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0178 - val_loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 361/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0177\n",
      "Epoch 361: val_loss did not improve from 0.01584\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0177 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 362/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0177\n",
      "Epoch 362: val_loss improved from 0.01584 to 0.01547, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0177 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 363/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0179\n",
      "Epoch 363: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0179 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 364/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0171\n",
      "Epoch 364: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0171 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 365/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0167\n",
      "Epoch 365: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0167 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 366/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0156\n",
      "Epoch 366: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0157 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 367/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0171\n",
      "Epoch 367: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0171 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 368/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0169\n",
      "Epoch 368: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0169 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 369/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0169\n",
      "Epoch 369: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0169 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 370/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0157\n",
      "Epoch 370: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0158 - val_loss: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 371/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0172\n",
      "Epoch 371: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0174 - val_loss: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 372/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0311\n",
      "Epoch 372: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0317 - val_loss: 0.0280 - learning_rate: 0.0010\n",
      "Epoch 373/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0372\n",
      "Epoch 373: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0372 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 374/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0344\n",
      "Epoch 374: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0342 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 375/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0287\n",
      "Epoch 375: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0286 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 376/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0260\n",
      "Epoch 376: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0260 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 377/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0234\n",
      "Epoch 377: val_loss did not improve from 0.01547\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0234 - val_loss: 0.0240 - learning_rate: 0.0010\n",
      "Epoch 378/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0216\n",
      "Epoch 378: val_loss improved from 0.01547 to 0.01536, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0217 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 379/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0211\n",
      "Epoch 379: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0211 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 380/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0200\n",
      "Epoch 380: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0200 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 381/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0202\n",
      "Epoch 381: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0202 - val_loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 382/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0192\n",
      "Epoch 382: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0193 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 383/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0184\n",
      "Epoch 383: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0185 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 384/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0184\n",
      "Epoch 384: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0184 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 385/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0187\n",
      "Epoch 385: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0187 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 386/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0174\n",
      "Epoch 386: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0174 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 387/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0178\n",
      "Epoch 387: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0179 - val_loss: 0.0245 - learning_rate: 0.0010\n",
      "Epoch 388/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0179\n",
      "Epoch 388: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0179 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 389/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0176\n",
      "Epoch 389: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0176 - val_loss: 0.0269 - learning_rate: 0.0010\n",
      "Epoch 390/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0186\n",
      "Epoch 390: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0186 - val_loss: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 391/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0191\n",
      "Epoch 391: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0190 - val_loss: 0.0218 - learning_rate: 0.0010\n",
      "Epoch 392/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0170\n",
      "Epoch 392: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0170 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 393/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0169\n",
      "Epoch 393: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0169 - val_loss: 0.0219 - learning_rate: 0.0010\n",
      "Epoch 394/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0161\n",
      "Epoch 394: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0161 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 395/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0175\n",
      "Epoch 395: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0175 - val_loss: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 396/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0172\n",
      "Epoch 396: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0172 - val_loss: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 397/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0163\n",
      "Epoch 397: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0163 - val_loss: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 398/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0156\n",
      "Epoch 398: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0156 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 399/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0155\n",
      "Epoch 399: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0156 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 400/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0153\n",
      "Epoch 400: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0154 - val_loss: 0.0246 - learning_rate: 0.0010\n",
      "Epoch 401/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0163\n",
      "Epoch 401: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0163 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 402/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0160\n",
      "Epoch 402: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0161 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 403/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0165\n",
      "Epoch 403: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0165 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 404/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0161\n",
      "Epoch 404: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0161 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 405/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0167\n",
      "Epoch 405: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0167 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 406/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0156\n",
      "Epoch 406: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0157 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 407/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0168\n",
      "Epoch 407: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0168 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 408/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0161\n",
      "Epoch 408: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0161 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 409/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0157\n",
      "Epoch 409: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0157 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 410/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0161\n",
      "Epoch 410: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0161 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 411/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0163\n",
      "Epoch 411: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0163 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 412/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0160\n",
      "Epoch 412: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0160 - val_loss: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 413/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0151\n",
      "Epoch 413: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0151 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 414/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0147\n",
      "Epoch 414: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0147 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 415/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0152\n",
      "Epoch 415: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0152 - val_loss: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 416/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0158\n",
      "Epoch 416: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0157 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 417/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0145\n",
      "Epoch 417: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0145 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 418/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0150\n",
      "Epoch 418: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0150 - val_loss: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 419/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0164\n",
      "Epoch 419: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0163 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 420/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0149\n",
      "Epoch 420: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0150 - val_loss: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 421/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0156\n",
      "Epoch 421: val_loss did not improve from 0.01536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0156 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 422/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0150\n",
      "Epoch 422: val_loss improved from 0.01536 to 0.01469, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0150 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 423/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0154\n",
      "Epoch 423: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0154 - val_loss: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 424/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0155\n",
      "Epoch 424: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0155 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 425/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0146\n",
      "Epoch 425: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0146 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 426/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0145\n",
      "Epoch 426: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0145 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 427/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0143\n",
      "Epoch 427: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0144 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 428/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0152\n",
      "Epoch 428: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - loss: 0.0152 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 429/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0162\n",
      "Epoch 429: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 0.0162 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 430/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0174\n",
      "Epoch 430: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0174 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 431/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0190\n",
      "Epoch 431: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0190 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 432/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0185\n",
      "Epoch 432: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0185 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 433/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0171\n",
      "Epoch 433: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0171 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 434/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0166\n",
      "Epoch 434: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0166 - val_loss: 0.0258 - learning_rate: 0.0010\n",
      "Epoch 435/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0168\n",
      "Epoch 435: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0168 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 436/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0162\n",
      "Epoch 436: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0162 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 437/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0150\n",
      "Epoch 437: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0151 - val_loss: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 438/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0154\n",
      "Epoch 438: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0154 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 439/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0150\n",
      "Epoch 439: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0150 - val_loss: 0.0239 - learning_rate: 0.0010\n",
      "Epoch 440/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0146\n",
      "Epoch 440: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0146 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 441/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0142\n",
      "Epoch 441: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0142 - val_loss: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 442/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0143\n",
      "Epoch 442: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0144 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 443/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0149\n",
      "Epoch 443: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0150 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 444/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0151\n",
      "Epoch 444: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0152 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 445/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0161\n",
      "Epoch 445: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0161 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 446/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0160\n",
      "Epoch 446: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0160 - val_loss: 0.0351 - learning_rate: 0.0010\n",
      "Epoch 447/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0160\n",
      "Epoch 447: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0160 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 448/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0160\n",
      "Epoch 448: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0160 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 449/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0158\n",
      "Epoch 449: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0157 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 450/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0163\n",
      "Epoch 450: val_loss did not improve from 0.01469\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0163 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 451/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0158\n",
      "Epoch 451: val_loss improved from 0.01469 to 0.01342, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0159 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 452/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0162\n",
      "Epoch 452: val_loss did not improve from 0.01342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0163 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 453/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0151\n",
      "Epoch 453: val_loss did not improve from 0.01342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0151 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 454/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0145\n",
      "Epoch 454: val_loss did not improve from 0.01342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0145 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 455/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0148\n",
      "Epoch 455: val_loss did not improve from 0.01342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0149 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 456/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0142\n",
      "Epoch 456: val_loss did not improve from 0.01342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0143 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 457/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0149\n",
      "Epoch 457: val_loss did not improve from 0.01342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0149 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 458/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0145\n",
      "Epoch 458: val_loss did not improve from 0.01342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0145 - val_loss: 0.0219 - learning_rate: 0.0010\n",
      "Epoch 459/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0146\n",
      "Epoch 459: val_loss did not improve from 0.01342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0146 - val_loss: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 460/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0136\n",
      "Epoch 460: val_loss did not improve from 0.01342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0136 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 461/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0137\n",
      "Epoch 461: val_loss did not improve from 0.01342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0137 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 462/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0133\n",
      "Epoch 462: val_loss did not improve from 0.01342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0133 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 463/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0133\n",
      "Epoch 463: val_loss did not improve from 0.01342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0133 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 464/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0138\n",
      "Epoch 464: val_loss did not improve from 0.01342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0138 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 465/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0171\n",
      "Epoch 465: val_loss did not improve from 0.01342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0170 - val_loss: 0.0219 - learning_rate: 0.0010\n",
      "Epoch 466/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0155\n",
      "Epoch 466: val_loss did not improve from 0.01342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0155 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 467/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0149\n",
      "Epoch 467: val_loss did not improve from 0.01342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0149 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 468/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0153\n",
      "Epoch 468: val_loss did not improve from 0.01342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0154 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 469/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0155\n",
      "Epoch 469: val_loss did not improve from 0.01342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0156 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 470/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0150\n",
      "Epoch 470: val_loss improved from 0.01342 to 0.01322, saving model to ./result_folder_no_misc/lstm_ts_9.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0149 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 471/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0143\n",
      "Epoch 471: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0143 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 472/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0142\n",
      "Epoch 472: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0142 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 473/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0143\n",
      "Epoch 473: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0143 - val_loss: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 474/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0150\n",
      "Epoch 474: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0149 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 475/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0140\n",
      "Epoch 475: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0140 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 476/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0135\n",
      "Epoch 476: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0136 - val_loss: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 477/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0139\n",
      "Epoch 477: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0139 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 478/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0139\n",
      "Epoch 478: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0139 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 479/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0139\n",
      "Epoch 479: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0139 - val_loss: 0.0269 - learning_rate: 0.0010\n",
      "Epoch 480/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0132\n",
      "Epoch 480: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0132 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 481/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0138\n",
      "Epoch 481: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0138 - val_loss: 0.0188 - learning_rate: 0.0010\n",
      "Epoch 482/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0132\n",
      "Epoch 482: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0132 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 483/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0134\n",
      "Epoch 483: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0134 - val_loss: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 484/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0133\n",
      "Epoch 484: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0133 - val_loss: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 485/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0154\n",
      "Epoch 485: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0154 - val_loss: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 486/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0141\n",
      "Epoch 486: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0141 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 487/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0143\n",
      "Epoch 487: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0143 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 488/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0143\n",
      "Epoch 488: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0143 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 489/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0138\n",
      "Epoch 489: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0138 - val_loss: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 490/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0136\n",
      "Epoch 490: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0136 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 491/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0131\n",
      "Epoch 491: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0131 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 492/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0129\n",
      "Epoch 492: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0129 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 493/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0131\n",
      "Epoch 493: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0132 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 494/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0139\n",
      "Epoch 494: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0139 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 495/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0150\n",
      "Epoch 495: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0150 - val_loss: 0.0324 - learning_rate: 0.0010\n",
      "Epoch 496/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0145\n",
      "Epoch 496: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0146 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 497/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0150\n",
      "Epoch 497: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0149 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 498/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0141\n",
      "Epoch 498: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0141 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 499/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0147\n",
      "Epoch 499: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0147 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 500/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0149\n",
      "Epoch 500: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0149 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 501/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0139\n",
      "Epoch 501: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0139 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 502/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0136\n",
      "Epoch 502: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0136 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 503/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0131\n",
      "Epoch 503: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0132 - val_loss: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 504/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0136\n",
      "Epoch 504: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0136 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 505/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0133\n",
      "Epoch 505: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0133 - val_loss: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 506/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0130\n",
      "Epoch 506: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0130 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 507/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0122\n",
      "Epoch 507: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0122 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 508/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0128\n",
      "Epoch 508: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0129 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 509/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0138\n",
      "Epoch 509: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0138 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 510/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0149\n",
      "Epoch 510: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.0149 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 511/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0148\n",
      "Epoch 511: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0148 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 512/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0144\n",
      "Epoch 512: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0144 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 513/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0136\n",
      "Epoch 513: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0137 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 514/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0138\n",
      "Epoch 514: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0138 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 515/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0134\n",
      "Epoch 515: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0134 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 516/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0140\n",
      "Epoch 516: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0139 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 517/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0136\n",
      "Epoch 517: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0136 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 518/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0136\n",
      "Epoch 518: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0136 - val_loss: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 519/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0127\n",
      "Epoch 519: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0128 - val_loss: 0.0218 - learning_rate: 0.0010\n",
      "Epoch 520/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0136\n",
      "Epoch 520: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0136 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 521/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0136\n",
      "Epoch 521: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 0.0136 - val_loss: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 522/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0132\n",
      "Epoch 522: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.0132 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 523/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0134\n",
      "Epoch 523: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0134 - val_loss: 0.0202 - learning_rate: 0.0010\n",
      "Epoch 524/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0128\n",
      "Epoch 524: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0128 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 525/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0129\n",
      "Epoch 525: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0129 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 526/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0128\n",
      "Epoch 526: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0128 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 527/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0125\n",
      "Epoch 527: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0125 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 528/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0122\n",
      "Epoch 528: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0123 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 529/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0127\n",
      "Epoch 529: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0128 - val_loss: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 530/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0133\n",
      "Epoch 530: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0133 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 531/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0139\n",
      "Epoch 531: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0139 - val_loss: 0.0206 - learning_rate: 0.0010\n",
      "Epoch 532/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0136\n",
      "Epoch 532: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0136 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 533/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0139\n",
      "Epoch 533: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0139 - val_loss: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 534/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0138\n",
      "Epoch 534: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0138 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 535/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0126\n",
      "Epoch 535: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0126 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 536/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0127\n",
      "Epoch 536: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0127 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 537/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0128\n",
      "Epoch 537: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0128 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 538/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0140\n",
      "Epoch 538: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0140 - val_loss: 0.0234 - learning_rate: 0.0010\n",
      "Epoch 539/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0125\n",
      "Epoch 539: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0125 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 540/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0129\n",
      "Epoch 540: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0130 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 541/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0313\n",
      "Epoch 541: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0341 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 542/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0835\n",
      "Epoch 542: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0832 - val_loss: 0.0322 - learning_rate: 0.0010\n",
      "Epoch 543/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0626\n",
      "Epoch 543: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0626 - val_loss: 0.0364 - learning_rate: 0.0010\n",
      "Epoch 544/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0558\n",
      "Epoch 544: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0558 - val_loss: 0.0298 - learning_rate: 0.0010\n",
      "Epoch 545/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0491\n",
      "Epoch 545: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0491 - val_loss: 0.0276 - learning_rate: 0.0010\n",
      "Epoch 546/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0424\n",
      "Epoch 546: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0424 - val_loss: 0.0384 - learning_rate: 0.0010\n",
      "Epoch 547/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0403\n",
      "Epoch 547: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0403 - val_loss: 0.0255 - learning_rate: 0.0010\n",
      "Epoch 548/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0448\n",
      "Epoch 548: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0446 - val_loss: 0.0521 - learning_rate: 0.0010\n",
      "Epoch 549/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0370\n",
      "Epoch 549: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0368 - val_loss: 0.0225 - learning_rate: 0.0010\n",
      "Epoch 550/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0315\n",
      "Epoch 550: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0315 - val_loss: 0.0218 - learning_rate: 0.0010\n",
      "Epoch 551/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0300\n",
      "Epoch 551: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0300 - val_loss: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 552/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0288\n",
      "Epoch 552: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0288 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 553/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0274\n",
      "Epoch 553: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0274 - val_loss: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 554/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0257\n",
      "Epoch 554: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0257 - val_loss: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 555/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0253\n",
      "Epoch 555: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0253 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 556/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0245\n",
      "Epoch 556: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0245 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 557/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0240\n",
      "Epoch 557: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0240 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 558/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0243\n",
      "Epoch 558: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0243 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 559/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0227\n",
      "Epoch 559: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0228 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 560/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0232\n",
      "Epoch 560: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0232 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 561/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0219\n",
      "Epoch 561: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0219 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 562/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0223\n",
      "Epoch 562: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0222 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 563/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0233\n",
      "Epoch 563: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0234 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 564/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0262\n",
      "Epoch 564: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0263 - val_loss: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 565/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0254\n",
      "Epoch 565: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0253 - val_loss: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 566/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0236\n",
      "Epoch 566: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0236 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 567/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0230\n",
      "Epoch 567: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0230 - val_loss: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 568/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0225\n",
      "Epoch 568: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0225 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 569/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0212\n",
      "Epoch 569: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0212 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 570/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0209\n",
      "Epoch 570: val_loss did not improve from 0.01322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0210 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 570: early stopping\n",
      "Restoring model weights from the end of the best epoch: 470.\n",
      "EUA\n",
      "0.058786049884723295\n",
      "Oil\n",
      "0.20869944303282953\n",
      "Coal\n",
      "0.048106677572080245\n",
      "NG\n",
      "0.06347564937251267\n",
      "USEU\n",
      "0.10139137214606746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 180/180 [01:19<00:00,  2.25it/s]\n",
      "100%|| 180/180 [04:23<00:00,  1.46s/it]\n",
      "/home/honggeunjo/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 2.3518\n",
      "Epoch 1: val_loss improved from inf to 0.70365, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 307ms/step - loss: 2.2840 - val_loss: 0.7037 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.6886\n",
      "Epoch 2: val_loss improved from 0.70365 to 0.59215, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.6820 - val_loss: 0.5922 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.5215\n",
      "Epoch 3: val_loss improved from 0.59215 to 0.45103, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - loss: 0.5191 - val_loss: 0.4510 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.4496\n",
      "Epoch 4: val_loss improved from 0.45103 to 0.37229, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 233ms/step - loss: 0.4488 - val_loss: 0.3723 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.4187\n",
      "Epoch 5: val_loss improved from 0.37229 to 0.36885, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 242ms/step - loss: 0.4184 - val_loss: 0.3689 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.4033\n",
      "Epoch 6: val_loss improved from 0.36885 to 0.36479, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 236ms/step - loss: 0.4030 - val_loss: 0.3648 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.3944\n",
      "Epoch 7: val_loss improved from 0.36479 to 0.35076, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.3942 - val_loss: 0.3508 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.3823\n",
      "Epoch 8: val_loss did not improve from 0.35076\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.3824 - val_loss: 0.3509 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.3733\n",
      "Epoch 9: val_loss improved from 0.35076 to 0.34261, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 233ms/step - loss: 0.3733 - val_loss: 0.3426 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.3733\n",
      "Epoch 10: val_loss improved from 0.34261 to 0.33380, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.3729 - val_loss: 0.3338 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.3623\n",
      "Epoch 11: val_loss improved from 0.33380 to 0.32948, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 236ms/step - loss: 0.3622 - val_loss: 0.3295 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.3559\n",
      "Epoch 12: val_loss improved from 0.32948 to 0.32446, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.3558 - val_loss: 0.3245 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 0.3491\n",
      "Epoch 13: val_loss improved from 0.32446 to 0.32171, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - loss: 0.3491 - val_loss: 0.3217 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.3421\n",
      "Epoch 14: val_loss improved from 0.32171 to 0.31225, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.3421 - val_loss: 0.3123 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.3363\n",
      "Epoch 15: val_loss improved from 0.31225 to 0.30840, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.3362 - val_loss: 0.3084 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.3322\n",
      "Epoch 16: val_loss improved from 0.30840 to 0.29980, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.3318 - val_loss: 0.2998 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.3205\n",
      "Epoch 17: val_loss improved from 0.29980 to 0.29467, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.3204 - val_loss: 0.2947 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.3138\n",
      "Epoch 18: val_loss improved from 0.29467 to 0.29111, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.3139 - val_loss: 0.2911 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.3094\n",
      "Epoch 19: val_loss improved from 0.29111 to 0.28293, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.3092 - val_loss: 0.2829 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.3025\n",
      "Epoch 20: val_loss did not improve from 0.28293\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.3025 - val_loss: 0.2853 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.2995\n",
      "Epoch 21: val_loss improved from 0.28293 to 0.27925, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.2994 - val_loss: 0.2792 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.2926\n",
      "Epoch 22: val_loss improved from 0.27925 to 0.26990, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 252ms/step - loss: 0.2925 - val_loss: 0.2699 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.2867\n",
      "Epoch 23: val_loss improved from 0.26990 to 0.26178, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.2865 - val_loss: 0.2618 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.2807\n",
      "Epoch 24: val_loss did not improve from 0.26178\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.2807 - val_loss: 0.2627 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.2744\n",
      "Epoch 25: val_loss improved from 0.26178 to 0.25654, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.2744 - val_loss: 0.2565 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.2683\n",
      "Epoch 26: val_loss improved from 0.25654 to 0.24910, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.2682 - val_loss: 0.2491 - learning_rate: 0.0010\n",
      "Epoch 27/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.2629\n",
      "Epoch 27: val_loss improved from 0.24910 to 0.24708, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.2628 - val_loss: 0.2471 - learning_rate: 0.0010\n",
      "Epoch 28/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.2577\n",
      "Epoch 28: val_loss improved from 0.24708 to 0.24118, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.2576 - val_loss: 0.2412 - learning_rate: 0.0010\n",
      "Epoch 29/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.2542\n",
      "Epoch 29: val_loss improved from 0.24118 to 0.23461, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - loss: 0.2539 - val_loss: 0.2346 - learning_rate: 0.0010\n",
      "Epoch 30/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.2491\n",
      "Epoch 30: val_loss did not improve from 0.23461\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.2490 - val_loss: 0.2473 - learning_rate: 0.0010\n",
      "Epoch 31/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.2428\n",
      "Epoch 31: val_loss improved from 0.23461 to 0.22789, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.2429 - val_loss: 0.2279 - learning_rate: 0.0010\n",
      "Epoch 32/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.2374\n",
      "Epoch 32: val_loss improved from 0.22789 to 0.22309, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.2374 - val_loss: 0.2231 - learning_rate: 0.0010\n",
      "Epoch 33/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.2350\n",
      "Epoch 33: val_loss improved from 0.22309 to 0.21764, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - loss: 0.2351 - val_loss: 0.2176 - learning_rate: 0.0010\n",
      "Epoch 34/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.2304\n",
      "Epoch 34: val_loss did not improve from 0.21764\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.2303 - val_loss: 0.2189 - learning_rate: 0.0010\n",
      "Epoch 35/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.2250\n",
      "Epoch 35: val_loss improved from 0.21764 to 0.21084, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 236ms/step - loss: 0.2248 - val_loss: 0.2108 - learning_rate: 0.0010\n",
      "Epoch 36/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.2208\n",
      "Epoch 36: val_loss improved from 0.21084 to 0.20594, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.2207 - val_loss: 0.2059 - learning_rate: 0.0010\n",
      "Epoch 37/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.2164\n",
      "Epoch 37: val_loss did not improve from 0.20594\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.2165 - val_loss: 0.2086 - learning_rate: 0.0010\n",
      "Epoch 38/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.2146\n",
      "Epoch 38: val_loss improved from 0.20594 to 0.19887, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.2145 - val_loss: 0.1989 - learning_rate: 0.0010\n",
      "Epoch 39/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.2101\n",
      "Epoch 39: val_loss did not improve from 0.19887\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.2099 - val_loss: 0.2000 - learning_rate: 0.0010\n",
      "Epoch 40/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.2056\n",
      "Epoch 40: val_loss improved from 0.19887 to 0.19275, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.2056 - val_loss: 0.1928 - learning_rate: 0.0010\n",
      "Epoch 41/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.2019\n",
      "Epoch 41: val_loss improved from 0.19275 to 0.18804, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.2019 - val_loss: 0.1880 - learning_rate: 0.0010\n",
      "Epoch 42/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.1977\n",
      "Epoch 42: val_loss did not improve from 0.18804\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.1976 - val_loss: 0.1927 - learning_rate: 0.0010\n",
      "Epoch 43/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.1941\n",
      "Epoch 43: val_loss improved from 0.18804 to 0.18075, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.1940 - val_loss: 0.1808 - learning_rate: 0.0010\n",
      "Epoch 44/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.1913\n",
      "Epoch 44: val_loss did not improve from 0.18075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.1912 - val_loss: 0.1809 - learning_rate: 0.0010\n",
      "Epoch 45/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.1879\n",
      "Epoch 45: val_loss improved from 0.18075 to 0.17907, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.1878 - val_loss: 0.1791 - learning_rate: 0.0010\n",
      "Epoch 46/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.1847\n",
      "Epoch 46: val_loss improved from 0.17907 to 0.17596, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.1847 - val_loss: 0.1760 - learning_rate: 0.0010\n",
      "Epoch 47/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.1814\n",
      "Epoch 47: val_loss improved from 0.17596 to 0.17017, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.1813 - val_loss: 0.1702 - learning_rate: 0.0010\n",
      "Epoch 48/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.1768\n",
      "Epoch 48: val_loss improved from 0.17017 to 0.16390, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.1767 - val_loss: 0.1639 - learning_rate: 0.0010\n",
      "Epoch 49/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.1735\n",
      "Epoch 49: val_loss did not improve from 0.16390\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.1735 - val_loss: 0.1681 - learning_rate: 0.0010\n",
      "Epoch 50/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.1723\n",
      "Epoch 50: val_loss did not improve from 0.16390\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.1723 - val_loss: 0.1672 - learning_rate: 0.0010\n",
      "Epoch 51/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.1704\n",
      "Epoch 51: val_loss improved from 0.16390 to 0.15752, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.1702 - val_loss: 0.1575 - learning_rate: 0.0010\n",
      "Epoch 52/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.1662\n",
      "Epoch 52: val_loss improved from 0.15752 to 0.15715, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.1661 - val_loss: 0.1572 - learning_rate: 0.0010\n",
      "Epoch 53/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.1631\n",
      "Epoch 53: val_loss improved from 0.15715 to 0.15375, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.1630 - val_loss: 0.1538 - learning_rate: 0.0010\n",
      "Epoch 54/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.1607\n",
      "Epoch 54: val_loss improved from 0.15375 to 0.15063, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - loss: 0.1606 - val_loss: 0.1506 - learning_rate: 0.0010\n",
      "Epoch 55/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.1582\n",
      "Epoch 55: val_loss improved from 0.15063 to 0.14611, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.1581 - val_loss: 0.1461 - learning_rate: 0.0010\n",
      "Epoch 56/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.1558\n",
      "Epoch 56: val_loss improved from 0.14611 to 0.14273, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.1556 - val_loss: 0.1427 - learning_rate: 0.0010\n",
      "Epoch 57/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.1542\n",
      "Epoch 57: val_loss improved from 0.14273 to 0.14216, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.1541 - val_loss: 0.1422 - learning_rate: 0.0010\n",
      "Epoch 58/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.1500\n",
      "Epoch 58: val_loss improved from 0.14216 to 0.13863, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.1500 - val_loss: 0.1386 - learning_rate: 0.0010\n",
      "Epoch 59/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.1479\n",
      "Epoch 59: val_loss improved from 0.13863 to 0.13759, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.1479 - val_loss: 0.1376 - learning_rate: 0.0010\n",
      "Epoch 60/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.1455\n",
      "Epoch 60: val_loss did not improve from 0.13759\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.1455 - val_loss: 0.1398 - learning_rate: 0.0010\n",
      "Epoch 61/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.1442\n",
      "Epoch 61: val_loss improved from 0.13759 to 0.13159, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.1442 - val_loss: 0.1316 - learning_rate: 0.0010\n",
      "Epoch 62/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.1416\n",
      "Epoch 62: val_loss did not improve from 0.13159\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.1415 - val_loss: 0.1365 - learning_rate: 0.0010\n",
      "Epoch 63/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.1400\n",
      "Epoch 63: val_loss improved from 0.13159 to 0.13082, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.1399 - val_loss: 0.1308 - learning_rate: 0.0010\n",
      "Epoch 64/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.1361\n",
      "Epoch 64: val_loss improved from 0.13082 to 0.13000, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 236ms/step - loss: 0.1362 - val_loss: 0.1300 - learning_rate: 0.0010\n",
      "Epoch 65/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.1348\n",
      "Epoch 65: val_loss improved from 0.13000 to 0.12605, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 236ms/step - loss: 0.1348 - val_loss: 0.1261 - learning_rate: 0.0010\n",
      "Epoch 66/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.1335\n",
      "Epoch 66: val_loss improved from 0.12605 to 0.12541, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.1336 - val_loss: 0.1254 - learning_rate: 0.0010\n",
      "Epoch 67/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.1310\n",
      "Epoch 67: val_loss improved from 0.12541 to 0.12266, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.1310 - val_loss: 0.1227 - learning_rate: 0.0010\n",
      "Epoch 68/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.1286\n",
      "Epoch 68: val_loss improved from 0.12266 to 0.12177, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.1288 - val_loss: 0.1218 - learning_rate: 0.0010\n",
      "Epoch 69/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.1285\n",
      "Epoch 69: val_loss did not improve from 0.12177\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.1285 - val_loss: 0.1259 - learning_rate: 0.0010\n",
      "Epoch 70/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.1247\n",
      "Epoch 70: val_loss improved from 0.12177 to 0.11539, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.1247 - val_loss: 0.1154 - learning_rate: 0.0010\n",
      "Epoch 71/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.1227\n",
      "Epoch 71: val_loss did not improve from 0.11539\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.1227 - val_loss: 0.1156 - learning_rate: 0.0010\n",
      "Epoch 72/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.1217\n",
      "Epoch 72: val_loss improved from 0.11539 to 0.11374, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - loss: 0.1217 - val_loss: 0.1137 - learning_rate: 0.0010\n",
      "Epoch 73/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.1187\n",
      "Epoch 73: val_loss did not improve from 0.11374\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.1187 - val_loss: 0.1143 - learning_rate: 0.0010\n",
      "Epoch 74/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.1175\n",
      "Epoch 74: val_loss improved from 0.11374 to 0.11276, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step - loss: 0.1174 - val_loss: 0.1128 - learning_rate: 0.0010\n",
      "Epoch 75/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.1168\n",
      "Epoch 75: val_loss improved from 0.11276 to 0.10685, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - loss: 0.1168 - val_loss: 0.1068 - learning_rate: 0.0010\n",
      "Epoch 76/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.1132\n",
      "Epoch 76: val_loss did not improve from 0.10685\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.1133 - val_loss: 0.1095 - learning_rate: 0.0010\n",
      "Epoch 77/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.1145\n",
      "Epoch 77: val_loss did not improve from 0.10685\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.1145 - val_loss: 0.1070 - learning_rate: 0.0010\n",
      "Epoch 78/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.1116\n",
      "Epoch 78: val_loss improved from 0.10685 to 0.10322, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.1116 - val_loss: 0.1032 - learning_rate: 0.0010\n",
      "Epoch 79/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.1108\n",
      "Epoch 79: val_loss did not improve from 0.10322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.1108 - val_loss: 0.1095 - learning_rate: 0.0010\n",
      "Epoch 80/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.1084\n",
      "Epoch 80: val_loss did not improve from 0.10322\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.1085 - val_loss: 0.1068 - learning_rate: 0.0010\n",
      "Epoch 81/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.1066\n",
      "Epoch 81: val_loss improved from 0.10322 to 0.10028, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.1066 - val_loss: 0.1003 - learning_rate: 0.0010\n",
      "Epoch 82/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.1062\n",
      "Epoch 82: val_loss improved from 0.10028 to 0.09715, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.1062 - val_loss: 0.0971 - learning_rate: 0.0010\n",
      "Epoch 83/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.1048\n",
      "Epoch 83: val_loss improved from 0.09715 to 0.09547, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 236ms/step - loss: 0.1048 - val_loss: 0.0955 - learning_rate: 0.0010\n",
      "Epoch 84/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.1033\n",
      "Epoch 84: val_loss improved from 0.09547 to 0.09534, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.1032 - val_loss: 0.0953 - learning_rate: 0.0010\n",
      "Epoch 85/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.1016\n",
      "Epoch 85: val_loss improved from 0.09534 to 0.09430, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.1016 - val_loss: 0.0943 - learning_rate: 0.0010\n",
      "Epoch 86/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.1003\n",
      "Epoch 86: val_loss improved from 0.09430 to 0.09393, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.1004 - val_loss: 0.0939 - learning_rate: 0.0010\n",
      "Epoch 87/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0987\n",
      "Epoch 87: val_loss did not improve from 0.09393\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0987 - val_loss: 0.0944 - learning_rate: 0.0010\n",
      "Epoch 88/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0968\n",
      "Epoch 88: val_loss improved from 0.09393 to 0.09348, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0968 - val_loss: 0.0935 - learning_rate: 0.0010\n",
      "Epoch 89/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0964\n",
      "Epoch 89: val_loss improved from 0.09348 to 0.09043, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0964 - val_loss: 0.0904 - learning_rate: 0.0010\n",
      "Epoch 90/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0971\n",
      "Epoch 90: val_loss improved from 0.09043 to 0.08908, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0971 - val_loss: 0.0891 - learning_rate: 0.0010\n",
      "Epoch 91/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0962\n",
      "Epoch 91: val_loss did not improve from 0.08908\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0961 - val_loss: 0.0938 - learning_rate: 0.0010\n",
      "Epoch 92/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0961\n",
      "Epoch 92: val_loss improved from 0.08908 to 0.08867, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0960 - val_loss: 0.0887 - learning_rate: 0.0010\n",
      "Epoch 93/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0934\n",
      "Epoch 93: val_loss improved from 0.08867 to 0.08748, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0933 - val_loss: 0.0875 - learning_rate: 0.0010\n",
      "Epoch 94/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0906\n",
      "Epoch 94: val_loss did not improve from 0.08748\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0906 - val_loss: 0.0876 - learning_rate: 0.0010\n",
      "Epoch 95/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0896\n",
      "Epoch 95: val_loss improved from 0.08748 to 0.08369, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0897 - val_loss: 0.0837 - learning_rate: 0.0010\n",
      "Epoch 96/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0883\n",
      "Epoch 96: val_loss improved from 0.08369 to 0.08328, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0884 - val_loss: 0.0833 - learning_rate: 0.0010\n",
      "Epoch 97/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0885\n",
      "Epoch 97: val_loss did not improve from 0.08328\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0885 - val_loss: 0.0835 - learning_rate: 0.0010\n",
      "Epoch 98/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0879\n",
      "Epoch 98: val_loss improved from 0.08328 to 0.08248, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0879 - val_loss: 0.0825 - learning_rate: 0.0010\n",
      "Epoch 99/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0856\n",
      "Epoch 99: val_loss improved from 0.08248 to 0.07940, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.0856 - val_loss: 0.0794 - learning_rate: 0.0010\n",
      "Epoch 100/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0850\n",
      "Epoch 100: val_loss did not improve from 0.07940\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0850 - val_loss: 0.0822 - learning_rate: 0.0010\n",
      "Epoch 101/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0850\n",
      "Epoch 101: val_loss did not improve from 0.07940\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0849 - val_loss: 0.0809 - learning_rate: 0.0010\n",
      "Epoch 102/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0830\n",
      "Epoch 102: val_loss improved from 0.07940 to 0.07845, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.0830 - val_loss: 0.0785 - learning_rate: 0.0010\n",
      "Epoch 103/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0825\n",
      "Epoch 103: val_loss did not improve from 0.07845\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0825 - val_loss: 0.0812 - learning_rate: 0.0010\n",
      "Epoch 104/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0814\n",
      "Epoch 104: val_loss did not improve from 0.07845\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0813 - val_loss: 0.0794 - learning_rate: 0.0010\n",
      "Epoch 105/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0801\n",
      "Epoch 105: val_loss improved from 0.07845 to 0.07370, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0801 - val_loss: 0.0737 - learning_rate: 0.0010\n",
      "Epoch 106/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 0.0790\n",
      "Epoch 106: val_loss improved from 0.07370 to 0.07345, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 244ms/step - loss: 0.0790 - val_loss: 0.0734 - learning_rate: 0.0010\n",
      "Epoch 107/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.0794\n",
      "Epoch 107: val_loss did not improve from 0.07345\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0794 - val_loss: 0.0742 - learning_rate: 0.0010\n",
      "Epoch 108/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0780\n",
      "Epoch 108: val_loss did not improve from 0.07345\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0780 - val_loss: 0.0736 - learning_rate: 0.0010\n",
      "Epoch 109/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0765\n",
      "Epoch 109: val_loss did not improve from 0.07345\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0766 - val_loss: 0.0777 - learning_rate: 0.0010\n",
      "Epoch 110/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0770\n",
      "Epoch 110: val_loss did not improve from 0.07345\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0769 - val_loss: 0.0747 - learning_rate: 0.0010\n",
      "Epoch 111/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 0.0752\n",
      "Epoch 111: val_loss improved from 0.07345 to 0.07277, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - loss: 0.0752 - val_loss: 0.0728 - learning_rate: 0.0010\n",
      "Epoch 112/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0747\n",
      "Epoch 112: val_loss did not improve from 0.07277\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0747 - val_loss: 0.0737 - learning_rate: 0.0010\n",
      "Epoch 113/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0760\n",
      "Epoch 113: val_loss did not improve from 0.07277\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0760 - val_loss: 0.0735 - learning_rate: 0.0010\n",
      "Epoch 114/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0751\n",
      "Epoch 114: val_loss did not improve from 0.07277\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0751 - val_loss: 0.0771 - learning_rate: 0.0010\n",
      "Epoch 115/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0753\n",
      "Epoch 115: val_loss improved from 0.07277 to 0.06845, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0752 - val_loss: 0.0684 - learning_rate: 0.0010\n",
      "Epoch 116/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0745\n",
      "Epoch 116: val_loss did not improve from 0.06845\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0745 - val_loss: 0.0696 - learning_rate: 0.0010\n",
      "Epoch 117/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0728\n",
      "Epoch 117: val_loss did not improve from 0.06845\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0727 - val_loss: 0.0688 - learning_rate: 0.0010\n",
      "Epoch 118/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0709\n",
      "Epoch 118: val_loss improved from 0.06845 to 0.06665, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0709 - val_loss: 0.0666 - learning_rate: 0.0010\n",
      "Epoch 119/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0710\n",
      "Epoch 119: val_loss improved from 0.06665 to 0.06480, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0709 - val_loss: 0.0648 - learning_rate: 0.0010\n",
      "Epoch 120/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0697\n",
      "Epoch 120: val_loss did not improve from 0.06480\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0697 - val_loss: 0.0654 - learning_rate: 0.0010\n",
      "Epoch 121/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0685\n",
      "Epoch 121: val_loss did not improve from 0.06480\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0685 - val_loss: 0.0695 - learning_rate: 0.0010\n",
      "Epoch 122/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 0.0684\n",
      "Epoch 122: val_loss improved from 0.06480 to 0.06179, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 244ms/step - loss: 0.0685 - val_loss: 0.0618 - learning_rate: 0.0010\n",
      "Epoch 123/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0680\n",
      "Epoch 123: val_loss did not improve from 0.06179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0681 - val_loss: 0.0624 - learning_rate: 0.0010\n",
      "Epoch 124/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0676\n",
      "Epoch 124: val_loss did not improve from 0.06179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0676 - val_loss: 0.0639 - learning_rate: 0.0010\n",
      "Epoch 125/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0660\n",
      "Epoch 125: val_loss did not improve from 0.06179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0661 - val_loss: 0.0628 - learning_rate: 0.0010\n",
      "Epoch 126/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0654\n",
      "Epoch 126: val_loss improved from 0.06179 to 0.06032, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0655 - val_loss: 0.0603 - learning_rate: 0.0010\n",
      "Epoch 127/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0652\n",
      "Epoch 127: val_loss did not improve from 0.06032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0652 - val_loss: 0.0616 - learning_rate: 0.0010\n",
      "Epoch 128/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0645\n",
      "Epoch 128: val_loss did not improve from 0.06032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0645 - val_loss: 0.0655 - learning_rate: 0.0010\n",
      "Epoch 129/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0639\n",
      "Epoch 129: val_loss did not improve from 0.06032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0640 - val_loss: 0.0610 - learning_rate: 0.0010\n",
      "Epoch 130/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0635\n",
      "Epoch 130: val_loss did not improve from 0.06032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0634 - val_loss: 0.0633 - learning_rate: 0.0010\n",
      "Epoch 131/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0638\n",
      "Epoch 131: val_loss did not improve from 0.06032\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0638 - val_loss: 0.0612 - learning_rate: 0.0010\n",
      "Epoch 132/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0624\n",
      "Epoch 132: val_loss improved from 0.06032 to 0.05857, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0625 - val_loss: 0.0586 - learning_rate: 0.0010\n",
      "Epoch 133/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0624\n",
      "Epoch 133: val_loss did not improve from 0.05857\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0624 - val_loss: 0.0690 - learning_rate: 0.0010\n",
      "Epoch 134/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0620\n",
      "Epoch 134: val_loss improved from 0.05857 to 0.05624, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.0620 - val_loss: 0.0562 - learning_rate: 0.0010\n",
      "Epoch 135/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0629\n",
      "Epoch 135: val_loss did not improve from 0.05624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0629 - val_loss: 0.0571 - learning_rate: 0.0010\n",
      "Epoch 136/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0611\n",
      "Epoch 136: val_loss did not improve from 0.05624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0611 - val_loss: 0.0674 - learning_rate: 0.0010\n",
      "Epoch 137/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0609\n",
      "Epoch 137: val_loss did not improve from 0.05624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0610 - val_loss: 0.0622 - learning_rate: 0.0010\n",
      "Epoch 138/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0601\n",
      "Epoch 138: val_loss improved from 0.05624 to 0.05592, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0601 - val_loss: 0.0559 - learning_rate: 0.0010\n",
      "Epoch 139/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0587\n",
      "Epoch 139: val_loss did not improve from 0.05592\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0587 - val_loss: 0.0566 - learning_rate: 0.0010\n",
      "Epoch 140/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0587\n",
      "Epoch 140: val_loss did not improve from 0.05592\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0587 - val_loss: 0.0587 - learning_rate: 0.0010\n",
      "Epoch 141/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0570\n",
      "Epoch 141: val_loss did not improve from 0.05592\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0570 - val_loss: 0.0626 - learning_rate: 0.0010\n",
      "Epoch 142/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0583\n",
      "Epoch 142: val_loss did not improve from 0.05592\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0582 - val_loss: 0.0577 - learning_rate: 0.0010\n",
      "Epoch 143/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0569\n",
      "Epoch 143: val_loss did not improve from 0.05592\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0569 - val_loss: 0.0602 - learning_rate: 0.0010\n",
      "Epoch 144/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0565\n",
      "Epoch 144: val_loss improved from 0.05592 to 0.05478, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0565 - val_loss: 0.0548 - learning_rate: 0.0010\n",
      "Epoch 145/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0554\n",
      "Epoch 145: val_loss did not improve from 0.05478\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0555 - val_loss: 0.0583 - learning_rate: 0.0010\n",
      "Epoch 146/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0560\n",
      "Epoch 146: val_loss did not improve from 0.05478\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0559 - val_loss: 0.0572 - learning_rate: 0.0010\n",
      "Epoch 147/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0550\n",
      "Epoch 147: val_loss did not improve from 0.05478\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0550 - val_loss: 0.0550 - learning_rate: 0.0010\n",
      "Epoch 148/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0551\n",
      "Epoch 148: val_loss improved from 0.05478 to 0.05198, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - loss: 0.0551 - val_loss: 0.0520 - learning_rate: 0.0010\n",
      "Epoch 149/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0559\n",
      "Epoch 149: val_loss did not improve from 0.05198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0559 - val_loss: 0.0533 - learning_rate: 0.0010\n",
      "Epoch 150/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0547\n",
      "Epoch 150: val_loss did not improve from 0.05198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0548 - val_loss: 0.0554 - learning_rate: 0.0010\n",
      "Epoch 151/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0539\n",
      "Epoch 151: val_loss did not improve from 0.05198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0539 - val_loss: 0.0582 - learning_rate: 0.0010\n",
      "Epoch 152/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0541\n",
      "Epoch 152: val_loss did not improve from 0.05198\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0541 - val_loss: 0.0553 - learning_rate: 0.0010\n",
      "Epoch 153/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0531\n",
      "Epoch 153: val_loss improved from 0.05198 to 0.04895, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.0531 - val_loss: 0.0490 - learning_rate: 0.0010\n",
      "Epoch 154/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0512\n",
      "Epoch 154: val_loss did not improve from 0.04895\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0512 - val_loss: 0.0503 - learning_rate: 0.0010\n",
      "Epoch 155/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0502\n",
      "Epoch 155: val_loss did not improve from 0.04895\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0502 - val_loss: 0.0497 - learning_rate: 0.0010\n",
      "Epoch 156/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0498\n",
      "Epoch 156: val_loss improved from 0.04895 to 0.04646, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.0498 - val_loss: 0.0465 - learning_rate: 0.0010\n",
      "Epoch 157/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0506\n",
      "Epoch 157: val_loss did not improve from 0.04646\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0506 - val_loss: 0.0528 - learning_rate: 0.0010\n",
      "Epoch 158/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0496\n",
      "Epoch 158: val_loss did not improve from 0.04646\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0497 - val_loss: 0.0471 - learning_rate: 0.0010\n",
      "Epoch 159/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0496\n",
      "Epoch 159: val_loss improved from 0.04646 to 0.04640, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0496 - val_loss: 0.0464 - learning_rate: 0.0010\n",
      "Epoch 160/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0478\n",
      "Epoch 160: val_loss did not improve from 0.04640\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0479 - val_loss: 0.0503 - learning_rate: 0.0010\n",
      "Epoch 161/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0470\n",
      "Epoch 161: val_loss did not improve from 0.04640\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0470 - val_loss: 0.0483 - learning_rate: 0.0010\n",
      "Epoch 162/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0467\n",
      "Epoch 162: val_loss did not improve from 0.04640\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0467 - val_loss: 0.0464 - learning_rate: 0.0010\n",
      "Epoch 163/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0470\n",
      "Epoch 163: val_loss did not improve from 0.04640\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0471 - val_loss: 0.0476 - learning_rate: 0.0010\n",
      "Epoch 164/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0477\n",
      "Epoch 164: val_loss did not improve from 0.04640\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0478 - val_loss: 0.0465 - learning_rate: 0.0010\n",
      "Epoch 165/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0479\n",
      "Epoch 165: val_loss did not improve from 0.04640\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0479 - val_loss: 0.0485 - learning_rate: 0.0010\n",
      "Epoch 166/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0466\n",
      "Epoch 166: val_loss improved from 0.04640 to 0.04603, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0466 - val_loss: 0.0460 - learning_rate: 0.0010\n",
      "Epoch 167/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0460\n",
      "Epoch 167: val_loss improved from 0.04603 to 0.04399, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0461 - val_loss: 0.0440 - learning_rate: 0.0010\n",
      "Epoch 168/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0459\n",
      "Epoch 168: val_loss improved from 0.04399 to 0.04284, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0459 - val_loss: 0.0428 - learning_rate: 0.0010\n",
      "Epoch 169/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0462\n",
      "Epoch 169: val_loss did not improve from 0.04284\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0461 - val_loss: 0.0437 - learning_rate: 0.0010\n",
      "Epoch 170/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0460\n",
      "Epoch 170: val_loss did not improve from 0.04284\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0459 - val_loss: 0.0460 - learning_rate: 0.0010\n",
      "Epoch 171/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0452\n",
      "Epoch 171: val_loss improved from 0.04284 to 0.04277, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0452 - val_loss: 0.0428 - learning_rate: 0.0010\n",
      "Epoch 172/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0458\n",
      "Epoch 172: val_loss did not improve from 0.04277\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0458 - val_loss: 0.0450 - learning_rate: 0.0010\n",
      "Epoch 173/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0447\n",
      "Epoch 173: val_loss did not improve from 0.04277\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0447 - val_loss: 0.0432 - learning_rate: 0.0010\n",
      "Epoch 174/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0435\n",
      "Epoch 174: val_loss did not improve from 0.04277\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0435 - val_loss: 0.0456 - learning_rate: 0.0010\n",
      "Epoch 175/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0436\n",
      "Epoch 175: val_loss improved from 0.04277 to 0.04181, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.0436 - val_loss: 0.0418 - learning_rate: 0.0010\n",
      "Epoch 176/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0427\n",
      "Epoch 176: val_loss improved from 0.04181 to 0.03974, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0427 - val_loss: 0.0397 - learning_rate: 0.0010\n",
      "Epoch 177/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0421\n",
      "Epoch 177: val_loss did not improve from 0.03974\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0422 - val_loss: 0.0399 - learning_rate: 0.0010\n",
      "Epoch 178/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0422\n",
      "Epoch 178: val_loss did not improve from 0.03974\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0422 - val_loss: 0.0410 - learning_rate: 0.0010\n",
      "Epoch 179/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0420\n",
      "Epoch 179: val_loss did not improve from 0.03974\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0421 - val_loss: 0.0412 - learning_rate: 0.0010\n",
      "Epoch 180/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0408\n",
      "Epoch 180: val_loss did not improve from 0.03974\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0409 - val_loss: 0.0432 - learning_rate: 0.0010\n",
      "Epoch 181/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0422\n",
      "Epoch 181: val_loss improved from 0.03974 to 0.03801, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0421 - val_loss: 0.0380 - learning_rate: 0.0010\n",
      "Epoch 182/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0407\n",
      "Epoch 182: val_loss did not improve from 0.03801\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0407 - val_loss: 0.0395 - learning_rate: 0.0010\n",
      "Epoch 183/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0411\n",
      "Epoch 183: val_loss improved from 0.03801 to 0.03795, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0411 - val_loss: 0.0380 - learning_rate: 0.0010\n",
      "Epoch 184/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0412\n",
      "Epoch 184: val_loss improved from 0.03795 to 0.03729, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0413 - val_loss: 0.0373 - learning_rate: 0.0010\n",
      "Epoch 185/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0417\n",
      "Epoch 185: val_loss did not improve from 0.03729\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0417 - val_loss: 0.0448 - learning_rate: 0.0010\n",
      "Epoch 186/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0411\n",
      "Epoch 186: val_loss did not improve from 0.03729\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0411 - val_loss: 0.0421 - learning_rate: 0.0010\n",
      "Epoch 187/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0419\n",
      "Epoch 187: val_loss did not improve from 0.03729\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0418 - val_loss: 0.0434 - learning_rate: 0.0010\n",
      "Epoch 188/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0397\n",
      "Epoch 188: val_loss did not improve from 0.03729\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0397 - val_loss: 0.0380 - learning_rate: 0.0010\n",
      "Epoch 189/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0401\n",
      "Epoch 189: val_loss improved from 0.03729 to 0.03698, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0401 - val_loss: 0.0370 - learning_rate: 0.0010\n",
      "Epoch 190/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0388\n",
      "Epoch 190: val_loss did not improve from 0.03698\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0388 - val_loss: 0.0397 - learning_rate: 0.0010\n",
      "Epoch 191/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0389\n",
      "Epoch 191: val_loss did not improve from 0.03698\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0389 - val_loss: 0.0414 - learning_rate: 0.0010\n",
      "Epoch 192/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0383\n",
      "Epoch 192: val_loss improved from 0.03698 to 0.03566, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0383 - val_loss: 0.0357 - learning_rate: 0.0010\n",
      "Epoch 193/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0381\n",
      "Epoch 193: val_loss did not improve from 0.03566\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0381 - val_loss: 0.0368 - learning_rate: 0.0010\n",
      "Epoch 194/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0376\n",
      "Epoch 194: val_loss did not improve from 0.03566\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0377 - val_loss: 0.0391 - learning_rate: 0.0010\n",
      "Epoch 195/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0374\n",
      "Epoch 195: val_loss did not improve from 0.03566\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0374 - val_loss: 0.0367 - learning_rate: 0.0010\n",
      "Epoch 196/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0370\n",
      "Epoch 196: val_loss did not improve from 0.03566\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0370 - val_loss: 0.0387 - learning_rate: 0.0010\n",
      "Epoch 197/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0366\n",
      "Epoch 197: val_loss improved from 0.03566 to 0.03526, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0366 - val_loss: 0.0353 - learning_rate: 0.0010\n",
      "Epoch 198/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0378\n",
      "Epoch 198: val_loss did not improve from 0.03526\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0378 - val_loss: 0.0366 - learning_rate: 0.0010\n",
      "Epoch 199/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0387\n",
      "Epoch 199: val_loss did not improve from 0.03526\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0386 - val_loss: 0.0354 - learning_rate: 0.0010\n",
      "Epoch 200/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0366\n",
      "Epoch 200: val_loss improved from 0.03526 to 0.03431, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0366 - val_loss: 0.0343 - learning_rate: 0.0010\n",
      "Epoch 201/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0375\n",
      "Epoch 201: val_loss did not improve from 0.03431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0374 - val_loss: 0.0344 - learning_rate: 0.0010\n",
      "Epoch 202/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0366\n",
      "Epoch 202: val_loss improved from 0.03431 to 0.03317, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0365 - val_loss: 0.0332 - learning_rate: 0.0010\n",
      "Epoch 203/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0353\n",
      "Epoch 203: val_loss did not improve from 0.03317\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0353 - val_loss: 0.0357 - learning_rate: 0.0010\n",
      "Epoch 204/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0348\n",
      "Epoch 204: val_loss did not improve from 0.03317\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0348 - val_loss: 0.0374 - learning_rate: 0.0010\n",
      "Epoch 205/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0358\n",
      "Epoch 205: val_loss did not improve from 0.03317\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0358 - val_loss: 0.0338 - learning_rate: 0.0010\n",
      "Epoch 206/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0354\n",
      "Epoch 206: val_loss improved from 0.03317 to 0.03270, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0354 - val_loss: 0.0327 - learning_rate: 0.0010\n",
      "Epoch 207/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0355\n",
      "Epoch 207: val_loss did not improve from 0.03270\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0356 - val_loss: 0.0338 - learning_rate: 0.0010\n",
      "Epoch 208/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0359\n",
      "Epoch 208: val_loss did not improve from 0.03270\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0359 - val_loss: 0.0363 - learning_rate: 0.0010\n",
      "Epoch 209/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0345\n",
      "Epoch 209: val_loss improved from 0.03270 to 0.03153, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0346 - val_loss: 0.0315 - learning_rate: 0.0010\n",
      "Epoch 210/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0342\n",
      "Epoch 210: val_loss improved from 0.03153 to 0.03098, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0342 - val_loss: 0.0310 - learning_rate: 0.0010\n",
      "Epoch 211/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0333\n",
      "Epoch 211: val_loss did not improve from 0.03098\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0334 - val_loss: 0.0365 - learning_rate: 0.0010\n",
      "Epoch 212/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0354\n",
      "Epoch 212: val_loss improved from 0.03098 to 0.03069, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0355 - val_loss: 0.0307 - learning_rate: 0.0010\n",
      "Epoch 213/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0346\n",
      "Epoch 213: val_loss did not improve from 0.03069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0345 - val_loss: 0.0330 - learning_rate: 0.0010\n",
      "Epoch 214/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0333\n",
      "Epoch 214: val_loss did not improve from 0.03069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0334 - val_loss: 0.0496 - learning_rate: 0.0010\n",
      "Epoch 215/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0340\n",
      "Epoch 215: val_loss did not improve from 0.03069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0340 - val_loss: 0.0356 - learning_rate: 0.0010\n",
      "Epoch 216/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0342\n",
      "Epoch 216: val_loss did not improve from 0.03069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0342 - val_loss: 0.0317 - learning_rate: 0.0010\n",
      "Epoch 217/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0328\n",
      "Epoch 217: val_loss improved from 0.03069 to 0.03069, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0328 - val_loss: 0.0307 - learning_rate: 0.0010\n",
      "Epoch 218/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0325\n",
      "Epoch 218: val_loss improved from 0.03069 to 0.02914, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0325 - val_loss: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 219/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0329\n",
      "Epoch 219: val_loss did not improve from 0.02914\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0329 - val_loss: 0.0329 - learning_rate: 0.0010\n",
      "Epoch 220/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0332\n",
      "Epoch 220: val_loss did not improve from 0.02914\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0331 - val_loss: 0.0304 - learning_rate: 0.0010\n",
      "Epoch 221/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0330\n",
      "Epoch 221: val_loss did not improve from 0.02914\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0330 - val_loss: 0.0315 - learning_rate: 0.0010\n",
      "Epoch 222/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0327\n",
      "Epoch 222: val_loss did not improve from 0.02914\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0328 - val_loss: 0.0335 - learning_rate: 0.0010\n",
      "Epoch 223/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0318\n",
      "Epoch 223: val_loss did not improve from 0.02914\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0318 - val_loss: 0.0322 - learning_rate: 0.0010\n",
      "Epoch 224/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0309\n",
      "Epoch 224: val_loss did not improve from 0.02914\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0309 - val_loss: 0.0323 - learning_rate: 0.0010\n",
      "Epoch 225/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0308\n",
      "Epoch 225: val_loss did not improve from 0.02914\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0308 - val_loss: 0.0295 - learning_rate: 0.0010\n",
      "Epoch 226/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0304\n",
      "Epoch 226: val_loss did not improve from 0.02914\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0304 - val_loss: 0.0312 - learning_rate: 0.0010\n",
      "Epoch 227/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0300\n",
      "Epoch 227: val_loss did not improve from 0.02914\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.0300 - val_loss: 0.0315 - learning_rate: 0.0010\n",
      "Epoch 228/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0307\n",
      "Epoch 228: val_loss did not improve from 0.02914\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0307 - val_loss: 0.0312 - learning_rate: 0.0010\n",
      "Epoch 229/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0305\n",
      "Epoch 229: val_loss did not improve from 0.02914\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0305 - val_loss: 0.0328 - learning_rate: 0.0010\n",
      "Epoch 230/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0308\n",
      "Epoch 230: val_loss did not improve from 0.02914\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.0308 - val_loss: 0.0299 - learning_rate: 0.0010\n",
      "Epoch 231/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0310\n",
      "Epoch 231: val_loss did not improve from 0.02914\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0310 - val_loss: 0.0305 - learning_rate: 0.0010\n",
      "Epoch 232/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0309\n",
      "Epoch 232: val_loss did not improve from 0.02914\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0309 - val_loss: 0.0311 - learning_rate: 0.0010\n",
      "Epoch 233/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0301\n",
      "Epoch 233: val_loss improved from 0.02914 to 0.02864, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 236ms/step - loss: 0.0301 - val_loss: 0.0286 - learning_rate: 0.0010\n",
      "Epoch 234/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0310\n",
      "Epoch 234: val_loss did not improve from 0.02864\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0310 - val_loss: 0.0300 - learning_rate: 0.0010\n",
      "Epoch 235/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0299\n",
      "Epoch 235: val_loss did not improve from 0.02864\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0299 - val_loss: 0.0352 - learning_rate: 0.0010\n",
      "Epoch 236/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 0.0284\n",
      "Epoch 236: val_loss improved from 0.02864 to 0.02801, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - loss: 0.0285 - val_loss: 0.0280 - learning_rate: 0.0010\n",
      "Epoch 237/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.0298\n",
      "Epoch 237: val_loss did not improve from 0.02801\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - loss: 0.0298 - val_loss: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 238/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.0294\n",
      "Epoch 238: val_loss did not improve from 0.02801\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.0294 - val_loss: 0.0282 - learning_rate: 0.0010\n",
      "Epoch 239/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0290\n",
      "Epoch 239: val_loss did not improve from 0.02801\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0291 - val_loss: 0.0296 - learning_rate: 0.0010\n",
      "Epoch 240/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0288\n",
      "Epoch 240: val_loss did not improve from 0.02801\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0289 - val_loss: 0.0320 - learning_rate: 0.0010\n",
      "Epoch 241/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0307\n",
      "Epoch 241: val_loss improved from 0.02801 to 0.02784, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0306 - val_loss: 0.0278 - learning_rate: 0.0010\n",
      "Epoch 242/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0299\n",
      "Epoch 242: val_loss improved from 0.02784 to 0.02568, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0298 - val_loss: 0.0257 - learning_rate: 0.0010\n",
      "Epoch 243/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0287\n",
      "Epoch 243: val_loss did not improve from 0.02568\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0287 - val_loss: 0.0286 - learning_rate: 0.0010\n",
      "Epoch 244/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0290\n",
      "Epoch 244: val_loss did not improve from 0.02568\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0289 - val_loss: 0.0272 - learning_rate: 0.0010\n",
      "Epoch 245/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0275\n",
      "Epoch 245: val_loss improved from 0.02568 to 0.02555, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0275 - val_loss: 0.0256 - learning_rate: 0.0010\n",
      "Epoch 246/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0288\n",
      "Epoch 246: val_loss did not improve from 0.02555\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0287 - val_loss: 0.0280 - learning_rate: 0.0010\n",
      "Epoch 247/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0274\n",
      "Epoch 247: val_loss did not improve from 0.02555\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0274 - val_loss: 0.0310 - learning_rate: 0.0010\n",
      "Epoch 248/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0268\n",
      "Epoch 248: val_loss did not improve from 0.02555\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0269 - val_loss: 0.0312 - learning_rate: 0.0010\n",
      "Epoch 249/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0286\n",
      "Epoch 249: val_loss did not improve from 0.02555\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0286 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 250/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0287\n",
      "Epoch 250: val_loss did not improve from 0.02555\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0286 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 251/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0274\n",
      "Epoch 251: val_loss improved from 0.02555 to 0.02508, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - loss: 0.0274 - val_loss: 0.0251 - learning_rate: 0.0010\n",
      "Epoch 252/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0267\n",
      "Epoch 252: val_loss did not improve from 0.02508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0267 - val_loss: 0.0276 - learning_rate: 0.0010\n",
      "Epoch 253/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0265\n",
      "Epoch 253: val_loss did not improve from 0.02508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0266 - val_loss: 0.0276 - learning_rate: 0.0010\n",
      "Epoch 254/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0280\n",
      "Epoch 254: val_loss did not improve from 0.02508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0280 - val_loss: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 255/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0261\n",
      "Epoch 255: val_loss did not improve from 0.02508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0261 - val_loss: 0.0256 - learning_rate: 0.0010\n",
      "Epoch 256/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0255\n",
      "Epoch 256: val_loss did not improve from 0.02508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0255 - val_loss: 0.0264 - learning_rate: 0.0010\n",
      "Epoch 257/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0261\n",
      "Epoch 257: val_loss did not improve from 0.02508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0261 - val_loss: 0.0267 - learning_rate: 0.0010\n",
      "Epoch 258/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0262\n",
      "Epoch 258: val_loss did not improve from 0.02508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0262 - val_loss: 0.0270 - learning_rate: 0.0010\n",
      "Epoch 259/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0250\n",
      "Epoch 259: val_loss did not improve from 0.02508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0250 - val_loss: 0.0280 - learning_rate: 0.0010\n",
      "Epoch 260/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0254\n",
      "Epoch 260: val_loss did not improve from 0.02508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0253 - val_loss: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 261/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0249\n",
      "Epoch 261: val_loss did not improve from 0.02508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0249 - val_loss: 0.0303 - learning_rate: 0.0010\n",
      "Epoch 262/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0256\n",
      "Epoch 262: val_loss did not improve from 0.02508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0257 - val_loss: 0.0301 - learning_rate: 0.0010\n",
      "Epoch 263/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0275\n",
      "Epoch 263: val_loss did not improve from 0.02508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0275 - val_loss: 0.0292 - learning_rate: 0.0010\n",
      "Epoch 264/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0255\n",
      "Epoch 264: val_loss did not improve from 0.02508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0255 - val_loss: 0.0260 - learning_rate: 0.0010\n",
      "Epoch 265/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0250\n",
      "Epoch 265: val_loss did not improve from 0.02508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0250 - val_loss: 0.0258 - learning_rate: 0.0010\n",
      "Epoch 266/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0245\n",
      "Epoch 266: val_loss did not improve from 0.02508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0245 - val_loss: 0.0269 - learning_rate: 0.0010\n",
      "Epoch 267/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0246\n",
      "Epoch 267: val_loss did not improve from 0.02508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0246 - val_loss: 0.0252 - learning_rate: 0.0010\n",
      "Epoch 268/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0249\n",
      "Epoch 268: val_loss did not improve from 0.02508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0250 - val_loss: 0.0255 - learning_rate: 0.0010\n",
      "Epoch 269/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0266\n",
      "Epoch 269: val_loss improved from 0.02508 to 0.02442, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0266 - val_loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 270/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0254\n",
      "Epoch 270: val_loss did not improve from 0.02442\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0254 - val_loss: 0.0266 - learning_rate: 0.0010\n",
      "Epoch 271/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0246\n",
      "Epoch 271: val_loss did not improve from 0.02442\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0247 - val_loss: 0.0267 - learning_rate: 0.0010\n",
      "Epoch 272/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0249\n",
      "Epoch 272: val_loss did not improve from 0.02442\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0249 - val_loss: 0.0247 - learning_rate: 0.0010\n",
      "Epoch 273/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0238\n",
      "Epoch 273: val_loss improved from 0.02442 to 0.02229, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.0239 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 274/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0245\n",
      "Epoch 274: val_loss did not improve from 0.02229\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0245 - val_loss: 0.0240 - learning_rate: 0.0010\n",
      "Epoch 275/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0244\n",
      "Epoch 275: val_loss improved from 0.02229 to 0.02157, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.0244 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 276/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0239\n",
      "Epoch 276: val_loss did not improve from 0.02157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0239 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 277/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0233\n",
      "Epoch 277: val_loss did not improve from 0.02157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0233 - val_loss: 0.0260 - learning_rate: 0.0010\n",
      "Epoch 278/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0223\n",
      "Epoch 278: val_loss did not improve from 0.02157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0224 - val_loss: 0.0240 - learning_rate: 0.0010\n",
      "Epoch 279/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0228\n",
      "Epoch 279: val_loss did not improve from 0.02157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0228 - val_loss: 0.0295 - learning_rate: 0.0010\n",
      "Epoch 280/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0232\n",
      "Epoch 280: val_loss did not improve from 0.02157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0231 - val_loss: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 281/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0232\n",
      "Epoch 281: val_loss did not improve from 0.02157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0232 - val_loss: 0.0249 - learning_rate: 0.0010\n",
      "Epoch 282/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0232\n",
      "Epoch 282: val_loss did not improve from 0.02157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0232 - val_loss: 0.0225 - learning_rate: 0.0010\n",
      "Epoch 283/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0233\n",
      "Epoch 283: val_loss did not improve from 0.02157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0233 - val_loss: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 284/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0233\n",
      "Epoch 284: val_loss did not improve from 0.02157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0233 - val_loss: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 285/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0227\n",
      "Epoch 285: val_loss did not improve from 0.02157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0227 - val_loss: 0.0239 - learning_rate: 0.0010\n",
      "Epoch 286/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0225\n",
      "Epoch 286: val_loss did not improve from 0.02157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0225 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 287/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0223\n",
      "Epoch 287: val_loss did not improve from 0.02157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0223 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 288/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0218\n",
      "Epoch 288: val_loss did not improve from 0.02157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0218 - val_loss: 0.0236 - learning_rate: 0.0010\n",
      "Epoch 289/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0219\n",
      "Epoch 289: val_loss improved from 0.02157 to 0.02100, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 243ms/step - loss: 0.0219 - val_loss: 0.0210 - learning_rate: 0.0010\n",
      "Epoch 290/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0214\n",
      "Epoch 290: val_loss did not improve from 0.02100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0214 - val_loss: 0.0232 - learning_rate: 0.0010\n",
      "Epoch 291/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0216\n",
      "Epoch 291: val_loss did not improve from 0.02100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0216 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 292/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0212\n",
      "Epoch 292: val_loss did not improve from 0.02100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0213 - val_loss: 0.0225 - learning_rate: 0.0010\n",
      "Epoch 293/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0207\n",
      "Epoch 293: val_loss improved from 0.02100 to 0.02069, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0208 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 294/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0204\n",
      "Epoch 294: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0205 - val_loss: 0.0218 - learning_rate: 0.0010\n",
      "Epoch 295/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0219\n",
      "Epoch 295: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0219 - val_loss: 0.0259 - learning_rate: 0.0010\n",
      "Epoch 296/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0215\n",
      "Epoch 296: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0216 - val_loss: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 297/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0212\n",
      "Epoch 297: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0212 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 298/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0230\n",
      "Epoch 298: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0230 - val_loss: 0.0229 - learning_rate: 0.0010\n",
      "Epoch 299/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0215\n",
      "Epoch 299: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0216 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 300/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0219\n",
      "Epoch 300: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0219 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 301/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0224\n",
      "Epoch 301: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0224 - val_loss: 0.0210 - learning_rate: 0.0010\n",
      "Epoch 302/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0210\n",
      "Epoch 302: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0211 - val_loss: 0.0259 - learning_rate: 0.0010\n",
      "Epoch 303/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0229\n",
      "Epoch 303: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0229 - val_loss: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 304/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0226\n",
      "Epoch 304: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0226 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 305/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0205\n",
      "Epoch 305: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0205 - val_loss: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 306/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0206\n",
      "Epoch 306: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0206 - val_loss: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 307/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0212\n",
      "Epoch 307: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0211 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 308/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0198\n",
      "Epoch 308: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0197 - val_loss: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 309/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0198\n",
      "Epoch 309: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0199 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 310/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0200\n",
      "Epoch 310: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0200 - val_loss: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 311/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0210\n",
      "Epoch 311: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0209 - val_loss: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 312/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0199\n",
      "Epoch 312: val_loss did not improve from 0.02069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0199 - val_loss: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 313/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0198\n",
      "Epoch 313: val_loss improved from 0.02069 to 0.02003, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0198 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 314/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0198\n",
      "Epoch 314: val_loss did not improve from 0.02003\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0198 - val_loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 315/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0204\n",
      "Epoch 315: val_loss did not improve from 0.02003\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0203 - val_loss: 0.0237 - learning_rate: 0.0010\n",
      "Epoch 316/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0199\n",
      "Epoch 316: val_loss improved from 0.02003 to 0.01978, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0200 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 317/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0228\n",
      "Epoch 317: val_loss did not improve from 0.01978\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0228 - val_loss: 0.0274 - learning_rate: 0.0010\n",
      "Epoch 318/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0235\n",
      "Epoch 318: val_loss improved from 0.01978 to 0.01937, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0233 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 319/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0222\n",
      "Epoch 319: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0222 - val_loss: 0.0288 - learning_rate: 0.0010\n",
      "Epoch 320/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0216\n",
      "Epoch 320: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0216 - val_loss: 0.0229 - learning_rate: 0.0010\n",
      "Epoch 321/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0208\n",
      "Epoch 321: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0208 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 322/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0208\n",
      "Epoch 322: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0208 - val_loss: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 323/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0192\n",
      "Epoch 323: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0193 - val_loss: 0.0237 - learning_rate: 0.0010\n",
      "Epoch 324/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0190\n",
      "Epoch 324: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0190 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 325/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0185\n",
      "Epoch 325: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0185 - val_loss: 0.0235 - learning_rate: 0.0010\n",
      "Epoch 326/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0187\n",
      "Epoch 326: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0187 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 327/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0190\n",
      "Epoch 327: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0191 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 328/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0187\n",
      "Epoch 328: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0187 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 329/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0187\n",
      "Epoch 329: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0187 - val_loss: 0.0229 - learning_rate: 0.0010\n",
      "Epoch 330/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0187\n",
      "Epoch 330: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0187 - val_loss: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 331/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0178\n",
      "Epoch 331: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0179 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 332/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0182\n",
      "Epoch 332: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0182 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 333/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0184\n",
      "Epoch 333: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0184 - val_loss: 0.0262 - learning_rate: 0.0010\n",
      "Epoch 334/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0196\n",
      "Epoch 334: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0196 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 335/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0198\n",
      "Epoch 335: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0197 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 336/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0188\n",
      "Epoch 336: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0189 - val_loss: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 337/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0188\n",
      "Epoch 337: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0189 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 338/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0192\n",
      "Epoch 338: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0192 - val_loss: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 339/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0189\n",
      "Epoch 339: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0189 - val_loss: 0.0202 - learning_rate: 0.0010\n",
      "Epoch 340/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0184\n",
      "Epoch 340: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0184 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 341/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0186\n",
      "Epoch 341: val_loss did not improve from 0.01937\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0186 - val_loss: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 342/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0185\n",
      "Epoch 342: val_loss improved from 0.01937 to 0.01740, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0186 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 343/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0178\n",
      "Epoch 343: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0178 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 344/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0170\n",
      "Epoch 344: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0170 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 345/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0167\n",
      "Epoch 345: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0168 - val_loss: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 346/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0169\n",
      "Epoch 346: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0170 - val_loss: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 347/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0176\n",
      "Epoch 347: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0176 - val_loss: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 348/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0184\n",
      "Epoch 348: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0184 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 349/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0170\n",
      "Epoch 349: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0171 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 350/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0190\n",
      "Epoch 350: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0190 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 351/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0178\n",
      "Epoch 351: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0179 - val_loss: 0.0219 - learning_rate: 0.0010\n",
      "Epoch 352/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0187\n",
      "Epoch 352: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0187 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 353/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0184\n",
      "Epoch 353: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0184 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 354/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0195\n",
      "Epoch 354: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0194 - val_loss: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 355/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0181\n",
      "Epoch 355: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0182 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 356/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0187\n",
      "Epoch 356: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0187 - val_loss: 0.0202 - learning_rate: 0.0010\n",
      "Epoch 357/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0172\n",
      "Epoch 357: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0172 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 358/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0178\n",
      "Epoch 358: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0177 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 359/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0183\n",
      "Epoch 359: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0183 - val_loss: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 360/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0181\n",
      "Epoch 360: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0182 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 361/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0181\n",
      "Epoch 361: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0181 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 362/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0176\n",
      "Epoch 362: val_loss did not improve from 0.01740\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0176 - val_loss: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 363/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0169\n",
      "Epoch 363: val_loss improved from 0.01740 to 0.01652, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0169 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 364/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0174\n",
      "Epoch 364: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0174 - val_loss: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 365/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0172\n",
      "Epoch 365: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0172 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 366/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0164\n",
      "Epoch 366: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0164 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 367/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0165\n",
      "Epoch 367: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0165 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 368/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0175\n",
      "Epoch 368: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0175 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 369/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0167\n",
      "Epoch 369: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0167 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 370/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0177\n",
      "Epoch 370: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0177 - val_loss: 0.0239 - learning_rate: 0.0010\n",
      "Epoch 371/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0171\n",
      "Epoch 371: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0171 - val_loss: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 372/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0170\n",
      "Epoch 372: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0170 - val_loss: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 373/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0167\n",
      "Epoch 373: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0168 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 374/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0166\n",
      "Epoch 374: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0166 - val_loss: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 375/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0153\n",
      "Epoch 375: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0153 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 376/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0158\n",
      "Epoch 376: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0158 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 377/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0159\n",
      "Epoch 377: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0160 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 378/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0168\n",
      "Epoch 378: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0168 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 379/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0165\n",
      "Epoch 379: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0165 - val_loss: 0.0210 - learning_rate: 0.0010\n",
      "Epoch 380/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0168\n",
      "Epoch 380: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0168 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 381/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0182\n",
      "Epoch 381: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0182 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 382/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0175\n",
      "Epoch 382: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0175 - val_loss: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 383/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0164\n",
      "Epoch 383: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0165 - val_loss: 0.0188 - learning_rate: 0.0010\n",
      "Epoch 384/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0163\n",
      "Epoch 384: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0163 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 385/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0165\n",
      "Epoch 385: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0165 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 386/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0153\n",
      "Epoch 386: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0154 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 387/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0162\n",
      "Epoch 387: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0162 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 388/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0154\n",
      "Epoch 388: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0155 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 389/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0158\n",
      "Epoch 389: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0158 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 390/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0160\n",
      "Epoch 390: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0160 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 391/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0173\n",
      "Epoch 391: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0173 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 392/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0167\n",
      "Epoch 392: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0167 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 393/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0159\n",
      "Epoch 393: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0159 - val_loss: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 394/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0166\n",
      "Epoch 394: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0166 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 395/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0158\n",
      "Epoch 395: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0158 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 396/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0168\n",
      "Epoch 396: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0169 - val_loss: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 397/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0171\n",
      "Epoch 397: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0171 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 398/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0163\n",
      "Epoch 398: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0164 - val_loss: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 399/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0170\n",
      "Epoch 399: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0170 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 400/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0177\n",
      "Epoch 400: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0177 - val_loss: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 401/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0172\n",
      "Epoch 401: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0171 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 402/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0160\n",
      "Epoch 402: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0160 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 403/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0160\n",
      "Epoch 403: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0160 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 404/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0150\n",
      "Epoch 404: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0150 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 405/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0146\n",
      "Epoch 405: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0146 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 406/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0155\n",
      "Epoch 406: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0155 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 407/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0151\n",
      "Epoch 407: val_loss did not improve from 0.01652\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0151 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 408/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0149\n",
      "Epoch 408: val_loss improved from 0.01652 to 0.01594, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0149 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 409/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0149\n",
      "Epoch 409: val_loss did not improve from 0.01594\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0149 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 410/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0148\n",
      "Epoch 410: val_loss did not improve from 0.01594\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0148 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 411/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0151\n",
      "Epoch 411: val_loss did not improve from 0.01594\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0151 - val_loss: 0.0255 - learning_rate: 0.0010\n",
      "Epoch 412/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0154\n",
      "Epoch 412: val_loss did not improve from 0.01594\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0155 - val_loss: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 413/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0151\n",
      "Epoch 413: val_loss did not improve from 0.01594\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0151 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 414/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0160\n",
      "Epoch 414: val_loss did not improve from 0.01594\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0160 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 415/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0158\n",
      "Epoch 415: val_loss did not improve from 0.01594\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0158 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 416/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0149\n",
      "Epoch 416: val_loss did not improve from 0.01594\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0149 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 417/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0149\n",
      "Epoch 417: val_loss did not improve from 0.01594\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0149 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 418/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0144\n",
      "Epoch 418: val_loss did not improve from 0.01594\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0144 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 419/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0151\n",
      "Epoch 419: val_loss did not improve from 0.01594\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0150 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 420/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0147\n",
      "Epoch 420: val_loss did not improve from 0.01594\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0147 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 421/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0146\n",
      "Epoch 421: val_loss did not improve from 0.01594\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0146 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 422/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0145\n",
      "Epoch 422: val_loss improved from 0.01594 to 0.01582, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0146 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 423/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0143\n",
      "Epoch 423: val_loss did not improve from 0.01582\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0144 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 424/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0150\n",
      "Epoch 424: val_loss did not improve from 0.01582\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0150 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 425/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0155\n",
      "Epoch 425: val_loss did not improve from 0.01582\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0155 - val_loss: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 426/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0158\n",
      "Epoch 426: val_loss did not improve from 0.01582\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0158 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 427/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0164\n",
      "Epoch 427: val_loss did not improve from 0.01582\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0164 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 428/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0181\n",
      "Epoch 428: val_loss did not improve from 0.01582\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0180 - val_loss: 0.0218 - learning_rate: 0.0010\n",
      "Epoch 429/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0154\n",
      "Epoch 429: val_loss did not improve from 0.01582\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0154 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 430/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0165\n",
      "Epoch 430: val_loss did not improve from 0.01582\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0165 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 431/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0162\n",
      "Epoch 431: val_loss did not improve from 0.01582\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0162 - val_loss: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 432/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0161\n",
      "Epoch 432: val_loss did not improve from 0.01582\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0161 - val_loss: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 433/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0151\n",
      "Epoch 433: val_loss did not improve from 0.01582\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0151 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 434/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0140\n",
      "Epoch 434: val_loss did not improve from 0.01582\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0141 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 435/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0143\n",
      "Epoch 435: val_loss improved from 0.01582 to 0.01559, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0143 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 436/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0150\n",
      "Epoch 436: val_loss did not improve from 0.01559\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0150 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 437/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0143\n",
      "Epoch 437: val_loss did not improve from 0.01559\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0143 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 438/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0149\n",
      "Epoch 438: val_loss did not improve from 0.01559\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0149 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 439/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0149\n",
      "Epoch 439: val_loss did not improve from 0.01559\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0149 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 440/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0169\n",
      "Epoch 440: val_loss did not improve from 0.01559\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0169 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 441/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0170\n",
      "Epoch 441: val_loss did not improve from 0.01559\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0171 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 442/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0163\n",
      "Epoch 442: val_loss improved from 0.01559 to 0.01485, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0163 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 443/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0167\n",
      "Epoch 443: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0166 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 444/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0150\n",
      "Epoch 444: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0151 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 445/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0144\n",
      "Epoch 445: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0145 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 446/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0159\n",
      "Epoch 446: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0159 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 447/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0154\n",
      "Epoch 447: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0154 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 448/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0146\n",
      "Epoch 448: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0146 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 449/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0139\n",
      "Epoch 449: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0139 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 450/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0142\n",
      "Epoch 450: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0143 - val_loss: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 451/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0148\n",
      "Epoch 451: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0147 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 452/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0143\n",
      "Epoch 452: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0142 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 453/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0139\n",
      "Epoch 453: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0139 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 454/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0149\n",
      "Epoch 454: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0149 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 455/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0147\n",
      "Epoch 455: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0147 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 456/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0142\n",
      "Epoch 456: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0142 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 457/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0134\n",
      "Epoch 457: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0135 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 458/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0140\n",
      "Epoch 458: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0140 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 459/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0134\n",
      "Epoch 459: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0134 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 460/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0146\n",
      "Epoch 460: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0146 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 461/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0142\n",
      "Epoch 461: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0142 - val_loss: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 462/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0143\n",
      "Epoch 462: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0143 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 463/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0155\n",
      "Epoch 463: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0155 - val_loss: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 464/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0150\n",
      "Epoch 464: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0149 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 465/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0138\n",
      "Epoch 465: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0138 - val_loss: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 466/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0135\n",
      "Epoch 466: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0135 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 467/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0132\n",
      "Epoch 467: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0132 - val_loss: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 468/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0129\n",
      "Epoch 468: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0130 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 469/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0131\n",
      "Epoch 469: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0132 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 470/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0140\n",
      "Epoch 470: val_loss did not improve from 0.01485\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0140 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 471/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.0134\n",
      "Epoch 471: val_loss improved from 0.01485 to 0.01477, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250ms/step - loss: 0.0134 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 472/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0137\n",
      "Epoch 472: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0138 - val_loss: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 473/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0137\n",
      "Epoch 473: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0137 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 474/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0146\n",
      "Epoch 474: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0146 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 475/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0139\n",
      "Epoch 475: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0139 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 476/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0139\n",
      "Epoch 476: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0139 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 477/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0139\n",
      "Epoch 477: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0140 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 478/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0146\n",
      "Epoch 478: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0145 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 479/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0133\n",
      "Epoch 479: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0133 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 480/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0138\n",
      "Epoch 480: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0139 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 481/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0140\n",
      "Epoch 481: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0140 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 482/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0132\n",
      "Epoch 482: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0132 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 483/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0129\n",
      "Epoch 483: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0129 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 484/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0131\n",
      "Epoch 484: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0131 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 485/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0137\n",
      "Epoch 485: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0138 - val_loss: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 486/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0141\n",
      "Epoch 486: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0141 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 487/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0130\n",
      "Epoch 487: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0130 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 488/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0125\n",
      "Epoch 488: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0125 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 489/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0130\n",
      "Epoch 489: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0130 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 490/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0132\n",
      "Epoch 490: val_loss did not improve from 0.01477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0132 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 491/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0132\n",
      "Epoch 491: val_loss improved from 0.01477 to 0.01415, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0132 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 492/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0133\n",
      "Epoch 492: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0133 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 493/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0129\n",
      "Epoch 493: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0129 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 494/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0132\n",
      "Epoch 494: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0132 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 495/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0137\n",
      "Epoch 495: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0137 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 496/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 0.0128\n",
      "Epoch 496: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - loss: 0.0129 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 497/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0130\n",
      "Epoch 497: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0130 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 498/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0137\n",
      "Epoch 498: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0137 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 499/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0163\n",
      "Epoch 499: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0164 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 500/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0154\n",
      "Epoch 500: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0154 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 501/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0142\n",
      "Epoch 501: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0142 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 502/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0138\n",
      "Epoch 502: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0138 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 503/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0129\n",
      "Epoch 503: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0129 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 504/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0137\n",
      "Epoch 504: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0136 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 505/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0124\n",
      "Epoch 505: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0124 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 506/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0130\n",
      "Epoch 506: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0130 - val_loss: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 507/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0137\n",
      "Epoch 507: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0137 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 508/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0129\n",
      "Epoch 508: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0130 - val_loss: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 509/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0146\n",
      "Epoch 509: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0147 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 510/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0160\n",
      "Epoch 510: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0161 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 511/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0153\n",
      "Epoch 511: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0153 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 512/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0155\n",
      "Epoch 512: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0155 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 513/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0150\n",
      "Epoch 513: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0150 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 514/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0139\n",
      "Epoch 514: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0139 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 515/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0139\n",
      "Epoch 515: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0139 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 516/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0126\n",
      "Epoch 516: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0126 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 517/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0123\n",
      "Epoch 517: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0123 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 518/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0129\n",
      "Epoch 518: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0129 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 519/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0131\n",
      "Epoch 519: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0132 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 520/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0130\n",
      "Epoch 520: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0130 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 521/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0131\n",
      "Epoch 521: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0131 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 522/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0132\n",
      "Epoch 522: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0132 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 523/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0124\n",
      "Epoch 523: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0124 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 524/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0122\n",
      "Epoch 524: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0122 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 525/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0129\n",
      "Epoch 525: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0129 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 526/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0135\n",
      "Epoch 526: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0135 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 527/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0133\n",
      "Epoch 527: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0134 - val_loss: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 528/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0135\n",
      "Epoch 528: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0136 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 529/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0140\n",
      "Epoch 529: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0140 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 530/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0129\n",
      "Epoch 530: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0130 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 531/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0131\n",
      "Epoch 531: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0132 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 532/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0137\n",
      "Epoch 532: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0137 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 533/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0137\n",
      "Epoch 533: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0137 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 534/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0126\n",
      "Epoch 534: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0127 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 535/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0122\n",
      "Epoch 535: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0123 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 536/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0142\n",
      "Epoch 536: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0141 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 537/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0137\n",
      "Epoch 537: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0137 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 538/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0143\n",
      "Epoch 538: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0143 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 539/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0129\n",
      "Epoch 539: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0129 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 540/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0125\n",
      "Epoch 540: val_loss did not improve from 0.01415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0125 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 541/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0126\n",
      "Epoch 541: val_loss improved from 0.01415 to 0.01380, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0126 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 542/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0117\n",
      "Epoch 542: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0117 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 543/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0117\n",
      "Epoch 543: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0117 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 544/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0125\n",
      "Epoch 544: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0125 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 545/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0119\n",
      "Epoch 545: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0119 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 546/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0124\n",
      "Epoch 546: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0124 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 547/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0134\n",
      "Epoch 547: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0135 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 548/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0132\n",
      "Epoch 548: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0132 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 549/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0129\n",
      "Epoch 549: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0129 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 550/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0136\n",
      "Epoch 550: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0136 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 551/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0133\n",
      "Epoch 551: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0133 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 552/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0131\n",
      "Epoch 552: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0131 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 553/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0124\n",
      "Epoch 553: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0124 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 554/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0123\n",
      "Epoch 554: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0124 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 555/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0128\n",
      "Epoch 555: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0128 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 556/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0126\n",
      "Epoch 556: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0126 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 557/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0129\n",
      "Epoch 557: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0130 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 558/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0134\n",
      "Epoch 558: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0134 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 559/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0123\n",
      "Epoch 559: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0123 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 560/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0122\n",
      "Epoch 560: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0123 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 561/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0128\n",
      "Epoch 561: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0128 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 562/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0137\n",
      "Epoch 562: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - loss: 0.0137 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 563/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0151\n",
      "Epoch 563: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0151 - val_loss: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 564/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0143\n",
      "Epoch 564: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0143 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 565/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0142\n",
      "Epoch 565: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0142 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 566/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0137\n",
      "Epoch 566: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0137 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 567/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0135\n",
      "Epoch 567: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0135 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 568/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0123\n",
      "Epoch 568: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0123 - val_loss: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 569/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0126\n",
      "Epoch 569: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0126 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 570/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0123\n",
      "Epoch 570: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0123 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 571/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0116\n",
      "Epoch 571: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0116 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 572/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0116\n",
      "Epoch 572: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0116 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 573/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0122\n",
      "Epoch 573: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0122 - val_loss: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 574/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0123\n",
      "Epoch 574: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0123 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 575/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0119\n",
      "Epoch 575: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0119 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 576/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0121\n",
      "Epoch 576: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0121 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 577/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0122\n",
      "Epoch 577: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0123 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 578/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0125\n",
      "Epoch 578: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0126 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 579/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0127\n",
      "Epoch 579: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0127 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 580/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0120\n",
      "Epoch 580: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0120 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 581/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0112\n",
      "Epoch 581: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0113 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 582/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0117\n",
      "Epoch 582: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0117 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 583/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0117\n",
      "Epoch 583: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0117 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 584/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0127\n",
      "Epoch 584: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0127 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 585/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0122\n",
      "Epoch 585: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0123 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 586/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0128\n",
      "Epoch 586: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0129 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 587/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0122\n",
      "Epoch 587: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0123 - val_loss: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 588/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0128\n",
      "Epoch 588: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0128 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 589/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0129\n",
      "Epoch 589: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0129 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 590/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0128\n",
      "Epoch 590: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0128 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 591/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0125\n",
      "Epoch 591: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0125 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 592/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0126\n",
      "Epoch 592: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0126 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 593/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0120\n",
      "Epoch 593: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0119 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 594/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0117\n",
      "Epoch 594: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0117 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 595/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0117\n",
      "Epoch 595: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0117 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 596/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0126\n",
      "Epoch 596: val_loss did not improve from 0.01380\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0125 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 597/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0119\n",
      "Epoch 597: val_loss improved from 0.01380 to 0.01255, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0119 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 598/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0132\n",
      "Epoch 598: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0131 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 599/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0122\n",
      "Epoch 599: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0123 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 600/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0130\n",
      "Epoch 600: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0130 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 601/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0119\n",
      "Epoch 601: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0119 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 602/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0122\n",
      "Epoch 602: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0122 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 603/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0114\n",
      "Epoch 603: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0114 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 604/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0116\n",
      "Epoch 604: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0116 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 605/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0115\n",
      "Epoch 605: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0115 - val_loss: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 606/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0113\n",
      "Epoch 606: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0113 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 607/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0117\n",
      "Epoch 607: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0117 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 608/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0104\n",
      "Epoch 608: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0104 - val_loss: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 609/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0113\n",
      "Epoch 609: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0114 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 610/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0110\n",
      "Epoch 610: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0111 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 611/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0115\n",
      "Epoch 611: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0115 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 612/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0111\n",
      "Epoch 612: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0111 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 613/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0125\n",
      "Epoch 613: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0125 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 614/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0123\n",
      "Epoch 614: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0124 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 615/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0119\n",
      "Epoch 615: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0119 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 616/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0116\n",
      "Epoch 616: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0116 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 617/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0109\n",
      "Epoch 617: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0109 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 618/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0106\n",
      "Epoch 618: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0106 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 619/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0109\n",
      "Epoch 619: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0109 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 620/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0112\n",
      "Epoch 620: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0112 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 621/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0113\n",
      "Epoch 621: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0114 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 622/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0122\n",
      "Epoch 622: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0122 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 623/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0121\n",
      "Epoch 623: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0121 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 624/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0115\n",
      "Epoch 624: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0115 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 625/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0114\n",
      "Epoch 625: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0115 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 626/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0110\n",
      "Epoch 626: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0110 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 627/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0106\n",
      "Epoch 627: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0106 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 628/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0105\n",
      "Epoch 628: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0106 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 629/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0128\n",
      "Epoch 629: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0128 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 630/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0126\n",
      "Epoch 630: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0126 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 631/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0117\n",
      "Epoch 631: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0118 - val_loss: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 632/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0126\n",
      "Epoch 632: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0126 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 633/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0115\n",
      "Epoch 633: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0115 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 634/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0111\n",
      "Epoch 634: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0111 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 635/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0117\n",
      "Epoch 635: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0117 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 636/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0113\n",
      "Epoch 636: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0113 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 637/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0111\n",
      "Epoch 637: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0111 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 638/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0119\n",
      "Epoch 638: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0119 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 639/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0122\n",
      "Epoch 639: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0122 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 640/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0118\n",
      "Epoch 640: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0118 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 641/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0115\n",
      "Epoch 641: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0116 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 642/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0115\n",
      "Epoch 642: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0116 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 643/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0119\n",
      "Epoch 643: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0120 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 644/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0122\n",
      "Epoch 644: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0122 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 645/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0148\n",
      "Epoch 645: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0148 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 646/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0146\n",
      "Epoch 646: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0146 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 647/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0133\n",
      "Epoch 647: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0133 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 648/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0132\n",
      "Epoch 648: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0132 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 649/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0134\n",
      "Epoch 649: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0134 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 650/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0136\n",
      "Epoch 650: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0136 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 651/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0129\n",
      "Epoch 651: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0129 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 652/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0130\n",
      "Epoch 652: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0131 - val_loss: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 653/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0129\n",
      "Epoch 653: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0129 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 654/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0125\n",
      "Epoch 654: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0125 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 655/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0122\n",
      "Epoch 655: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0122 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 656/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0123\n",
      "Epoch 656: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0124 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 657/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0343\n",
      "Epoch 657: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0369 - val_loss: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 658/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0935\n",
      "Epoch 658: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0931 - val_loss: 0.0451 - learning_rate: 0.0010\n",
      "Epoch 659/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0750\n",
      "Epoch 659: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0749 - val_loss: 0.0383 - learning_rate: 0.0010\n",
      "Epoch 660/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0609\n",
      "Epoch 660: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0608 - val_loss: 0.0345 - learning_rate: 0.0010\n",
      "Epoch 661/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0494\n",
      "Epoch 661: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0493 - val_loss: 0.0306 - learning_rate: 0.0010\n",
      "Epoch 662/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0444\n",
      "Epoch 662: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0442 - val_loss: 0.0364 - learning_rate: 0.0010\n",
      "Epoch 663/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0381\n",
      "Epoch 663: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0380 - val_loss: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 664/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0340\n",
      "Epoch 664: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0339 - val_loss: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 665/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0303\n",
      "Epoch 665: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0302 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 666/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0278\n",
      "Epoch 666: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0279 - val_loss: 0.0202 - learning_rate: 0.0010\n",
      "Epoch 667/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0264\n",
      "Epoch 667: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0265 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 668/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0252\n",
      "Epoch 668: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0252 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 669/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0243\n",
      "Epoch 669: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0243 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 670/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0234\n",
      "Epoch 670: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0235 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 671/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0224\n",
      "Epoch 671: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0225 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 672/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0221\n",
      "Epoch 672: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0222 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 673/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0219\n",
      "Epoch 673: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0219 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 674/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0215\n",
      "Epoch 674: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0216 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 675/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0224\n",
      "Epoch 675: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0224 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 676/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0208\n",
      "Epoch 676: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0208 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 677/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0196\n",
      "Epoch 677: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0197 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 678/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0205\n",
      "Epoch 678: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0204 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 679/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0201\n",
      "Epoch 679: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0201 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 680/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0187\n",
      "Epoch 680: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0187 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 681/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0184\n",
      "Epoch 681: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0184 - val_loss: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 682/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0183\n",
      "Epoch 682: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0183 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 683/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0177\n",
      "Epoch 683: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0176 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 684/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0180\n",
      "Epoch 684: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0179 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 685/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0171\n",
      "Epoch 685: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0171 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 686/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0174\n",
      "Epoch 686: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0174 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 687/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0172\n",
      "Epoch 687: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0172 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 688/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0178\n",
      "Epoch 688: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0178 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 689/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0169\n",
      "Epoch 689: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0169 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 690/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0168\n",
      "Epoch 690: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0168 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 691/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0162\n",
      "Epoch 691: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0163 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 692/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0167\n",
      "Epoch 692: val_loss did not improve from 0.01255\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0166 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 693/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0156\n",
      "Epoch 693: val_loss improved from 0.01255 to 0.01206, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0156 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 694/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0149\n",
      "Epoch 694: val_loss did not improve from 0.01206\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0150 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 695/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0153\n",
      "Epoch 695: val_loss did not improve from 0.01206\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0153 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 696/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0153\n",
      "Epoch 696: val_loss did not improve from 0.01206\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0153 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 697/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0155\n",
      "Epoch 697: val_loss did not improve from 0.01206\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0155 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 698/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0155\n",
      "Epoch 698: val_loss did not improve from 0.01206\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0155 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 699/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0151\n",
      "Epoch 699: val_loss did not improve from 0.01206\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0151 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 700/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0163\n",
      "Epoch 700: val_loss did not improve from 0.01206\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0163 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 701/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0173\n",
      "Epoch 701: val_loss did not improve from 0.01206\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0172 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 702/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0171\n",
      "Epoch 702: val_loss did not improve from 0.01206\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0171 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 703/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0158\n",
      "Epoch 703: val_loss did not improve from 0.01206\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0158 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 704/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0167\n",
      "Epoch 704: val_loss did not improve from 0.01206\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0167 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 705/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0151\n",
      "Epoch 705: val_loss did not improve from 0.01206\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0151 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 706/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0148\n",
      "Epoch 706: val_loss did not improve from 0.01206\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.0148 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 707/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0145\n",
      "Epoch 707: val_loss improved from 0.01206 to 0.01204, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0145 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 708/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0141\n",
      "Epoch 708: val_loss did not improve from 0.01204\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0142 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 709/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0144\n",
      "Epoch 709: val_loss did not improve from 0.01204\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0143 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 710/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0139\n",
      "Epoch 710: val_loss improved from 0.01204 to 0.01179, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0139 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 711/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0137\n",
      "Epoch 711: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0137 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 712/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0138\n",
      "Epoch 712: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0138 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 713/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0141\n",
      "Epoch 713: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0141 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 714/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0135\n",
      "Epoch 714: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0135 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 715/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0136\n",
      "Epoch 715: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0136 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 716/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0137\n",
      "Epoch 716: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0137 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 717/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0132\n",
      "Epoch 717: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0132 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 718/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0141\n",
      "Epoch 718: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0140 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 719/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0130\n",
      "Epoch 719: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0131 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 720/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0129\n",
      "Epoch 720: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0129 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 721/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0128\n",
      "Epoch 721: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0129 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 722/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0125\n",
      "Epoch 722: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0126 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 723/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0125\n",
      "Epoch 723: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0126 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 724/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0129\n",
      "Epoch 724: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0129 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 725/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0134\n",
      "Epoch 725: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0135 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 726/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0138\n",
      "Epoch 726: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0138 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 727/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0133\n",
      "Epoch 727: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0133 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 728/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0132\n",
      "Epoch 728: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0132 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 729/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0133\n",
      "Epoch 729: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0133 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 730/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0130\n",
      "Epoch 730: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0130 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 731/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0128\n",
      "Epoch 731: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0128 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 732/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0128\n",
      "Epoch 732: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0128 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 733/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0139\n",
      "Epoch 733: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0138 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 734/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0125\n",
      "Epoch 734: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0125 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 735/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0122\n",
      "Epoch 735: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0122 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 736/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0128\n",
      "Epoch 736: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0128 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 737/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0126\n",
      "Epoch 737: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0126 - val_loss: 0.0150 - learning_rate: 0.0010\n",
      "Epoch 738/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0122\n",
      "Epoch 738: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0123 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 739/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0128\n",
      "Epoch 739: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0128 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 740/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0124\n",
      "Epoch 740: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0124 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 741/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0127\n",
      "Epoch 741: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0127 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 742/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0119\n",
      "Epoch 742: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0119 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 743/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0124\n",
      "Epoch 743: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0124 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 744/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0119\n",
      "Epoch 744: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0119 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 745/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0118\n",
      "Epoch 745: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0118 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 746/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0117\n",
      "Epoch 746: val_loss did not improve from 0.01179\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0117 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 747/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0113\n",
      "Epoch 747: val_loss improved from 0.01179 to 0.01114, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0113 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 748/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0110\n",
      "Epoch 748: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0111 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 749/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0114\n",
      "Epoch 749: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0114 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 750/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0120\n",
      "Epoch 750: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0120 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 751/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0126\n",
      "Epoch 751: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0127 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 752/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0140\n",
      "Epoch 752: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0141 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 753/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0150\n",
      "Epoch 753: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0151 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 754/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0141\n",
      "Epoch 754: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0141 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 755/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0126\n",
      "Epoch 755: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0126 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 756/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0124\n",
      "Epoch 756: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0124 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 757/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0126\n",
      "Epoch 757: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0126 - val_loss: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 758/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0123\n",
      "Epoch 758: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0122 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 759/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0116\n",
      "Epoch 759: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0116 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 760/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0121\n",
      "Epoch 760: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0121 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 761/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0112\n",
      "Epoch 761: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0113 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 762/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0112\n",
      "Epoch 762: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0112 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 763/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0112\n",
      "Epoch 763: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0113 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 764/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0115\n",
      "Epoch 764: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0115 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 765/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0118\n",
      "Epoch 765: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0118 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 766/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0118\n",
      "Epoch 766: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0118 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 767/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0117\n",
      "Epoch 767: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0117 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 768/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0118\n",
      "Epoch 768: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0119 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 769/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0120\n",
      "Epoch 769: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0120 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 770/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0118\n",
      "Epoch 770: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0118 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 771/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0114\n",
      "Epoch 771: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0115 - val_loss: 0.0155 - learning_rate: 0.0010\n",
      "Epoch 772/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0129\n",
      "Epoch 772: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0128 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 773/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0116\n",
      "Epoch 773: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0117 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 774/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0110\n",
      "Epoch 774: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0110 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 775/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0112\n",
      "Epoch 775: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0112 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 776/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0107\n",
      "Epoch 776: val_loss did not improve from 0.01114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0108 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 777/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0118\n",
      "Epoch 777: val_loss improved from 0.01114 to 0.01108, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0119 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 778/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0111\n",
      "Epoch 778: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0111 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 779/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0113\n",
      "Epoch 779: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0113 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 780/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0112\n",
      "Epoch 780: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0112 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 781/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0116\n",
      "Epoch 781: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0116 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 782/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0117\n",
      "Epoch 782: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0116 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 783/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0108\n",
      "Epoch 783: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 0.0109 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 784/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0115\n",
      "Epoch 784: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0116 - val_loss: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 785/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0111\n",
      "Epoch 785: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0112 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 786/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0122\n",
      "Epoch 786: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0122 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 787/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0113\n",
      "Epoch 787: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0114 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 788/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0121\n",
      "Epoch 788: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0121 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 789/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0123\n",
      "Epoch 789: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0124 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 790/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0117\n",
      "Epoch 790: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.0118 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 791/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0113\n",
      "Epoch 791: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0113 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 792/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0111\n",
      "Epoch 792: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0111 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 793/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0112\n",
      "Epoch 793: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0112 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 794/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0111\n",
      "Epoch 794: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0111 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 795/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0115\n",
      "Epoch 795: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0115 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 796/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0116\n",
      "Epoch 796: val_loss did not improve from 0.01108\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0116 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 797/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0110\n",
      "Epoch 797: val_loss improved from 0.01108 to 0.01078, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0110 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 798/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0113\n",
      "Epoch 798: val_loss did not improve from 0.01078\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0113 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 799/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0106\n",
      "Epoch 799: val_loss did not improve from 0.01078\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0107 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 800/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0103\n",
      "Epoch 800: val_loss did not improve from 0.01078\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0103 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 801/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0113\n",
      "Epoch 801: val_loss did not improve from 0.01078\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0113 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 802/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0115\n",
      "Epoch 802: val_loss did not improve from 0.01078\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0114 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 803/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0105\n",
      "Epoch 803: val_loss did not improve from 0.01078\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0105 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 804/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0102\n",
      "Epoch 804: val_loss did not improve from 0.01078\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0101 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 805/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0102\n",
      "Epoch 805: val_loss did not improve from 0.01078\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0102 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 806/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0104\n",
      "Epoch 806: val_loss improved from 0.01078 to 0.01075, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0104 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 807/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0099\n",
      "Epoch 807: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0100 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 808/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0103\n",
      "Epoch 808: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0103 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 809/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0104\n",
      "Epoch 809: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0105 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 810/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0104\n",
      "Epoch 810: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0104 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 811/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0106\n",
      "Epoch 811: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0106 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 812/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0107\n",
      "Epoch 812: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0107 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 813/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0106\n",
      "Epoch 813: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0106 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 814/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0110\n",
      "Epoch 814: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0111 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 815/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0110\n",
      "Epoch 815: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0110 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 816/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0110\n",
      "Epoch 816: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0110 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 817/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0112\n",
      "Epoch 817: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0112 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 818/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0111\n",
      "Epoch 818: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0111 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 819/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0109\n",
      "Epoch 819: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0109 - val_loss: 0.0137 - learning_rate: 0.0010\n",
      "Epoch 820/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0106\n",
      "Epoch 820: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0106 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 821/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0101\n",
      "Epoch 821: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0101 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 822/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0104\n",
      "Epoch 822: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0104 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 823/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0109\n",
      "Epoch 823: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0109 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 824/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0108\n",
      "Epoch 824: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0108 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 825/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0104\n",
      "Epoch 825: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0104 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 826/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0105\n",
      "Epoch 826: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0105 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 827/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.0103\n",
      "Epoch 827: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 233ms/step - loss: 0.0103 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 828/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0107\n",
      "Epoch 828: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0108 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 829/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0101\n",
      "Epoch 829: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0101 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 830/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0107\n",
      "Epoch 830: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0107 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 831/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0106\n",
      "Epoch 831: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0106 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 832/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0105\n",
      "Epoch 832: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0106 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 833/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0115\n",
      "Epoch 833: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0115 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 834/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0116\n",
      "Epoch 834: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0116 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 835/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0114\n",
      "Epoch 835: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0114 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 836/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0111\n",
      "Epoch 836: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0111 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 837/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0103\n",
      "Epoch 837: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0103 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 838/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0105\n",
      "Epoch 838: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0105 - val_loss: 0.0140 - learning_rate: 0.0010\n",
      "Epoch 839/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0107\n",
      "Epoch 839: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0107 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 840/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0116\n",
      "Epoch 840: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0116 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 841/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0110\n",
      "Epoch 841: val_loss did not improve from 0.01075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0110 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 842/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0108\n",
      "Epoch 842: val_loss improved from 0.01075 to 0.01000, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0108 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 843/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0103\n",
      "Epoch 843: val_loss did not improve from 0.01000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0103 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 844/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0101\n",
      "Epoch 844: val_loss did not improve from 0.01000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0101 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 845/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0099\n",
      "Epoch 845: val_loss did not improve from 0.01000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0099 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 846/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0097\n",
      "Epoch 846: val_loss did not improve from 0.01000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0097 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 847/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0104\n",
      "Epoch 847: val_loss did not improve from 0.01000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0104 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 848/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0105\n",
      "Epoch 848: val_loss did not improve from 0.01000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0105 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 849/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0114\n",
      "Epoch 849: val_loss did not improve from 0.01000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0114 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 850/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0109\n",
      "Epoch 850: val_loss did not improve from 0.01000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0109 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 851/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0102\n",
      "Epoch 851: val_loss did not improve from 0.01000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0102 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 852/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0110\n",
      "Epoch 852: val_loss improved from 0.01000 to 0.00988, saving model to ./result_folder_no_misc/lstm_ts_10.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0110 - val_loss: 0.0099 - learning_rate: 0.0010\n",
      "Epoch 853/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0107\n",
      "Epoch 853: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0107 - val_loss: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 854/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0108\n",
      "Epoch 854: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0108 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 855/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0103\n",
      "Epoch 855: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0104 - val_loss: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 856/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0104\n",
      "Epoch 856: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0104 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 857/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0107\n",
      "Epoch 857: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.0107 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 858/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0109\n",
      "Epoch 858: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0110 - val_loss: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 859/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0113\n",
      "Epoch 859: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0113 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 860/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0104\n",
      "Epoch 860: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0104 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 861/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0102\n",
      "Epoch 861: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0102 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 862/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0105\n",
      "Epoch 862: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0105 - val_loss: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 863/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0105\n",
      "Epoch 863: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0105 - val_loss: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 864/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0111\n",
      "Epoch 864: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0111 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 865/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0121\n",
      "Epoch 865: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0120 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 866/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0113\n",
      "Epoch 866: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0113 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 867/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0110\n",
      "Epoch 867: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0110 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 868/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0116\n",
      "Epoch 868: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0116 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 869/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0114\n",
      "Epoch 869: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0114 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 870/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0121\n",
      "Epoch 870: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0121 - val_loss: 0.0143 - learning_rate: 0.0010\n",
      "Epoch 871/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0117\n",
      "Epoch 871: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0116 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 872/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0112\n",
      "Epoch 872: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0113 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 873/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0134\n",
      "Epoch 873: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0134 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 874/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0132\n",
      "Epoch 874: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0132 - val_loss: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 875/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0133\n",
      "Epoch 875: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0133 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 876/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0129\n",
      "Epoch 876: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0129 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 877/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0126\n",
      "Epoch 877: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0126 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 878/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0121\n",
      "Epoch 878: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0122 - val_loss: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 879/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0106\n",
      "Epoch 879: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0107 - val_loss: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 880/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0114\n",
      "Epoch 880: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0114 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 881/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0110\n",
      "Epoch 881: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0110 - val_loss: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 882/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0103\n",
      "Epoch 882: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0103 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 883/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0099\n",
      "Epoch 883: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0099 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 884/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0107\n",
      "Epoch 884: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0107 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 885/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0104\n",
      "Epoch 885: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0105 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 886/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0114\n",
      "Epoch 886: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0114 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 887/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0112\n",
      "Epoch 887: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0112 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 888/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0102\n",
      "Epoch 888: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0102 - val_loss: 0.0134 - learning_rate: 0.0010\n",
      "Epoch 889/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0104\n",
      "Epoch 889: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0104 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 890/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0105\n",
      "Epoch 890: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0105 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 891/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0093\n",
      "Epoch 891: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0093 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 892/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0091\n",
      "Epoch 892: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0091 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 893/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0098\n",
      "Epoch 893: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0098 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 894/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0100\n",
      "Epoch 894: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0100 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 895/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0107\n",
      "Epoch 895: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0108 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 896/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0126\n",
      "Epoch 896: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0127 - val_loss: 0.0129 - learning_rate: 0.0010\n",
      "Epoch 897/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0122\n",
      "Epoch 897: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0122 - val_loss: 0.0113 - learning_rate: 0.0010\n",
      "Epoch 898/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0101\n",
      "Epoch 898: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0101 - val_loss: 0.0111 - learning_rate: 0.0010\n",
      "Epoch 899/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0097\n",
      "Epoch 899: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0097 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 900/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0098\n",
      "Epoch 900: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0099 - val_loss: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 901/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0099\n",
      "Epoch 901: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0100 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 902/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.0103\n",
      "Epoch 902: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0103 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 903/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0097\n",
      "Epoch 903: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0098 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 904/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0100\n",
      "Epoch 904: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0100 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 905/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0094\n",
      "Epoch 905: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0095 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 906/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0097\n",
      "Epoch 906: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0097 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 907/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0101\n",
      "Epoch 907: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0101 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 908/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0093\n",
      "Epoch 908: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0094 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 909/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0100\n",
      "Epoch 909: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0100 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 910/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0093\n",
      "Epoch 910: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0093 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 911/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0097\n",
      "Epoch 911: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0097 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 912/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0098\n",
      "Epoch 912: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0098 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 913/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0093\n",
      "Epoch 913: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0093 - val_loss: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 914/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0094\n",
      "Epoch 914: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0095 - val_loss: 0.0123 - learning_rate: 0.0010\n",
      "Epoch 915/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0097\n",
      "Epoch 915: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0098 - val_loss: 0.0138 - learning_rate: 0.0010\n",
      "Epoch 916/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0095\n",
      "Epoch 916: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0095 - val_loss: 0.0133 - learning_rate: 0.0010\n",
      "Epoch 917/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0090\n",
      "Epoch 917: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0091 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 918/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0091\n",
      "Epoch 918: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0091 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 919/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0096\n",
      "Epoch 919: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0096 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 920/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0095\n",
      "Epoch 920: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0095 - val_loss: 0.0139 - learning_rate: 0.0010\n",
      "Epoch 921/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0095\n",
      "Epoch 921: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0094 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 922/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0090\n",
      "Epoch 922: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0091 - val_loss: 0.0116 - learning_rate: 0.0010\n",
      "Epoch 923/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0098\n",
      "Epoch 923: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0098 - val_loss: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 924/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0102\n",
      "Epoch 924: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0101 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 925/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0104\n",
      "Epoch 925: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0104 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 926/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0104\n",
      "Epoch 926: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0104 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 927/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0098\n",
      "Epoch 927: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0098 - val_loss: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 928/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0103\n",
      "Epoch 928: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0103 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 929/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0099\n",
      "Epoch 929: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0098 - val_loss: 0.0130 - learning_rate: 0.0010\n",
      "Epoch 930/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0095\n",
      "Epoch 930: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0095 - val_loss: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 931/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0095\n",
      "Epoch 931: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0096 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 932/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0106\n",
      "Epoch 932: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0106 - val_loss: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 933/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0103\n",
      "Epoch 933: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0103 - val_loss: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 934/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0098\n",
      "Epoch 934: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0098 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 935/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0098\n",
      "Epoch 935: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.0099 - val_loss: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 936/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0103\n",
      "Epoch 936: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0103 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 937/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0100\n",
      "Epoch 937: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0101 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 938/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0104\n",
      "Epoch 938: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0104 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 939/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0106\n",
      "Epoch 939: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.0106 - val_loss: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 940/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0096\n",
      "Epoch 940: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0096 - val_loss: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 941/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0098\n",
      "Epoch 941: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0098 - val_loss: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 942/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0094\n",
      "Epoch 942: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0094 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 943/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0092\n",
      "Epoch 943: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0093 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 944/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0100\n",
      "Epoch 944: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0100 - val_loss: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 945/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0094\n",
      "Epoch 945: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0094 - val_loss: 0.0126 - learning_rate: 0.0010\n",
      "Epoch 946/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0097\n",
      "Epoch 946: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0097 - val_loss: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 947/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0091\n",
      "Epoch 947: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0092 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 948/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0091\n",
      "Epoch 948: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0091 - val_loss: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 949/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0092\n",
      "Epoch 949: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0092 - val_loss: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 950/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0096\n",
      "Epoch 950: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0096 - val_loss: 0.0110 - learning_rate: 0.0010\n",
      "Epoch 951/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0092\n",
      "Epoch 951: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0093 - val_loss: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 952/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0097\n",
      "Epoch 952: val_loss did not improve from 0.00988\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0097 - val_loss: 0.0142 - learning_rate: 0.0010\n",
      "Epoch 952: early stopping\n",
      "Restoring model weights from the end of the best epoch: 852.\n",
      "EUA\n",
      "0.13540244245570726\n",
      "Oil\n",
      "0.12155840558457794\n",
      "Coal\n",
      "0.05237842555419466\n",
      "NG\n",
      "0.023169357327744337\n",
      "USEU\n",
      "0.14141099890217002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 180/180 [01:21<00:00,  2.21it/s]\n",
      "100%|| 180/180 [04:23<00:00,  1.46s/it]\n",
      "/home/honggeunjo/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 2.1759\n",
      "Epoch 1: val_loss improved from inf to 0.61687, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 324ms/step - loss: 2.1176 - val_loss: 0.6169 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.6641\n",
      "Epoch 2: val_loss improved from 0.61687 to 0.52474, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 249ms/step - loss: 0.6595 - val_loss: 0.5247 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 0.5092\n",
      "Epoch 3: val_loss improved from 0.52474 to 0.44164, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 260ms/step - loss: 0.5075 - val_loss: 0.4416 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.4429\n",
      "Epoch 4: val_loss improved from 0.44164 to 0.37660, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - loss: 0.4427 - val_loss: 0.3766 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.4206\n",
      "Epoch 5: val_loss improved from 0.37660 to 0.37563, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 250ms/step - loss: 0.4202 - val_loss: 0.3756 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 0.4020\n",
      "Epoch 6: val_loss improved from 0.37563 to 0.36578, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - loss: 0.4019 - val_loss: 0.3658 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.3937\n",
      "Epoch 7: val_loss did not improve from 0.36578\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.3936 - val_loss: 0.3681 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.3841\n",
      "Epoch 8: val_loss improved from 0.36578 to 0.35248, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.3842 - val_loss: 0.3525 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.3759\n",
      "Epoch 9: val_loss improved from 0.35248 to 0.35027, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 249ms/step - loss: 0.3759 - val_loss: 0.3503 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.3711\n",
      "Epoch 10: val_loss improved from 0.35027 to 0.33937, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - loss: 0.3707 - val_loss: 0.3394 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.3595\n",
      "Epoch 11: val_loss improved from 0.33937 to 0.33580, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 248ms/step - loss: 0.3596 - val_loss: 0.3358 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.3551\n",
      "Epoch 12: val_loss improved from 0.33580 to 0.32500, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - loss: 0.3550 - val_loss: 0.3250 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.3493\n",
      "Epoch 13: val_loss did not improve from 0.32500\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - loss: 0.3494 - val_loss: 0.3266 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.3414\n",
      "Epoch 14: val_loss improved from 0.32500 to 0.31993, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 248ms/step - loss: 0.3414 - val_loss: 0.3199 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.3353\n",
      "Epoch 15: val_loss improved from 0.31993 to 0.31470, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 254ms/step - loss: 0.3353 - val_loss: 0.3147 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 0.3290\n",
      "Epoch 16: val_loss improved from 0.31470 to 0.31036, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 257ms/step - loss: 0.3289 - val_loss: 0.3104 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.3245\n",
      "Epoch 17: val_loss improved from 0.31036 to 0.30296, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 236ms/step - loss: 0.3243 - val_loss: 0.3030 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.3189\n",
      "Epoch 18: val_loss improved from 0.30296 to 0.29652, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250ms/step - loss: 0.3187 - val_loss: 0.2965 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.3094\n",
      "Epoch 19: val_loss improved from 0.29652 to 0.29208, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 252ms/step - loss: 0.3095 - val_loss: 0.2921 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.3062\n",
      "Epoch 20: val_loss improved from 0.29208 to 0.28826, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - loss: 0.3061 - val_loss: 0.2883 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.3017\n",
      "Epoch 21: val_loss improved from 0.28826 to 0.27908, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 249ms/step - loss: 0.3015 - val_loss: 0.2791 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 0.2914\n",
      "Epoch 22: val_loss improved from 0.27908 to 0.27622, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 252ms/step - loss: 0.2914 - val_loss: 0.2762 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 0.2876\n",
      "Epoch 23: val_loss improved from 0.27622 to 0.26717, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 254ms/step - loss: 0.2876 - val_loss: 0.2672 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.2804\n",
      "Epoch 24: val_loss improved from 0.26717 to 0.26285, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 248ms/step - loss: 0.2804 - val_loss: 0.2628 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.2781\n",
      "Epoch 25: val_loss did not improve from 0.26285\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.2779 - val_loss: 0.2761 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.2725\n",
      "Epoch 26: val_loss improved from 0.26285 to 0.25306, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step - loss: 0.2722 - val_loss: 0.2531 - learning_rate: 0.0010\n",
      "Epoch 27/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 0.2663\n",
      "Epoch 27: val_loss improved from 0.25306 to 0.24837, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 252ms/step - loss: 0.2661 - val_loss: 0.2484 - learning_rate: 0.0010\n",
      "Epoch 28/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.2613\n",
      "Epoch 28: val_loss improved from 0.24837 to 0.24446, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.2611 - val_loss: 0.2445 - learning_rate: 0.0010\n",
      "Epoch 29/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 0.2541\n",
      "Epoch 29: val_loss improved from 0.24446 to 0.23712, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 266ms/step - loss: 0.2541 - val_loss: 0.2371 - learning_rate: 0.0010\n",
      "Epoch 30/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 0.2507\n",
      "Epoch 30: val_loss improved from 0.23712 to 0.23371, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 262ms/step - loss: 0.2506 - val_loss: 0.2337 - learning_rate: 0.0010\n",
      "Epoch 31/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 0.2438\n",
      "Epoch 31: val_loss improved from 0.23371 to 0.22981, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 255ms/step - loss: 0.2439 - val_loss: 0.2298 - learning_rate: 0.0010\n",
      "Epoch 32/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - loss: 0.2415\n",
      "Epoch 32: val_loss improved from 0.22981 to 0.22472, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 258ms/step - loss: 0.2414 - val_loss: 0.2247 - learning_rate: 0.0010\n",
      "Epoch 33/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.2381\n",
      "Epoch 33: val_loss improved from 0.22472 to 0.22391, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 255ms/step - loss: 0.2379 - val_loss: 0.2239 - learning_rate: 0.0010\n",
      "Epoch 34/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - loss: 0.2327\n",
      "Epoch 34: val_loss improved from 0.22391 to 0.21585, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 260ms/step - loss: 0.2325 - val_loss: 0.2159 - learning_rate: 0.0010\n",
      "Epoch 35/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 0.2271\n",
      "Epoch 35: val_loss did not improve from 0.21585\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.2270 - val_loss: 0.2168 - learning_rate: 0.0010\n",
      "Epoch 36/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.2236\n",
      "Epoch 36: val_loss improved from 0.21585 to 0.20745, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 252ms/step - loss: 0.2235 - val_loss: 0.2075 - learning_rate: 0.0010\n",
      "Epoch 37/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 0.2184\n",
      "Epoch 37: val_loss improved from 0.20745 to 0.20402, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 273ms/step - loss: 0.2184 - val_loss: 0.2040 - learning_rate: 0.0010\n",
      "Epoch 38/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 0.2145\n",
      "Epoch 38: val_loss improved from 0.20402 to 0.20047, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 260ms/step - loss: 0.2145 - val_loss: 0.2005 - learning_rate: 0.0010\n",
      "Epoch 39/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 0.2114\n",
      "Epoch 39: val_loss improved from 0.20047 to 0.19874, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 280ms/step - loss: 0.2113 - val_loss: 0.1987 - learning_rate: 0.0010\n",
      "Epoch 40/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.2059\n",
      "Epoch 40: val_loss improved from 0.19874 to 0.19499, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 257ms/step - loss: 0.2060 - val_loss: 0.1950 - learning_rate: 0.0010\n",
      "Epoch 41/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.2047\n",
      "Epoch 41: val_loss improved from 0.19499 to 0.19454, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 252ms/step - loss: 0.2046 - val_loss: 0.1945 - learning_rate: 0.0010\n",
      "Epoch 42/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.2001\n",
      "Epoch 42: val_loss improved from 0.19454 to 0.19056, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - loss: 0.1999 - val_loss: 0.1906 - learning_rate: 0.0010\n",
      "Epoch 43/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 0.1942\n",
      "Epoch 43: val_loss improved from 0.19056 to 0.18693, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 251ms/step - loss: 0.1942 - val_loss: 0.1869 - learning_rate: 0.0010\n",
      "Epoch 44/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.1926\n",
      "Epoch 44: val_loss improved from 0.18693 to 0.18163, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - loss: 0.1926 - val_loss: 0.1816 - learning_rate: 0.0010\n",
      "Epoch 45/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.1902\n",
      "Epoch 45: val_loss improved from 0.18163 to 0.17715, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.1902 - val_loss: 0.1772 - learning_rate: 0.0010\n",
      "Epoch 46/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.1864\n",
      "Epoch 46: val_loss improved from 0.17715 to 0.17125, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - loss: 0.1862 - val_loss: 0.1713 - learning_rate: 0.0010\n",
      "Epoch 47/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 0.1810\n",
      "Epoch 47: val_loss did not improve from 0.17125\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 241ms/step - loss: 0.1811 - val_loss: 0.1713 - learning_rate: 0.0010\n",
      "Epoch 48/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.1786\n",
      "Epoch 48: val_loss improved from 0.17125 to 0.16664, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - loss: 0.1786 - val_loss: 0.1666 - learning_rate: 0.0010\n",
      "Epoch 49/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.1756\n",
      "Epoch 49: val_loss improved from 0.16664 to 0.16581, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - loss: 0.1756 - val_loss: 0.1658 - learning_rate: 0.0010\n",
      "Epoch 50/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.1723\n",
      "Epoch 50: val_loss improved from 0.16581 to 0.15930, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.1722 - val_loss: 0.1593 - learning_rate: 0.0010\n",
      "Epoch 51/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.1692\n",
      "Epoch 51: val_loss did not improve from 0.15930\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.1692 - val_loss: 0.1594 - learning_rate: 0.0010\n",
      "Epoch 52/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.1649\n",
      "Epoch 52: val_loss improved from 0.15930 to 0.15559, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 248ms/step - loss: 0.1649 - val_loss: 0.1556 - learning_rate: 0.0010\n",
      "Epoch 53/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.1628\n",
      "Epoch 53: val_loss improved from 0.15559 to 0.15319, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 253ms/step - loss: 0.1627 - val_loss: 0.1532 - learning_rate: 0.0010\n",
      "Epoch 54/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.1599\n",
      "Epoch 54: val_loss did not improve from 0.15319\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.1599 - val_loss: 0.1558 - learning_rate: 0.0010\n",
      "Epoch 55/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.1569\n",
      "Epoch 55: val_loss did not improve from 0.15319\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.1570 - val_loss: 0.1541 - learning_rate: 0.0010\n",
      "Epoch 56/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.1554\n",
      "Epoch 56: val_loss did not improve from 0.15319\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.1556 - val_loss: 0.1546 - learning_rate: 0.0010\n",
      "Epoch 57/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 0.1552\n",
      "Epoch 57: val_loss did not improve from 0.15319\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - loss: 0.1551 - val_loss: 0.1627 - learning_rate: 0.0010\n",
      "Epoch 58/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 0.1520\n",
      "Epoch 58: val_loss improved from 0.15319 to 0.14415, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 241ms/step - loss: 0.1519 - val_loss: 0.1442 - learning_rate: 0.0010\n",
      "Epoch 59/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.1481\n",
      "Epoch 59: val_loss improved from 0.14415 to 0.13755, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.1481 - val_loss: 0.1376 - learning_rate: 0.0010\n",
      "Epoch 60/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.1462\n",
      "Epoch 60: val_loss did not improve from 0.13755\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - loss: 0.1460 - val_loss: 0.1385 - learning_rate: 0.0010\n",
      "Epoch 61/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 0.1423\n",
      "Epoch 61: val_loss improved from 0.13755 to 0.13272, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 273ms/step - loss: 0.1423 - val_loss: 0.1327 - learning_rate: 0.0010\n",
      "Epoch 62/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 0.1410\n",
      "Epoch 62: val_loss did not improve from 0.13272\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.1410 - val_loss: 0.1365 - learning_rate: 0.0010\n",
      "Epoch 63/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.1404\n",
      "Epoch 63: val_loss improved from 0.13272 to 0.12987, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 249ms/step - loss: 0.1403 - val_loss: 0.1299 - learning_rate: 0.0010\n",
      "Epoch 64/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - loss: 0.1376\n",
      "Epoch 64: val_loss did not improve from 0.12987\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 248ms/step - loss: 0.1375 - val_loss: 0.1406 - learning_rate: 0.0010\n",
      "Epoch 65/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 0.1336\n",
      "Epoch 65: val_loss improved from 0.12987 to 0.12858, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 266ms/step - loss: 0.1335 - val_loss: 0.1286 - learning_rate: 0.0010\n",
      "Epoch 66/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 0.1316\n",
      "Epoch 66: val_loss improved from 0.12858 to 0.12462, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 264ms/step - loss: 0.1316 - val_loss: 0.1246 - learning_rate: 0.0010\n",
      "Epoch 67/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.1295\n",
      "Epoch 67: val_loss improved from 0.12462 to 0.12282, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step - loss: 0.1295 - val_loss: 0.1228 - learning_rate: 0.0010\n",
      "Epoch 68/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 0.1274\n",
      "Epoch 68: val_loss improved from 0.12282 to 0.12101, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 242ms/step - loss: 0.1274 - val_loss: 0.1210 - learning_rate: 0.0010\n",
      "Epoch 69/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.1253\n",
      "Epoch 69: val_loss improved from 0.12101 to 0.11800, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 244ms/step - loss: 0.1253 - val_loss: 0.1180 - learning_rate: 0.0010\n",
      "Epoch 70/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.1237\n",
      "Epoch 70: val_loss improved from 0.11800 to 0.11502, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.1237 - val_loss: 0.1150 - learning_rate: 0.0010\n",
      "Epoch 71/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.1217\n",
      "Epoch 71: val_loss did not improve from 0.11502\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 233ms/step - loss: 0.1217 - val_loss: 0.1228 - learning_rate: 0.0010\n",
      "Epoch 72/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.1213\n",
      "Epoch 72: val_loss did not improve from 0.11502\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 233ms/step - loss: 0.1213 - val_loss: 0.1194 - learning_rate: 0.0010\n",
      "Epoch 73/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.1206\n",
      "Epoch 73: val_loss improved from 0.11502 to 0.11150, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250ms/step - loss: 0.1206 - val_loss: 0.1115 - learning_rate: 0.0010\n",
      "Epoch 74/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.1184\n",
      "Epoch 74: val_loss did not improve from 0.11150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.1183 - val_loss: 0.1137 - learning_rate: 0.0010\n",
      "Epoch 75/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.1167\n",
      "Epoch 75: val_loss did not improve from 0.11150\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - loss: 0.1167 - val_loss: 0.1120 - learning_rate: 0.0010\n",
      "Epoch 76/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.1144\n",
      "Epoch 76: val_loss improved from 0.11150 to 0.10836, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 242ms/step - loss: 0.1144 - val_loss: 0.1084 - learning_rate: 0.0010\n",
      "Epoch 77/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - loss: 0.1133\n",
      "Epoch 77: val_loss did not improve from 0.10836\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 251ms/step - loss: 0.1132 - val_loss: 0.1097 - learning_rate: 0.0010\n",
      "Epoch 78/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.1102\n",
      "Epoch 78: val_loss improved from 0.10836 to 0.10712, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - loss: 0.1103 - val_loss: 0.1071 - learning_rate: 0.0010\n",
      "Epoch 79/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 0.1097\n",
      "Epoch 79: val_loss improved from 0.10712 to 0.10136, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 244ms/step - loss: 0.1098 - val_loss: 0.1014 - learning_rate: 0.0010\n",
      "Epoch 80/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.1085\n",
      "Epoch 80: val_loss did not improve from 0.10136\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.1084 - val_loss: 0.1087 - learning_rate: 0.0010\n",
      "Epoch 81/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.1077\n",
      "Epoch 81: val_loss improved from 0.10136 to 0.10058, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.1077 - val_loss: 0.1006 - learning_rate: 0.0010\n",
      "Epoch 82/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - loss: 0.1046\n",
      "Epoch 82: val_loss did not improve from 0.10058\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 249ms/step - loss: 0.1047 - val_loss: 0.1054 - learning_rate: 0.0010\n",
      "Epoch 83/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 0.1055\n",
      "Epoch 83: val_loss improved from 0.10058 to 0.09985, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 265ms/step - loss: 0.1053 - val_loss: 0.0998 - learning_rate: 0.0010\n",
      "Epoch 84/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.1007\n",
      "Epoch 84: val_loss improved from 0.09985 to 0.09719, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 252ms/step - loss: 0.1007 - val_loss: 0.0972 - learning_rate: 0.0010\n",
      "Epoch 85/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.1006\n",
      "Epoch 85: val_loss improved from 0.09719 to 0.09540, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 243ms/step - loss: 0.1006 - val_loss: 0.0954 - learning_rate: 0.0010\n",
      "Epoch 86/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0999\n",
      "Epoch 86: val_loss improved from 0.09540 to 0.09377, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - loss: 0.0998 - val_loss: 0.0938 - learning_rate: 0.0010\n",
      "Epoch 87/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0976\n",
      "Epoch 87: val_loss improved from 0.09377 to 0.09188, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.0976 - val_loss: 0.0919 - learning_rate: 0.0010\n",
      "Epoch 88/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0959\n",
      "Epoch 88: val_loss did not improve from 0.09188\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0959 - val_loss: 0.0921 - learning_rate: 0.0010\n",
      "Epoch 89/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0948\n",
      "Epoch 89: val_loss improved from 0.09188 to 0.09158, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0948 - val_loss: 0.0916 - learning_rate: 0.0010\n",
      "Epoch 90/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0937\n",
      "Epoch 90: val_loss improved from 0.09158 to 0.08933, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.0937 - val_loss: 0.0893 - learning_rate: 0.0010\n",
      "Epoch 91/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0928\n",
      "Epoch 91: val_loss improved from 0.08933 to 0.08737, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.0927 - val_loss: 0.0874 - learning_rate: 0.0010\n",
      "Epoch 92/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0931\n",
      "Epoch 92: val_loss did not improve from 0.08737\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0931 - val_loss: 0.0926 - learning_rate: 0.0010\n",
      "Epoch 93/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0912\n",
      "Epoch 93: val_loss did not improve from 0.08737\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0912 - val_loss: 0.0887 - learning_rate: 0.0010\n",
      "Epoch 94/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.0885\n",
      "Epoch 94: val_loss improved from 0.08737 to 0.08620, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - loss: 0.0886 - val_loss: 0.0862 - learning_rate: 0.0010\n",
      "Epoch 95/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0885\n",
      "Epoch 95: val_loss did not improve from 0.08620\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0885 - val_loss: 0.0878 - learning_rate: 0.0010\n",
      "Epoch 96/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0870\n",
      "Epoch 96: val_loss did not improve from 0.08620\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0871 - val_loss: 0.0864 - learning_rate: 0.0010\n",
      "Epoch 97/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0882\n",
      "Epoch 97: val_loss improved from 0.08620 to 0.08125, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 236ms/step - loss: 0.0882 - val_loss: 0.0813 - learning_rate: 0.0010\n",
      "Epoch 98/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0880\n",
      "Epoch 98: val_loss did not improve from 0.08125\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0879 - val_loss: 0.0886 - learning_rate: 0.0010\n",
      "Epoch 99/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.0854\n",
      "Epoch 99: val_loss did not improve from 0.08125\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 233ms/step - loss: 0.0854 - val_loss: 0.0828 - learning_rate: 0.0010\n",
      "Epoch 100/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.0842\n",
      "Epoch 100: val_loss improved from 0.08125 to 0.08091, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - loss: 0.0841 - val_loss: 0.0809 - learning_rate: 0.0010\n",
      "Epoch 101/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.0825\n",
      "Epoch 101: val_loss did not improve from 0.08091\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - loss: 0.0825 - val_loss: 0.0878 - learning_rate: 0.0010\n",
      "Epoch 102/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.0826\n",
      "Epoch 102: val_loss did not improve from 0.08091\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 241ms/step - loss: 0.0827 - val_loss: 0.0846 - learning_rate: 0.0010\n",
      "Epoch 103/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0818\n",
      "Epoch 103: val_loss improved from 0.08091 to 0.07975, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 236ms/step - loss: 0.0818 - val_loss: 0.0798 - learning_rate: 0.0010\n",
      "Epoch 104/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0797\n",
      "Epoch 104: val_loss did not improve from 0.07975\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0797 - val_loss: 0.0814 - learning_rate: 0.0010\n",
      "Epoch 105/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0786\n",
      "Epoch 105: val_loss did not improve from 0.07975\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0786 - val_loss: 0.0810 - learning_rate: 0.0010\n",
      "Epoch 106/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0797\n",
      "Epoch 106: val_loss improved from 0.07975 to 0.07867, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - loss: 0.0797 - val_loss: 0.0787 - learning_rate: 0.0010\n",
      "Epoch 107/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0798\n",
      "Epoch 107: val_loss improved from 0.07867 to 0.07458, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0796 - val_loss: 0.0746 - learning_rate: 0.0010\n",
      "Epoch 108/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0753\n",
      "Epoch 108: val_loss improved from 0.07458 to 0.07399, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - loss: 0.0754 - val_loss: 0.0740 - learning_rate: 0.0010\n",
      "Epoch 109/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.0753\n",
      "Epoch 109: val_loss did not improve from 0.07399\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.0753 - val_loss: 0.0745 - learning_rate: 0.0010\n",
      "Epoch 110/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0741\n",
      "Epoch 110: val_loss improved from 0.07399 to 0.07097, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.0742 - val_loss: 0.0710 - learning_rate: 0.0010\n",
      "Epoch 111/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0739\n",
      "Epoch 111: val_loss did not improve from 0.07097\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0740 - val_loss: 0.0724 - learning_rate: 0.0010\n",
      "Epoch 112/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0733\n",
      "Epoch 112: val_loss improved from 0.07097 to 0.07058, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 244ms/step - loss: 0.0733 - val_loss: 0.0706 - learning_rate: 0.0010\n",
      "Epoch 113/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.0732\n",
      "Epoch 113: val_loss did not improve from 0.07058\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - loss: 0.0731 - val_loss: 0.0749 - learning_rate: 0.0010\n",
      "Epoch 114/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0715\n",
      "Epoch 114: val_loss improved from 0.07058 to 0.07010, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - loss: 0.0715 - val_loss: 0.0701 - learning_rate: 0.0010\n",
      "Epoch 115/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 0.0699\n",
      "Epoch 115: val_loss did not improve from 0.07010\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - loss: 0.0699 - val_loss: 0.0702 - learning_rate: 0.0010\n",
      "Epoch 116/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0696\n",
      "Epoch 116: val_loss did not improve from 0.07010\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0696 - val_loss: 0.0743 - learning_rate: 0.0010\n",
      "Epoch 117/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0696\n",
      "Epoch 117: val_loss did not improve from 0.07010\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0695 - val_loss: 0.0720 - learning_rate: 0.0010\n",
      "Epoch 118/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.0689\n",
      "Epoch 118: val_loss improved from 0.07010 to 0.06436, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 250ms/step - loss: 0.0689 - val_loss: 0.0644 - learning_rate: 0.0010\n",
      "Epoch 119/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.0675\n",
      "Epoch 119: val_loss did not improve from 0.06436\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - loss: 0.0674 - val_loss: 0.0673 - learning_rate: 0.0010\n",
      "Epoch 120/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0669\n",
      "Epoch 120: val_loss did not improve from 0.06436\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0669 - val_loss: 0.0648 - learning_rate: 0.0010\n",
      "Epoch 121/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.0669\n",
      "Epoch 121: val_loss improved from 0.06436 to 0.06366, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 253ms/step - loss: 0.0669 - val_loss: 0.0637 - learning_rate: 0.0010\n",
      "Epoch 122/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0662\n",
      "Epoch 122: val_loss did not improve from 0.06366\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0662 - val_loss: 0.0681 - learning_rate: 0.0010\n",
      "Epoch 123/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.0676\n",
      "Epoch 123: val_loss did not improve from 0.06366\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0676 - val_loss: 0.0673 - learning_rate: 0.0010\n",
      "Epoch 124/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.0670\n",
      "Epoch 124: val_loss did not improve from 0.06366\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 243ms/step - loss: 0.0670 - val_loss: 0.0713 - learning_rate: 0.0010\n",
      "Epoch 125/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0659\n",
      "Epoch 125: val_loss did not improve from 0.06366\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0659 - val_loss: 0.0682 - learning_rate: 0.0010\n",
      "Epoch 126/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0659\n",
      "Epoch 126: val_loss did not improve from 0.06366\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0659 - val_loss: 0.0791 - learning_rate: 0.0010\n",
      "Epoch 127/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0648\n",
      "Epoch 127: val_loss improved from 0.06366 to 0.06157, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.0647 - val_loss: 0.0616 - learning_rate: 0.0010\n",
      "Epoch 128/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0615\n",
      "Epoch 128: val_loss did not improve from 0.06157\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0615 - val_loss: 0.0648 - learning_rate: 0.0010\n",
      "Epoch 129/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0612\n",
      "Epoch 129: val_loss improved from 0.06157 to 0.06012, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.0612 - val_loss: 0.0601 - learning_rate: 0.0010\n",
      "Epoch 130/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0601\n",
      "Epoch 130: val_loss did not improve from 0.06012\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0602 - val_loss: 0.0656 - learning_rate: 0.0010\n",
      "Epoch 131/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0607\n",
      "Epoch 131: val_loss did not improve from 0.06012\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0607 - val_loss: 0.0612 - learning_rate: 0.0010\n",
      "Epoch 132/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0610\n",
      "Epoch 132: val_loss improved from 0.06012 to 0.05940, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - loss: 0.0609 - val_loss: 0.0594 - learning_rate: 0.0010\n",
      "Epoch 133/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0592\n",
      "Epoch 133: val_loss improved from 0.05940 to 0.05827, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 233ms/step - loss: 0.0592 - val_loss: 0.0583 - learning_rate: 0.0010\n",
      "Epoch 134/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0590\n",
      "Epoch 134: val_loss did not improve from 0.05827\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0590 - val_loss: 0.0625 - learning_rate: 0.0010\n",
      "Epoch 135/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.0584\n",
      "Epoch 135: val_loss did not improve from 0.05827\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - loss: 0.0585 - val_loss: 0.0596 - learning_rate: 0.0010\n",
      "Epoch 136/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0576\n",
      "Epoch 136: val_loss did not improve from 0.05827\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0576 - val_loss: 0.0610 - learning_rate: 0.0010\n",
      "Epoch 137/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0559\n",
      "Epoch 137: val_loss did not improve from 0.05827\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0561 - val_loss: 0.0584 - learning_rate: 0.0010\n",
      "Epoch 138/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0580\n",
      "Epoch 138: val_loss did not improve from 0.05827\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0581 - val_loss: 0.0622 - learning_rate: 0.0010\n",
      "Epoch 139/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0572\n",
      "Epoch 139: val_loss did not improve from 0.05827\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0572 - val_loss: 0.0643 - learning_rate: 0.0010\n",
      "Epoch 140/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0577\n",
      "Epoch 140: val_loss did not improve from 0.05827\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0576 - val_loss: 0.0621 - learning_rate: 0.0010\n",
      "Epoch 141/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0555\n",
      "Epoch 141: val_loss improved from 0.05827 to 0.05319, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - loss: 0.0555 - val_loss: 0.0532 - learning_rate: 0.0010\n",
      "Epoch 142/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0549\n",
      "Epoch 142: val_loss did not improve from 0.05319\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0551 - val_loss: 0.0543 - learning_rate: 0.0010\n",
      "Epoch 143/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0553\n",
      "Epoch 143: val_loss did not improve from 0.05319\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0552 - val_loss: 0.0558 - learning_rate: 0.0010\n",
      "Epoch 144/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0541\n",
      "Epoch 144: val_loss improved from 0.05319 to 0.05253, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0541 - val_loss: 0.0525 - learning_rate: 0.0010\n",
      "Epoch 145/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0534\n",
      "Epoch 145: val_loss did not improve from 0.05253\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0534 - val_loss: 0.0592 - learning_rate: 0.0010\n",
      "Epoch 146/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0530\n",
      "Epoch 146: val_loss did not improve from 0.05253\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0531 - val_loss: 0.0591 - learning_rate: 0.0010\n",
      "Epoch 147/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 0.0526\n",
      "Epoch 147: val_loss did not improve from 0.05253\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 249ms/step - loss: 0.0526 - val_loss: 0.0674 - learning_rate: 0.0010\n",
      "Epoch 148/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0532\n",
      "Epoch 148: val_loss improved from 0.05253 to 0.05133, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.0533 - val_loss: 0.0513 - learning_rate: 0.0010\n",
      "Epoch 149/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0520\n",
      "Epoch 149: val_loss did not improve from 0.05133\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0520 - val_loss: 0.0572 - learning_rate: 0.0010\n",
      "Epoch 150/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.0502\n",
      "Epoch 150: val_loss improved from 0.05133 to 0.04929, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 251ms/step - loss: 0.0502 - val_loss: 0.0493 - learning_rate: 0.0010\n",
      "Epoch 151/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 0.0498\n",
      "Epoch 151: val_loss did not improve from 0.04929\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 243ms/step - loss: 0.0498 - val_loss: 0.0493 - learning_rate: 0.0010\n",
      "Epoch 152/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 0.0499\n",
      "Epoch 152: val_loss did not improve from 0.04929\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 244ms/step - loss: 0.0499 - val_loss: 0.0496 - learning_rate: 0.0010\n",
      "Epoch 153/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0494\n",
      "Epoch 153: val_loss did not improve from 0.04929\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.0494 - val_loss: 0.0532 - learning_rate: 0.0010\n",
      "Epoch 154/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 0.0498\n",
      "Epoch 154: val_loss did not improve from 0.04929\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.0498 - val_loss: 0.0567 - learning_rate: 0.0010\n",
      "Epoch 155/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 0.0505\n",
      "Epoch 155: val_loss did not improve from 0.04929\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - loss: 0.0504 - val_loss: 0.0571 - learning_rate: 0.0010\n",
      "Epoch 156/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0481\n",
      "Epoch 156: val_loss improved from 0.04929 to 0.04867, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 245ms/step - loss: 0.0481 - val_loss: 0.0487 - learning_rate: 0.0010\n",
      "Epoch 157/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0475\n",
      "Epoch 157: val_loss improved from 0.04867 to 0.04655, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - loss: 0.0476 - val_loss: 0.0466 - learning_rate: 0.0010\n",
      "Epoch 158/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0467\n",
      "Epoch 158: val_loss did not improve from 0.04655\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.0467 - val_loss: 0.0470 - learning_rate: 0.0010\n",
      "Epoch 159/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 0.0470\n",
      "Epoch 159: val_loss did not improve from 0.04655\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 241ms/step - loss: 0.0470 - val_loss: 0.0473 - learning_rate: 0.0010\n",
      "Epoch 160/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.0467\n",
      "Epoch 160: val_loss did not improve from 0.04655\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.0467 - val_loss: 0.0538 - learning_rate: 0.0010\n",
      "Epoch 161/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0473\n",
      "Epoch 161: val_loss did not improve from 0.04655\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0473 - val_loss: 0.0504 - learning_rate: 0.0010\n",
      "Epoch 162/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.0462\n",
      "Epoch 162: val_loss did not improve from 0.04655\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.0462 - val_loss: 0.0511 - learning_rate: 0.0010\n",
      "Epoch 163/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0457\n",
      "Epoch 163: val_loss improved from 0.04655 to 0.04559, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step - loss: 0.0457 - val_loss: 0.0456 - learning_rate: 0.0010\n",
      "Epoch 164/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0438\n",
      "Epoch 164: val_loss improved from 0.04559 to 0.04282, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 242ms/step - loss: 0.0438 - val_loss: 0.0428 - learning_rate: 0.0010\n",
      "Epoch 165/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0435\n",
      "Epoch 165: val_loss did not improve from 0.04282\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0435 - val_loss: 0.0443 - learning_rate: 0.0010\n",
      "Epoch 166/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0434\n",
      "Epoch 166: val_loss did not improve from 0.04282\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0435 - val_loss: 0.0433 - learning_rate: 0.0010\n",
      "Epoch 167/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0442\n",
      "Epoch 167: val_loss did not improve from 0.04282\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0442 - val_loss: 0.0450 - learning_rate: 0.0010\n",
      "Epoch 168/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0434\n",
      "Epoch 168: val_loss did not improve from 0.04282\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0435 - val_loss: 0.0481 - learning_rate: 0.0010\n",
      "Epoch 169/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0437\n",
      "Epoch 169: val_loss did not improve from 0.04282\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0436 - val_loss: 0.0441 - learning_rate: 0.0010\n",
      "Epoch 170/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.0432\n",
      "Epoch 170: val_loss did not improve from 0.04282\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.0433 - val_loss: 0.0434 - learning_rate: 0.0010\n",
      "Epoch 171/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0416\n",
      "Epoch 171: val_loss improved from 0.04282 to 0.04191, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0416 - val_loss: 0.0419 - learning_rate: 0.0010\n",
      "Epoch 172/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0428\n",
      "Epoch 172: val_loss did not improve from 0.04191\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0428 - val_loss: 0.0435 - learning_rate: 0.0010\n",
      "Epoch 173/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0415\n",
      "Epoch 173: val_loss improved from 0.04191 to 0.04135, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 236ms/step - loss: 0.0415 - val_loss: 0.0414 - learning_rate: 0.0010\n",
      "Epoch 174/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0414\n",
      "Epoch 174: val_loss did not improve from 0.04135\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0415 - val_loss: 0.0463 - learning_rate: 0.0010\n",
      "Epoch 175/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0411\n",
      "Epoch 175: val_loss did not improve from 0.04135\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0410 - val_loss: 0.0439 - learning_rate: 0.0010\n",
      "Epoch 176/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0405\n",
      "Epoch 176: val_loss did not improve from 0.04135\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0405 - val_loss: 0.0421 - learning_rate: 0.0010\n",
      "Epoch 177/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0400\n",
      "Epoch 177: val_loss improved from 0.04135 to 0.03992, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - loss: 0.0400 - val_loss: 0.0399 - learning_rate: 0.0010\n",
      "Epoch 178/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0401\n",
      "Epoch 178: val_loss did not improve from 0.03992\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0401 - val_loss: 0.0440 - learning_rate: 0.0010\n",
      "Epoch 179/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.0397\n",
      "Epoch 179: val_loss did not improve from 0.03992\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.0398 - val_loss: 0.0434 - learning_rate: 0.0010\n",
      "Epoch 180/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.0417\n",
      "Epoch 180: val_loss did not improve from 0.03992\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - loss: 0.0417 - val_loss: 0.0411 - learning_rate: 0.0010\n",
      "Epoch 181/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 0.0401\n",
      "Epoch 181: val_loss did not improve from 0.03992\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 244ms/step - loss: 0.0401 - val_loss: 0.0439 - learning_rate: 0.0010\n",
      "Epoch 182/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.0393\n",
      "Epoch 182: val_loss improved from 0.03992 to 0.03933, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 253ms/step - loss: 0.0393 - val_loss: 0.0393 - learning_rate: 0.0010\n",
      "Epoch 183/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 0.0373\n",
      "Epoch 183: val_loss did not improve from 0.03933\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.0374 - val_loss: 0.0511 - learning_rate: 0.0010\n",
      "Epoch 184/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0386\n",
      "Epoch 184: val_loss did not improve from 0.03933\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0387 - val_loss: 0.0395 - learning_rate: 0.0010\n",
      "Epoch 185/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 0.0394\n",
      "Epoch 185: val_loss improved from 0.03933 to 0.03579, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 252ms/step - loss: 0.0394 - val_loss: 0.0358 - learning_rate: 0.0010\n",
      "Epoch 186/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - loss: 0.0383\n",
      "Epoch 186: val_loss did not improve from 0.03579\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250ms/step - loss: 0.0383 - val_loss: 0.0459 - learning_rate: 0.0010\n",
      "Epoch 187/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0373\n",
      "Epoch 187: val_loss did not improve from 0.03579\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.0373 - val_loss: 0.0393 - learning_rate: 0.0010\n",
      "Epoch 188/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0362\n",
      "Epoch 188: val_loss did not improve from 0.03579\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.0363 - val_loss: 0.0430 - learning_rate: 0.0010\n",
      "Epoch 189/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.0379\n",
      "Epoch 189: val_loss did not improve from 0.03579\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 241ms/step - loss: 0.0379 - val_loss: 0.0414 - learning_rate: 0.0010\n",
      "Epoch 190/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.0365\n",
      "Epoch 190: val_loss did not improve from 0.03579\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - loss: 0.0365 - val_loss: 0.0440 - learning_rate: 0.0010\n",
      "Epoch 191/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 0.0357\n",
      "Epoch 191: val_loss did not improve from 0.03579\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step - loss: 0.0358 - val_loss: 0.0369 - learning_rate: 0.0010\n",
      "Epoch 192/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0356\n",
      "Epoch 192: val_loss did not improve from 0.03579\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.0356 - val_loss: 0.0359 - learning_rate: 0.0010\n",
      "Epoch 193/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.0370\n",
      "Epoch 193: val_loss did not improve from 0.03579\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - loss: 0.0370 - val_loss: 0.0430 - learning_rate: 0.0010\n",
      "Epoch 194/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.0375\n",
      "Epoch 194: val_loss did not improve from 0.03579\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.0375 - val_loss: 0.0378 - learning_rate: 0.0010\n",
      "Epoch 195/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0380\n",
      "Epoch 195: val_loss did not improve from 0.03579\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0380 - val_loss: 0.0407 - learning_rate: 0.0010\n",
      "Epoch 196/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0360\n",
      "Epoch 196: val_loss did not improve from 0.03579\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0359 - val_loss: 0.0380 - learning_rate: 0.0010\n",
      "Epoch 197/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0357\n",
      "Epoch 197: val_loss did not improve from 0.03579\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0357 - val_loss: 0.0369 - learning_rate: 0.0010\n",
      "Epoch 198/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0342\n",
      "Epoch 198: val_loss did not improve from 0.03579\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0343 - val_loss: 0.0366 - learning_rate: 0.0010\n",
      "Epoch 199/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0352\n",
      "Epoch 199: val_loss improved from 0.03579 to 0.03394, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.0351 - val_loss: 0.0339 - learning_rate: 0.0010\n",
      "Epoch 200/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0327\n",
      "Epoch 200: val_loss did not improve from 0.03394\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0328 - val_loss: 0.0340 - learning_rate: 0.0010\n",
      "Epoch 201/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0344\n",
      "Epoch 201: val_loss did not improve from 0.03394\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0344 - val_loss: 0.0382 - learning_rate: 0.0010\n",
      "Epoch 202/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0334\n",
      "Epoch 202: val_loss did not improve from 0.03394\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0334 - val_loss: 0.0344 - learning_rate: 0.0010\n",
      "Epoch 203/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0341\n",
      "Epoch 203: val_loss did not improve from 0.03394\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0341 - val_loss: 0.0369 - learning_rate: 0.0010\n",
      "Epoch 204/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0333\n",
      "Epoch 204: val_loss did not improve from 0.03394\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0333 - val_loss: 0.0366 - learning_rate: 0.0010\n",
      "Epoch 205/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0330\n",
      "Epoch 205: val_loss did not improve from 0.03394\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0330 - val_loss: 0.0351 - learning_rate: 0.0010\n",
      "Epoch 206/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0332\n",
      "Epoch 206: val_loss did not improve from 0.03394\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0332 - val_loss: 0.0353 - learning_rate: 0.0010\n",
      "Epoch 207/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0316\n",
      "Epoch 207: val_loss did not improve from 0.03394\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0317 - val_loss: 0.0366 - learning_rate: 0.0010\n",
      "Epoch 208/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0350\n",
      "Epoch 208: val_loss did not improve from 0.03394\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0350 - val_loss: 0.0363 - learning_rate: 0.0010\n",
      "Epoch 209/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0315\n",
      "Epoch 209: val_loss improved from 0.03394 to 0.03281, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - loss: 0.0316 - val_loss: 0.0328 - learning_rate: 0.0010\n",
      "Epoch 210/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0330\n",
      "Epoch 210: val_loss did not improve from 0.03281\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0329 - val_loss: 0.0352 - learning_rate: 0.0010\n",
      "Epoch 211/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0321\n",
      "Epoch 211: val_loss did not improve from 0.03281\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0321 - val_loss: 0.0367 - learning_rate: 0.0010\n",
      "Epoch 212/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0319\n",
      "Epoch 212: val_loss did not improve from 0.03281\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0320 - val_loss: 0.0371 - learning_rate: 0.0010\n",
      "Epoch 213/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0337\n",
      "Epoch 213: val_loss did not improve from 0.03281\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0337 - val_loss: 0.0363 - learning_rate: 0.0010\n",
      "Epoch 214/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0328\n",
      "Epoch 214: val_loss did not improve from 0.03281\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0328 - val_loss: 0.0343 - learning_rate: 0.0010\n",
      "Epoch 215/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0339\n",
      "Epoch 215: val_loss improved from 0.03281 to 0.03267, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.0339 - val_loss: 0.0327 - learning_rate: 0.0010\n",
      "Epoch 216/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0320\n",
      "Epoch 216: val_loss improved from 0.03267 to 0.03136, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 233ms/step - loss: 0.0320 - val_loss: 0.0314 - learning_rate: 0.0010\n",
      "Epoch 217/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0309\n",
      "Epoch 217: val_loss did not improve from 0.03136\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0309 - val_loss: 0.0323 - learning_rate: 0.0010\n",
      "Epoch 218/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0296\n",
      "Epoch 218: val_loss did not improve from 0.03136\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0296 - val_loss: 0.0326 - learning_rate: 0.0010\n",
      "Epoch 219/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0299\n",
      "Epoch 219: val_loss did not improve from 0.03136\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.0299 - val_loss: 0.0335 - learning_rate: 0.0010\n",
      "Epoch 220/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.0288\n",
      "Epoch 220: val_loss did not improve from 0.03136\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - loss: 0.0288 - val_loss: 0.0317 - learning_rate: 0.0010\n",
      "Epoch 221/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0298\n",
      "Epoch 221: val_loss did not improve from 0.03136\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 236ms/step - loss: 0.0297 - val_loss: 0.0342 - learning_rate: 0.0010\n",
      "Epoch 222/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0290\n",
      "Epoch 222: val_loss did not improve from 0.03136\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0290 - val_loss: 0.0324 - learning_rate: 0.0010\n",
      "Epoch 223/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0300\n",
      "Epoch 223: val_loss improved from 0.03136 to 0.02926, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 236ms/step - loss: 0.0301 - val_loss: 0.0293 - learning_rate: 0.0010\n",
      "Epoch 224/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0297\n",
      "Epoch 224: val_loss did not improve from 0.02926\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0297 - val_loss: 0.0323 - learning_rate: 0.0010\n",
      "Epoch 225/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0288\n",
      "Epoch 225: val_loss did not improve from 0.02926\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0289 - val_loss: 0.0346 - learning_rate: 0.0010\n",
      "Epoch 226/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.0297\n",
      "Epoch 226: val_loss did not improve from 0.02926\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - loss: 0.0297 - val_loss: 0.0313 - learning_rate: 0.0010\n",
      "Epoch 227/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0291\n",
      "Epoch 227: val_loss did not improve from 0.02926\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0291 - val_loss: 0.0325 - learning_rate: 0.0010\n",
      "Epoch 228/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0307\n",
      "Epoch 228: val_loss improved from 0.02926 to 0.02892, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - loss: 0.0307 - val_loss: 0.0289 - learning_rate: 0.0010\n",
      "Epoch 229/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0301\n",
      "Epoch 229: val_loss did not improve from 0.02892\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.0301 - val_loss: 0.0334 - learning_rate: 0.0010\n",
      "Epoch 230/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.0296\n",
      "Epoch 230: val_loss did not improve from 0.02892\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - loss: 0.0296 - val_loss: 0.0307 - learning_rate: 0.0010\n",
      "Epoch 231/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 0.0292\n",
      "Epoch 231: val_loss did not improve from 0.02892\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250ms/step - loss: 0.0292 - val_loss: 0.0382 - learning_rate: 0.0010\n",
      "Epoch 232/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.0287\n",
      "Epoch 232: val_loss did not improve from 0.02892\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.0287 - val_loss: 0.0304 - learning_rate: 0.0010\n",
      "Epoch 233/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - loss: 0.0282\n",
      "Epoch 233: val_loss did not improve from 0.02892\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 254ms/step - loss: 0.0282 - val_loss: 0.0324 - learning_rate: 0.0010\n",
      "Epoch 234/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0284\n",
      "Epoch 234: val_loss did not improve from 0.02892\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0285 - val_loss: 0.0320 - learning_rate: 0.0010\n",
      "Epoch 235/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.0284\n",
      "Epoch 235: val_loss did not improve from 0.02892\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - loss: 0.0284 - val_loss: 0.0302 - learning_rate: 0.0010\n",
      "Epoch 236/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.0272\n",
      "Epoch 236: val_loss did not improve from 0.02892\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - loss: 0.0272 - val_loss: 0.0361 - learning_rate: 0.0010\n",
      "Epoch 237/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.0278\n",
      "Epoch 237: val_loss improved from 0.02892 to 0.02831, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250ms/step - loss: 0.0278 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 238/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0264\n",
      "Epoch 238: val_loss did not improve from 0.02831\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0264 - val_loss: 0.0300 - learning_rate: 0.0010\n",
      "Epoch 239/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0269\n",
      "Epoch 239: val_loss did not improve from 0.02831\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0270 - val_loss: 0.0307 - learning_rate: 0.0010\n",
      "Epoch 240/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0278\n",
      "Epoch 240: val_loss improved from 0.02831 to 0.02761, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.0278 - val_loss: 0.0276 - learning_rate: 0.0010\n",
      "Epoch 241/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0266\n",
      "Epoch 241: val_loss did not improve from 0.02761\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0267 - val_loss: 0.0297 - learning_rate: 0.0010\n",
      "Epoch 242/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0271\n",
      "Epoch 242: val_loss did not improve from 0.02761\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0270 - val_loss: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 243/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0265\n",
      "Epoch 243: val_loss did not improve from 0.02761\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.0265 - val_loss: 0.0338 - learning_rate: 0.0010\n",
      "Epoch 244/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.0255\n",
      "Epoch 244: val_loss did not improve from 0.02761\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0256 - val_loss: 0.0296 - learning_rate: 0.0010\n",
      "Epoch 245/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - loss: 0.0263\n",
      "Epoch 245: val_loss did not improve from 0.02761\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 247ms/step - loss: 0.0263 - val_loss: 0.0316 - learning_rate: 0.0010\n",
      "Epoch 246/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0264\n",
      "Epoch 246: val_loss improved from 0.02761 to 0.02624, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - loss: 0.0264 - val_loss: 0.0262 - learning_rate: 0.0010\n",
      "Epoch 247/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0257\n",
      "Epoch 247: val_loss did not improve from 0.02624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0257 - val_loss: 0.0297 - learning_rate: 0.0010\n",
      "Epoch 248/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0253\n",
      "Epoch 248: val_loss did not improve from 0.02624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0253 - val_loss: 0.0304 - learning_rate: 0.0010\n",
      "Epoch 249/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0271\n",
      "Epoch 249: val_loss did not improve from 0.02624\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0271 - val_loss: 0.0284 - learning_rate: 0.0010\n",
      "Epoch 250/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0250\n",
      "Epoch 250: val_loss improved from 0.02624 to 0.02577, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0250 - val_loss: 0.0258 - learning_rate: 0.0010\n",
      "Epoch 251/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.0266\n",
      "Epoch 251: val_loss did not improve from 0.02577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.0265 - val_loss: 0.0271 - learning_rate: 0.0010\n",
      "Epoch 252/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0262\n",
      "Epoch 252: val_loss did not improve from 0.02577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.0262 - val_loss: 0.0338 - learning_rate: 0.0010\n",
      "Epoch 253/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0258\n",
      "Epoch 253: val_loss did not improve from 0.02577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0258 - val_loss: 0.0300 - learning_rate: 0.0010\n",
      "Epoch 254/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.0271\n",
      "Epoch 254: val_loss did not improve from 0.02577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.0271 - val_loss: 0.0282 - learning_rate: 0.0010\n",
      "Epoch 255/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0257\n",
      "Epoch 255: val_loss did not improve from 0.02577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0257 - val_loss: 0.0276 - learning_rate: 0.0010\n",
      "Epoch 256/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0254\n",
      "Epoch 256: val_loss did not improve from 0.02577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0254 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 257/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.0249\n",
      "Epoch 257: val_loss did not improve from 0.02577\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.0249 - val_loss: 0.0262 - learning_rate: 0.0010\n",
      "Epoch 258/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0238\n",
      "Epoch 258: val_loss improved from 0.02577 to 0.02446, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 233ms/step - loss: 0.0239 - val_loss: 0.0245 - learning_rate: 0.0010\n",
      "Epoch 259/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0236\n",
      "Epoch 259: val_loss did not improve from 0.02446\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0237 - val_loss: 0.0300 - learning_rate: 0.0010\n",
      "Epoch 260/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0253\n",
      "Epoch 260: val_loss did not improve from 0.02446\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.0254 - val_loss: 0.0284 - learning_rate: 0.0010\n",
      "Epoch 261/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0266\n",
      "Epoch 261: val_loss did not improve from 0.02446\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0266 - val_loss: 0.0278 - learning_rate: 0.0010\n",
      "Epoch 262/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0248\n",
      "Epoch 262: val_loss improved from 0.02446 to 0.02435, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0249 - val_loss: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 263/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0262\n",
      "Epoch 263: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0263 - val_loss: 0.0332 - learning_rate: 0.0010\n",
      "Epoch 264/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0265\n",
      "Epoch 264: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0265 - val_loss: 0.0324 - learning_rate: 0.0010\n",
      "Epoch 265/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0266\n",
      "Epoch 265: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0266 - val_loss: 0.0252 - learning_rate: 0.0010\n",
      "Epoch 266/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0243\n",
      "Epoch 266: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0243 - val_loss: 0.0247 - learning_rate: 0.0010\n",
      "Epoch 267/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0242\n",
      "Epoch 267: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.0243 - val_loss: 0.0245 - learning_rate: 0.0010\n",
      "Epoch 268/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0239\n",
      "Epoch 268: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0239 - val_loss: 0.0260 - learning_rate: 0.0010\n",
      "Epoch 269/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0228\n",
      "Epoch 269: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0228 - val_loss: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 270/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0238\n",
      "Epoch 270: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0238 - val_loss: 0.0320 - learning_rate: 0.0010\n",
      "Epoch 271/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0236\n",
      "Epoch 271: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0236 - val_loss: 0.0276 - learning_rate: 0.0010\n",
      "Epoch 272/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0241\n",
      "Epoch 272: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0242 - val_loss: 0.0260 - learning_rate: 0.0010\n",
      "Epoch 273/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 0.0264\n",
      "Epoch 273: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 241ms/step - loss: 0.0264 - val_loss: 0.0341 - learning_rate: 0.0010\n",
      "Epoch 274/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0255\n",
      "Epoch 274: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - loss: 0.0255 - val_loss: 0.0264 - learning_rate: 0.0010\n",
      "Epoch 275/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0259\n",
      "Epoch 275: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0259 - val_loss: 0.0315 - learning_rate: 0.0010\n",
      "Epoch 276/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0235\n",
      "Epoch 276: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0235 - val_loss: 0.0301 - learning_rate: 0.0010\n",
      "Epoch 277/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0226\n",
      "Epoch 277: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0227 - val_loss: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 278/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0227\n",
      "Epoch 278: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0227 - val_loss: 0.0265 - learning_rate: 0.0010\n",
      "Epoch 279/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0220\n",
      "Epoch 279: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0220 - val_loss: 0.0269 - learning_rate: 0.0010\n",
      "Epoch 280/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0222\n",
      "Epoch 280: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0222 - val_loss: 0.0252 - learning_rate: 0.0010\n",
      "Epoch 281/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.0227\n",
      "Epoch 281: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - loss: 0.0227 - val_loss: 0.0259 - learning_rate: 0.0010\n",
      "Epoch 282/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0217\n",
      "Epoch 282: val_loss did not improve from 0.02435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.0217 - val_loss: 0.0251 - learning_rate: 0.0010\n",
      "Epoch 283/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0218\n",
      "Epoch 283: val_loss improved from 0.02435 to 0.02312, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.0218 - val_loss: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 284/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0219\n",
      "Epoch 284: val_loss did not improve from 0.02312\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0219 - val_loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 285/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0215\n",
      "Epoch 285: val_loss did not improve from 0.02312\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - loss: 0.0216 - val_loss: 0.0308 - learning_rate: 0.0010\n",
      "Epoch 286/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0215\n",
      "Epoch 286: val_loss did not improve from 0.02312\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0215 - val_loss: 0.0236 - learning_rate: 0.0010\n",
      "Epoch 287/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.0229\n",
      "Epoch 287: val_loss improved from 0.02312 to 0.02304, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 246ms/step - loss: 0.0229 - val_loss: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 288/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0214\n",
      "Epoch 288: val_loss did not improve from 0.02304\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0214 - val_loss: 0.0252 - learning_rate: 0.0010\n",
      "Epoch 289/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0208\n",
      "Epoch 289: val_loss did not improve from 0.02304\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0209 - val_loss: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 290/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0220\n",
      "Epoch 290: val_loss did not improve from 0.02304\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0221 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 291/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0233\n",
      "Epoch 291: val_loss improved from 0.02304 to 0.02217, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.0233 - val_loss: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 292/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0221\n",
      "Epoch 292: val_loss did not improve from 0.02217\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.0221 - val_loss: 0.0293 - learning_rate: 0.0010\n",
      "Epoch 293/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0217\n",
      "Epoch 293: val_loss did not improve from 0.02217\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0216 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 294/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0206\n",
      "Epoch 294: val_loss did not improve from 0.02217\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0206 - val_loss: 0.0260 - learning_rate: 0.0010\n",
      "Epoch 295/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0204\n",
      "Epoch 295: val_loss did not improve from 0.02217\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0204 - val_loss: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 296/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0210\n",
      "Epoch 296: val_loss improved from 0.02217 to 0.02199, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.0210 - val_loss: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 297/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0206\n",
      "Epoch 297: val_loss did not improve from 0.02199\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0206 - val_loss: 0.0282 - learning_rate: 0.0010\n",
      "Epoch 298/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0198\n",
      "Epoch 298: val_loss did not improve from 0.02199\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0198 - val_loss: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 299/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0202\n",
      "Epoch 299: val_loss did not improve from 0.02199\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0202 - val_loss: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 300/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0200\n",
      "Epoch 300: val_loss did not improve from 0.02199\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0200 - val_loss: 0.0235 - learning_rate: 0.0010\n",
      "Epoch 301/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0200\n",
      "Epoch 301: val_loss did not improve from 0.02199\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0200 - val_loss: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 302/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0205\n",
      "Epoch 302: val_loss did not improve from 0.02199\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0205 - val_loss: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 303/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0205\n",
      "Epoch 303: val_loss did not improve from 0.02199\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0205 - val_loss: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 304/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.0206\n",
      "Epoch 304: val_loss did not improve from 0.02199\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - loss: 0.0205 - val_loss: 0.0288 - learning_rate: 0.0010\n",
      "Epoch 305/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0196\n",
      "Epoch 305: val_loss improved from 0.02199 to 0.02193, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 236ms/step - loss: 0.0196 - val_loss: 0.0219 - learning_rate: 0.0010\n",
      "Epoch 306/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0191\n",
      "Epoch 306: val_loss improved from 0.02193 to 0.02035, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - loss: 0.0191 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 307/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0186\n",
      "Epoch 307: val_loss did not improve from 0.02035\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0186 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 308/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0193\n",
      "Epoch 308: val_loss did not improve from 0.02035\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0193 - val_loss: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 309/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.0198\n",
      "Epoch 309: val_loss did not improve from 0.02035\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - loss: 0.0197 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 310/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0195\n",
      "Epoch 310: val_loss did not improve from 0.02035\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0195 - val_loss: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 311/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0193\n",
      "Epoch 311: val_loss did not improve from 0.02035\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0194 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 312/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0194\n",
      "Epoch 312: val_loss did not improve from 0.02035\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0195 - val_loss: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 313/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0198\n",
      "Epoch 313: val_loss did not improve from 0.02035\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0198 - val_loss: 0.0206 - learning_rate: 0.0010\n",
      "Epoch 314/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0192\n",
      "Epoch 314: val_loss did not improve from 0.02035\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0192 - val_loss: 0.0225 - learning_rate: 0.0010\n",
      "Epoch 315/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0196\n",
      "Epoch 315: val_loss did not improve from 0.02035\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0196 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 316/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0195\n",
      "Epoch 316: val_loss did not improve from 0.02035\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0195 - val_loss: 0.0278 - learning_rate: 0.0010\n",
      "Epoch 317/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0206\n",
      "Epoch 317: val_loss did not improve from 0.02035\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0207 - val_loss: 0.0286 - learning_rate: 0.0010\n",
      "Epoch 318/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0195\n",
      "Epoch 318: val_loss did not improve from 0.02035\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0195 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 319/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0202\n",
      "Epoch 319: val_loss improved from 0.02035 to 0.01940, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0202 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 320/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0198\n",
      "Epoch 320: val_loss did not improve from 0.01940\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0198 - val_loss: 0.0277 - learning_rate: 0.0010\n",
      "Epoch 321/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0201\n",
      "Epoch 321: val_loss did not improve from 0.01940\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0201 - val_loss: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 322/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0202\n",
      "Epoch 322: val_loss did not improve from 0.01940\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0201 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 323/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0193\n",
      "Epoch 323: val_loss improved from 0.01940 to 0.01884, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.0193 - val_loss: 0.0188 - learning_rate: 0.0010\n",
      "Epoch 324/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.0194\n",
      "Epoch 324: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - loss: 0.0194 - val_loss: 0.0295 - learning_rate: 0.0010\n",
      "Epoch 325/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0195\n",
      "Epoch 325: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0196 - val_loss: 0.0257 - learning_rate: 0.0010\n",
      "Epoch 326/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0192\n",
      "Epoch 326: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - loss: 0.0192 - val_loss: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 327/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0186\n",
      "Epoch 327: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0187 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 328/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.0196\n",
      "Epoch 328: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.0196 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 329/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0195\n",
      "Epoch 329: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0194 - val_loss: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 330/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0190\n",
      "Epoch 330: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0190 - val_loss: 0.0246 - learning_rate: 0.0010\n",
      "Epoch 331/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0186\n",
      "Epoch 331: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0186 - val_loss: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 332/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0177\n",
      "Epoch 332: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0178 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 333/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0189\n",
      "Epoch 333: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0189 - val_loss: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 334/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0194\n",
      "Epoch 334: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0195 - val_loss: 0.0232 - learning_rate: 0.0010\n",
      "Epoch 335/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0201\n",
      "Epoch 335: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0201 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 336/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0193\n",
      "Epoch 336: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0193 - val_loss: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 337/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0186\n",
      "Epoch 337: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0187 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 338/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0183\n",
      "Epoch 338: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0183 - val_loss: 0.0232 - learning_rate: 0.0010\n",
      "Epoch 339/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0192\n",
      "Epoch 339: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0192 - val_loss: 0.0260 - learning_rate: 0.0010\n",
      "Epoch 340/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0194\n",
      "Epoch 340: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0194 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 341/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.0189\n",
      "Epoch 341: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.0189 - val_loss: 0.0206 - learning_rate: 0.0010\n",
      "Epoch 342/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0193\n",
      "Epoch 342: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0194 - val_loss: 0.0285 - learning_rate: 0.0010\n",
      "Epoch 343/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0197\n",
      "Epoch 343: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0197 - val_loss: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 344/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.0179\n",
      "Epoch 344: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - loss: 0.0179 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 345/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0183\n",
      "Epoch 345: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 233ms/step - loss: 0.0183 - val_loss: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 346/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0190\n",
      "Epoch 346: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0190 - val_loss: 0.0245 - learning_rate: 0.0010\n",
      "Epoch 347/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0183\n",
      "Epoch 347: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - loss: 0.0183 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 348/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0175\n",
      "Epoch 348: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0175 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 349/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0175\n",
      "Epoch 349: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0176 - val_loss: 0.0202 - learning_rate: 0.0010\n",
      "Epoch 350/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.0176\n",
      "Epoch 350: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 233ms/step - loss: 0.0176 - val_loss: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 351/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - loss: 0.0174\n",
      "Epoch 351: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 253ms/step - loss: 0.0174 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 352/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 0.0173\n",
      "Epoch 352: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 244ms/step - loss: 0.0173 - val_loss: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 353/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 0.0191\n",
      "Epoch 353: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 243ms/step - loss: 0.0191 - val_loss: 0.0206 - learning_rate: 0.0010\n",
      "Epoch 354/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0190\n",
      "Epoch 354: val_loss did not improve from 0.01884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0191 - val_loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 355/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.0199\n",
      "Epoch 355: val_loss improved from 0.01884 to 0.01690, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 244ms/step - loss: 0.0199 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 356/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 0.0174\n",
      "Epoch 356: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - loss: 0.0174 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 357/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.0170\n",
      "Epoch 357: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.0170 - val_loss: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 358/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 0.0177\n",
      "Epoch 358: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.0177 - val_loss: 0.0202 - learning_rate: 0.0010\n",
      "Epoch 359/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.0177\n",
      "Epoch 359: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - loss: 0.0177 - val_loss: 0.0237 - learning_rate: 0.0010\n",
      "Epoch 360/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.0182\n",
      "Epoch 360: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - loss: 0.0181 - val_loss: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 361/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 0.0173\n",
      "Epoch 361: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 244ms/step - loss: 0.0173 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 362/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - loss: 0.0181\n",
      "Epoch 362: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 250ms/step - loss: 0.0181 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 363/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 0.0170\n",
      "Epoch 363: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 242ms/step - loss: 0.0170 - val_loss: 0.0252 - learning_rate: 0.0010\n",
      "Epoch 364/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.0181\n",
      "Epoch 364: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.0181 - val_loss: 0.0234 - learning_rate: 0.0010\n",
      "Epoch 365/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.0167\n",
      "Epoch 365: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.0167 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 366/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0163\n",
      "Epoch 366: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.0163 - val_loss: 0.0245 - learning_rate: 0.0010\n",
      "Epoch 367/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0175\n",
      "Epoch 367: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0175 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 368/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0174\n",
      "Epoch 368: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0174 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 369/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0177\n",
      "Epoch 369: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0177 - val_loss: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 370/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.0170\n",
      "Epoch 370: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.0170 - val_loss: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 371/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0164\n",
      "Epoch 371: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0164 - val_loss: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 372/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0157\n",
      "Epoch 372: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0157 - val_loss: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 373/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 0.0167\n",
      "Epoch 373: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - loss: 0.0167 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 374/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.0167\n",
      "Epoch 374: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - loss: 0.0167 - val_loss: 0.0202 - learning_rate: 0.0010\n",
      "Epoch 375/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.0177\n",
      "Epoch 375: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - loss: 0.0177 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 376/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0167\n",
      "Epoch 376: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.0167 - val_loss: 0.0206 - learning_rate: 0.0010\n",
      "Epoch 377/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0163\n",
      "Epoch 377: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0163 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 378/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0164\n",
      "Epoch 378: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0164 - val_loss: 0.0206 - learning_rate: 0.0010\n",
      "Epoch 379/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0163\n",
      "Epoch 379: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - loss: 0.0163 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 380/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0158\n",
      "Epoch 380: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0158 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 381/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0158\n",
      "Epoch 381: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 0.0158 - val_loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 382/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.0159\n",
      "Epoch 382: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 233ms/step - loss: 0.0160 - val_loss: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 383/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0169\n",
      "Epoch 383: val_loss did not improve from 0.01690\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0170 - val_loss: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 384/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0164\n",
      "Epoch 384: val_loss improved from 0.01690 to 0.01679, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.0164 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 385/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0164\n",
      "Epoch 385: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0164 - val_loss: 0.0202 - learning_rate: 0.0010\n",
      "Epoch 386/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0166\n",
      "Epoch 386: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 233ms/step - loss: 0.0166 - val_loss: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 387/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0169\n",
      "Epoch 387: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0169 - val_loss: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 388/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0168\n",
      "Epoch 388: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0169 - val_loss: 0.0280 - learning_rate: 0.0010\n",
      "Epoch 389/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0164\n",
      "Epoch 389: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0164 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 390/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 0.0171\n",
      "Epoch 390: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - loss: 0.0172 - val_loss: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 391/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 0.0172\n",
      "Epoch 391: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 241ms/step - loss: 0.0171 - val_loss: 0.0262 - learning_rate: 0.0010\n",
      "Epoch 392/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 0.0173\n",
      "Epoch 392: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 231ms/step - loss: 0.0173 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 393/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0163\n",
      "Epoch 393: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0164 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 394/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0169\n",
      "Epoch 394: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0169 - val_loss: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 395/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0157\n",
      "Epoch 395: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0157 - val_loss: 0.0188 - learning_rate: 0.0010\n",
      "Epoch 396/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0161\n",
      "Epoch 396: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0160 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 397/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0158\n",
      "Epoch 397: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0158 - val_loss: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 398/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0162\n",
      "Epoch 398: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0163 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 399/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0163\n",
      "Epoch 399: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0164 - val_loss: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 400/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0157\n",
      "Epoch 400: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0158 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 401/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0172\n",
      "Epoch 401: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0172 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 402/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0166\n",
      "Epoch 402: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0167 - val_loss: 0.0246 - learning_rate: 0.0010\n",
      "Epoch 403/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0182\n",
      "Epoch 403: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0182 - val_loss: 0.0210 - learning_rate: 0.0010\n",
      "Epoch 404/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0169\n",
      "Epoch 404: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0169 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 405/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0161\n",
      "Epoch 405: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0161 - val_loss: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 406/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0158\n",
      "Epoch 406: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0158 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 407/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0151\n",
      "Epoch 407: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0152 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 408/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0145\n",
      "Epoch 408: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0145 - val_loss: 0.0193 - learning_rate: 0.0010\n",
      "Epoch 409/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0141\n",
      "Epoch 409: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0142 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 410/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0146\n",
      "Epoch 410: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0147 - val_loss: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 411/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0145\n",
      "Epoch 411: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0145 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 412/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0159\n",
      "Epoch 412: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0159 - val_loss: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 413/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0172\n",
      "Epoch 413: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0173 - val_loss: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 414/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0166\n",
      "Epoch 414: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0166 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 415/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0161\n",
      "Epoch 415: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0161 - val_loss: 0.0210 - learning_rate: 0.0010\n",
      "Epoch 416/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0150\n",
      "Epoch 416: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0150 - val_loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 417/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0153\n",
      "Epoch 417: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0153 - val_loss: 0.0256 - learning_rate: 0.0010\n",
      "Epoch 418/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0152\n",
      "Epoch 418: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0152 - val_loss: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 419/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0173\n",
      "Epoch 419: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0173 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 420/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0160\n",
      "Epoch 420: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0160 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 421/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0151\n",
      "Epoch 421: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0151 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 422/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0154\n",
      "Epoch 422: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0155 - val_loss: 0.0259 - learning_rate: 0.0010\n",
      "Epoch 423/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0156\n",
      "Epoch 423: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0157 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 424/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0157\n",
      "Epoch 424: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0157 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 425/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0149\n",
      "Epoch 425: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0149 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 426/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0147\n",
      "Epoch 426: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0147 - val_loss: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 427/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0157\n",
      "Epoch 427: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0157 - val_loss: 0.0251 - learning_rate: 0.0010\n",
      "Epoch 428/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0151\n",
      "Epoch 428: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0152 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 429/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0149\n",
      "Epoch 429: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0150 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 430/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0153\n",
      "Epoch 430: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0153 - val_loss: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 431/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0149\n",
      "Epoch 431: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0149 - val_loss: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 432/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0143\n",
      "Epoch 432: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0144 - val_loss: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 433/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0152\n",
      "Epoch 433: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0152 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 434/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0169\n",
      "Epoch 434: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0168 - val_loss: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 435/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0168\n",
      "Epoch 435: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0168 - val_loss: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 436/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0148\n",
      "Epoch 436: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0148 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 437/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0147\n",
      "Epoch 437: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0147 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 438/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0152\n",
      "Epoch 438: val_loss did not improve from 0.01679\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0152 - val_loss: 0.0246 - learning_rate: 0.0010\n",
      "Epoch 439/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0144\n",
      "Epoch 439: val_loss improved from 0.01679 to 0.01664, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 0.0144 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 440/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0146\n",
      "Epoch 440: val_loss did not improve from 0.01664\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0147 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 441/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0149\n",
      "Epoch 441: val_loss did not improve from 0.01664\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.0150 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 442/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0148\n",
      "Epoch 442: val_loss did not improve from 0.01664\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0148 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 443/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0153\n",
      "Epoch 443: val_loss did not improve from 0.01664\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0153 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 444/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0160\n",
      "Epoch 444: val_loss improved from 0.01664 to 0.01626, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0160 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 445/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.0170\n",
      "Epoch 445: val_loss did not improve from 0.01626\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 230ms/step - loss: 0.0170 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 446/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0152\n",
      "Epoch 446: val_loss did not improve from 0.01626\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0152 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 447/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0144\n",
      "Epoch 447: val_loss did not improve from 0.01626\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0144 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 448/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0151\n",
      "Epoch 448: val_loss did not improve from 0.01626\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0151 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 449/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0147\n",
      "Epoch 449: val_loss did not improve from 0.01626\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0148 - val_loss: 0.0202 - learning_rate: 0.0010\n",
      "Epoch 450/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0137\n",
      "Epoch 450: val_loss did not improve from 0.01626\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0137 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 451/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0140\n",
      "Epoch 451: val_loss did not improve from 0.01626\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0140 - val_loss: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 452/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0145\n",
      "Epoch 452: val_loss did not improve from 0.01626\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - loss: 0.0145 - val_loss: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 453/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0137\n",
      "Epoch 453: val_loss did not improve from 0.01626\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0137 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 454/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.0141\n",
      "Epoch 454: val_loss improved from 0.01626 to 0.01606, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - loss: 0.0142 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 455/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0149\n",
      "Epoch 455: val_loss did not improve from 0.01606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.0149 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 456/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0187\n",
      "Epoch 456: val_loss did not improve from 0.01606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0189 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 457/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0194\n",
      "Epoch 457: val_loss did not improve from 0.01606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0194 - val_loss: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 458/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0185\n",
      "Epoch 458: val_loss did not improve from 0.01606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.0185 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 459/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0161\n",
      "Epoch 459: val_loss did not improve from 0.01606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0161 - val_loss: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 460/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0145\n",
      "Epoch 460: val_loss did not improve from 0.01606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - loss: 0.0146 - val_loss: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 461/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0156\n",
      "Epoch 461: val_loss did not improve from 0.01606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0156 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 462/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0157\n",
      "Epoch 462: val_loss did not improve from 0.01606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0157 - val_loss: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 463/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0155\n",
      "Epoch 463: val_loss improved from 0.01606 to 0.01535, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 241ms/step - loss: 0.0156 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 464/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0148\n",
      "Epoch 464: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.0148 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 465/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.0146\n",
      "Epoch 465: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - loss: 0.0147 - val_loss: 0.0173 - learning_rate: 0.0010\n",
      "Epoch 466/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0138\n",
      "Epoch 466: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0139 - val_loss: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 467/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0146\n",
      "Epoch 467: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0147 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 468/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0149\n",
      "Epoch 468: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0149 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 469/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0154\n",
      "Epoch 469: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0154 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 470/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0149\n",
      "Epoch 470: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0148 - val_loss: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 471/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0144\n",
      "Epoch 471: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0145 - val_loss: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 472/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0146\n",
      "Epoch 472: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0146 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 473/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0136\n",
      "Epoch 473: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0136 - val_loss: 0.0194 - learning_rate: 0.0010\n",
      "Epoch 474/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0137\n",
      "Epoch 474: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0137 - val_loss: 0.0237 - learning_rate: 0.0010\n",
      "Epoch 475/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0135\n",
      "Epoch 475: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0136 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 476/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0155\n",
      "Epoch 476: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0155 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 477/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0163\n",
      "Epoch 477: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0164 - val_loss: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 478/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0157\n",
      "Epoch 478: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0158 - val_loss: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 479/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0148\n",
      "Epoch 479: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0148 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 480/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0145\n",
      "Epoch 480: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0145 - val_loss: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 481/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0142\n",
      "Epoch 481: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0141 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 482/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0132\n",
      "Epoch 482: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0132 - val_loss: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 483/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0131\n",
      "Epoch 483: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0131 - val_loss: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 484/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0127\n",
      "Epoch 484: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0127 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 485/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0136\n",
      "Epoch 485: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0136 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 486/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0136\n",
      "Epoch 486: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0137 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 487/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0130\n",
      "Epoch 487: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0131 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 488/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0132\n",
      "Epoch 488: val_loss did not improve from 0.01535\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0132 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 489/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0142\n",
      "Epoch 489: val_loss improved from 0.01535 to 0.01532, saving model to ./result_folder_no_misc/lstm_ts_11.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0143 - val_loss: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 490/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0148\n",
      "Epoch 490: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0147 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 491/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0139\n",
      "Epoch 491: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0139 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 492/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0131\n",
      "Epoch 492: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0131 - val_loss: 0.0239 - learning_rate: 0.0010\n",
      "Epoch 493/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0130\n",
      "Epoch 493: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0131 - val_loss: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 494/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0144\n",
      "Epoch 494: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0144 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 495/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0137\n",
      "Epoch 495: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0137 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 496/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 0.0132\n",
      "Epoch 496: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 242ms/step - loss: 0.0133 - val_loss: 0.0197 - learning_rate: 0.0010\n",
      "Epoch 497/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.0141\n",
      "Epoch 497: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0141 - val_loss: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 498/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0136\n",
      "Epoch 498: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 0.0137 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 499/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.0132\n",
      "Epoch 499: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0132 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 500/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0134\n",
      "Epoch 500: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 0.0134 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 501/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0132\n",
      "Epoch 501: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0133 - val_loss: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 502/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0140\n",
      "Epoch 502: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0140 - val_loss: 0.0266 - learning_rate: 0.0010\n",
      "Epoch 503/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0143\n",
      "Epoch 503: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0142 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 504/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0137\n",
      "Epoch 504: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 0.0137 - val_loss: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 505/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0130\n",
      "Epoch 505: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0130 - val_loss: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 506/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0130\n",
      "Epoch 506: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0130 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 507/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0137\n",
      "Epoch 507: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0138 - val_loss: 0.0232 - learning_rate: 0.0010\n",
      "Epoch 508/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0135\n",
      "Epoch 508: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - loss: 0.0135 - val_loss: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 509/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0138\n",
      "Epoch 509: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0138 - val_loss: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 510/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0136\n",
      "Epoch 510: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0136 - val_loss: 0.0188 - learning_rate: 0.0010\n",
      "Epoch 511/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0137\n",
      "Epoch 511: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - loss: 0.0137 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 512/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0139\n",
      "Epoch 512: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 0.0138 - val_loss: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 513/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0130\n",
      "Epoch 513: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0130 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 514/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0124\n",
      "Epoch 514: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.0125 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 515/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0128\n",
      "Epoch 515: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - loss: 0.0129 - val_loss: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 516/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0137\n",
      "Epoch 516: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0138 - val_loss: 0.0219 - learning_rate: 0.0010\n",
      "Epoch 517/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0152\n",
      "Epoch 517: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0152 - val_loss: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 518/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0154\n",
      "Epoch 518: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - loss: 0.0154 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 519/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0139\n",
      "Epoch 519: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0139 - val_loss: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 520/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0140\n",
      "Epoch 520: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0140 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 521/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0133\n",
      "Epoch 521: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0133 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 522/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0141\n",
      "Epoch 522: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - loss: 0.0142 - val_loss: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 523/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0147\n",
      "Epoch 523: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0147 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 524/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0138\n",
      "Epoch 524: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0138 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 525/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0130\n",
      "Epoch 525: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 0.0130 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 526/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0128\n",
      "Epoch 526: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.0128 - val_loss: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 527/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0140\n",
      "Epoch 527: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0140 - val_loss: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 528/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0133\n",
      "Epoch 528: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0133 - val_loss: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 529/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0129\n",
      "Epoch 529: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - loss: 0.0129 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 530/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0131\n",
      "Epoch 530: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0132 - val_loss: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 531/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0130\n",
      "Epoch 531: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0131 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 532/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0132\n",
      "Epoch 532: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 0.0132 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 533/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0131\n",
      "Epoch 533: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0131 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 534/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0131\n",
      "Epoch 534: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0131 - val_loss: 0.0206 - learning_rate: 0.0010\n",
      "Epoch 535/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0130\n",
      "Epoch 535: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0130 - val_loss: 0.0192 - learning_rate: 0.0010\n",
      "Epoch 536/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0147\n",
      "Epoch 536: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0146 - val_loss: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 537/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0136\n",
      "Epoch 537: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 0.0136 - val_loss: 0.0167 - learning_rate: 0.0010\n",
      "Epoch 538/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0135\n",
      "Epoch 538: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0134 - val_loss: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 539/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0132\n",
      "Epoch 539: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0133 - val_loss: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 540/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0134\n",
      "Epoch 540: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0134 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 541/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0134\n",
      "Epoch 541: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0134 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 542/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0134\n",
      "Epoch 542: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - loss: 0.0134 - val_loss: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 543/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0137\n",
      "Epoch 543: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.0137 - val_loss: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 544/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0136\n",
      "Epoch 544: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 0.0136 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 545/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.0126\n",
      "Epoch 545: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - loss: 0.0126 - val_loss: 0.0157 - learning_rate: 0.0010\n",
      "Epoch 546/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0126\n",
      "Epoch 546: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 0.0126 - val_loss: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 547/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0120\n",
      "Epoch 547: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - loss: 0.0120 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 548/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0131\n",
      "Epoch 548: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0132 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 549/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0133\n",
      "Epoch 549: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 0.0133 - val_loss: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 550/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0124\n",
      "Epoch 550: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0124 - val_loss: 0.0210 - learning_rate: 0.0010\n",
      "Epoch 551/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0128\n",
      "Epoch 551: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0128 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 552/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.0129\n",
      "Epoch 552: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0130 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 553/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0129\n",
      "Epoch 553: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0130 - val_loss: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 554/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0126\n",
      "Epoch 554: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0126 - val_loss: 0.0171 - learning_rate: 0.0010\n",
      "Epoch 555/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0135\n",
      "Epoch 555: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - loss: 0.0135 - val_loss: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 556/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 0.0134\n",
      "Epoch 556: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 0.0134 - val_loss: 0.0156 - learning_rate: 0.0010\n",
      "Epoch 557/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0152\n",
      "Epoch 557: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0152 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 558/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.0144\n",
      "Epoch 558: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 0.0143 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 559/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0139\n",
      "Epoch 559: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0139 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 560/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 0.0129\n",
      "Epoch 560: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0129 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 561/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 0.0126\n",
      "Epoch 561: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - loss: 0.0125 - val_loss: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 562/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0120\n",
      "Epoch 562: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0120 - val_loss: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 563/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.0121\n",
      "Epoch 563: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0121 - val_loss: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 564/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.0130\n",
      "Epoch 564: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - loss: 0.0131 - val_loss: 0.0180 - learning_rate: 0.0010\n",
      "Epoch 565/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.0142\n",
      "Epoch 565: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step - loss: 0.0142 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 566/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0131\n",
      "Epoch 566: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - loss: 0.0131 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 567/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0144\n",
      "Epoch 567: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0143 - val_loss: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 568/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0126\n",
      "Epoch 568: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0126 - val_loss: 0.0162 - learning_rate: 0.0010\n",
      "Epoch 569/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.0132\n",
      "Epoch 569: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.0131 - val_loss: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 570/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.0126\n",
      "Epoch 570: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0126 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 571/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - loss: 0.0123\n",
      "Epoch 571: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - loss: 0.0123 - val_loss: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 572/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0127\n",
      "Epoch 572: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 0.0128 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 573/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.0134\n",
      "Epoch 573: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0134 - val_loss: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 574/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0135\n",
      "Epoch 574: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 0.0135 - val_loss: 0.0165 - learning_rate: 0.0010\n",
      "Epoch 575/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0136\n",
      "Epoch 575: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0137 - val_loss: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 576/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0132\n",
      "Epoch 576: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - loss: 0.0133 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 577/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0135\n",
      "Epoch 577: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 0.0135 - val_loss: 0.0184 - learning_rate: 0.0010\n",
      "Epoch 578/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0143\n",
      "Epoch 578: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 0.0143 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 579/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0132\n",
      "Epoch 579: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0132 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 580/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0121\n",
      "Epoch 580: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 0.0121 - val_loss: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 581/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.0122\n",
      "Epoch 581: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 0.0122 - val_loss: 0.0205 - learning_rate: 0.0010\n",
      "Epoch 582/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - loss: 0.0115\n",
      "Epoch 582: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - loss: 0.0116 - val_loss: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 583/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.0121\n",
      "Epoch 583: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.0122 - val_loss: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 584/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0138\n",
      "Epoch 584: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 0.0138 - val_loss: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 585/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0124\n",
      "Epoch 585: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - loss: 0.0124 - val_loss: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 586/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0120\n",
      "Epoch 586: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - loss: 0.0120 - val_loss: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 587/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - loss: 0.0120\n",
      "Epoch 587: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 0.0120 - val_loss: 0.0207 - learning_rate: 0.0010\n",
      "Epoch 588/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.0125\n",
      "Epoch 588: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 0.0125 - val_loss: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 589/1000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 0.0118\n",
      "Epoch 589: val_loss did not improve from 0.01532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - loss: 0.0119 - val_loss: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 589: early stopping\n",
      "Restoring model weights from the end of the best epoch: 489.\n",
      "EUA\n",
      "0.16684612440622937\n",
      "Oil\n",
      "0.2162316581090052\n",
      "Coal\n",
      "0.05566410962391136\n",
      "NG\n",
      "0.11091385901800684\n",
      "USEU\n",
      "0.09829244546153865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 180/180 [01:39<00:00,  1.81it/s]\n",
      " 64%|   | 115/180 [02:22<02:09,  1.99s/it]"
     ]
    }
   ],
   "source": [
    "predictors_lst = ['EUA', 'Oil', 'Coal', 'NG']\n",
    "test_date = '2024-08-01'\n",
    "folder_name = \"result_folder_no_misc_v2\"\n",
    "modeltype='lstm'\n",
    "\n",
    "# save original EUA & date\n",
    "original_EUA = df_all['EUA'].values  \n",
    "dates = df_all['Date'].values\n",
    "\n",
    "for sequence_length in [i for i in range(3, 61)]:\n",
    "    last_train_date = pd.to_datetime(test_date) - pd.to_timedelta(1, unit = 'day')\n",
    "    X_train, y_train, X_test, y_test, scaler = curate_training_test_data(df_all, \n",
    "                                                                         flatten = False,\n",
    "                                                                         sequence_length=sequence_length,\n",
    "                                                                         test_date = test_date,\n",
    "                                                                         predictors_lst = predictors_lst )\n",
    "\n",
    "    checkpoint_path = f\"./{folder_name}/{modeltype}_ts_{sequence_length}.keras\"\n",
    "    model = generate_lstm(X_train, predictors_lst)\n",
    "    history = train_lstm(model, checkpoint_path, X_train, y_train)\n",
    "    # model.load_weights(checkpoint_path) \n",
    "\n",
    "    # plot loss curves \n",
    "    plt.plot(history.history['loss'], label='Training loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{folder_name}/{modeltype}_LossCurve_ts_{sequence_length}.pdf')\n",
    "    plt.close()\n",
    "\n",
    "    # accuracy plot\n",
    "    train_predictions = model.predict(X_train, verbose = 0);\n",
    "    train_predictions_rescaled = scaler.inverse_transform(train_predictions)\n",
    "    test_predictions = model.predict(X_test, verbose = 0);\n",
    "    test_predictions_rescaled = scaler.inverse_transform(test_predictions)\n",
    "\n",
    "    ground_truth_train = scaler.inverse_transform(y_train)\n",
    "    ground_truth_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "    plt.figure(figsize = (13,13))\n",
    "    for i, feature in enumerate(predictors_lst):\n",
    "        plt.subplot(len(predictors_lst)//3 + 1 if len(predictors_lst)%3 !=0 else len(predictors_lst)//3, 3, i+1)\n",
    "        plt.scatter(ground_truth_train[:,i],train_predictions_rescaled[:,i], label = 'train')\n",
    "        plt.scatter(ground_truth_test[:,i],test_predictions_rescaled[:,i], label = 'test')\n",
    "        plt.plot([min(ground_truth_train[:,i]), max(ground_truth_train[:,i])], \n",
    "                [min(ground_truth_train[:,i]), max(ground_truth_train[:,i])], color='red', label='1:1 Line')\n",
    "        \n",
    "        r2_train = r2_score(ground_truth_train[:,i],train_predictions_rescaled[:,i])\n",
    "        r2_test = r2_score(ground_truth_test[:,i],test_predictions_rescaled[:,i])\n",
    "        plt.title(f\"{feature} - train: {r2_train:.5f} / test: {r2_test:.5f}\")\n",
    "        plt.legend()\n",
    "        plt.grid('on')\n",
    "        plt.xlabel('ground truth')\n",
    "        plt.ylabel('prediction')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{folder_name}/{modeltype}_acc_ts_{sequence_length}.pdf')\n",
    "    plt.close()\n",
    "\n",
    "    # get RMSE:\n",
    "    rel_erorrs = []\n",
    "    for i in range(test_predictions_rescaled.shape[1]):\n",
    "        prediction = test_predictions[:, i]\n",
    "        ground_truth = y_test[:,i]\n",
    "        rel_error = np.mean(np.sqrt(((prediction-ground_truth)**2)))\n",
    "        print(predictors_lst[i])\n",
    "        print(rel_error)\n",
    "        rel_erorrs.append(rel_error)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    num_of_prediction = 30*6\n",
    "    corr = df_all[predictors_lst].corr()\n",
    "    for factor, num_ensemble in zip([0, 1.0], [2, 100]):\n",
    "        rel_erorrs_mat = np.array([rel_erorrs for i in range(num_ensemble)])\n",
    "        next_predictions = []\n",
    "        current_input = X_train[-1]\n",
    "        current_input = np.array([current_input for i in range(num_ensemble)]).squeeze()\n",
    "        for iter_ in tqdm(range(num_of_prediction)):\n",
    "            next_prediction = model.predict(current_input, verbose = 0)\n",
    "            error_p = generate_multivariate_samples(corr, n_samples=num_ensemble)\n",
    "            next_prediction = next_prediction * (1+error_p*rel_erorrs_mat*factor)\n",
    "            next_predictions.append(next_prediction)\n",
    "            current_input = np.concatenate([current_input, \n",
    "                                            np.expand_dims(next_prediction,1)], axis=1)\n",
    "        next_predictions = np.array(next_predictions)\n",
    "        future_dates = [last_train_date + pd.DateOffset(days=i + 1) for i in range(num_of_prediction)]\n",
    "        ensemble_future_predictions = np.array([scaler.inverse_transform(next_predictions[i]) for i in range(num_of_prediction)])\n",
    "\n",
    "\n",
    "        # Calculate mean, P10, and P90 of predictions\n",
    "        mean_predictions = ensemble_future_predictions[:, :, 0].mean(axis=1)\n",
    "        P50 = np.percentile(ensemble_future_predictions[:, :, 0], 50, axis=1)\n",
    "        P10 = np.percentile(ensemble_future_predictions[:, :, 0], 10, axis=1)\n",
    "        P90 = np.percentile(ensemble_future_predictions[:, :, 0], 90, axis=1)\n",
    "\n",
    "        # Create the plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Plot historical EUA prices\n",
    "        plt.plot(dates, original_EUA, label='Historical EUA Price', color='black')\n",
    "\n",
    "        # Plot all realizations\n",
    "        for realization in ensemble_future_predictions[:, :, 0].T:\n",
    "            plt.plot(future_dates, realization, color='gray', alpha=0.3)\n",
    "\n",
    "        # Plot P10 and P90 percentile predictions\n",
    "        plt.plot(future_dates, P10, label='P10 & P90', color='green', linestyle='-')\n",
    "        plt.plot(future_dates, P90, color='green', linestyle='-')\n",
    "        # Plot mean of future predictions\n",
    "        plt.plot(future_dates, P50, label='Median of Predictions', color='red')\n",
    "        plt.plot(df_all[df_all['Date']>test_date]['Date'],\n",
    "                    df_all[df_all['Date']>test_date]['EUA'],\n",
    "                    color = 'blue',\n",
    "                    label = 'Future EUA Price' \n",
    "                    )\n",
    "\n",
    "\n",
    "        # Customize the plot\n",
    "        plt.title('EUA Price Prediction for the Next 24 Months')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('EUA Price')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f\"{folder_name}/{modeltype}_timeplot_ts_{sequence_length}_factor_{str(factor).replace('.','_')}.pdf\")\n",
    "        plt.close()\n",
    "\n",
    "    record = {}\n",
    "    with open(f'{folder_name}/{modeltype}_record_ts_{sequence_length}.txt', 'w') as f:\n",
    "        # report metrics\n",
    "        for i, feature in enumerate(predictors_lst):\n",
    "            r2_train = r2_score(ground_truth_train[:,i],train_predictions_rescaled[:,i])\n",
    "            r2_test = r2_score(ground_truth_test[:,i],test_predictions_rescaled[:,i])\n",
    "            mse_train = mean_squared_error(ground_truth_train[:,i],train_predictions_rescaled[:,i])\n",
    "            mse_test  = mean_squared_error(ground_truth_test[:,i],test_predictions_rescaled[:,i])\n",
    "            mae_train = mean_absolute_error(ground_truth_train[:,i],train_predictions_rescaled[:,i])\n",
    "            mae_test  = mean_absolute_error(ground_truth_test[:,i],test_predictions_rescaled[:,i])\n",
    "            f.write(f'{feature}\\n')\n",
    "            f.write(f'r2(train): {r2_train}\\n')\n",
    "            f.write(f'r2(test): {r2_test}\\n')\n",
    "            f.write(f'mse(train): {mse_train}\\n')\n",
    "            f.write(f'mse(test): {mse_test}\\n')\n",
    "            f.write(f'mae(train): {mae_train}\\n')\n",
    "            f.write(f'mae(test): {mae_test}\\n')\n",
    "            f.write('---------------------------\\n')\n",
    "            record['feature'] = {\"r2_train\":r2_train, \n",
    "                                \"r2_test\": r2_test,\n",
    "                                \"mse_train\": mse_train, \n",
    "                                \"mse_test\": mse_test, \n",
    "                                \"mae_train\": mae_train, \n",
    "                                \"mae_test\": mae_test,}\n",
    "    # save metric as dictionary\n",
    "    with open(f'{folder_name}/{modeltype}_record_ts_{sequence_length}.pkl', 'wb') as f:\n",
    "        pickle.dump(record, f)\n",
    "    # Save the best model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for factor in [1, 2, 3]:\n",
    "    num_of_prediction = 30*12\n",
    "    num_ensemble = 100\n",
    "    rel_erorrs_mat = np.array([rel_erorrs for i in range(num_ensemble)])\n",
    "    corr = df_all[predictors_lst].corr()\n",
    "\n",
    "    next_predictions = []\n",
    "    current_input = train_predictions[-sequence_length:, :]\n",
    "    current_input = np.array([current_input for i in range(num_ensemble)]).squeeze()\n",
    "    for iter_ in tqdm(range(num_of_prediction)):\n",
    "        next_prediction = model.predict(current_input, verbose = 0)\n",
    "        error_p = generate_multivariate_samples(corr, n_samples=num_ensemble)\n",
    "        next_prediction = next_prediction * (1+error_p*rel_erorrs_mat*factor)\n",
    "        next_predictions.append(next_prediction)\n",
    "        current_input = np.concatenate([current_input[:,1:], \n",
    "                                        next_prediction.reshape(next_prediction.shape[0],1,\n",
    "                                                                next_prediction.shape[1])], axis=1)\n",
    "    next_predictions = np.array(next_predictions)\n",
    "    future_dates = [pd.to_datetime(train_dates[-1]) + pd.DateOffset(days=i + 1) for i in range(num_of_prediction)]\n",
    "    ensemble_future_predictions = np.array([scaler.inverse_transform(next_predictions[i]) for i in range(num_of_prediction)])\n",
    "    # Calculate mean, P10, and P90 of predictions\n",
    "    mean_predictions = ensemble_future_predictions[:, :, 0].mean(axis=1)\n",
    "    P50 = np.percentile(ensemble_future_predictions[:, :, 0], 50, axis=1)\n",
    "    P10 = np.percentile(ensemble_future_predictions[:, :, 0], 10, axis=1)\n",
    "    P90 = np.percentile(ensemble_future_predictions[:, :, 0], 90, axis=1)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot historical EUA prices\n",
    "    plt.plot(dates, original_EUA, label='Historical EUA Price', color='blue')\n",
    "\n",
    "    # Plot all realizations\n",
    "    for realization in ensemble_future_predictions[:, :, 0].T:\n",
    "        plt.plot(future_dates, realization, color='gray', alpha=0.3)\n",
    "\n",
    "    # Plot P10 and P90 percentile predictions\n",
    "    plt.plot(future_dates, P10, label='P10 & P90', color='green', linestyle='-')\n",
    "    plt.plot(future_dates, P90, color='green', linestyle='-')\n",
    "    # Plot mean of future predictions\n",
    "    plt.plot(future_dates, P50, label='Median of Predictions', color='red')\n",
    "\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.title(f'EUA Price Prediction for the Next 24 Months - factor of {factor}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('EUA Price')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_prediction = 30*24\n",
    "num_ensemble = 3\n",
    "\n",
    "ensemble_future_predictions = []\n",
    "for en in range(num_ensemble):\n",
    "    future_predictions = []\n",
    "    current_input = train_predictions[-sequence_length:, :]\n",
    "    for i in tqdm(range(num_of_prediction)):\n",
    "        current_input_scaled = np.reshape(current_input, (1, sequence_length, current_input.shape[1]))\n",
    "        next_prediction = model.predict(current_input_scaled, verbose = 0)\n",
    "        for j in range(train_predictions_rescaled.shape[1]):\n",
    "            next_prediction[0, j] *= (1+np.random.normal(0, rel_erorrs[j]))\n",
    "        future_predictions.append(next_prediction[0])  \n",
    "        current_input = np.concatenate([current_input[1:], [next_prediction[0]]], axis=0)\n",
    "    ensemble_future_predictions.append(scaler.inverse_transform(np.array(future_predictions)))\n",
    "\n",
    "ensemble_future_predictions= np.array(ensemble_future_predictions)\n",
    "\n",
    "\n",
    "# future_predictions_original = scaler.inverse_transform(future_predictions)\n",
    "future_dates = [pd.to_datetime(train_dates[-1]) + pd.DateOffset(days=i + 1) for i in range(num_of_prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create traces for each plot\n",
    "trace1 = go.Scatter(x=dates, y=original_EUA, mode='lines', name='Historical EUA Price', \n",
    "                    line=dict(color='blue'))\n",
    "\n",
    "trace2 = go.Scatter(x=future_dates, y=ensemble_future_predictions[0,:,0], mode='lines', \n",
    "                    name='Predicted EUA Price_1', \n",
    "                    line=dict(color='red'))\n",
    "\n",
    "trace3 = go.Scatter(x=future_dates, y=ensemble_future_predictions[1,:,0], mode='lines', \n",
    "                    name='Predicted EUA Price_2', \n",
    "                    line=dict(color='purple'))\n",
    "\n",
    "trace4 = go.Scatter(x=future_dates, y=ensemble_future_predictions[2,:,0], mode='lines', \n",
    "                    name='Predicted EUA Price_3', \n",
    "                    line=dict(color='orange'))\n",
    "\n",
    "trace5 = go.Scatter(x=train_dates[-train_predictions_rescaled.shape[0]:], \n",
    "                    y=train_predictions_rescaled[:, 0], mode='lines+markers', \n",
    "                    name='Train Predicted EUA Price', marker=dict(color='green', size=4), \n",
    "                    line=dict(color='green'))\n",
    "\n",
    "# Layout for the plot\n",
    "layout = go.Layout(\n",
    "    title='EUA Price Prediction for the Next 24 Months',\n",
    "    xaxis=dict(title='Date'),\n",
    "    yaxis=dict(title='EUA Price'),\n",
    "    legend=dict(x=0, y=1, traceorder='normal'),\n",
    "    height=600,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "# Create the figure with the traces\n",
    "fig = go.Figure(data=[trace1, trace2, trace3, trace4, trace5], layout=layout)\n",
    "\n",
    "# Show the figure (interactive plot)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(dates, original_EUA, 'b', label='Historical EUA Price')  #  EUA \n",
    "# plt.plot(train_dates, scaler.inverse_transform(test_data_scaled)[:, 0], 'skyblue', label='Test EUA Price')  #  \n",
    "plt.plot(future_dates, ensemble_future_predictions[0, :, 0].T, 'red', linewidth = 0.1, label = 'real_1')\n",
    "plt.plot(future_dates, ensemble_future_predictions[0, :, 0].T, 'purple', linewidth = 0.1, label = 'real_2')\n",
    "plt.plot(future_dates, ensemble_future_predictions[0, :, 0].T, 'yellow', linewidth = 0.1, label = 'real_3')\n",
    "plt.plot(train_dates[-train_predictions_rescaled.shape[0]:], train_predictions_rescaled[:, 0], 'g.', marker='.', markersize=2, label='Train Predicted EUA Price')\n",
    "\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('EUA Price')\n",
    "plt.title('EUA Price Prediction for the Next 24 Months')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
