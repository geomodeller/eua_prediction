{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from script.generate_multivariate_samples import generate_multivariate_samples\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from script.curate_training_test_data import curate_training_test_data, curate_training_test_data_many\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('eua_price_data.csv', thousands=',') \n",
    "df_all['Date'] = pd.to_datetime(df_all['Date'], format='%Y-%m-%d')  \n",
    "df_all = df_all.sort_values(by = 'Date', ascending=True).reset_index(drop = True)\n",
    "df_all = df_all[(df_all['Date'] > pd.to_datetime('2020-11-24')) & (df_all['Date'] < pd.to_datetime('2024-10-07'))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    " \n",
    "def create_dataset(dataset, lookback):\n",
    "    \"\"\"Transform a time series into a prediction dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset: A numpy array of time series, first dimension is the time steps\n",
    "        lookback: Size of window for prediction\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset)-lookback):\n",
    "        feature = dataset[i:i+lookback]\n",
    "        target = dataset[i+1:i+lookback+1]\n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "    return torch.tensor(X), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 16:32:43.336765: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-23 16:32:43.351878: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-23 16:32:43.370893: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-23 16:32:43.376460: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-23 16:32:43.389955: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-23 16:32:44.438879: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from script.generate_lstm import generate_lstm, train_lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729668767.859898    1908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729668767.860323    1908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:d5:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729668767.908622    1908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729668767.908686    1908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:d5:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729668767.908714    1908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729668767.908744    1908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:d5:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729668768.485484    1908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729668768.485631    1908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:d5:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729668768.485733    1908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729668768.485813    1908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:d5:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729668768.485889    1908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729668768.485965    1908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:d5:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729668768.514377    1908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729668768.515148    1908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:d5:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729668768.515265    1908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-23 16:32:48.515282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1729668768.515354    1908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:d5:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-23 16:32:48.515363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 1, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1729668768.515422    1908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:73:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-23 16:32:48.515459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21770 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:73:00.0, compute capability: 8.6\n",
      "I0000 00:00:1729668768.522767    1908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:d5:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-23 16:32:48.522826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21770 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:d5:00.0, compute capability: 8.6\n",
      "/home/honggeunjo/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - loss: 3.0616\n",
      "Epoch 1: val_loss improved from inf to 1.24775, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 922ms/step - loss: 3.0684 - val_loss: 1.2477 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - loss: 1.0316\n",
      "Epoch 2: val_loss improved from 1.24775 to 1.18534, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 585ms/step - loss: 1.0421 - val_loss: 1.1853 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - loss: 1.0214\n",
      "Epoch 3: val_loss improved from 1.18534 to 0.66218, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 642ms/step - loss: 0.9991 - val_loss: 0.6622 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step - loss: 0.6706\n",
      "Epoch 4: val_loss improved from 0.66218 to 0.58238, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 643ms/step - loss: 0.6727 - val_loss: 0.5824 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step - loss: 0.6816\n",
      "Epoch 5: val_loss did not improve from 0.58238\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 550ms/step - loss: 0.6768 - val_loss: 0.6052 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - loss: 0.5359\n",
      "Epoch 6: val_loss improved from 0.58238 to 0.42131, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 549ms/step - loss: 0.5363 - val_loss: 0.4213 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - loss: 0.5490\n",
      "Epoch 7: val_loss did not improve from 0.42131\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 541ms/step - loss: 0.5481 - val_loss: 0.4913 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - loss: 0.5055\n",
      "Epoch 8: val_loss did not improve from 0.42131\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 556ms/step - loss: 0.5041 - val_loss: 0.4627 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - loss: 0.4802\n",
      "Epoch 9: val_loss improved from 0.42131 to 0.40447, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 598ms/step - loss: 0.4792 - val_loss: 0.4045 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.4732\n",
      "Epoch 10: val_loss did not improve from 0.40447\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489ms/step - loss: 0.4725 - val_loss: 0.4311 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - loss: 0.4537\n",
      "Epoch 11: val_loss did not improve from 0.40447\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 483ms/step - loss: 0.4532 - val_loss: 0.4157 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - loss: 0.4425\n",
      "Epoch 12: val_loss improved from 0.40447 to 0.39482, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 610ms/step - loss: 0.4426 - val_loss: 0.3948 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.4390\n",
      "Epoch 13: val_loss improved from 0.39482 to 0.38748, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 529ms/step - loss: 0.4391 - val_loss: 0.3875 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - loss: 0.4319\n",
      "Epoch 14: val_loss did not improve from 0.38748\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step - loss: 0.4313 - val_loss: 0.3943 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - loss: 0.4202\n",
      "Epoch 15: val_loss did not improve from 0.38748\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 529ms/step - loss: 0.4203 - val_loss: 0.3896 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - loss: 0.4162\n",
      "Epoch 16: val_loss improved from 0.38748 to 0.37873, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 569ms/step - loss: 0.4163 - val_loss: 0.3787 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - loss: 0.4132\n",
      "Epoch 17: val_loss improved from 0.37873 to 0.37443, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 585ms/step - loss: 0.4129 - val_loss: 0.3744 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - loss: 0.4117\n",
      "Epoch 18: val_loss improved from 0.37443 to 0.37067, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 610ms/step - loss: 0.4116 - val_loss: 0.3707 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - loss: 0.4049\n",
      "Epoch 19: val_loss did not improve from 0.37067\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 556ms/step - loss: 0.4049 - val_loss: 0.3727 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - loss: 0.4025\n",
      "Epoch 20: val_loss did not improve from 0.37067\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 550ms/step - loss: 0.4021 - val_loss: 0.3773 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - loss: 0.3999\n",
      "Epoch 21: val_loss improved from 0.37067 to 0.36713, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 603ms/step - loss: 0.3999 - val_loss: 0.3671 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step - loss: 0.3957\n",
      "Epoch 22: val_loss improved from 0.36713 to 0.36071, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 589ms/step - loss: 0.3957 - val_loss: 0.3607 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - loss: 0.3916\n",
      "Epoch 23: val_loss did not improve from 0.36071\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 560ms/step - loss: 0.3915 - val_loss: 0.3622 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - loss: 0.3923\n",
      "Epoch 24: val_loss improved from 0.36071 to 0.35631, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 585ms/step - loss: 0.3919 - val_loss: 0.3563 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - loss: 0.3858\n",
      "Epoch 25: val_loss improved from 0.35631 to 0.35143, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 623ms/step - loss: 0.3861 - val_loss: 0.3514 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - loss: 0.3851\n",
      "Epoch 26: val_loss did not improve from 0.35143\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 514ms/step - loss: 0.3851 - val_loss: 0.3550 - learning_rate: 0.0010\n",
      "Epoch 27/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - loss: 0.3843\n",
      "Epoch 27: val_loss did not improve from 0.35143\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 485ms/step - loss: 0.3837 - val_loss: 0.3611 - learning_rate: 0.0010\n",
      "Epoch 28/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - loss: 0.3810\n",
      "Epoch 28: val_loss improved from 0.35143 to 0.35075, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 553ms/step - loss: 0.3807 - val_loss: 0.3508 - learning_rate: 0.0010\n",
      "Epoch 29/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - loss: 0.3772\n",
      "Epoch 29: val_loss improved from 0.35075 to 0.34738, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 576ms/step - loss: 0.3769 - val_loss: 0.3474 - learning_rate: 0.0010\n",
      "Epoch 30/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - loss: 0.3728\n",
      "Epoch 30: val_loss did not improve from 0.34738\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 580ms/step - loss: 0.3728 - val_loss: 0.3512 - learning_rate: 0.0010\n",
      "Epoch 31/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - loss: 0.3691\n",
      "Epoch 31: val_loss did not improve from 0.34738\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 531ms/step - loss: 0.3692 - val_loss: 0.3493 - learning_rate: 0.0010\n",
      "Epoch 32/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - loss: 0.3685\n",
      "Epoch 32: val_loss improved from 0.34738 to 0.34205, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 558ms/step - loss: 0.3686 - val_loss: 0.3421 - learning_rate: 0.0010\n",
      "Epoch 33/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - loss: 0.3670\n",
      "Epoch 33: val_loss improved from 0.34205 to 0.33967, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 622ms/step - loss: 0.3670 - val_loss: 0.3397 - learning_rate: 0.0010\n",
      "Epoch 34/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - loss: 0.3658\n",
      "Epoch 34: val_loss improved from 0.33967 to 0.33605, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 597ms/step - loss: 0.3654 - val_loss: 0.3361 - learning_rate: 0.0010\n",
      "Epoch 35/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - loss: 0.3600\n",
      "Epoch 35: val_loss did not improve from 0.33605\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 496ms/step - loss: 0.3604 - val_loss: 0.3377 - learning_rate: 0.0010\n",
      "Epoch 36/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - loss: 0.3611\n",
      "Epoch 36: val_loss did not improve from 0.33605\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step - loss: 0.3610 - val_loss: 0.3365 - learning_rate: 0.0010\n",
      "Epoch 37/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - loss: 0.3592\n",
      "Epoch 37: val_loss improved from 0.33605 to 0.33340, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 556ms/step - loss: 0.3585 - val_loss: 0.3334 - learning_rate: 0.0010\n",
      "Epoch 38/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 0.3558\n",
      "Epoch 38: val_loss improved from 0.33340 to 0.33092, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 483ms/step - loss: 0.3556 - val_loss: 0.3309 - learning_rate: 0.0010\n",
      "Epoch 39/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - loss: 0.3530\n",
      "Epoch 39: val_loss did not improve from 0.33092\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422ms/step - loss: 0.3534 - val_loss: 0.3337 - learning_rate: 0.0010\n",
      "Epoch 40/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - loss: 0.3503\n",
      "Epoch 40: val_loss improved from 0.33092 to 0.32910, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 470ms/step - loss: 0.3503 - val_loss: 0.3291 - learning_rate: 0.0010\n",
      "Epoch 41/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - loss: 0.3483\n",
      "Epoch 41: val_loss improved from 0.32910 to 0.32413, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 653ms/step - loss: 0.3481 - val_loss: 0.3241 - learning_rate: 0.0010\n",
      "Epoch 42/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - loss: 0.3461\n",
      "Epoch 42: val_loss improved from 0.32413 to 0.32318, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 632ms/step - loss: 0.3461 - val_loss: 0.3232 - learning_rate: 0.0010\n",
      "Epoch 43/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - loss: 0.3455\n",
      "Epoch 43: val_loss improved from 0.32318 to 0.31852, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 643ms/step - loss: 0.3452 - val_loss: 0.3185 - learning_rate: 0.0010\n",
      "Epoch 44/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518ms/step - loss: 0.3435\n",
      "Epoch 44: val_loss improved from 0.31852 to 0.31764, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 690ms/step - loss: 0.3433 - val_loss: 0.3176 - learning_rate: 0.0010\n",
      "Epoch 45/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541ms/step - loss: 0.3389\n",
      "Epoch 45: val_loss improved from 0.31764 to 0.31759, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 693ms/step - loss: 0.3389 - val_loss: 0.3176 - learning_rate: 0.0010\n",
      "Epoch 46/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527ms/step - loss: 0.3385\n",
      "Epoch 46: val_loss improved from 0.31759 to 0.31343, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 669ms/step - loss: 0.3384 - val_loss: 0.3134 - learning_rate: 0.0010\n",
      "Epoch 47/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558ms/step - loss: 0.3336\n",
      "Epoch 47: val_loss improved from 0.31343 to 0.31327, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 688ms/step - loss: 0.3339 - val_loss: 0.3133 - learning_rate: 0.0010\n",
      "Epoch 48/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - loss: 0.3341\n",
      "Epoch 48: val_loss improved from 0.31327 to 0.30985, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 644ms/step - loss: 0.3341 - val_loss: 0.3098 - learning_rate: 0.0010\n",
      "Epoch 49/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - loss: 0.3308\n",
      "Epoch 49: val_loss improved from 0.30985 to 0.30862, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 670ms/step - loss: 0.3308 - val_loss: 0.3086 - learning_rate: 0.0010\n",
      "Epoch 50/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582ms/step - loss: 0.3291\n",
      "Epoch 50: val_loss improved from 0.30862 to 0.30690, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 729ms/step - loss: 0.3289 - val_loss: 0.3069 - learning_rate: 0.0010\n",
      "Epoch 51/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522ms/step - loss: 0.3249\n",
      "Epoch 51: val_loss improved from 0.30690 to 0.30509, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 636ms/step - loss: 0.3251 - val_loss: 0.3051 - learning_rate: 0.0010\n",
      "Epoch 52/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step - loss: 0.3269\n",
      "Epoch 52: val_loss did not improve from 0.30509\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 650ms/step - loss: 0.3264 - val_loss: 0.3088 - learning_rate: 0.0010\n",
      "Epoch 53/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550ms/step - loss: 0.3224\n",
      "Epoch 53: val_loss improved from 0.30509 to 0.30154, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 700ms/step - loss: 0.3223 - val_loss: 0.3015 - learning_rate: 0.0010\n",
      "Epoch 54/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - loss: 0.3205\n",
      "Epoch 54: val_loss improved from 0.30154 to 0.29689, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 646ms/step - loss: 0.3206 - val_loss: 0.2969 - learning_rate: 0.0010\n",
      "Epoch 55/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - loss: 0.3183\n",
      "Epoch 55: val_loss did not improve from 0.29689\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 548ms/step - loss: 0.3186 - val_loss: 0.3004 - learning_rate: 0.0010\n",
      "Epoch 56/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - loss: 0.3182\n",
      "Epoch 56: val_loss improved from 0.29689 to 0.29579, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 665ms/step - loss: 0.3181 - val_loss: 0.2958 - learning_rate: 0.0010\n",
      "Epoch 57/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - loss: 0.3135\n",
      "Epoch 57: val_loss did not improve from 0.29579\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 552ms/step - loss: 0.3136 - val_loss: 0.2993 - learning_rate: 0.0010\n",
      "Epoch 58/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - loss: 0.3129\n",
      "Epoch 58: val_loss improved from 0.29579 to 0.29325, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 648ms/step - loss: 0.3127 - val_loss: 0.2933 - learning_rate: 0.0010\n",
      "Epoch 59/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541ms/step - loss: 0.3111\n",
      "Epoch 59: val_loss improved from 0.29325 to 0.28965, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 691ms/step - loss: 0.3110 - val_loss: 0.2896 - learning_rate: 0.0010\n",
      "Epoch 60/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545ms/step - loss: 0.3087\n",
      "Epoch 60: val_loss did not improve from 0.28965\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 640ms/step - loss: 0.3085 - val_loss: 0.2906 - learning_rate: 0.0010\n",
      "Epoch 61/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549ms/step - loss: 0.3063\n",
      "Epoch 61: val_loss did not improve from 0.28965\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 645ms/step - loss: 0.3065 - val_loss: 0.2900 - learning_rate: 0.0010\n",
      "Epoch 62/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - loss: 0.3051\n",
      "Epoch 62: val_loss improved from 0.28965 to 0.28516, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 658ms/step - loss: 0.3050 - val_loss: 0.2852 - learning_rate: 0.0010\n",
      "Epoch 63/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - loss: 0.3028\n",
      "Epoch 63: val_loss did not improve from 0.28516\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 604ms/step - loss: 0.3028 - val_loss: 0.2906 - learning_rate: 0.0010\n",
      "Epoch 64/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540ms/step - loss: 0.3018\n",
      "Epoch 64: val_loss improved from 0.28516 to 0.28376, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 688ms/step - loss: 0.3015 - val_loss: 0.2838 - learning_rate: 0.0010\n",
      "Epoch 65/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step - loss: 0.2992\n",
      "Epoch 65: val_loss improved from 0.28376 to 0.27763, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 640ms/step - loss: 0.2990 - val_loss: 0.2776 - learning_rate: 0.0010\n",
      "Epoch 66/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - loss: 0.2966\n",
      "Epoch 66: val_loss did not improve from 0.27763\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 549ms/step - loss: 0.2967 - val_loss: 0.2791 - learning_rate: 0.0010\n",
      "Epoch 67/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - loss: 0.2945\n",
      "Epoch 67: val_loss did not improve from 0.27763\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 553ms/step - loss: 0.2947 - val_loss: 0.2807 - learning_rate: 0.0010\n",
      "Epoch 68/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - loss: 0.2952\n",
      "Epoch 68: val_loss improved from 0.27763 to 0.27267, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 622ms/step - loss: 0.2949 - val_loss: 0.2727 - learning_rate: 0.0010\n",
      "Epoch 69/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555ms/step - loss: 0.2916\n",
      "Epoch 69: val_loss did not improve from 0.27267\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 651ms/step - loss: 0.2917 - val_loss: 0.2763 - learning_rate: 0.0010\n",
      "Epoch 70/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step - loss: 0.2894\n",
      "Epoch 70: val_loss improved from 0.27267 to 0.27223, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 677ms/step - loss: 0.2892 - val_loss: 0.2722 - learning_rate: 0.0010\n",
      "Epoch 71/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529ms/step - loss: 0.2887\n",
      "Epoch 71: val_loss improved from 0.27223 to 0.27148, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 672ms/step - loss: 0.2886 - val_loss: 0.2715 - learning_rate: 0.0010\n",
      "Epoch 72/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - loss: 0.2867\n",
      "Epoch 72: val_loss did not improve from 0.27148\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 575ms/step - loss: 0.2866 - val_loss: 0.2722 - learning_rate: 0.0010\n",
      "Epoch 73/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525ms/step - loss: 0.2833\n",
      "Epoch 73: val_loss improved from 0.27148 to 0.26559, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 681ms/step - loss: 0.2833 - val_loss: 0.2656 - learning_rate: 0.0010\n",
      "Epoch 74/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - loss: 0.2822\n",
      "Epoch 74: val_loss did not improve from 0.26559\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 622ms/step - loss: 0.2821 - val_loss: 0.2668 - learning_rate: 0.0010\n",
      "Epoch 75/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - loss: 0.2805\n",
      "Epoch 75: val_loss improved from 0.26559 to 0.26035, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 680ms/step - loss: 0.2805 - val_loss: 0.2603 - learning_rate: 0.0010\n",
      "Epoch 76/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - loss: 0.2782\n",
      "Epoch 76: val_loss did not improve from 0.26035\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 594ms/step - loss: 0.2782 - val_loss: 0.2634 - learning_rate: 0.0010\n",
      "Epoch 77/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539ms/step - loss: 0.2752\n",
      "Epoch 77: val_loss did not improve from 0.26035\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 634ms/step - loss: 0.2756 - val_loss: 0.2606 - learning_rate: 0.0010\n",
      "Epoch 78/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - loss: 0.2745\n",
      "Epoch 78: val_loss improved from 0.26035 to 0.25715, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 631ms/step - loss: 0.2746 - val_loss: 0.2571 - learning_rate: 0.0010\n",
      "Epoch 79/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533ms/step - loss: 0.2728\n",
      "Epoch 79: val_loss did not improve from 0.25715\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 629ms/step - loss: 0.2728 - val_loss: 0.2573 - learning_rate: 0.0010\n",
      "Epoch 80/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - loss: 0.2727\n",
      "Epoch 80: val_loss improved from 0.25715 to 0.25462, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 634ms/step - loss: 0.2726 - val_loss: 0.2546 - learning_rate: 0.0010\n",
      "Epoch 81/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - loss: 0.2698\n",
      "Epoch 81: val_loss improved from 0.25462 to 0.25264, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 621ms/step - loss: 0.2698 - val_loss: 0.2526 - learning_rate: 0.0010\n",
      "Epoch 82/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - loss: 0.2674\n",
      "Epoch 82: val_loss improved from 0.25264 to 0.25239, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 619ms/step - loss: 0.2676 - val_loss: 0.2524 - learning_rate: 0.0010\n",
      "Epoch 83/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - loss: 0.2673\n",
      "Epoch 83: val_loss did not improve from 0.25239\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 558ms/step - loss: 0.2670 - val_loss: 0.2542 - learning_rate: 0.0010\n",
      "Epoch 84/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - loss: 0.2658\n",
      "Epoch 84: val_loss improved from 0.25239 to 0.24666, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 592ms/step - loss: 0.2655 - val_loss: 0.2467 - learning_rate: 0.0010\n",
      "Epoch 85/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - loss: 0.2623\n",
      "Epoch 85: val_loss did not improve from 0.24666\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 574ms/step - loss: 0.2624 - val_loss: 0.2508 - learning_rate: 0.0010\n",
      "Epoch 86/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - loss: 0.2605\n",
      "Epoch 86: val_loss did not improve from 0.24666\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 589ms/step - loss: 0.2605 - val_loss: 0.2477 - learning_rate: 0.0010\n",
      "Epoch 87/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525ms/step - loss: 0.2602\n",
      "Epoch 87: val_loss improved from 0.24666 to 0.24528, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 676ms/step - loss: 0.2602 - val_loss: 0.2453 - learning_rate: 0.0010\n",
      "Epoch 88/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511ms/step - loss: 0.2573\n",
      "Epoch 88: val_loss improved from 0.24528 to 0.24215, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 668ms/step - loss: 0.2573 - val_loss: 0.2421 - learning_rate: 0.0010\n",
      "Epoch 89/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511ms/step - loss: 0.2557\n",
      "Epoch 89: val_loss did not improve from 0.24215\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 596ms/step - loss: 0.2559 - val_loss: 0.2442 - learning_rate: 0.0010\n",
      "Epoch 90/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - loss: 0.2550\n",
      "Epoch 90: val_loss improved from 0.24215 to 0.23999, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 640ms/step - loss: 0.2551 - val_loss: 0.2400 - learning_rate: 0.0010\n",
      "Epoch 91/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - loss: 0.2528\n",
      "Epoch 91: val_loss improved from 0.23999 to 0.23830, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 638ms/step - loss: 0.2530 - val_loss: 0.2383 - learning_rate: 0.0010\n",
      "Epoch 92/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step - loss: 0.2528\n",
      "Epoch 92: val_loss improved from 0.23830 to 0.23689, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 600ms/step - loss: 0.2526 - val_loss: 0.2369 - learning_rate: 0.0010\n",
      "Epoch 93/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - loss: 0.2493\n",
      "Epoch 93: val_loss improved from 0.23689 to 0.23488, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 610ms/step - loss: 0.2494 - val_loss: 0.2349 - learning_rate: 0.0010\n",
      "Epoch 94/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - loss: 0.2475\n",
      "Epoch 94: val_loss improved from 0.23488 to 0.23444, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 602ms/step - loss: 0.2476 - val_loss: 0.2344 - learning_rate: 0.0010\n",
      "Epoch 95/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - loss: 0.2479\n",
      "Epoch 95: val_loss improved from 0.23444 to 0.23431, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 719ms/step - loss: 0.2477 - val_loss: 0.2343 - learning_rate: 0.0010\n",
      "Epoch 96/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - loss: 0.2444\n",
      "Epoch 96: val_loss improved from 0.23431 to 0.23258, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 640ms/step - loss: 0.2444 - val_loss: 0.2326 - learning_rate: 0.0010\n",
      "Epoch 97/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - loss: 0.2442\n",
      "Epoch 97: val_loss improved from 0.23258 to 0.22868, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 718ms/step - loss: 0.2439 - val_loss: 0.2287 - learning_rate: 0.0010\n",
      "Epoch 98/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - loss: 0.2447\n",
      "Epoch 98: val_loss did not improve from 0.22868\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 540ms/step - loss: 0.2443 - val_loss: 0.2295 - learning_rate: 0.0010\n",
      "Epoch 99/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527ms/step - loss: 0.2417\n",
      "Epoch 99: val_loss improved from 0.22868 to 0.22752, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 671ms/step - loss: 0.2415 - val_loss: 0.2275 - learning_rate: 0.0010\n",
      "Epoch 100/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - loss: 0.2389\n",
      "Epoch 100: val_loss improved from 0.22752 to 0.22582, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 559ms/step - loss: 0.2391 - val_loss: 0.2258 - learning_rate: 0.0010\n",
      "Epoch 101/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - loss: 0.2380\n",
      "Epoch 101: val_loss improved from 0.22582 to 0.22455, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 540ms/step - loss: 0.2379 - val_loss: 0.2246 - learning_rate: 0.0010\n",
      "Epoch 102/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - loss: 0.2369\n",
      "Epoch 102: val_loss did not improve from 0.22455\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 567ms/step - loss: 0.2368 - val_loss: 0.2248 - learning_rate: 0.0010\n",
      "Epoch 103/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - loss: 0.2356\n",
      "Epoch 103: val_loss did not improve from 0.22455\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 585ms/step - loss: 0.2355 - val_loss: 0.2249 - learning_rate: 0.0010\n",
      "Epoch 104/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522ms/step - loss: 0.2336\n",
      "Epoch 104: val_loss improved from 0.22455 to 0.21989, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 659ms/step - loss: 0.2334 - val_loss: 0.2199 - learning_rate: 0.0010\n",
      "Epoch 105/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548ms/step - loss: 0.2317\n",
      "Epoch 105: val_loss did not improve from 0.21989\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 638ms/step - loss: 0.2318 - val_loss: 0.2241 - learning_rate: 0.0010\n",
      "Epoch 106/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - loss: 0.2309\n",
      "Epoch 106: val_loss improved from 0.21989 to 0.21497, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 651ms/step - loss: 0.2311 - val_loss: 0.2150 - learning_rate: 0.0010\n",
      "Epoch 107/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - loss: 0.2290\n",
      "Epoch 107: val_loss improved from 0.21497 to 0.21464, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 595ms/step - loss: 0.2291 - val_loss: 0.2146 - learning_rate: 0.0010\n",
      "Epoch 108/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520ms/step - loss: 0.2290\n",
      "Epoch 108: val_loss did not improve from 0.21464\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 599ms/step - loss: 0.2287 - val_loss: 0.2214 - learning_rate: 0.0010\n",
      "Epoch 109/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - loss: 0.2272\n",
      "Epoch 109: val_loss improved from 0.21464 to 0.20977, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 674ms/step - loss: 0.2272 - val_loss: 0.2098 - learning_rate: 0.0010\n",
      "Epoch 110/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527ms/step - loss: 0.2268\n",
      "Epoch 110: val_loss did not improve from 0.20977\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 610ms/step - loss: 0.2267 - val_loss: 0.2166 - learning_rate: 0.0010\n",
      "Epoch 111/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539ms/step - loss: 0.2244\n",
      "Epoch 111: val_loss did not improve from 0.20977\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 632ms/step - loss: 0.2245 - val_loss: 0.2165 - learning_rate: 0.0010\n",
      "Epoch 112/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - loss: 0.2232\n",
      "Epoch 112: val_loss improved from 0.20977 to 0.20908, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 615ms/step - loss: 0.2231 - val_loss: 0.2091 - learning_rate: 0.0010\n",
      "Epoch 113/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524ms/step - loss: 0.2222\n",
      "Epoch 113: val_loss improved from 0.20908 to 0.20843, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 683ms/step - loss: 0.2221 - val_loss: 0.2084 - learning_rate: 0.0010\n",
      "Epoch 114/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - loss: 0.2199\n",
      "Epoch 114: val_loss did not improve from 0.20843\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 575ms/step - loss: 0.2200 - val_loss: 0.2121 - learning_rate: 0.0010\n",
      "Epoch 115/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527ms/step - loss: 0.2201\n",
      "Epoch 115: val_loss improved from 0.20843 to 0.20496, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 673ms/step - loss: 0.2199 - val_loss: 0.2050 - learning_rate: 0.0010\n",
      "Epoch 116/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - loss: 0.2171\n",
      "Epoch 116: val_loss improved from 0.20496 to 0.20473, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 657ms/step - loss: 0.2173 - val_loss: 0.2047 - learning_rate: 0.0010\n",
      "Epoch 117/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559ms/step - loss: 0.2173\n",
      "Epoch 117: val_loss improved from 0.20473 to 0.20398, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716ms/step - loss: 0.2172 - val_loss: 0.2040 - learning_rate: 0.0010\n",
      "Epoch 118/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - loss: 0.2141\n",
      "Epoch 118: val_loss improved from 0.20398 to 0.20186, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 642ms/step - loss: 0.2142 - val_loss: 0.2019 - learning_rate: 0.0010\n",
      "Epoch 119/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - loss: 0.2132\n",
      "Epoch 119: val_loss improved from 0.20186 to 0.20053, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 720ms/step - loss: 0.2131 - val_loss: 0.2005 - learning_rate: 0.0010\n",
      "Epoch 120/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - loss: 0.2114\n",
      "Epoch 120: val_loss did not improve from 0.20053\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 574ms/step - loss: 0.2115 - val_loss: 0.2015 - learning_rate: 0.0010\n",
      "Epoch 121/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - loss: 0.2109\n",
      "Epoch 121: val_loss improved from 0.20053 to 0.19897, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 651ms/step - loss: 0.2108 - val_loss: 0.1990 - learning_rate: 0.0010\n",
      "Epoch 122/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512ms/step - loss: 0.2102\n",
      "Epoch 122: val_loss improved from 0.19897 to 0.19745, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 663ms/step - loss: 0.2100 - val_loss: 0.1974 - learning_rate: 0.0010\n",
      "Epoch 123/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - loss: 0.2086\n",
      "Epoch 123: val_loss did not improve from 0.19745\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 563ms/step - loss: 0.2087 - val_loss: 0.1979 - learning_rate: 0.0010\n",
      "Epoch 124/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - loss: 0.2090\n",
      "Epoch 124: val_loss improved from 0.19745 to 0.19593, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 572ms/step - loss: 0.2088 - val_loss: 0.1959 - learning_rate: 0.0010\n",
      "Epoch 125/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - loss: 0.2065\n",
      "Epoch 125: val_loss did not improve from 0.19593\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 521ms/step - loss: 0.2067 - val_loss: 0.1963 - learning_rate: 0.0010\n",
      "Epoch 126/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - loss: 0.2043\n",
      "Epoch 126: val_loss improved from 0.19593 to 0.19362, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 628ms/step - loss: 0.2044 - val_loss: 0.1936 - learning_rate: 0.0010\n",
      "Epoch 127/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - loss: 0.2042\n",
      "Epoch 127: val_loss improved from 0.19362 to 0.19319, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 611ms/step - loss: 0.2042 - val_loss: 0.1932 - learning_rate: 0.0010\n",
      "Epoch 128/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - loss: 0.2024\n",
      "Epoch 128: val_loss did not improve from 0.19319\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 577ms/step - loss: 0.2024 - val_loss: 0.1952 - learning_rate: 0.0010\n",
      "Epoch 129/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - loss: 0.2018\n",
      "Epoch 129: val_loss improved from 0.19319 to 0.19081, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 651ms/step - loss: 0.2017 - val_loss: 0.1908 - learning_rate: 0.0010\n",
      "Epoch 130/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - loss: 0.1998\n",
      "Epoch 130: val_loss improved from 0.19081 to 0.18806, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 612ms/step - loss: 0.1998 - val_loss: 0.1881 - learning_rate: 0.0010\n",
      "Epoch 131/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - loss: 0.1999\n",
      "Epoch 131: val_loss improved from 0.18806 to 0.18635, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 621ms/step - loss: 0.1997 - val_loss: 0.1864 - learning_rate: 0.0010\n",
      "Epoch 132/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step - loss: 0.1983\n",
      "Epoch 132: val_loss did not improve from 0.18635\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 598ms/step - loss: 0.1982 - val_loss: 0.1867 - learning_rate: 0.0010\n",
      "Epoch 133/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - loss: 0.1968\n",
      "Epoch 133: val_loss improved from 0.18635 to 0.18399, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 602ms/step - loss: 0.1967 - val_loss: 0.1840 - learning_rate: 0.0010\n",
      "Epoch 134/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510ms/step - loss: 0.1946\n",
      "Epoch 134: val_loss did not improve from 0.18399\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 603ms/step - loss: 0.1947 - val_loss: 0.1860 - learning_rate: 0.0010\n",
      "Epoch 135/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - loss: 0.1936\n",
      "Epoch 135: val_loss improved from 0.18399 to 0.18384, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 630ms/step - loss: 0.1937 - val_loss: 0.1838 - learning_rate: 0.0010\n",
      "Epoch 136/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - loss: 0.1933\n",
      "Epoch 136: val_loss did not improve from 0.18384\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 587ms/step - loss: 0.1932 - val_loss: 0.1842 - learning_rate: 0.0010\n",
      "Epoch 137/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - loss: 0.1907\n",
      "Epoch 137: val_loss improved from 0.18384 to 0.18114, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 663ms/step - loss: 0.1908 - val_loss: 0.1811 - learning_rate: 0.0010\n",
      "Epoch 138/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540ms/step - loss: 0.1898\n",
      "Epoch 138: val_loss improved from 0.18114 to 0.18039, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 672ms/step - loss: 0.1899 - val_loss: 0.1804 - learning_rate: 0.0010\n",
      "Epoch 139/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - loss: 0.1897\n",
      "Epoch 139: val_loss did not improve from 0.18039\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 589ms/step - loss: 0.1896 - val_loss: 0.1821 - learning_rate: 0.0010\n",
      "Epoch 140/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511ms/step - loss: 0.1880\n",
      "Epoch 140: val_loss improved from 0.18039 to 0.17886, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 635ms/step - loss: 0.1882 - val_loss: 0.1789 - learning_rate: 0.0010\n",
      "Epoch 141/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - loss: 0.1882\n",
      "Epoch 141: val_loss improved from 0.17886 to 0.17875, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 496ms/step - loss: 0.1882 - val_loss: 0.1788 - learning_rate: 0.0010\n",
      "Epoch 142/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - loss: 0.1854\n",
      "Epoch 142: val_loss improved from 0.17875 to 0.17841, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 623ms/step - loss: 0.1855 - val_loss: 0.1784 - learning_rate: 0.0010\n",
      "Epoch 143/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - loss: 0.1844\n",
      "Epoch 143: val_loss improved from 0.17841 to 0.17424, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 633ms/step - loss: 0.1845 - val_loss: 0.1742 - learning_rate: 0.0010\n",
      "Epoch 144/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518ms/step - loss: 0.1852\n",
      "Epoch 144: val_loss did not improve from 0.17424\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 607ms/step - loss: 0.1850 - val_loss: 0.1749 - learning_rate: 0.0010\n",
      "Epoch 145/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553ms/step - loss: 0.1827\n",
      "Epoch 145: val_loss did not improve from 0.17424\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 643ms/step - loss: 0.1826 - val_loss: 0.1748 - learning_rate: 0.0010\n",
      "Epoch 146/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552ms/step - loss: 0.1818\n",
      "Epoch 146: val_loss improved from 0.17424 to 0.16992, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 679ms/step - loss: 0.1817 - val_loss: 0.1699 - learning_rate: 0.0010\n",
      "Epoch 147/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - loss: 0.1802\n",
      "Epoch 147: val_loss did not improve from 0.16992\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 544ms/step - loss: 0.1804 - val_loss: 0.1712 - learning_rate: 0.0010\n",
      "Epoch 148/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - loss: 0.1809\n",
      "Epoch 148: val_loss improved from 0.16992 to 0.16988, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 599ms/step - loss: 0.1808 - val_loss: 0.1699 - learning_rate: 0.0010\n",
      "Epoch 149/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.1777\n",
      "Epoch 149: val_loss improved from 0.16988 to 0.16849, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 476ms/step - loss: 0.1779 - val_loss: 0.1685 - learning_rate: 0.0010\n",
      "Epoch 150/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - loss: 0.1778\n",
      "Epoch 150: val_loss improved from 0.16849 to 0.16661, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 473ms/step - loss: 0.1778 - val_loss: 0.1666 - learning_rate: 0.0010\n",
      "Epoch 151/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.1780\n",
      "Epoch 151: val_loss did not improve from 0.16661\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - loss: 0.1779 - val_loss: 0.1686 - learning_rate: 0.0010\n",
      "Epoch 152/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 0.1758\n",
      "Epoch 152: val_loss did not improve from 0.16661\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - loss: 0.1758 - val_loss: 0.1669 - learning_rate: 0.0010\n",
      "Epoch 153/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - loss: 0.1742\n",
      "Epoch 153: val_loss improved from 0.16661 to 0.16586, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487ms/step - loss: 0.1743 - val_loss: 0.1659 - learning_rate: 0.0010\n",
      "Epoch 154/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - loss: 0.1729\n",
      "Epoch 154: val_loss improved from 0.16586 to 0.16375, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490ms/step - loss: 0.1729 - val_loss: 0.1638 - learning_rate: 0.0010\n",
      "Epoch 155/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - loss: 0.1739\n",
      "Epoch 155: val_loss did not improve from 0.16375\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step - loss: 0.1736 - val_loss: 0.1645 - learning_rate: 0.0010\n",
      "Epoch 156/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - loss: 0.1732\n",
      "Epoch 156: val_loss improved from 0.16375 to 0.16170, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step - loss: 0.1730 - val_loss: 0.1617 - learning_rate: 0.0010\n",
      "Epoch 157/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - loss: 0.1699\n",
      "Epoch 157: val_loss improved from 0.16170 to 0.16114, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498ms/step - loss: 0.1701 - val_loss: 0.1611 - learning_rate: 0.0010\n",
      "Epoch 158/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - loss: 0.1712\n",
      "Epoch 158: val_loss did not improve from 0.16114\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452ms/step - loss: 0.1713 - val_loss: 0.1631 - learning_rate: 0.0010\n",
      "Epoch 159/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 0.1705\n",
      "Epoch 159: val_loss improved from 0.16114 to 0.15756, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 484ms/step - loss: 0.1704 - val_loss: 0.1576 - learning_rate: 0.0010\n",
      "Epoch 160/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - loss: 0.1681\n",
      "Epoch 160: val_loss did not improve from 0.15756\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 465ms/step - loss: 0.1681 - val_loss: 0.1635 - learning_rate: 0.0010\n",
      "Epoch 161/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - loss: 0.1675\n",
      "Epoch 161: val_loss improved from 0.15756 to 0.15628, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486ms/step - loss: 0.1673 - val_loss: 0.1563 - learning_rate: 0.0010\n",
      "Epoch 162/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - loss: 0.1656\n",
      "Epoch 162: val_loss did not improve from 0.15628\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step - loss: 0.1657 - val_loss: 0.1594 - learning_rate: 0.0010\n",
      "Epoch 163/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 0.1664\n",
      "Epoch 163: val_loss did not improve from 0.15628\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step - loss: 0.1663 - val_loss: 0.1563 - learning_rate: 0.0010\n",
      "Epoch 164/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - loss: 0.1654\n",
      "Epoch 164: val_loss did not improve from 0.15628\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425ms/step - loss: 0.1654 - val_loss: 0.1583 - learning_rate: 0.0010\n",
      "Epoch 165/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.1646\n",
      "Epoch 165: val_loss improved from 0.15628 to 0.15275, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 485ms/step - loss: 0.1645 - val_loss: 0.1527 - learning_rate: 0.0010\n",
      "Epoch 166/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.1631\n",
      "Epoch 166: val_loss did not improve from 0.15275\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step - loss: 0.1632 - val_loss: 0.1551 - learning_rate: 0.0010\n",
      "Epoch 167/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - loss: 0.1634\n",
      "Epoch 167: val_loss improved from 0.15275 to 0.15258, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487ms/step - loss: 0.1633 - val_loss: 0.1526 - learning_rate: 0.0010\n",
      "Epoch 168/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: 0.1632\n",
      "Epoch 168: val_loss improved from 0.15258 to 0.15237, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 475ms/step - loss: 0.1629 - val_loss: 0.1524 - learning_rate: 0.0010\n",
      "Epoch 169/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - loss: 0.1643\n",
      "Epoch 169: val_loss did not improve from 0.15237\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450ms/step - loss: 0.1641 - val_loss: 0.1547 - learning_rate: 0.0010\n",
      "Epoch 170/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - loss: 0.1597\n",
      "Epoch 170: val_loss improved from 0.15237 to 0.14628, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 479ms/step - loss: 0.1599 - val_loss: 0.1463 - learning_rate: 0.0010\n",
      "Epoch 171/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 0.1597\n",
      "Epoch 171: val_loss did not improve from 0.14628\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - loss: 0.1596 - val_loss: 0.1565 - learning_rate: 0.0010\n",
      "Epoch 172/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - loss: 0.1576\n",
      "Epoch 172: val_loss improved from 0.14628 to 0.14608, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492ms/step - loss: 0.1576 - val_loss: 0.1461 - learning_rate: 0.0010\n",
      "Epoch 173/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - loss: 0.1587\n",
      "Epoch 173: val_loss did not improve from 0.14608\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449ms/step - loss: 0.1585 - val_loss: 0.1471 - learning_rate: 0.0010\n",
      "Epoch 174/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 0.1566\n",
      "Epoch 174: val_loss did not improve from 0.14608\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step - loss: 0.1565 - val_loss: 0.1488 - learning_rate: 0.0010\n",
      "Epoch 175/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - loss: 0.1546\n",
      "Epoch 175: val_loss improved from 0.14608 to 0.14374, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step - loss: 0.1547 - val_loss: 0.1437 - learning_rate: 0.0010\n",
      "Epoch 176/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - loss: 0.1538\n",
      "Epoch 176: val_loss did not improve from 0.14374\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 459ms/step - loss: 0.1540 - val_loss: 0.1515 - learning_rate: 0.0010\n",
      "Epoch 177/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - loss: 0.1530\n",
      "Epoch 177: val_loss improved from 0.14374 to 0.14205, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515ms/step - loss: 0.1532 - val_loss: 0.1421 - learning_rate: 0.0010\n",
      "Epoch 178/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - loss: 0.1517\n",
      "Epoch 178: val_loss did not improve from 0.14205\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449ms/step - loss: 0.1518 - val_loss: 0.1482 - learning_rate: 0.0010\n",
      "Epoch 179/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - loss: 0.1530\n",
      "Epoch 179: val_loss improved from 0.14205 to 0.14126, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step - loss: 0.1529 - val_loss: 0.1413 - learning_rate: 0.0010\n",
      "Epoch 180/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - loss: 0.1512\n",
      "Epoch 180: val_loss improved from 0.14126 to 0.14074, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498ms/step - loss: 0.1513 - val_loss: 0.1407 - learning_rate: 0.0010\n",
      "Epoch 181/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - loss: 0.1497\n",
      "Epoch 181: val_loss did not improve from 0.14074\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445ms/step - loss: 0.1498 - val_loss: 0.1445 - learning_rate: 0.0010\n",
      "Epoch 182/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - loss: 0.1495\n",
      "Epoch 182: val_loss improved from 0.14074 to 0.13921, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494ms/step - loss: 0.1496 - val_loss: 0.1392 - learning_rate: 0.0010\n",
      "Epoch 183/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - loss: 0.1487\n",
      "Epoch 183: val_loss did not improve from 0.13921\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - loss: 0.1489 - val_loss: 0.1418 - learning_rate: 0.0010\n",
      "Epoch 184/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - loss: 0.1485\n",
      "Epoch 184: val_loss did not improve from 0.13921\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462ms/step - loss: 0.1485 - val_loss: 0.1404 - learning_rate: 0.0010\n",
      "Epoch 185/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - loss: 0.1477\n",
      "Epoch 185: val_loss improved from 0.13921 to 0.13894, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489ms/step - loss: 0.1477 - val_loss: 0.1389 - learning_rate: 0.0010\n",
      "Epoch 186/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - loss: 0.1472\n",
      "Epoch 186: val_loss improved from 0.13894 to 0.13770, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488ms/step - loss: 0.1472 - val_loss: 0.1377 - learning_rate: 0.0010\n",
      "Epoch 187/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - loss: 0.1482\n",
      "Epoch 187: val_loss did not improve from 0.13770\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451ms/step - loss: 0.1481 - val_loss: 0.1381 - learning_rate: 0.0010\n",
      "Epoch 188/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - loss: 0.1471\n",
      "Epoch 188: val_loss improved from 0.13770 to 0.13734, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 470ms/step - loss: 0.1469 - val_loss: 0.1373 - learning_rate: 0.0010\n",
      "Epoch 189/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - loss: 0.1444\n",
      "Epoch 189: val_loss improved from 0.13734 to 0.13613, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493ms/step - loss: 0.1444 - val_loss: 0.1361 - learning_rate: 0.0010\n",
      "Epoch 190/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - loss: 0.1433\n",
      "Epoch 190: val_loss improved from 0.13613 to 0.13473, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step - loss: 0.1433 - val_loss: 0.1347 - learning_rate: 0.0010\n",
      "Epoch 191/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - loss: 0.1433\n",
      "Epoch 191: val_loss improved from 0.13473 to 0.13428, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494ms/step - loss: 0.1432 - val_loss: 0.1343 - learning_rate: 0.0010\n",
      "Epoch 192/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - loss: 0.1429\n",
      "Epoch 192: val_loss did not improve from 0.13428\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step - loss: 0.1426 - val_loss: 0.1344 - learning_rate: 0.0010\n",
      "Epoch 193/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - loss: 0.1408\n",
      "Epoch 193: val_loss improved from 0.13428 to 0.13346, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480ms/step - loss: 0.1409 - val_loss: 0.1335 - learning_rate: 0.0010\n",
      "Epoch 194/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - loss: 0.1406\n",
      "Epoch 194: val_loss improved from 0.13346 to 0.13169, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480ms/step - loss: 0.1407 - val_loss: 0.1317 - learning_rate: 0.0010\n",
      "Epoch 195/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: 0.1399\n",
      "Epoch 195: val_loss did not improve from 0.13169\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step - loss: 0.1398 - val_loss: 0.1340 - learning_rate: 0.0010\n",
      "Epoch 196/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - loss: 0.1395\n",
      "Epoch 196: val_loss did not improve from 0.13169\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step - loss: 0.1394 - val_loss: 0.1324 - learning_rate: 0.0010\n",
      "Epoch 197/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - loss: 0.1384\n",
      "Epoch 197: val_loss improved from 0.13169 to 0.12870, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487ms/step - loss: 0.1384 - val_loss: 0.1287 - learning_rate: 0.0010\n",
      "Epoch 198/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - loss: 0.1377\n",
      "Epoch 198: val_loss did not improve from 0.12870\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448ms/step - loss: 0.1378 - val_loss: 0.1333 - learning_rate: 0.0010\n",
      "Epoch 199/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - loss: 0.1373\n",
      "Epoch 199: val_loss improved from 0.12870 to 0.12812, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 485ms/step - loss: 0.1372 - val_loss: 0.1281 - learning_rate: 0.0010\n",
      "Epoch 200/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - loss: 0.1376\n",
      "Epoch 200: val_loss did not improve from 0.12812\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444ms/step - loss: 0.1376 - val_loss: 0.1312 - learning_rate: 0.0010\n",
      "Epoch 201/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - loss: 0.1362\n",
      "Epoch 201: val_loss did not improve from 0.12812\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step - loss: 0.1363 - val_loss: 0.1285 - learning_rate: 0.0010\n",
      "Epoch 202/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 0.1371\n",
      "Epoch 202: val_loss improved from 0.12812 to 0.12729, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488ms/step - loss: 0.1370 - val_loss: 0.1273 - learning_rate: 0.0010\n",
      "Epoch 203/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - loss: 0.1359\n",
      "Epoch 203: val_loss did not improve from 0.12729\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418ms/step - loss: 0.1357 - val_loss: 0.1299 - learning_rate: 0.0010\n",
      "Epoch 204/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - loss: 0.1349\n",
      "Epoch 204: val_loss improved from 0.12729 to 0.12552, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464ms/step - loss: 0.1348 - val_loss: 0.1255 - learning_rate: 0.0010\n",
      "Epoch 205/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - loss: 0.1353\n",
      "Epoch 205: val_loss improved from 0.12552 to 0.12397, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 470ms/step - loss: 0.1352 - val_loss: 0.1240 - learning_rate: 0.0010\n",
      "Epoch 206/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 0.1335\n",
      "Epoch 206: val_loss did not improve from 0.12397\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434ms/step - loss: 0.1337 - val_loss: 0.1275 - learning_rate: 0.0010\n",
      "Epoch 207/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - loss: 0.1336\n",
      "Epoch 207: val_loss did not improve from 0.12397\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step - loss: 0.1335 - val_loss: 0.1248 - learning_rate: 0.0010\n",
      "Epoch 208/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - loss: 0.1319\n",
      "Epoch 208: val_loss did not improve from 0.12397\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step - loss: 0.1319 - val_loss: 0.1272 - learning_rate: 0.0010\n",
      "Epoch 209/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: 0.1322\n",
      "Epoch 209: val_loss improved from 0.12397 to 0.12274, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 479ms/step - loss: 0.1324 - val_loss: 0.1227 - learning_rate: 0.0010\n",
      "Epoch 210/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - loss: 0.1310\n",
      "Epoch 210: val_loss did not improve from 0.12274\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step - loss: 0.1310 - val_loss: 0.1232 - learning_rate: 0.0010\n",
      "Epoch 211/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - loss: 0.1333\n",
      "Epoch 211: val_loss did not improve from 0.12274\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434ms/step - loss: 0.1330 - val_loss: 0.1250 - learning_rate: 0.0010\n",
      "Epoch 212/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 0.1309\n",
      "Epoch 212: val_loss improved from 0.12274 to 0.12169, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 477ms/step - loss: 0.1308 - val_loss: 0.1217 - learning_rate: 0.0010\n",
      "Epoch 213/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - loss: 0.1286\n",
      "Epoch 213: val_loss improved from 0.12169 to 0.12147, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 465ms/step - loss: 0.1287 - val_loss: 0.1215 - learning_rate: 0.0010\n",
      "Epoch 214/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - loss: 0.1274\n",
      "Epoch 214: val_loss did not improve from 0.12147\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step - loss: 0.1277 - val_loss: 0.1222 - learning_rate: 0.0010\n",
      "Epoch 215/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - loss: 0.1274\n",
      "Epoch 215: val_loss improved from 0.12147 to 0.11882, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492ms/step - loss: 0.1275 - val_loss: 0.1188 - learning_rate: 0.0010\n",
      "Epoch 216/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 0.1281\n",
      "Epoch 216: val_loss did not improve from 0.11882\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - loss: 0.1281 - val_loss: 0.1204 - learning_rate: 0.0010\n",
      "Epoch 217/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - loss: 0.1274\n",
      "Epoch 217: val_loss did not improve from 0.11882\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419ms/step - loss: 0.1273 - val_loss: 0.1207 - learning_rate: 0.0010\n",
      "Epoch 218/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.1264\n",
      "Epoch 218: val_loss improved from 0.11882 to 0.11651, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 479ms/step - loss: 0.1265 - val_loss: 0.1165 - learning_rate: 0.0010\n",
      "Epoch 219/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - loss: 0.1254\n",
      "Epoch 219: val_loss did not improve from 0.11651\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417ms/step - loss: 0.1254 - val_loss: 0.1220 - learning_rate: 0.0010\n",
      "Epoch 220/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 0.1252\n",
      "Epoch 220: val_loss did not improve from 0.11651\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - loss: 0.1251 - val_loss: 0.1197 - learning_rate: 0.0010\n",
      "Epoch 221/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - loss: 0.1241\n",
      "Epoch 221: val_loss improved from 0.11651 to 0.11530, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step - loss: 0.1242 - val_loss: 0.1153 - learning_rate: 0.0010\n",
      "Epoch 222/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - loss: 0.1236\n",
      "Epoch 222: val_loss did not improve from 0.11530\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step - loss: 0.1236 - val_loss: 0.1211 - learning_rate: 0.0010\n",
      "Epoch 223/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - loss: 0.1227\n",
      "Epoch 223: val_loss improved from 0.11530 to 0.11486, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461ms/step - loss: 0.1227 - val_loss: 0.1149 - learning_rate: 0.0010\n",
      "Epoch 224/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - loss: 0.1222\n",
      "Epoch 224: val_loss did not improve from 0.11486\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step - loss: 0.1224 - val_loss: 0.1174 - learning_rate: 0.0010\n",
      "Epoch 225/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - loss: 0.1214\n",
      "Epoch 225: val_loss improved from 0.11486 to 0.11451, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 479ms/step - loss: 0.1216 - val_loss: 0.1145 - learning_rate: 0.0010\n",
      "Epoch 226/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 0.1214\n",
      "Epoch 226: val_loss did not improve from 0.11451\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - loss: 0.1214 - val_loss: 0.1149 - learning_rate: 0.0010\n",
      "Epoch 227/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.1205\n",
      "Epoch 227: val_loss improved from 0.11451 to 0.11264, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 482ms/step - loss: 0.1206 - val_loss: 0.1126 - learning_rate: 0.0010\n",
      "Epoch 228/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - loss: 0.1195\n",
      "Epoch 228: val_loss did not improve from 0.11264\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420ms/step - loss: 0.1195 - val_loss: 0.1133 - learning_rate: 0.0010\n",
      "Epoch 229/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - loss: 0.1191\n",
      "Epoch 229: val_loss did not improve from 0.11264\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step - loss: 0.1192 - val_loss: 0.1155 - learning_rate: 0.0010\n",
      "Epoch 230/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - loss: 0.1191\n",
      "Epoch 230: val_loss improved from 0.11264 to 0.11028, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 466ms/step - loss: 0.1189 - val_loss: 0.1103 - learning_rate: 0.0010\n",
      "Epoch 231/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - loss: 0.1190\n",
      "Epoch 231: val_loss did not improve from 0.11028\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426ms/step - loss: 0.1190 - val_loss: 0.1144 - learning_rate: 0.0010\n",
      "Epoch 232/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - loss: 0.1192\n",
      "Epoch 232: val_loss did not improve from 0.11028\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452ms/step - loss: 0.1190 - val_loss: 0.1110 - learning_rate: 0.0010\n",
      "Epoch 233/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.1178\n",
      "Epoch 233: val_loss did not improve from 0.11028\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step - loss: 0.1178 - val_loss: 0.1128 - learning_rate: 0.0010\n",
      "Epoch 234/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - loss: 0.1159\n",
      "Epoch 234: val_loss did not improve from 0.11028\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step - loss: 0.1160 - val_loss: 0.1108 - learning_rate: 0.0010\n",
      "Epoch 235/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - loss: 0.1161\n",
      "Epoch 235: val_loss did not improve from 0.11028\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423ms/step - loss: 0.1160 - val_loss: 0.1113 - learning_rate: 0.0010\n",
      "Epoch 236/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - loss: 0.1157\n",
      "Epoch 236: val_loss did not improve from 0.11028\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - loss: 0.1157 - val_loss: 0.1112 - learning_rate: 0.0010\n",
      "Epoch 237/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - loss: 0.1149\n",
      "Epoch 237: val_loss improved from 0.11028 to 0.10756, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 472ms/step - loss: 0.1149 - val_loss: 0.1076 - learning_rate: 0.0010\n",
      "Epoch 238/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - loss: 0.1150\n",
      "Epoch 238: val_loss did not improve from 0.10756\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453ms/step - loss: 0.1149 - val_loss: 0.1082 - learning_rate: 0.0010\n",
      "Epoch 239/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - loss: 0.1135\n",
      "Epoch 239: val_loss improved from 0.10756 to 0.10566, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498ms/step - loss: 0.1134 - val_loss: 0.1057 - learning_rate: 0.0010\n",
      "Epoch 240/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.1131\n",
      "Epoch 240: val_loss did not improve from 0.10566\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - loss: 0.1131 - val_loss: 0.1094 - learning_rate: 0.0010\n",
      "Epoch 241/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 0.1137\n",
      "Epoch 241: val_loss did not improve from 0.10566\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - loss: 0.1136 - val_loss: 0.1059 - learning_rate: 0.0010\n",
      "Epoch 242/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - loss: 0.1125\n",
      "Epoch 242: val_loss did not improve from 0.10566\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453ms/step - loss: 0.1125 - val_loss: 0.1078 - learning_rate: 0.0010\n",
      "Epoch 243/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.1130\n",
      "Epoch 243: val_loss did not improve from 0.10566\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step - loss: 0.1129 - val_loss: 0.1061 - learning_rate: 0.0010\n",
      "Epoch 244/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - loss: 0.1119\n",
      "Epoch 244: val_loss did not improve from 0.10566\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450ms/step - loss: 0.1118 - val_loss: 0.1100 - learning_rate: 0.0010\n",
      "Epoch 245/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - loss: 0.1105\n",
      "Epoch 245: val_loss improved from 0.10566 to 0.10211, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490ms/step - loss: 0.1105 - val_loss: 0.1021 - learning_rate: 0.0010\n",
      "Epoch 246/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - loss: 0.1092\n",
      "Epoch 246: val_loss did not improve from 0.10211\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451ms/step - loss: 0.1092 - val_loss: 0.1089 - learning_rate: 0.0010\n",
      "Epoch 247/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - loss: 0.1099\n",
      "Epoch 247: val_loss improved from 0.10211 to 0.10148, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 485ms/step - loss: 0.1099 - val_loss: 0.1015 - learning_rate: 0.0010\n",
      "Epoch 248/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 0.1090\n",
      "Epoch 248: val_loss did not improve from 0.10148\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444ms/step - loss: 0.1091 - val_loss: 0.1052 - learning_rate: 0.0010\n",
      "Epoch 249/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - loss: 0.1093\n",
      "Epoch 249: val_loss did not improve from 0.10148\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444ms/step - loss: 0.1094 - val_loss: 0.1029 - learning_rate: 0.0010\n",
      "Epoch 250/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - loss: 0.1066\n",
      "Epoch 250: val_loss did not improve from 0.10148\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step - loss: 0.1067 - val_loss: 0.1056 - learning_rate: 0.0010\n",
      "Epoch 251/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - loss: 0.1077\n",
      "Epoch 251: val_loss improved from 0.10148 to 0.10024, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 484ms/step - loss: 0.1078 - val_loss: 0.1002 - learning_rate: 0.0010\n",
      "Epoch 252/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - loss: 0.1085\n",
      "Epoch 252: val_loss did not improve from 0.10024\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462ms/step - loss: 0.1083 - val_loss: 0.1040 - learning_rate: 0.0010\n",
      "Epoch 253/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - loss: 0.1085\n",
      "Epoch 253: val_loss did not improve from 0.10024\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456ms/step - loss: 0.1083 - val_loss: 0.1004 - learning_rate: 0.0010\n",
      "Epoch 254/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - loss: 0.1065\n",
      "Epoch 254: val_loss did not improve from 0.10024\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451ms/step - loss: 0.1066 - val_loss: 0.1037 - learning_rate: 0.0010\n",
      "Epoch 255/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.1060\n",
      "Epoch 255: val_loss did not improve from 0.10024\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - loss: 0.1060 - val_loss: 0.1033 - learning_rate: 0.0010\n",
      "Epoch 256/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: 0.1070\n",
      "Epoch 256: val_loss improved from 0.10024 to 0.09903, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 475ms/step - loss: 0.1069 - val_loss: 0.0990 - learning_rate: 0.0010\n",
      "Epoch 257/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - loss: 0.1056\n",
      "Epoch 257: val_loss did not improve from 0.09903\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - loss: 0.1056 - val_loss: 0.1030 - learning_rate: 0.0010\n",
      "Epoch 258/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - loss: 0.1057\n",
      "Epoch 258: val_loss did not improve from 0.09903\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 457ms/step - loss: 0.1056 - val_loss: 0.1001 - learning_rate: 0.0010\n",
      "Epoch 259/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 0.1034\n",
      "Epoch 259: val_loss did not improve from 0.09903\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step - loss: 0.1036 - val_loss: 0.1012 - learning_rate: 0.0010\n",
      "Epoch 260/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - loss: 0.1043\n",
      "Epoch 260: val_loss improved from 0.09903 to 0.09794, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step - loss: 0.1044 - val_loss: 0.0979 - learning_rate: 0.0010\n",
      "Epoch 261/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - loss: 0.1042\n",
      "Epoch 261: val_loss did not improve from 0.09794\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453ms/step - loss: 0.1040 - val_loss: 0.1008 - learning_rate: 0.0010\n",
      "Epoch 262/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - loss: 0.1049\n",
      "Epoch 262: val_loss improved from 0.09794 to 0.09712, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486ms/step - loss: 0.1051 - val_loss: 0.0971 - learning_rate: 0.0010\n",
      "Epoch 263/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - loss: 0.1035\n",
      "Epoch 263: val_loss did not improve from 0.09712\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 469ms/step - loss: 0.1034 - val_loss: 0.0977 - learning_rate: 0.0010\n",
      "Epoch 264/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - loss: 0.1014\n",
      "Epoch 264: val_loss did not improve from 0.09712\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - loss: 0.1016 - val_loss: 0.0972 - learning_rate: 0.0010\n",
      "Epoch 265/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.1033\n",
      "Epoch 265: val_loss improved from 0.09712 to 0.09577, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490ms/step - loss: 0.1032 - val_loss: 0.0958 - learning_rate: 0.0010\n",
      "Epoch 266/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - loss: 0.1017\n",
      "Epoch 266: val_loss did not improve from 0.09577\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step - loss: 0.1017 - val_loss: 0.1005 - learning_rate: 0.0010\n",
      "Epoch 267/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - loss: 0.1011\n",
      "Epoch 267: val_loss did not improve from 0.09577\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - loss: 0.1012 - val_loss: 0.0985 - learning_rate: 0.0010\n",
      "Epoch 268/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - loss: 0.1012\n",
      "Epoch 268: val_loss did not improve from 0.09577\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step - loss: 0.1011 - val_loss: 0.0980 - learning_rate: 0.0010\n",
      "Epoch 269/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.0986\n",
      "Epoch 269: val_loss did not improve from 0.09577\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - loss: 0.0987 - val_loss: 0.0983 - learning_rate: 0.0010\n",
      "Epoch 270/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 0.0997\n",
      "Epoch 270: val_loss improved from 0.09577 to 0.09407, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 485ms/step - loss: 0.0998 - val_loss: 0.0941 - learning_rate: 0.0010\n",
      "Epoch 271/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - loss: 0.0986\n",
      "Epoch 271: val_loss improved from 0.09407 to 0.09375, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 485ms/step - loss: 0.0986 - val_loss: 0.0938 - learning_rate: 0.0010\n",
      "Epoch 272/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - loss: 0.1000\n",
      "Epoch 272: val_loss did not improve from 0.09375\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450ms/step - loss: 0.0998 - val_loss: 0.0945 - learning_rate: 0.0010\n",
      "Epoch 273/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - loss: 0.0990\n",
      "Epoch 273: val_loss did not improve from 0.09375\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453ms/step - loss: 0.0990 - val_loss: 0.0939 - learning_rate: 0.0010\n",
      "Epoch 274/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - loss: 0.0979\n",
      "Epoch 274: val_loss did not improve from 0.09375\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step - loss: 0.0979 - val_loss: 0.0942 - learning_rate: 0.0010\n",
      "Epoch 275/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - loss: 0.0985\n",
      "Epoch 275: val_loss improved from 0.09375 to 0.09366, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 457ms/step - loss: 0.0983 - val_loss: 0.0937 - learning_rate: 0.0010\n",
      "Epoch 276/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.0966\n",
      "Epoch 276: val_loss did not improve from 0.09366\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - loss: 0.0966 - val_loss: 0.0967 - learning_rate: 0.0010\n",
      "Epoch 277/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.0974\n",
      "Epoch 277: val_loss improved from 0.09366 to 0.09269, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 473ms/step - loss: 0.0976 - val_loss: 0.0927 - learning_rate: 0.0010\n",
      "Epoch 278/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - loss: 0.0974\n",
      "Epoch 278: val_loss did not improve from 0.09269\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - loss: 0.0974 - val_loss: 0.0952 - learning_rate: 0.0010\n",
      "Epoch 279/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - loss: 0.0972\n",
      "Epoch 279: val_loss did not improve from 0.09269\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449ms/step - loss: 0.0971 - val_loss: 0.0963 - learning_rate: 0.0010\n",
      "Epoch 280/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - loss: 0.0975\n",
      "Epoch 280: val_loss improved from 0.09269 to 0.09208, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 469ms/step - loss: 0.0975 - val_loss: 0.0921 - learning_rate: 0.0010\n",
      "Epoch 281/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.0965\n",
      "Epoch 281: val_loss improved from 0.09208 to 0.09160, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 478ms/step - loss: 0.0964 - val_loss: 0.0916 - learning_rate: 0.0010\n",
      "Epoch 282/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - loss: 0.0971\n",
      "Epoch 282: val_loss improved from 0.09160 to 0.08883, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 473ms/step - loss: 0.0969 - val_loss: 0.0888 - learning_rate: 0.0010\n",
      "Epoch 283/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.0961\n",
      "Epoch 283: val_loss did not improve from 0.08883\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step - loss: 0.0961 - val_loss: 0.0911 - learning_rate: 0.0010\n",
      "Epoch 284/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - loss: 0.0952\n",
      "Epoch 284: val_loss did not improve from 0.08883\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455ms/step - loss: 0.0951 - val_loss: 0.0926 - learning_rate: 0.0010\n",
      "Epoch 285/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - loss: 0.0939\n",
      "Epoch 285: val_loss did not improve from 0.08883\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450ms/step - loss: 0.0940 - val_loss: 0.0927 - learning_rate: 0.0010\n",
      "Epoch 286/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.0928\n",
      "Epoch 286: val_loss improved from 0.08883 to 0.08686, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 481ms/step - loss: 0.0930 - val_loss: 0.0869 - learning_rate: 0.0010\n",
      "Epoch 287/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - loss: 0.0924\n",
      "Epoch 287: val_loss did not improve from 0.08686\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 491ms/step - loss: 0.0926 - val_loss: 0.0892 - learning_rate: 0.0010\n",
      "Epoch 288/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - loss: 0.0937\n",
      "Epoch 288: val_loss did not improve from 0.08686\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 563ms/step - loss: 0.0937 - val_loss: 0.0945 - learning_rate: 0.0010\n",
      "Epoch 289/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512ms/step - loss: 0.0932\n",
      "Epoch 289: val_loss did not improve from 0.08686\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 589ms/step - loss: 0.0930 - val_loss: 0.0872 - learning_rate: 0.0010\n",
      "Epoch 290/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - loss: 0.0923\n",
      "Epoch 290: val_loss did not improve from 0.08686\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 543ms/step - loss: 0.0922 - val_loss: 0.0887 - learning_rate: 0.0010\n",
      "Epoch 291/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522ms/step - loss: 0.0918\n",
      "Epoch 291: val_loss did not improve from 0.08686\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 605ms/step - loss: 0.0918 - val_loss: 0.0898 - learning_rate: 0.0010\n",
      "Epoch 292/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - loss: 0.0905\n",
      "Epoch 292: val_loss did not improve from 0.08686\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 527ms/step - loss: 0.0906 - val_loss: 0.0880 - learning_rate: 0.0010\n",
      "Epoch 293/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - loss: 0.0917\n",
      "Epoch 293: val_loss improved from 0.08686 to 0.08558, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 636ms/step - loss: 0.0915 - val_loss: 0.0856 - learning_rate: 0.0010\n",
      "Epoch 294/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - loss: 0.0904\n",
      "Epoch 294: val_loss did not improve from 0.08558\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 523ms/step - loss: 0.0904 - val_loss: 0.0889 - learning_rate: 0.0010\n",
      "Epoch 295/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - loss: 0.0897\n",
      "Epoch 295: val_loss improved from 0.08558 to 0.08538, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 681ms/step - loss: 0.0896 - val_loss: 0.0854 - learning_rate: 0.0010\n",
      "Epoch 296/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - loss: 0.0900\n",
      "Epoch 296: val_loss did not improve from 0.08538\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 523ms/step - loss: 0.0899 - val_loss: 0.0876 - learning_rate: 0.0010\n",
      "Epoch 297/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - loss: 0.0893\n",
      "Epoch 297: val_loss improved from 0.08538 to 0.08527, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 647ms/step - loss: 0.0893 - val_loss: 0.0853 - learning_rate: 0.0010\n",
      "Epoch 298/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - loss: 0.0886\n",
      "Epoch 298: val_loss did not improve from 0.08527\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 561ms/step - loss: 0.0887 - val_loss: 0.0898 - learning_rate: 0.0010\n",
      "Epoch 299/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - loss: 0.0891\n",
      "Epoch 299: val_loss improved from 0.08527 to 0.08304, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 630ms/step - loss: 0.0891 - val_loss: 0.0830 - learning_rate: 0.0010\n",
      "Epoch 300/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - loss: 0.0889\n",
      "Epoch 300: val_loss did not improve from 0.08304\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 561ms/step - loss: 0.0888 - val_loss: 0.0846 - learning_rate: 0.0010\n",
      "Epoch 301/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - loss: 0.0872\n",
      "Epoch 301: val_loss did not improve from 0.08304\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 567ms/step - loss: 0.0873 - val_loss: 0.0840 - learning_rate: 0.0010\n",
      "Epoch 302/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516ms/step - loss: 0.0879\n",
      "Epoch 302: val_loss did not improve from 0.08304\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 594ms/step - loss: 0.0877 - val_loss: 0.0853 - learning_rate: 0.0010\n",
      "Epoch 303/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - loss: 0.0876\n",
      "Epoch 303: val_loss did not improve from 0.08304\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 565ms/step - loss: 0.0875 - val_loss: 0.0859 - learning_rate: 0.0010\n",
      "Epoch 304/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - loss: 0.0894\n",
      "Epoch 304: val_loss improved from 0.08304 to 0.08224, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 622ms/step - loss: 0.0891 - val_loss: 0.0822 - learning_rate: 0.0010\n",
      "Epoch 305/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - loss: 0.0873\n",
      "Epoch 305: val_loss improved from 0.08224 to 0.08075, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 591ms/step - loss: 0.0874 - val_loss: 0.0808 - learning_rate: 0.0010\n",
      "Epoch 306/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - loss: 0.0873\n",
      "Epoch 306: val_loss did not improve from 0.08075\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 526ms/step - loss: 0.0871 - val_loss: 0.0891 - learning_rate: 0.0010\n",
      "Epoch 307/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - loss: 0.0869\n",
      "Epoch 307: val_loss improved from 0.08075 to 0.08050, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 662ms/step - loss: 0.0870 - val_loss: 0.0805 - learning_rate: 0.0010\n",
      "Epoch 308/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - loss: 0.0869\n",
      "Epoch 308: val_loss did not improve from 0.08050\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 531ms/step - loss: 0.0869 - val_loss: 0.0819 - learning_rate: 0.0010\n",
      "Epoch 309/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - loss: 0.0854\n",
      "Epoch 309: val_loss did not improve from 0.08050\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461ms/step - loss: 0.0854 - val_loss: 0.0813 - learning_rate: 0.0010\n",
      "Epoch 310/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - loss: 0.0856\n",
      "Epoch 310: val_loss did not improve from 0.08050\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 460ms/step - loss: 0.0855 - val_loss: 0.0857 - learning_rate: 0.0010\n",
      "Epoch 311/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - loss: 0.0846\n",
      "Epoch 311: val_loss did not improve from 0.08050\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 484ms/step - loss: 0.0848 - val_loss: 0.0807 - learning_rate: 0.0010\n",
      "Epoch 312/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: 0.0858\n",
      "Epoch 312: val_loss improved from 0.08050 to 0.07901, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539ms/step - loss: 0.0856 - val_loss: 0.0790 - learning_rate: 0.0010\n",
      "Epoch 313/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - loss: 0.0859\n",
      "Epoch 313: val_loss did not improve from 0.07901\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step - loss: 0.0858 - val_loss: 0.0873 - learning_rate: 0.0010\n",
      "Epoch 314/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - loss: 0.0841\n",
      "Epoch 314: val_loss did not improve from 0.07901\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 535ms/step - loss: 0.0842 - val_loss: 0.0794 - learning_rate: 0.0010\n",
      "Epoch 315/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - loss: 0.0835\n",
      "Epoch 315: val_loss did not improve from 0.07901\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 510ms/step - loss: 0.0835 - val_loss: 0.0815 - learning_rate: 0.0010\n",
      "Epoch 316/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step - loss: 0.0837\n",
      "Epoch 316: val_loss improved from 0.07901 to 0.07794, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 633ms/step - loss: 0.0837 - val_loss: 0.0779 - learning_rate: 0.0010\n",
      "Epoch 317/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: 0.0850\n",
      "Epoch 317: val_loss did not improve from 0.07794\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 476ms/step - loss: 0.0849 - val_loss: 0.0864 - learning_rate: 0.0010\n",
      "Epoch 318/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.0832\n",
      "Epoch 318: val_loss did not improve from 0.07794\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - loss: 0.0832 - val_loss: 0.0782 - learning_rate: 0.0010\n",
      "Epoch 319/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - loss: 0.0829\n",
      "Epoch 319: val_loss did not improve from 0.07794\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425ms/step - loss: 0.0830 - val_loss: 0.0792 - learning_rate: 0.0010\n",
      "Epoch 320/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - loss: 0.0817\n",
      "Epoch 320: val_loss did not improve from 0.07794\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step - loss: 0.0817 - val_loss: 0.0784 - learning_rate: 0.0010\n",
      "Epoch 321/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - loss: 0.0823\n",
      "Epoch 321: val_loss did not improve from 0.07794\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451ms/step - loss: 0.0823 - val_loss: 0.0807 - learning_rate: 0.0010\n",
      "Epoch 322/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 0.0816\n",
      "Epoch 322: val_loss improved from 0.07794 to 0.07673, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 484ms/step - loss: 0.0816 - val_loss: 0.0767 - learning_rate: 0.0010\n",
      "Epoch 323/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - loss: 0.0815\n",
      "Epoch 323: val_loss improved from 0.07673 to 0.07579, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 471ms/step - loss: 0.0814 - val_loss: 0.0758 - learning_rate: 0.0010\n",
      "Epoch 324/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - loss: 0.0801\n",
      "Epoch 324: val_loss did not improve from 0.07579\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445ms/step - loss: 0.0801 - val_loss: 0.0781 - learning_rate: 0.0010\n",
      "Epoch 325/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - loss: 0.0803\n",
      "Epoch 325: val_loss improved from 0.07579 to 0.07534, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 491ms/step - loss: 0.0802 - val_loss: 0.0753 - learning_rate: 0.0010\n",
      "Epoch 326/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - loss: 0.0800\n",
      "Epoch 326: val_loss did not improve from 0.07534\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - loss: 0.0801 - val_loss: 0.0778 - learning_rate: 0.0010\n",
      "Epoch 327/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 0.0798\n",
      "Epoch 327: val_loss did not improve from 0.07534\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - loss: 0.0798 - val_loss: 0.0762 - learning_rate: 0.0010\n",
      "Epoch 328/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - loss: 0.0798\n",
      "Epoch 328: val_loss improved from 0.07534 to 0.07427, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 496ms/step - loss: 0.0799 - val_loss: 0.0743 - learning_rate: 0.0010\n",
      "Epoch 329/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 0.0786\n",
      "Epoch 329: val_loss did not improve from 0.07427\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - loss: 0.0786 - val_loss: 0.0765 - learning_rate: 0.0010\n",
      "Epoch 330/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - loss: 0.0792\n",
      "Epoch 330: val_loss did not improve from 0.07427\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452ms/step - loss: 0.0792 - val_loss: 0.0764 - learning_rate: 0.0010\n",
      "Epoch 331/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 0.0783\n",
      "Epoch 331: val_loss did not improve from 0.07427\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step - loss: 0.0783 - val_loss: 0.0745 - learning_rate: 0.0010\n",
      "Epoch 332/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - loss: 0.0794\n",
      "Epoch 332: val_loss improved from 0.07427 to 0.07364, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 471ms/step - loss: 0.0794 - val_loss: 0.0736 - learning_rate: 0.0010\n",
      "Epoch 333/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - loss: 0.0779\n",
      "Epoch 333: val_loss did not improve from 0.07364\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426ms/step - loss: 0.0779 - val_loss: 0.0768 - learning_rate: 0.0010\n",
      "Epoch 334/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.0775\n",
      "Epoch 334: val_loss did not improve from 0.07364\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step - loss: 0.0775 - val_loss: 0.0769 - learning_rate: 0.0010\n",
      "Epoch 335/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.0777\n",
      "Epoch 335: val_loss improved from 0.07364 to 0.07325, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 483ms/step - loss: 0.0775 - val_loss: 0.0733 - learning_rate: 0.0010\n",
      "Epoch 336/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - loss: 0.0766\n",
      "Epoch 336: val_loss did not improve from 0.07325\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 457ms/step - loss: 0.0767 - val_loss: 0.0742 - learning_rate: 0.0010\n",
      "Epoch 337/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.0760\n",
      "Epoch 337: val_loss improved from 0.07325 to 0.07285, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 475ms/step - loss: 0.0761 - val_loss: 0.0729 - learning_rate: 0.0010\n",
      "Epoch 338/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - loss: 0.0757\n",
      "Epoch 338: val_loss did not improve from 0.07285\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424ms/step - loss: 0.0757 - val_loss: 0.0740 - learning_rate: 0.0010\n",
      "Epoch 339/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 0.0768\n",
      "Epoch 339: val_loss did not improve from 0.07285\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434ms/step - loss: 0.0768 - val_loss: 0.0742 - learning_rate: 0.0010\n",
      "Epoch 340/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.0770\n",
      "Epoch 340: val_loss did not improve from 0.07285\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - loss: 0.0770 - val_loss: 0.0745 - learning_rate: 0.0010\n",
      "Epoch 341/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - loss: 0.0768\n",
      "Epoch 341: val_loss did not improve from 0.07285\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step - loss: 0.0769 - val_loss: 0.0730 - learning_rate: 0.0010\n",
      "Epoch 342/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - loss: 0.0764\n",
      "Epoch 342: val_loss did not improve from 0.07285\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - loss: 0.0763 - val_loss: 0.0738 - learning_rate: 0.0010\n",
      "Epoch 343/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - loss: 0.0761\n",
      "Epoch 343: val_loss improved from 0.07285 to 0.07196, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 473ms/step - loss: 0.0759 - val_loss: 0.0720 - learning_rate: 0.0010\n",
      "Epoch 344/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.0759\n",
      "Epoch 344: val_loss did not improve from 0.07196\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - loss: 0.0758 - val_loss: 0.0720 - learning_rate: 0.0010\n",
      "Epoch 345/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - loss: 0.0752\n",
      "Epoch 345: val_loss did not improve from 0.07196\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426ms/step - loss: 0.0753 - val_loss: 0.0789 - learning_rate: 0.0010\n",
      "Epoch 346/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - loss: 0.0744\n",
      "Epoch 346: val_loss improved from 0.07196 to 0.06887, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 470ms/step - loss: 0.0744 - val_loss: 0.0689 - learning_rate: 0.0010\n",
      "Epoch 347/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.0737\n",
      "Epoch 347: val_loss did not improve from 0.06887\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step - loss: 0.0738 - val_loss: 0.0767 - learning_rate: 0.0010\n",
      "Epoch 348/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - loss: 0.0744\n",
      "Epoch 348: val_loss improved from 0.06887 to 0.06863, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 469ms/step - loss: 0.0744 - val_loss: 0.0686 - learning_rate: 0.0010\n",
      "Epoch 349/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - loss: 0.0738\n",
      "Epoch 349: val_loss did not improve from 0.06863\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 454ms/step - loss: 0.0738 - val_loss: 0.0733 - learning_rate: 0.0010\n",
      "Epoch 350/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 0.0732\n",
      "Epoch 350: val_loss did not improve from 0.06863\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - loss: 0.0733 - val_loss: 0.0698 - learning_rate: 0.0010\n",
      "Epoch 351/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - loss: 0.0728\n",
      "Epoch 351: val_loss did not improve from 0.06863\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 457ms/step - loss: 0.0729 - val_loss: 0.0699 - learning_rate: 0.0010\n",
      "Epoch 352/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - loss: 0.0725\n",
      "Epoch 352: val_loss did not improve from 0.06863\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419ms/step - loss: 0.0725 - val_loss: 0.0718 - learning_rate: 0.0010\n",
      "Epoch 353/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - loss: 0.0734\n",
      "Epoch 353: val_loss improved from 0.06863 to 0.06816, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 470ms/step - loss: 0.0735 - val_loss: 0.0682 - learning_rate: 0.0010\n",
      "Epoch 354/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: 0.0732\n",
      "Epoch 354: val_loss did not improve from 0.06816\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434ms/step - loss: 0.0733 - val_loss: 0.0701 - learning_rate: 0.0010\n",
      "Epoch 355/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 0.0718\n",
      "Epoch 355: val_loss did not improve from 0.06816\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - loss: 0.0719 - val_loss: 0.0710 - learning_rate: 0.0010\n",
      "Epoch 356/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - loss: 0.0721\n",
      "Epoch 356: val_loss did not improve from 0.06816\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455ms/step - loss: 0.0721 - val_loss: 0.0692 - learning_rate: 0.0010\n",
      "Epoch 357/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - loss: 0.0709\n",
      "Epoch 357: val_loss did not improve from 0.06816\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 463ms/step - loss: 0.0709 - val_loss: 0.0689 - learning_rate: 0.0010\n",
      "Epoch 358/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - loss: 0.0712\n",
      "Epoch 358: val_loss did not improve from 0.06816\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 458ms/step - loss: 0.0712 - val_loss: 0.0703 - learning_rate: 0.0010\n",
      "Epoch 359/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - loss: 0.0710\n",
      "Epoch 359: val_loss improved from 0.06816 to 0.06768, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 472ms/step - loss: 0.0710 - val_loss: 0.0677 - learning_rate: 0.0010\n",
      "Epoch 360/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - loss: 0.0721\n",
      "Epoch 360: val_loss did not improve from 0.06768\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step - loss: 0.0720 - val_loss: 0.0707 - learning_rate: 0.0010\n",
      "Epoch 361/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - loss: 0.0711\n",
      "Epoch 361: val_loss improved from 0.06768 to 0.06658, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - loss: 0.0710 - val_loss: 0.0666 - learning_rate: 0.0010\n",
      "Epoch 362/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - loss: 0.0721\n",
      "Epoch 362: val_loss did not improve from 0.06658\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462ms/step - loss: 0.0721 - val_loss: 0.0726 - learning_rate: 0.0010\n",
      "Epoch 363/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.0722\n",
      "Epoch 363: val_loss did not improve from 0.06658\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - loss: 0.0721 - val_loss: 0.0670 - learning_rate: 0.0010\n",
      "Epoch 364/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: 0.0706\n",
      "Epoch 364: val_loss did not improve from 0.06658\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - loss: 0.0707 - val_loss: 0.0689 - learning_rate: 0.0010\n",
      "Epoch 365/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - loss: 0.0700\n",
      "Epoch 365: val_loss improved from 0.06658 to 0.06646, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step - loss: 0.0702 - val_loss: 0.0665 - learning_rate: 0.0010\n",
      "Epoch 366/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - loss: 0.0709\n",
      "Epoch 366: val_loss did not improve from 0.06646\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451ms/step - loss: 0.0709 - val_loss: 0.0751 - learning_rate: 0.0010\n",
      "Epoch 367/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.0706\n",
      "Epoch 367: val_loss did not improve from 0.06646\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - loss: 0.0705 - val_loss: 0.0667 - learning_rate: 0.0010\n",
      "Epoch 368/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - loss: 0.0710\n",
      "Epoch 368: val_loss did not improve from 0.06646\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415ms/step - loss: 0.0709 - val_loss: 0.0691 - learning_rate: 0.0010\n",
      "Epoch 369/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - loss: 0.0695\n",
      "Epoch 369: val_loss improved from 0.06646 to 0.06575, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464ms/step - loss: 0.0696 - val_loss: 0.0658 - learning_rate: 0.0010\n",
      "Epoch 370/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - loss: 0.0691\n",
      "Epoch 370: val_loss did not improve from 0.06575\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424ms/step - loss: 0.0693 - val_loss: 0.0700 - learning_rate: 0.0010\n",
      "Epoch 371/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - loss: 0.0685\n",
      "Epoch 371: val_loss improved from 0.06575 to 0.06493, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 470ms/step - loss: 0.0686 - val_loss: 0.0649 - learning_rate: 0.0010\n",
      "Epoch 372/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - loss: 0.0705\n",
      "Epoch 372: val_loss did not improve from 0.06493\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419ms/step - loss: 0.0705 - val_loss: 0.0668 - learning_rate: 0.0010\n",
      "Epoch 373/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - loss: 0.0685\n",
      "Epoch 373: val_loss did not improve from 0.06493\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420ms/step - loss: 0.0685 - val_loss: 0.0674 - learning_rate: 0.0010\n",
      "Epoch 374/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.0691\n",
      "Epoch 374: val_loss did not improve from 0.06493\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step - loss: 0.0690 - val_loss: 0.0676 - learning_rate: 0.0010\n",
      "Epoch 375/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.0683\n",
      "Epoch 375: val_loss improved from 0.06493 to 0.06348, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 477ms/step - loss: 0.0682 - val_loss: 0.0635 - learning_rate: 0.0010\n",
      "Epoch 376/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - loss: 0.0677\n",
      "Epoch 376: val_loss did not improve from 0.06348\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416ms/step - loss: 0.0679 - val_loss: 0.0673 - learning_rate: 0.0010\n",
      "Epoch 377/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - loss: 0.0673\n",
      "Epoch 377: val_loss did not improve from 0.06348\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414ms/step - loss: 0.0675 - val_loss: 0.0690 - learning_rate: 0.0010\n",
      "Epoch 378/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 0.0685\n",
      "Epoch 378: val_loss did not improve from 0.06348\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434ms/step - loss: 0.0686 - val_loss: 0.0649 - learning_rate: 0.0010\n",
      "Epoch 379/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - loss: 0.0674\n",
      "Epoch 379: val_loss did not improve from 0.06348\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step - loss: 0.0675 - val_loss: 0.0652 - learning_rate: 0.0010\n",
      "Epoch 380/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - loss: 0.0680\n",
      "Epoch 380: val_loss did not improve from 0.06348\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step - loss: 0.0680 - val_loss: 0.0650 - learning_rate: 0.0010\n",
      "Epoch 381/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - loss: 0.0670\n",
      "Epoch 381: val_loss did not improve from 0.06348\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448ms/step - loss: 0.0670 - val_loss: 0.0657 - learning_rate: 0.0010\n",
      "Epoch 382/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 0.0664\n",
      "Epoch 382: val_loss improved from 0.06348 to 0.06347, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 483ms/step - loss: 0.0663 - val_loss: 0.0635 - learning_rate: 0.0010\n",
      "Epoch 383/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - loss: 0.0675\n",
      "Epoch 383: val_loss did not improve from 0.06347\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step - loss: 0.0674 - val_loss: 0.0698 - learning_rate: 0.0010\n",
      "Epoch 384/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.0664\n",
      "Epoch 384: val_loss did not improve from 0.06347\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446ms/step - loss: 0.0664 - val_loss: 0.0640 - learning_rate: 0.0010\n",
      "Epoch 385/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - loss: 0.0658\n",
      "Epoch 385: val_loss did not improve from 0.06347\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step - loss: 0.0658 - val_loss: 0.0694 - learning_rate: 0.0010\n",
      "Epoch 386/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - loss: 0.0674\n",
      "Epoch 386: val_loss improved from 0.06347 to 0.06029, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474ms/step - loss: 0.0672 - val_loss: 0.0603 - learning_rate: 0.0010\n",
      "Epoch 387/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - loss: 0.0661\n",
      "Epoch 387: val_loss did not improve from 0.06029\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - loss: 0.0662 - val_loss: 0.0705 - learning_rate: 0.0010\n",
      "Epoch 388/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - loss: 0.0651\n",
      "Epoch 388: val_loss did not improve from 0.06029\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - loss: 0.0651 - val_loss: 0.0629 - learning_rate: 0.0010\n",
      "Epoch 389/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - loss: 0.0648\n",
      "Epoch 389: val_loss did not improve from 0.06029\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step - loss: 0.0649 - val_loss: 0.0654 - learning_rate: 0.0010\n",
      "Epoch 390/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - loss: 0.0655\n",
      "Epoch 390: val_loss did not improve from 0.06029\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453ms/step - loss: 0.0655 - val_loss: 0.0622 - learning_rate: 0.0010\n",
      "Epoch 391/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - loss: 0.0659\n",
      "Epoch 391: val_loss did not improve from 0.06029\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step - loss: 0.0659 - val_loss: 0.0616 - learning_rate: 0.0010\n",
      "Epoch 392/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - loss: 0.0662\n",
      "Epoch 392: val_loss did not improve from 0.06029\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step - loss: 0.0662 - val_loss: 0.0616 - learning_rate: 0.0010\n",
      "Epoch 393/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: 0.0662\n",
      "Epoch 393: val_loss did not improve from 0.06029\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - loss: 0.0661 - val_loss: 0.0678 - learning_rate: 0.0010\n",
      "Epoch 394/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.0650\n",
      "Epoch 394: val_loss did not improve from 0.06029\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - loss: 0.0651 - val_loss: 0.0608 - learning_rate: 0.0010\n",
      "Epoch 395/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.0633\n",
      "Epoch 395: val_loss did not improve from 0.06029\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - loss: 0.0634 - val_loss: 0.0613 - learning_rate: 0.0010\n",
      "Epoch 396/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.0639\n",
      "Epoch 396: val_loss did not improve from 0.06029\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step - loss: 0.0639 - val_loss: 0.0636 - learning_rate: 0.0010\n",
      "Epoch 397/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - loss: 0.0640\n",
      "Epoch 397: val_loss did not improve from 0.06029\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444ms/step - loss: 0.0638 - val_loss: 0.0650 - learning_rate: 0.0010\n",
      "Epoch 398/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - loss: 0.0627\n",
      "Epoch 398: val_loss improved from 0.06029 to 0.05806, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486ms/step - loss: 0.0628 - val_loss: 0.0581 - learning_rate: 0.0010\n",
      "Epoch 399/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - loss: 0.0626\n",
      "Epoch 399: val_loss did not improve from 0.05806\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445ms/step - loss: 0.0626 - val_loss: 0.0625 - learning_rate: 0.0010\n",
      "Epoch 400/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - loss: 0.0628\n",
      "Epoch 400: val_loss did not improve from 0.05806\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 466ms/step - loss: 0.0629 - val_loss: 0.0633 - learning_rate: 0.0010\n",
      "Epoch 401/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - loss: 0.0627\n",
      "Epoch 401: val_loss did not improve from 0.05806\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453ms/step - loss: 0.0627 - val_loss: 0.0595 - learning_rate: 0.0010\n",
      "Epoch 402/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - loss: 0.0633\n",
      "Epoch 402: val_loss did not improve from 0.05806\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449ms/step - loss: 0.0633 - val_loss: 0.0647 - learning_rate: 0.0010\n",
      "Epoch 403/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - loss: 0.0635\n",
      "Epoch 403: val_loss did not improve from 0.05806\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step - loss: 0.0634 - val_loss: 0.0608 - learning_rate: 0.0010\n",
      "Epoch 404/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: 0.0618\n",
      "Epoch 404: val_loss did not improve from 0.05806\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - loss: 0.0619 - val_loss: 0.0669 - learning_rate: 0.0010\n",
      "Epoch 405/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - loss: 0.0623\n",
      "Epoch 405: val_loss did not improve from 0.05806\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - loss: 0.0623 - val_loss: 0.0629 - learning_rate: 0.0010\n",
      "Epoch 406/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 0.0620\n",
      "Epoch 406: val_loss did not improve from 0.05806\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - loss: 0.0621 - val_loss: 0.0582 - learning_rate: 0.0010\n",
      "Epoch 407/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - loss: 0.0617\n",
      "Epoch 407: val_loss did not improve from 0.05806\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420ms/step - loss: 0.0618 - val_loss: 0.0641 - learning_rate: 0.0010\n",
      "Epoch 408/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - loss: 0.0614\n",
      "Epoch 408: val_loss improved from 0.05806 to 0.05655, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493ms/step - loss: 0.0615 - val_loss: 0.0566 - learning_rate: 0.0010\n",
      "Epoch 409/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - loss: 0.0613\n",
      "Epoch 409: val_loss did not improve from 0.05655\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 459ms/step - loss: 0.0613 - val_loss: 0.0617 - learning_rate: 0.0010\n",
      "Epoch 410/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - loss: 0.0606\n",
      "Epoch 410: val_loss did not improve from 0.05655\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - loss: 0.0606 - val_loss: 0.0603 - learning_rate: 0.0010\n",
      "Epoch 411/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - loss: 0.0601\n",
      "Epoch 411: val_loss did not improve from 0.05655\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444ms/step - loss: 0.0601 - val_loss: 0.0599 - learning_rate: 0.0010\n",
      "Epoch 412/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - loss: 0.0610\n",
      "Epoch 412: val_loss improved from 0.05655 to 0.05618, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495ms/step - loss: 0.0609 - val_loss: 0.0562 - learning_rate: 0.0010\n",
      "Epoch 413/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - loss: 0.0607\n",
      "Epoch 413: val_loss did not improve from 0.05618\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 465ms/step - loss: 0.0606 - val_loss: 0.0606 - learning_rate: 0.0010\n",
      "Epoch 414/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - loss: 0.0603\n",
      "Epoch 414: val_loss did not improve from 0.05618\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456ms/step - loss: 0.0602 - val_loss: 0.0624 - learning_rate: 0.0010\n",
      "Epoch 415/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - loss: 0.0592\n",
      "Epoch 415: val_loss did not improve from 0.05618\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - loss: 0.0594 - val_loss: 0.0564 - learning_rate: 0.0010\n",
      "Epoch 416/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - loss: 0.0596\n",
      "Epoch 416: val_loss improved from 0.05618 to 0.05588, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492ms/step - loss: 0.0596 - val_loss: 0.0559 - learning_rate: 0.0010\n",
      "Epoch 417/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - loss: 0.0599\n",
      "Epoch 417: val_loss did not improve from 0.05588\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456ms/step - loss: 0.0600 - val_loss: 0.0631 - learning_rate: 0.0010\n",
      "Epoch 418/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - loss: 0.0597\n",
      "Epoch 418: val_loss improved from 0.05588 to 0.05462, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 481ms/step - loss: 0.0597 - val_loss: 0.0546 - learning_rate: 0.0010\n",
      "Epoch 419/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - loss: 0.0588\n",
      "Epoch 419: val_loss did not improve from 0.05462\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 457ms/step - loss: 0.0592 - val_loss: 0.0604 - learning_rate: 0.0010\n",
      "Epoch 420/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - loss: 0.0589\n",
      "Epoch 420: val_loss improved from 0.05462 to 0.05357, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 499ms/step - loss: 0.0592 - val_loss: 0.0536 - learning_rate: 0.0010\n",
      "Epoch 421/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 0.0604\n",
      "Epoch 421: val_loss did not improve from 0.05357\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step - loss: 0.0603 - val_loss: 0.0623 - learning_rate: 0.0010\n",
      "Epoch 422/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - loss: 0.0589\n",
      "Epoch 422: val_loss did not improve from 0.05357\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 485ms/step - loss: 0.0588 - val_loss: 0.0554 - learning_rate: 0.0010\n",
      "Epoch 423/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - loss: 0.0588\n",
      "Epoch 423: val_loss did not improve from 0.05357\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445ms/step - loss: 0.0588 - val_loss: 0.0606 - learning_rate: 0.0010\n",
      "Epoch 424/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - loss: 0.0581\n",
      "Epoch 424: val_loss improved from 0.05357 to 0.05302, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step - loss: 0.0582 - val_loss: 0.0530 - learning_rate: 0.0010\n",
      "Epoch 425/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - loss: 0.0586\n",
      "Epoch 425: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423ms/step - loss: 0.0586 - val_loss: 0.0584 - learning_rate: 0.0010\n",
      "Epoch 426/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 0.0603\n",
      "Epoch 426: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - loss: 0.0600 - val_loss: 0.0549 - learning_rate: 0.0010\n",
      "Epoch 427/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - loss: 0.0579\n",
      "Epoch 427: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450ms/step - loss: 0.0580 - val_loss: 0.0571 - learning_rate: 0.0010\n",
      "Epoch 428/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - loss: 0.0577\n",
      "Epoch 428: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445ms/step - loss: 0.0578 - val_loss: 0.0532 - learning_rate: 0.0010\n",
      "Epoch 429/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - loss: 0.0576\n",
      "Epoch 429: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step - loss: 0.0577 - val_loss: 0.0611 - learning_rate: 0.0010\n",
      "Epoch 430/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - loss: 0.0583\n",
      "Epoch 430: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step - loss: 0.0583 - val_loss: 0.0559 - learning_rate: 0.0010\n",
      "Epoch 431/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - loss: 0.0574\n",
      "Epoch 431: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452ms/step - loss: 0.0575 - val_loss: 0.0572 - learning_rate: 0.0010\n",
      "Epoch 432/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - loss: 0.0576\n",
      "Epoch 432: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step - loss: 0.0575 - val_loss: 0.0534 - learning_rate: 0.0010\n",
      "Epoch 433/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.0582\n",
      "Epoch 433: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - loss: 0.0581 - val_loss: 0.0588 - learning_rate: 0.0010\n",
      "Epoch 434/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 0.0576\n",
      "Epoch 434: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - loss: 0.0577 - val_loss: 0.0545 - learning_rate: 0.0010\n",
      "Epoch 435/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - loss: 0.0562\n",
      "Epoch 435: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step - loss: 0.0563 - val_loss: 0.0555 - learning_rate: 0.0010\n",
      "Epoch 436/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - loss: 0.0577\n",
      "Epoch 436: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425ms/step - loss: 0.0577 - val_loss: 0.0650 - learning_rate: 0.0010\n",
      "Epoch 437/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - loss: 0.0574\n",
      "Epoch 437: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420ms/step - loss: 0.0573 - val_loss: 0.0567 - learning_rate: 0.0010\n",
      "Epoch 438/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - loss: 0.0561\n",
      "Epoch 438: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step - loss: 0.0561 - val_loss: 0.0534 - learning_rate: 0.0010\n",
      "Epoch 439/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - loss: 0.0553\n",
      "Epoch 439: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425ms/step - loss: 0.0554 - val_loss: 0.0547 - learning_rate: 0.0010\n",
      "Epoch 440/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - loss: 0.0560\n",
      "Epoch 440: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 408ms/step - loss: 0.0560 - val_loss: 0.0576 - learning_rate: 0.0010\n",
      "Epoch 441/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: 0.0554\n",
      "Epoch 441: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step - loss: 0.0554 - val_loss: 0.0534 - learning_rate: 0.0010\n",
      "Epoch 442/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - loss: 0.0553\n",
      "Epoch 442: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - loss: 0.0552 - val_loss: 0.0549 - learning_rate: 0.0010\n",
      "Epoch 443/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - loss: 0.0545\n",
      "Epoch 443: val_loss did not improve from 0.05302\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425ms/step - loss: 0.0545 - val_loss: 0.0537 - learning_rate: 0.0010\n",
      "Epoch 444/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - loss: 0.0549\n",
      "Epoch 444: val_loss improved from 0.05302 to 0.05242, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497ms/step - loss: 0.0549 - val_loss: 0.0524 - learning_rate: 0.0010\n",
      "Epoch 445/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - loss: 0.0568\n",
      "Epoch 445: val_loss did not improve from 0.05242\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428ms/step - loss: 0.0566 - val_loss: 0.0598 - learning_rate: 0.0010\n",
      "Epoch 446/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - loss: 0.0560\n",
      "Epoch 446: val_loss improved from 0.05242 to 0.05231, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 478ms/step - loss: 0.0561 - val_loss: 0.0523 - learning_rate: 0.0010\n",
      "Epoch 447/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - loss: 0.0547\n",
      "Epoch 447: val_loss did not improve from 0.05231\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444ms/step - loss: 0.0547 - val_loss: 0.0544 - learning_rate: 0.0010\n",
      "Epoch 448/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.0558\n",
      "Epoch 448: val_loss did not improve from 0.05231\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - loss: 0.0556 - val_loss: 0.0540 - learning_rate: 0.0010\n",
      "Epoch 449/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - loss: 0.0556\n",
      "Epoch 449: val_loss did not improve from 0.05231\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step - loss: 0.0553 - val_loss: 0.0525 - learning_rate: 0.0010\n",
      "Epoch 450/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - loss: 0.0545\n",
      "Epoch 450: val_loss did not improve from 0.05231\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417ms/step - loss: 0.0545 - val_loss: 0.0587 - learning_rate: 0.0010\n",
      "Epoch 451/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: 0.0548\n",
      "Epoch 451: val_loss did not improve from 0.05231\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step - loss: 0.0547 - val_loss: 0.0537 - learning_rate: 0.0010\n",
      "Epoch 452/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - loss: 0.0551\n",
      "Epoch 452: val_loss did not improve from 0.05231\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426ms/step - loss: 0.0549 - val_loss: 0.0534 - learning_rate: 0.0010\n",
      "Epoch 453/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 0.0530\n",
      "Epoch 453: val_loss did not improve from 0.05231\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - loss: 0.0532 - val_loss: 0.0526 - learning_rate: 0.0010\n",
      "Epoch 454/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.0539\n",
      "Epoch 454: val_loss improved from 0.05231 to 0.04925, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486ms/step - loss: 0.0538 - val_loss: 0.0492 - learning_rate: 0.0010\n",
      "Epoch 455/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - loss: 0.0527\n",
      "Epoch 455: val_loss did not improve from 0.04925\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451ms/step - loss: 0.0528 - val_loss: 0.0521 - learning_rate: 0.0010\n",
      "Epoch 456/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - loss: 0.0532\n",
      "Epoch 456: val_loss did not improve from 0.04925\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452ms/step - loss: 0.0533 - val_loss: 0.0508 - learning_rate: 0.0010\n",
      "Epoch 457/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - loss: 0.0528\n",
      "Epoch 457: val_loss did not improve from 0.04925\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449ms/step - loss: 0.0530 - val_loss: 0.0539 - learning_rate: 0.0010\n",
      "Epoch 458/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - loss: 0.0555\n",
      "Epoch 458: val_loss did not improve from 0.04925\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445ms/step - loss: 0.0554 - val_loss: 0.0513 - learning_rate: 0.0010\n",
      "Epoch 459/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.0544\n",
      "Epoch 459: val_loss did not improve from 0.04925\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - loss: 0.0542 - val_loss: 0.0511 - learning_rate: 0.0010\n",
      "Epoch 460/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - loss: 0.0527\n",
      "Epoch 460: val_loss did not improve from 0.04925\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step - loss: 0.0528 - val_loss: 0.0541 - learning_rate: 0.0010\n",
      "Epoch 461/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - loss: 0.0525\n",
      "Epoch 461: val_loss did not improve from 0.04925\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448ms/step - loss: 0.0525 - val_loss: 0.0510 - learning_rate: 0.0010\n",
      "Epoch 462/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - loss: 0.0527\n",
      "Epoch 462: val_loss did not improve from 0.04925\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451ms/step - loss: 0.0527 - val_loss: 0.0534 - learning_rate: 0.0010\n",
      "Epoch 463/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - loss: 0.0524\n",
      "Epoch 463: val_loss did not improve from 0.04925\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448ms/step - loss: 0.0524 - val_loss: 0.0499 - learning_rate: 0.0010\n",
      "Epoch 464/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - loss: 0.0518\n",
      "Epoch 464: val_loss did not improve from 0.04925\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450ms/step - loss: 0.0518 - val_loss: 0.0524 - learning_rate: 0.0010\n",
      "Epoch 465/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: 0.0522\n",
      "Epoch 465: val_loss did not improve from 0.04925\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - loss: 0.0522 - val_loss: 0.0527 - learning_rate: 0.0010\n",
      "Epoch 466/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - loss: 0.0522\n",
      "Epoch 466: val_loss did not improve from 0.04925\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425ms/step - loss: 0.0523 - val_loss: 0.0503 - learning_rate: 0.0010\n",
      "Epoch 467/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - loss: 0.0531\n",
      "Epoch 467: val_loss improved from 0.04925 to 0.04778, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 496ms/step - loss: 0.0532 - val_loss: 0.0478 - learning_rate: 0.0010\n",
      "Epoch 468/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - loss: 0.0522\n",
      "Epoch 468: val_loss did not improve from 0.04778\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451ms/step - loss: 0.0523 - val_loss: 0.0537 - learning_rate: 0.0010\n",
      "Epoch 469/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - loss: 0.0519\n",
      "Epoch 469: val_loss did not improve from 0.04778\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452ms/step - loss: 0.0520 - val_loss: 0.0524 - learning_rate: 0.0010\n",
      "Epoch 470/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - loss: 0.0522\n",
      "Epoch 470: val_loss did not improve from 0.04778\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453ms/step - loss: 0.0523 - val_loss: 0.0500 - learning_rate: 0.0010\n",
      "Epoch 471/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.0516\n",
      "Epoch 471: val_loss did not improve from 0.04778\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step - loss: 0.0516 - val_loss: 0.0512 - learning_rate: 0.0010\n",
      "Epoch 472/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 0.0524\n",
      "Epoch 472: val_loss improved from 0.04778 to 0.04698, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492ms/step - loss: 0.0524 - val_loss: 0.0470 - learning_rate: 0.0010\n",
      "Epoch 473/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - loss: 0.0511\n",
      "Epoch 473: val_loss did not improve from 0.04698\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step - loss: 0.0516 - val_loss: 0.0556 - learning_rate: 0.0010\n",
      "Epoch 474/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - loss: 0.0522\n",
      "Epoch 474: val_loss did not improve from 0.04698\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step - loss: 0.0522 - val_loss: 0.0506 - learning_rate: 0.0010\n",
      "Epoch 475/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - loss: 0.0512\n",
      "Epoch 475: val_loss did not improve from 0.04698\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step - loss: 0.0513 - val_loss: 0.0484 - learning_rate: 0.0010\n",
      "Epoch 476/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - loss: 0.0522\n",
      "Epoch 476: val_loss did not improve from 0.04698\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425ms/step - loss: 0.0521 - val_loss: 0.0504 - learning_rate: 0.0010\n",
      "Epoch 477/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - loss: 0.0516\n",
      "Epoch 477: val_loss did not improve from 0.04698\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428ms/step - loss: 0.0517 - val_loss: 0.0587 - learning_rate: 0.0010\n",
      "Epoch 478/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.0512\n",
      "Epoch 478: val_loss did not improve from 0.04698\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step - loss: 0.0512 - val_loss: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 479/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - loss: 0.0507\n",
      "Epoch 479: val_loss did not improve from 0.04698\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423ms/step - loss: 0.0506 - val_loss: 0.0478 - learning_rate: 0.0010\n",
      "Epoch 480/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.0500\n",
      "Epoch 480: val_loss did not improve from 0.04698\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428ms/step - loss: 0.0501 - val_loss: 0.0507 - learning_rate: 0.0010\n",
      "Epoch 481/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.0499\n",
      "Epoch 481: val_loss did not improve from 0.04698\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - loss: 0.0499 - val_loss: 0.0505 - learning_rate: 0.0010\n",
      "Epoch 482/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 0.0497\n",
      "Epoch 482: val_loss did not improve from 0.04698\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - loss: 0.0497 - val_loss: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 483/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - loss: 0.0507\n",
      "Epoch 483: val_loss did not improve from 0.04698\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step - loss: 0.0506 - val_loss: 0.0489 - learning_rate: 0.0010\n",
      "Epoch 484/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - loss: 0.0495\n",
      "Epoch 484: val_loss did not improve from 0.04698\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step - loss: 0.0495 - val_loss: 0.0539 - learning_rate: 0.0010\n",
      "Epoch 485/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 0.0498\n",
      "Epoch 485: val_loss did not improve from 0.04698\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - loss: 0.0499 - val_loss: 0.0492 - learning_rate: 0.0010\n",
      "Epoch 486/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 0.0490\n",
      "Epoch 486: val_loss improved from 0.04698 to 0.04693, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480ms/step - loss: 0.0490 - val_loss: 0.0469 - learning_rate: 0.0010\n",
      "Epoch 487/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: 0.0492\n",
      "Epoch 487: val_loss did not improve from 0.04693\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - loss: 0.0492 - val_loss: 0.0505 - learning_rate: 0.0010\n",
      "Epoch 488/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - loss: 0.0500\n",
      "Epoch 488: val_loss improved from 0.04693 to 0.04632, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 457ms/step - loss: 0.0499 - val_loss: 0.0463 - learning_rate: 0.0010\n",
      "Epoch 489/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - loss: 0.0493\n",
      "Epoch 489: val_loss did not improve from 0.04632\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422ms/step - loss: 0.0491 - val_loss: 0.0563 - learning_rate: 0.0010\n",
      "Epoch 490/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.0489\n",
      "Epoch 490: val_loss did not improve from 0.04632\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step - loss: 0.0489 - val_loss: 0.0471 - learning_rate: 0.0010\n",
      "Epoch 491/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - loss: 0.0483\n",
      "Epoch 491: val_loss did not improve from 0.04632\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step - loss: 0.0482 - val_loss: 0.0502 - learning_rate: 0.0010\n",
      "Epoch 492/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - loss: 0.0478\n",
      "Epoch 492: val_loss improved from 0.04632 to 0.04506, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 478ms/step - loss: 0.0477 - val_loss: 0.0451 - learning_rate: 0.0010\n",
      "Epoch 493/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.0492\n",
      "Epoch 493: val_loss did not improve from 0.04506\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - loss: 0.0491 - val_loss: 0.0518 - learning_rate: 0.0010\n",
      "Epoch 494/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - loss: 0.0474\n",
      "Epoch 494: val_loss did not improve from 0.04506\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425ms/step - loss: 0.0475 - val_loss: 0.0462 - learning_rate: 0.0010\n",
      "Epoch 495/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.0479\n",
      "Epoch 495: val_loss did not improve from 0.04506\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step - loss: 0.0479 - val_loss: 0.0501 - learning_rate: 0.0010\n",
      "Epoch 496/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.0470\n",
      "Epoch 496: val_loss did not improve from 0.04506\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - loss: 0.0471 - val_loss: 0.0466 - learning_rate: 0.0010\n",
      "Epoch 497/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 0.0469\n",
      "Epoch 497: val_loss improved from 0.04506 to 0.04490, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493ms/step - loss: 0.0471 - val_loss: 0.0449 - learning_rate: 0.0010\n",
      "Epoch 498/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - loss: 0.0469\n",
      "Epoch 498: val_loss did not improve from 0.04490\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417ms/step - loss: 0.0469 - val_loss: 0.0525 - learning_rate: 0.0010\n",
      "Epoch 499/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - loss: 0.0467\n",
      "Epoch 499: val_loss did not improve from 0.04490\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step - loss: 0.0467 - val_loss: 0.0452 - learning_rate: 0.0010\n",
      "Epoch 500/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 0.0470\n",
      "Epoch 500: val_loss did not improve from 0.04490\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step - loss: 0.0469 - val_loss: 0.0467 - learning_rate: 0.0010\n",
      "Epoch 501/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 0.0465\n",
      "Epoch 501: val_loss did not improve from 0.04490\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - loss: 0.0465 - val_loss: 0.0465 - learning_rate: 0.0010\n",
      "Epoch 502/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - loss: 0.0473\n",
      "Epoch 502: val_loss did not improve from 0.04490\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step - loss: 0.0472 - val_loss: 0.0473 - learning_rate: 0.0010\n",
      "Epoch 503/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.0458\n",
      "Epoch 503: val_loss did not improve from 0.04490\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445ms/step - loss: 0.0459 - val_loss: 0.0499 - learning_rate: 0.0010\n",
      "Epoch 504/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: 0.0474\n",
      "Epoch 504: val_loss did not improve from 0.04490\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step - loss: 0.0473 - val_loss: 0.0458 - learning_rate: 0.0010\n",
      "Epoch 505/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - loss: 0.0465\n",
      "Epoch 505: val_loss did not improve from 0.04490\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step - loss: 0.0465 - val_loss: 0.0476 - learning_rate: 0.0010\n",
      "Epoch 506/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - loss: 0.0457\n",
      "Epoch 506: val_loss did not improve from 0.04490\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422ms/step - loss: 0.0459 - val_loss: 0.0491 - learning_rate: 0.0010\n",
      "Epoch 507/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - loss: 0.0459\n",
      "Epoch 507: val_loss improved from 0.04490 to 0.04407, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 472ms/step - loss: 0.0460 - val_loss: 0.0441 - learning_rate: 0.0010\n",
      "Epoch 508/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - loss: 0.0471\n",
      "Epoch 508: val_loss did not improve from 0.04407\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step - loss: 0.0470 - val_loss: 0.0477 - learning_rate: 0.0010\n",
      "Epoch 509/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - loss: 0.0461\n",
      "Epoch 509: val_loss did not improve from 0.04407\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434ms/step - loss: 0.0461 - val_loss: 0.0462 - learning_rate: 0.0010\n",
      "Epoch 510/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 0.0458\n",
      "Epoch 510: val_loss did not improve from 0.04407\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - loss: 0.0459 - val_loss: 0.0482 - learning_rate: 0.0010\n",
      "Epoch 511/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - loss: 0.0461\n",
      "Epoch 511: val_loss improved from 0.04407 to 0.04201, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467ms/step - loss: 0.0461 - val_loss: 0.0420 - learning_rate: 0.0010\n",
      "Epoch 512/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - loss: 0.0459\n",
      "Epoch 512: val_loss did not improve from 0.04201\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444ms/step - loss: 0.0460 - val_loss: 0.0485 - learning_rate: 0.0010\n",
      "Epoch 513/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - loss: 0.0451\n",
      "Epoch 513: val_loss did not improve from 0.04201\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411ms/step - loss: 0.0451 - val_loss: 0.0438 - learning_rate: 0.0010\n",
      "Epoch 514/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - loss: 0.0460\n",
      "Epoch 514: val_loss did not improve from 0.04201\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410ms/step - loss: 0.0461 - val_loss: 0.0463 - learning_rate: 0.0010\n",
      "Epoch 515/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - loss: 0.0449\n",
      "Epoch 515: val_loss did not improve from 0.04201\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step - loss: 0.0450 - val_loss: 0.0462 - learning_rate: 0.0010\n",
      "Epoch 516/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.0449\n",
      "Epoch 516: val_loss did not improve from 0.04201\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step - loss: 0.0449 - val_loss: 0.0443 - learning_rate: 0.0010\n",
      "Epoch 517/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - loss: 0.0453\n",
      "Epoch 517: val_loss did not improve from 0.04201\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step - loss: 0.0452 - val_loss: 0.0455 - learning_rate: 0.0010\n",
      "Epoch 518/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 0.0456\n",
      "Epoch 518: val_loss did not improve from 0.04201\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - loss: 0.0455 - val_loss: 0.0430 - learning_rate: 0.0010\n",
      "Epoch 519/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - loss: 0.0460\n",
      "Epoch 519: val_loss did not improve from 0.04201\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step - loss: 0.0459 - val_loss: 0.0536 - learning_rate: 0.0010\n",
      "Epoch 520/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - loss: 0.0463\n",
      "Epoch 520: val_loss improved from 0.04201 to 0.04131, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 481ms/step - loss: 0.0463 - val_loss: 0.0413 - learning_rate: 0.0010\n",
      "Epoch 521/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 0.0454\n",
      "Epoch 521: val_loss did not improve from 0.04131\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step - loss: 0.0454 - val_loss: 0.0424 - learning_rate: 0.0010\n",
      "Epoch 522/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - loss: 0.0459\n",
      "Epoch 522: val_loss did not improve from 0.04131\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423ms/step - loss: 0.0458 - val_loss: 0.0457 - learning_rate: 0.0010\n",
      "Epoch 523/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - loss: 0.0442\n",
      "Epoch 523: val_loss did not improve from 0.04131\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423ms/step - loss: 0.0443 - val_loss: 0.0460 - learning_rate: 0.0010\n",
      "Epoch 524/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.0444\n",
      "Epoch 524: val_loss did not improve from 0.04131\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434ms/step - loss: 0.0445 - val_loss: 0.0529 - learning_rate: 0.0010\n",
      "Epoch 525/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: 0.0451\n",
      "Epoch 525: val_loss did not improve from 0.04131\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - loss: 0.0450 - val_loss: 0.0436 - learning_rate: 0.0010\n",
      "Epoch 526/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 0.0439\n",
      "Epoch 526: val_loss did not improve from 0.04131\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - loss: 0.0440 - val_loss: 0.0491 - learning_rate: 0.0010\n",
      "Epoch 527/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - loss: 0.0451\n",
      "Epoch 527: val_loss did not improve from 0.04131\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423ms/step - loss: 0.0449 - val_loss: 0.0415 - learning_rate: 0.0010\n",
      "Epoch 528/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - loss: 0.0441\n",
      "Epoch 528: val_loss did not improve from 0.04131\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step - loss: 0.0440 - val_loss: 0.0497 - learning_rate: 0.0010\n",
      "Epoch 529/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - loss: 0.0435\n",
      "Epoch 529: val_loss did not improve from 0.04131\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451ms/step - loss: 0.0436 - val_loss: 0.0422 - learning_rate: 0.0010\n",
      "Epoch 530/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - loss: 0.0435\n",
      "Epoch 530: val_loss did not improve from 0.04131\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417ms/step - loss: 0.0436 - val_loss: 0.0488 - learning_rate: 0.0010\n",
      "Epoch 531/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - loss: 0.0434\n",
      "Epoch 531: val_loss improved from 0.04131 to 0.04052, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 458ms/step - loss: 0.0434 - val_loss: 0.0405 - learning_rate: 0.0010\n",
      "Epoch 532/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - loss: 0.0430\n",
      "Epoch 532: val_loss did not improve from 0.04052\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419ms/step - loss: 0.0430 - val_loss: 0.0480 - learning_rate: 0.0010\n",
      "Epoch 533/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - loss: 0.0438\n",
      "Epoch 533: val_loss did not improve from 0.04052\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step - loss: 0.0437 - val_loss: 0.0430 - learning_rate: 0.0010\n",
      "Epoch 534/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - loss: 0.0437\n",
      "Epoch 534: val_loss did not improve from 0.04052\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step - loss: 0.0436 - val_loss: 0.0442 - learning_rate: 0.0010\n",
      "Epoch 535/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 0.0431\n",
      "Epoch 535: val_loss did not improve from 0.04052\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step - loss: 0.0431 - val_loss: 0.0421 - learning_rate: 0.0010\n",
      "Epoch 536/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 0.0429\n",
      "Epoch 536: val_loss did not improve from 0.04052\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - loss: 0.0428 - val_loss: 0.0432 - learning_rate: 0.0010\n",
      "Epoch 537/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: 0.0418\n",
      "Epoch 537: val_loss did not improve from 0.04052\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step - loss: 0.0418 - val_loss: 0.0408 - learning_rate: 0.0010\n",
      "Epoch 538/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.0434\n",
      "Epoch 538: val_loss did not improve from 0.04052\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step - loss: 0.0433 - val_loss: 0.0446 - learning_rate: 0.0010\n",
      "Epoch 539/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - loss: 0.0441\n",
      "Epoch 539: val_loss did not improve from 0.04052\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step - loss: 0.0440 - val_loss: 0.0418 - learning_rate: 0.0010\n",
      "Epoch 540/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - loss: 0.0443\n",
      "Epoch 540: val_loss improved from 0.04052 to 0.03943, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462ms/step - loss: 0.0441 - val_loss: 0.0394 - learning_rate: 0.0010\n",
      "Epoch 541/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - loss: 0.0440\n",
      "Epoch 541: val_loss did not improve from 0.03943\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416ms/step - loss: 0.0438 - val_loss: 0.0436 - learning_rate: 0.0010\n",
      "Epoch 542/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - loss: 0.0421\n",
      "Epoch 542: val_loss did not improve from 0.03943\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419ms/step - loss: 0.0422 - val_loss: 0.0482 - learning_rate: 0.0010\n",
      "Epoch 543/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - loss: 0.0418\n",
      "Epoch 543: val_loss did not improve from 0.03943\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429ms/step - loss: 0.0418 - val_loss: 0.0406 - learning_rate: 0.0010\n",
      "Epoch 544/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - loss: 0.0407\n",
      "Epoch 544: val_loss did not improve from 0.03943\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423ms/step - loss: 0.0408 - val_loss: 0.0398 - learning_rate: 0.0010\n",
      "Epoch 545/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - loss: 0.0411\n",
      "Epoch 545: val_loss did not improve from 0.03943\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step - loss: 0.0411 - val_loss: 0.0438 - learning_rate: 0.0010\n",
      "Epoch 546/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - loss: 0.0413\n",
      "Epoch 546: val_loss did not improve from 0.03943\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424ms/step - loss: 0.0413 - val_loss: 0.0405 - learning_rate: 0.0010\n",
      "Epoch 547/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - loss: 0.0412\n",
      "Epoch 547: val_loss did not improve from 0.03943\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step - loss: 0.0412 - val_loss: 0.0395 - learning_rate: 0.0010\n",
      "Epoch 548/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - loss: 0.0412\n",
      "Epoch 548: val_loss did not improve from 0.03943\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step - loss: 0.0412 - val_loss: 0.0428 - learning_rate: 0.0010\n",
      "Epoch 549/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: 0.0408\n",
      "Epoch 549: val_loss did not improve from 0.03943\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step - loss: 0.0409 - val_loss: 0.0403 - learning_rate: 0.0010\n",
      "Epoch 550/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - loss: 0.0424\n",
      "Epoch 550: val_loss did not improve from 0.03943\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423ms/step - loss: 0.0424 - val_loss: 0.0427 - learning_rate: 0.0010\n",
      "Epoch 551/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - loss: 0.0413\n",
      "Epoch 551: val_loss did not improve from 0.03943\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step - loss: 0.0414 - val_loss: 0.0395 - learning_rate: 0.0010\n",
      "Epoch 552/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - loss: 0.0419\n",
      "Epoch 552: val_loss did not improve from 0.03943\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step - loss: 0.0418 - val_loss: 0.0439 - learning_rate: 0.0010\n",
      "Epoch 553/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - loss: 0.0409\n",
      "Epoch 553: val_loss did not improve from 0.03943\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - loss: 0.0410 - val_loss: 0.0405 - learning_rate: 0.0010\n",
      "Epoch 554/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - loss: 0.0410\n",
      "Epoch 554: val_loss did not improve from 0.03943\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414ms/step - loss: 0.0410 - val_loss: 0.0435 - learning_rate: 0.0010\n",
      "Epoch 555/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - loss: 0.0412\n",
      "Epoch 555: val_loss did not improve from 0.03943\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418ms/step - loss: 0.0412 - val_loss: 0.0419 - learning_rate: 0.0010\n",
      "Epoch 556/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - loss: 0.0403\n",
      "Epoch 556: val_loss improved from 0.03943 to 0.03910, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497ms/step - loss: 0.0403 - val_loss: 0.0391 - learning_rate: 0.0010\n",
      "Epoch 557/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - loss: 0.0402\n",
      "Epoch 557: val_loss did not improve from 0.03910\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 465ms/step - loss: 0.0403 - val_loss: 0.0412 - learning_rate: 0.0010\n",
      "Epoch 558/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - loss: 0.0421\n",
      "Epoch 558: val_loss did not improve from 0.03910\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425ms/step - loss: 0.0420 - val_loss: 0.0426 - learning_rate: 0.0010\n",
      "Epoch 559/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - loss: 0.0425\n",
      "Epoch 559: val_loss improved from 0.03910 to 0.03808, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 472ms/step - loss: 0.0423 - val_loss: 0.0381 - learning_rate: 0.0010\n",
      "Epoch 560/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - loss: 0.0407\n",
      "Epoch 560: val_loss did not improve from 0.03808\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step - loss: 0.0407 - val_loss: 0.0420 - learning_rate: 0.0010\n",
      "Epoch 561/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - loss: 0.0407\n",
      "Epoch 561: val_loss did not improve from 0.03808\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430ms/step - loss: 0.0407 - val_loss: 0.0405 - learning_rate: 0.0010\n",
      "Epoch 562/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - loss: 0.0397\n",
      "Epoch 562: val_loss did not improve from 0.03808\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step - loss: 0.0397 - val_loss: 0.0408 - learning_rate: 0.0010\n",
      "Epoch 563/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - loss: 0.0402\n",
      "Epoch 563: val_loss did not improve from 0.03808\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456ms/step - loss: 0.0401 - val_loss: 0.0458 - learning_rate: 0.0010\n",
      "Epoch 564/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - loss: 0.0406\n",
      "Epoch 564: val_loss did not improve from 0.03808\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419ms/step - loss: 0.0407 - val_loss: 0.0443 - learning_rate: 0.0010\n",
      "Epoch 565/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.0411\n",
      "Epoch 565: val_loss did not improve from 0.03808\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - loss: 0.0412 - val_loss: 0.0391 - learning_rate: 0.0010\n",
      "Epoch 566/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.0414\n",
      "Epoch 566: val_loss improved from 0.03808 to 0.03779, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480ms/step - loss: 0.0413 - val_loss: 0.0378 - learning_rate: 0.0010\n",
      "Epoch 567/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - loss: 0.0414\n",
      "Epoch 567: val_loss did not improve from 0.03779\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448ms/step - loss: 0.0415 - val_loss: 0.0414 - learning_rate: 0.0010\n",
      "Epoch 568/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - loss: 0.0406\n",
      "Epoch 568: val_loss did not improve from 0.03779\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step - loss: 0.0406 - val_loss: 0.0429 - learning_rate: 0.0010\n",
      "Epoch 569/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - loss: 0.0396\n",
      "Epoch 569: val_loss improved from 0.03779 to 0.03770, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467ms/step - loss: 0.0396 - val_loss: 0.0377 - learning_rate: 0.0010\n",
      "Epoch 570/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 0.0393\n",
      "Epoch 570: val_loss did not improve from 0.03770\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - loss: 0.0393 - val_loss: 0.0426 - learning_rate: 0.0010\n",
      "Epoch 571/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - loss: 0.0390\n",
      "Epoch 571: val_loss did not improve from 0.03770\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step - loss: 0.0392 - val_loss: 0.0401 - learning_rate: 0.0010\n",
      "Epoch 572/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - loss: 0.0394\n",
      "Epoch 572: val_loss did not improve from 0.03770\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 421ms/step - loss: 0.0394 - val_loss: 0.0404 - learning_rate: 0.0010\n",
      "Epoch 573/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - loss: 0.0394\n",
      "Epoch 573: val_loss did not improve from 0.03770\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step - loss: 0.0393 - val_loss: 0.0417 - learning_rate: 0.0010\n",
      "Epoch 574/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.0385\n",
      "Epoch 574: val_loss improved from 0.03770 to 0.03675, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 479ms/step - loss: 0.0385 - val_loss: 0.0367 - learning_rate: 0.0010\n",
      "Epoch 575/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 0.0382\n",
      "Epoch 575: val_loss did not improve from 0.03675\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - loss: 0.0382 - val_loss: 0.0371 - learning_rate: 0.0010\n",
      "Epoch 576/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - loss: 0.0378\n",
      "Epoch 576: val_loss did not improve from 0.03675\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428ms/step - loss: 0.0378 - val_loss: 0.0431 - learning_rate: 0.0010\n",
      "Epoch 577/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - loss: 0.0376\n",
      "Epoch 577: val_loss did not improve from 0.03675\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448ms/step - loss: 0.0376 - val_loss: 0.0437 - learning_rate: 0.0010\n",
      "Epoch 578/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - loss: 0.0380\n",
      "Epoch 578: val_loss did not improve from 0.03675\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - loss: 0.0380 - val_loss: 0.0423 - learning_rate: 0.0010\n",
      "Epoch 579/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - loss: 0.0382\n",
      "Epoch 579: val_loss did not improve from 0.03675\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step - loss: 0.0383 - val_loss: 0.0370 - learning_rate: 0.0010\n",
      "Epoch 580/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - loss: 0.0392\n",
      "Epoch 580: val_loss did not improve from 0.03675\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420ms/step - loss: 0.0394 - val_loss: 0.0425 - learning_rate: 0.0010\n",
      "Epoch 581/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.0409\n",
      "Epoch 581: val_loss did not improve from 0.03675\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - loss: 0.0407 - val_loss: 0.0399 - learning_rate: 0.0010\n",
      "Epoch 582/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - loss: 0.0397\n",
      "Epoch 582: val_loss improved from 0.03675 to 0.03496, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 469ms/step - loss: 0.0395 - val_loss: 0.0350 - learning_rate: 0.0010\n",
      "Epoch 583/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - loss: 0.0385\n",
      "Epoch 583: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423ms/step - loss: 0.0386 - val_loss: 0.0396 - learning_rate: 0.0010\n",
      "Epoch 584/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.0385\n",
      "Epoch 584: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - loss: 0.0385 - val_loss: 0.0400 - learning_rate: 0.0010\n",
      "Epoch 585/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - loss: 0.0377\n",
      "Epoch 585: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 463ms/step - loss: 0.0378 - val_loss: 0.0398 - learning_rate: 0.0010\n",
      "Epoch 586/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - loss: 0.0381\n",
      "Epoch 586: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426ms/step - loss: 0.0381 - val_loss: 0.0373 - learning_rate: 0.0010\n",
      "Epoch 587/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - loss: 0.0385\n",
      "Epoch 587: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step - loss: 0.0386 - val_loss: 0.0369 - learning_rate: 0.0010\n",
      "Epoch 588/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: 0.0376\n",
      "Epoch 588: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434ms/step - loss: 0.0377 - val_loss: 0.0459 - learning_rate: 0.0010\n",
      "Epoch 589/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.0390\n",
      "Epoch 589: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - loss: 0.0390 - val_loss: 0.0380 - learning_rate: 0.0010\n",
      "Epoch 590/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 0.0381\n",
      "Epoch 590: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step - loss: 0.0382 - val_loss: 0.0402 - learning_rate: 0.0010\n",
      "Epoch 591/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - loss: 0.0387\n",
      "Epoch 591: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - loss: 0.0387 - val_loss: 0.0396 - learning_rate: 0.0010\n",
      "Epoch 592/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - loss: 0.0384\n",
      "Epoch 592: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427ms/step - loss: 0.0383 - val_loss: 0.0433 - learning_rate: 0.0010\n",
      "Epoch 593/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 0.0372\n",
      "Epoch 593: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431ms/step - loss: 0.0372 - val_loss: 0.0356 - learning_rate: 0.0010\n",
      "Epoch 594/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - loss: 0.0371\n",
      "Epoch 594: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446ms/step - loss: 0.0373 - val_loss: 0.0371 - learning_rate: 0.0010\n",
      "Epoch 595/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - loss: 0.0370\n",
      "Epoch 595: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step - loss: 0.0371 - val_loss: 0.0366 - learning_rate: 0.0010\n",
      "Epoch 596/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - loss: 0.0364\n",
      "Epoch 596: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 517ms/step - loss: 0.0363 - val_loss: 0.0358 - learning_rate: 0.0010\n",
      "Epoch 597/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - loss: 0.0362\n",
      "Epoch 597: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 551ms/step - loss: 0.0362 - val_loss: 0.0421 - learning_rate: 0.0010\n",
      "Epoch 598/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - loss: 0.0368\n",
      "Epoch 598: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 559ms/step - loss: 0.0368 - val_loss: 0.0382 - learning_rate: 0.0010\n",
      "Epoch 599/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - loss: 0.0365\n",
      "Epoch 599: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 544ms/step - loss: 0.0365 - val_loss: 0.0377 - learning_rate: 0.0010\n",
      "Epoch 600/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - loss: 0.0363\n",
      "Epoch 600: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 559ms/step - loss: 0.0363 - val_loss: 0.0382 - learning_rate: 0.0010\n",
      "Epoch 601/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - loss: 0.0365\n",
      "Epoch 601: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 556ms/step - loss: 0.0364 - val_loss: 0.0392 - learning_rate: 0.0010\n",
      "Epoch 602/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - loss: 0.0354\n",
      "Epoch 602: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 553ms/step - loss: 0.0355 - val_loss: 0.0371 - learning_rate: 0.0010\n",
      "Epoch 603/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - loss: 0.0354\n",
      "Epoch 603: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 538ms/step - loss: 0.0355 - val_loss: 0.0368 - learning_rate: 0.0010\n",
      "Epoch 604/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - loss: 0.0354\n",
      "Epoch 604: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 571ms/step - loss: 0.0354 - val_loss: 0.0380 - learning_rate: 0.0010\n",
      "Epoch 605/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - loss: 0.0358\n",
      "Epoch 605: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 561ms/step - loss: 0.0358 - val_loss: 0.0350 - learning_rate: 0.0010\n",
      "Epoch 606/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - loss: 0.0353\n",
      "Epoch 606: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 511ms/step - loss: 0.0352 - val_loss: 0.0370 - learning_rate: 0.0010\n",
      "Epoch 607/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - loss: 0.0347\n",
      "Epoch 607: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 614ms/step - loss: 0.0348 - val_loss: 0.0393 - learning_rate: 0.0010\n",
      "Epoch 608/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - loss: 0.0351\n",
      "Epoch 608: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 580ms/step - loss: 0.0352 - val_loss: 0.0365 - learning_rate: 0.0010\n",
      "Epoch 609/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - loss: 0.0352\n",
      "Epoch 609: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 571ms/step - loss: 0.0352 - val_loss: 0.0352 - learning_rate: 0.0010\n",
      "Epoch 610/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - loss: 0.0345\n",
      "Epoch 610: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 567ms/step - loss: 0.0346 - val_loss: 0.0363 - learning_rate: 0.0010\n",
      "Epoch 611/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516ms/step - loss: 0.0351\n",
      "Epoch 611: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 611ms/step - loss: 0.0350 - val_loss: 0.0352 - learning_rate: 0.0010\n",
      "Epoch 612/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - loss: 0.0353\n",
      "Epoch 612: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 555ms/step - loss: 0.0352 - val_loss: 0.0361 - learning_rate: 0.0010\n",
      "Epoch 613/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - loss: 0.0354\n",
      "Epoch 613: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 519ms/step - loss: 0.0353 - val_loss: 0.0379 - learning_rate: 0.0010\n",
      "Epoch 614/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - loss: 0.0353\n",
      "Epoch 614: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 519ms/step - loss: 0.0354 - val_loss: 0.0352 - learning_rate: 0.0010\n",
      "Epoch 615/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - loss: 0.0355\n",
      "Epoch 615: val_loss did not improve from 0.03496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 555ms/step - loss: 0.0355 - val_loss: 0.0422 - learning_rate: 0.0010\n",
      "Epoch 616/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - loss: 0.0353\n",
      "Epoch 616: val_loss improved from 0.03496 to 0.03254, saving model to ./result_folder_no_misc_v4/lstm_ts_28.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 587ms/step - loss: 0.0354 - val_loss: 0.0325 - learning_rate: 0.0010\n",
      "Epoch 617/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - loss: 0.0354\n",
      "Epoch 617: val_loss did not improve from 0.03254\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 533ms/step - loss: 0.0355 - val_loss: 0.0336 - learning_rate: 0.0010\n",
      "Epoch 618/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - loss: 0.0358\n",
      "Epoch 618: val_loss did not improve from 0.03254\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step - loss: 0.0358 - val_loss: 0.0431 - learning_rate: 0.0010\n",
      "Epoch 619/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - loss: 0.0352\n",
      "Epoch 619: val_loss did not improve from 0.03254\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 536ms/step - loss: 0.0351 - val_loss: 0.0341 - learning_rate: 0.0010\n",
      "Epoch 620/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - loss: 0.0348\n",
      "Epoch 620: val_loss did not improve from 0.03254\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 549ms/step - loss: 0.0348 - val_loss: 0.0399 - learning_rate: 0.0010\n",
      "Epoch 621/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - loss: 0.0348\n",
      "Epoch 621: val_loss did not improve from 0.03254\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 544ms/step - loss: 0.0347 - val_loss: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 622/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - loss: 0.0343\n",
      "Epoch 622: val_loss did not improve from 0.03254\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 554ms/step - loss: 0.0344 - val_loss: 0.0355 - learning_rate: 0.0010\n",
      "Epoch 623/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - loss: 0.0342\n",
      "Epoch 623: val_loss did not improve from 0.03254\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 587ms/step - loss: 0.0342 - val_loss: 0.0387 - learning_rate: 0.0010\n",
      "Epoch 624/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - loss: 0.0341\n",
      "Epoch 624: val_loss did not improve from 0.03254\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 569ms/step - loss: 0.0341 - val_loss: 0.0348 - learning_rate: 0.0010\n",
      "Epoch 625/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - loss: 0.0341\n",
      "Epoch 625: val_loss did not improve from 0.03254\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - loss: 0.0341 - val_loss: 0.0395 - learning_rate: 0.0010\n",
      "Epoch 626/1000\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - loss: 0.0348"
     ]
    }
   ],
   "source": [
    "predictors_lst = ['EUA', 'Oil', 'Coal', 'Power', 'GDP']\n",
    "test_date = '2024-08-01'\n",
    "folder_name = \"result_folder_no_misc_v4\"\n",
    "modeltype='lstm'\n",
    "\n",
    "# save original EUA & date\n",
    "original_EUA = df_all['EUA'].values  \n",
    "dates = df_all['Date'].values\n",
    "\n",
    "for sequence_length in [28]:\n",
    "    last_train_date = pd.to_datetime(test_date) - pd.to_timedelta(1, unit = 'day')\n",
    "    X_train, y_train, X_test, y_test, scaler = curate_training_test_data(df_all, \n",
    "                                                                         flatten = False,\n",
    "                                                                         sequence_length=sequence_length,\n",
    "                                                                         test_date = test_date,\n",
    "                                                                         predictors_lst = predictors_lst )\n",
    "\n",
    "    checkpoint_path = f\"./{folder_name}/{modeltype}_ts_{sequence_length}.keras\"\n",
    "    model = generate_lstm(X_train, predictors_lst)\n",
    "    history = train_lstm(model, checkpoint_path, X_train, y_train)\n",
    "    # model.load_weights(checkpoint_path) \n",
    "\n",
    "    # plot loss curves \n",
    "    plt.plot(history.history['loss'], label='Training loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{folder_name}/{modeltype}_LossCurve_ts_{sequence_length}.pdf')\n",
    "    plt.close()\n",
    "\n",
    "    # accuracy plot\n",
    "    train_predictions = model.predict(X_train, verbose = 0);\n",
    "    train_predictions_rescaled = scaler.inverse_transform(train_predictions)\n",
    "    test_predictions = model.predict(X_test, verbose = 0);\n",
    "    test_predictions_rescaled = scaler.inverse_transform(test_predictions)\n",
    "\n",
    "    ground_truth_train = scaler.inverse_transform(y_train)\n",
    "    ground_truth_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "    plt.figure(figsize = (13,13))\n",
    "    for i, feature in enumerate(predictors_lst):\n",
    "        plt.subplot(len(predictors_lst)//3 + 1 if len(predictors_lst)%3 !=0 else len(predictors_lst)//3, 3, i+1)\n",
    "        plt.scatter(ground_truth_train[:,i],train_predictions_rescaled[:,i], label = 'train')\n",
    "        plt.scatter(ground_truth_test[:,i],test_predictions_rescaled[:,i], label = 'test')\n",
    "        plt.plot([min(ground_truth_train[:,i]), max(ground_truth_train[:,i])], \n",
    "                [min(ground_truth_train[:,i]), max(ground_truth_train[:,i])], color='red', label='1:1 Line')\n",
    "        \n",
    "        r2_train = r2_score(ground_truth_train[:,i],train_predictions_rescaled[:,i])\n",
    "        r2_test = r2_score(ground_truth_test[:,i],test_predictions_rescaled[:,i])\n",
    "        plt.title(f\"{feature} - train: {r2_train:.5f} / test: {r2_test:.5f}\")\n",
    "        plt.legend()\n",
    "        plt.grid('on')\n",
    "        plt.xlabel('ground truth')\n",
    "        plt.ylabel('prediction')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{folder_name}/{modeltype}_acc_ts_{sequence_length}.pdf')\n",
    "    plt.close()\n",
    "\n",
    "    # get RMSE:\n",
    "    rel_erorrs = []\n",
    "    for i in range(test_predictions_rescaled.shape[1]):\n",
    "        prediction = test_predictions[:, i]\n",
    "        ground_truth = y_test[:,i]\n",
    "        rel_error = np.mean(np.sqrt(((prediction-ground_truth)**2)))\n",
    "        print(predictors_lst[i])\n",
    "        print(rel_error)\n",
    "        rel_erorrs.append(rel_error)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    num_of_prediction = 30*6\n",
    "    corr = df_all[predictors_lst].corr()\n",
    "    for factor, num_ensemble in zip([0, 1.0], [2, 100]):\n",
    "        rel_erorrs_mat = np.array([rel_erorrs for i in range(num_ensemble)])\n",
    "        next_predictions = []\n",
    "        current_input = X_train[-1]\n",
    "        current_input = np.array([current_input for i in range(num_ensemble)]).squeeze()\n",
    "        for iter_ in tqdm(range(num_of_prediction)):\n",
    "            next_prediction = model.predict(current_input, verbose = 0)\n",
    "            error_p = generate_multivariate_samples(corr, n_samples=num_ensemble)\n",
    "            next_prediction = next_prediction * (1+error_p*rel_erorrs_mat*factor)\n",
    "            next_predictions.append(next_prediction)\n",
    "            current_input = np.concatenate([current_input, \n",
    "                                            np.expand_dims(next_prediction,1)], axis=1)\n",
    "        next_predictions = np.array(next_predictions)\n",
    "        future_dates = [last_train_date + pd.DateOffset(days=i + 1) for i in range(num_of_prediction)]\n",
    "        ensemble_future_predictions = np.array([scaler.inverse_transform(next_predictions[i]) for i in range(num_of_prediction)])\n",
    "\n",
    "\n",
    "        # Calculate mean, P10, and P90 of predictions\n",
    "        mean_predictions = ensemble_future_predictions[:, :, 0].mean(axis=1)\n",
    "        P50 = np.percentile(ensemble_future_predictions[:, :, 0], 50, axis=1)\n",
    "        P10 = np.percentile(ensemble_future_predictions[:, :, 0], 10, axis=1)\n",
    "        P90 = np.percentile(ensemble_future_predictions[:, :, 0], 90, axis=1)\n",
    "\n",
    "        # Create the plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Plot historical EUA prices\n",
    "        plt.plot(dates, original_EUA, label='Historical EUA Price', color='black')\n",
    "\n",
    "        # Plot all realizations\n",
    "        for realization in ensemble_future_predictions[:, :, 0].T:\n",
    "            plt.plot(future_dates, realization, color='gray', alpha=0.3)\n",
    "\n",
    "        # Plot P10 and P90 percentile predictions\n",
    "        plt.plot(future_dates, P10, label='P10 & P90', color='green', linestyle='-')\n",
    "        plt.plot(future_dates, P90, color='green', linestyle='-')\n",
    "        # Plot mean of future predictions\n",
    "        plt.plot(future_dates, P50, label='Median of Predictions', color='red')\n",
    "        plt.plot(df_all[df_all['Date']>test_date]['Date'],\n",
    "                    df_all[df_all['Date']>test_date]['EUA'],\n",
    "                    color = 'blue',\n",
    "                    label = 'Future EUA Price' \n",
    "                    )\n",
    "\n",
    "\n",
    "        # Customize the plot\n",
    "        plt.title('EUA Price Prediction for the Next 24 Months')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('EUA Price')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f\"{folder_name}/{modeltype}_timeplot_ts_{sequence_length}_factor_{str(factor).replace('.','_')}.pdf\")\n",
    "        plt.close()\n",
    "\n",
    "    record = {}\n",
    "    with open(f'{folder_name}/{modeltype}_record_ts_{sequence_length}.txt', 'w') as f:\n",
    "        # report metrics\n",
    "        for i, feature in enumerate(predictors_lst):\n",
    "            r2_train = r2_score(ground_truth_train[:,i],train_predictions_rescaled[:,i])\n",
    "            r2_test = r2_score(ground_truth_test[:,i],test_predictions_rescaled[:,i])\n",
    "            mse_train = mean_squared_error(ground_truth_train[:,i],train_predictions_rescaled[:,i])\n",
    "            mse_test  = mean_squared_error(ground_truth_test[:,i],test_predictions_rescaled[:,i])\n",
    "            mae_train = mean_absolute_error(ground_truth_train[:,i],train_predictions_rescaled[:,i])\n",
    "            mae_test  = mean_absolute_error(ground_truth_test[:,i],test_predictions_rescaled[:,i])\n",
    "            f.write(f'{feature}\\n')\n",
    "            f.write(f'r2(train): {r2_train}\\n')\n",
    "            f.write(f'r2(test): {r2_test}\\n')\n",
    "            f.write(f'mse(train): {mse_train}\\n')\n",
    "            f.write(f'mse(test): {mse_test}\\n')\n",
    "            f.write(f'mae(train): {mae_train}\\n')\n",
    "            f.write(f'mae(test): {mae_test}\\n')\n",
    "            f.write('---------------------------\\n')\n",
    "            record['feature'] = {\"r2_train\":r2_train, \n",
    "                                \"r2_test\": r2_test,\n",
    "                                \"mse_train\": mse_train, \n",
    "                                \"mse_test\": mse_test, \n",
    "                                \"mae_train\": mae_train, \n",
    "                                \"mae_test\": mae_test,}\n",
    "    # save metric as dictionary\n",
    "    with open(f'{folder_name}/{modeltype}_record_ts_{sequence_length}.pkl', 'wb') as f:\n",
    "        pickle.dump(record, f)\n",
    "    # Save the best model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create traces for each plot\n",
    "trace1 = go.Scatter(x=dates, y=original_EUA, mode='lines', name='Historical EUA Price', \n",
    "                    line=dict(color='blue'))\n",
    "\n",
    "trace2 = go.Scatter(x=future_dates, y=ensemble_future_predictions[0,:,0], mode='lines', \n",
    "                    name='Predicted EUA Price_1', \n",
    "                    line=dict(color='red'))\n",
    "\n",
    "trace3 = go.Scatter(x=future_dates, y=ensemble_future_predictions[1,:,0], mode='lines', \n",
    "                    name='Predicted EUA Price_2', \n",
    "                    line=dict(color='purple'))\n",
    "\n",
    "trace4 = go.Scatter(x=future_dates, y=ensemble_future_predictions[2,:,0], mode='lines', \n",
    "                    name='Predicted EUA Price_3', \n",
    "                    line=dict(color='orange'))\n",
    "\n",
    "trace5 = go.Scatter(x=train_dates[-train_predictions_rescaled.shape[0]:], \n",
    "                    y=train_predictions_rescaled[:, 0], mode='lines+markers', \n",
    "                    name='Train Predicted EUA Price', marker=dict(color='green', size=4), \n",
    "                    line=dict(color='green'))\n",
    "\n",
    "# Layout for the plot\n",
    "layout = go.Layout(\n",
    "    title='EUA Price Prediction for the Next 24 Months',\n",
    "    xaxis=dict(title='Date'),\n",
    "    yaxis=dict(title='EUA Price'),\n",
    "    legend=dict(x=0, y=1, traceorder='normal'),\n",
    "    height=600,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "# Create the figure with the traces\n",
    "fig = go.Figure(data=[trace1, trace2, trace3, trace4, trace5], layout=layout)\n",
    "\n",
    "# Show the figure (interactive plot)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(dates, original_EUA, 'b', label='Historical EUA Price')  # 원본 EUA 데이터\n",
    "# plt.plot(train_dates, scaler.inverse_transform(test_data_scaled)[:, 0], 'skyblue', label='Test EUA Price')  # 테스트 데이터\n",
    "plt.plot(future_dates, ensemble_future_predictions[0, :, 0].T, 'red', linewidth = 0.1, label = 'real_1')\n",
    "plt.plot(future_dates, ensemble_future_predictions[0, :, 0].T, 'purple', linewidth = 0.1, label = 'real_2')\n",
    "plt.plot(future_dates, ensemble_future_predictions[0, :, 0].T, 'yellow', linewidth = 0.1, label = 'real_3')\n",
    "plt.plot(train_dates[-train_predictions_rescaled.shape[0]:], train_predictions_rescaled[:, 0], 'g.', marker='.', markersize=2, label='Train Predicted EUA Price')\n",
    "\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('EUA Price')\n",
    "plt.title('EUA Price Prediction for the Next 24 Months')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
